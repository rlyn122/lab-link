Author,Title,Year,URL,Abstract
Eugene Agichtein,Studying the effectiveness of conversational search refinement through user simulation,2021,https://link.springer.com/chapter/10.1007/978-3-030-72113-8_39,"A key application of conversational search is refining a user’s search intent by asking a series of clarification questions, aiming to improve the relevance of search results. Training and evaluating such conversational systems currently requires human participation, making it unfeasible to examine a wide range of user behaviors. To support robust training/evaluation of such systems, we propose a simulation framework called CoSearcher (Information about code/resources available at                    https://github.com/alexandres/CoSearcher                                    .) that includes a parameterized user simulator controlling key behavioral factors like cooperativeness and patience. Using a standard conversational query clarification benchmark, we experiment with a range of user behaviors, semantic policies, and dynamic facet generation. Our results quantify the effects of user behaviors, and identify critical conditions …"
Eugene Agichtein,Rlirank: Learning to rank with reinforcement learning for dynamic search,2020,https://dl.acm.org/doi/abs/10.1145/3366423.3380047,"To support complex search tasks, where the initial information requirements are complex or may change during the search, a search engine must adapt the information delivery as the user’s information requirements evolve. To support this dynamic ranking paradigm effectively, search result ranking must incorporate both the user feedback received, and the information displayed so far. To address this problem, we introduce a novel reinforcement learning-based approach, RLIRank. We first build an adapted reinforcement learning framework to integrate the key components of the dynamic search. Then, we implement a new Learning to Rank (LTR) model for each iteration of the dynamic search, using a recurrent Long Short Term Memory neural network (LSTM), which estimates the gain for each next result, learning from each previously ranked document. To incorporate the user’s feedback, we develop a word …"
Eugene Agichtein,Identifying helpful sentences in product reviews,2021,https://arxiv.org/abs/2104.09792,"In recent years online shopping has gained momentum and became an important venue for customers wishing to save time and simplify their shopping process. A key advantage of shopping online is the ability to read what other customers are saying about products of interest. In this work, we aim to maintain this advantage in situations where extreme brevity is needed, for example, when shopping by voice. We suggest a novel task of extracting a single representative helpful sentence from a set of reviews for a given product. The selected sentence should meet two conditions: first, it should be helpful for a purchase decision and second, the opinion it expresses should be supported by multiple reviewers. This task is closely related to the task of Multi Document Summarization in the product reviews domain but differs in its objective and its level of conciseness. We collect a dataset in English of sentence helpfulness scores via crowd-sourcing and demonstrate its reliability despite the inherent subjectivity involved. Next, we describe a complete model that extracts representative helpful sentences with positive and negative sentiment towards the product and demonstrate that it outperforms several baselines."
Eugene Agichtein,Diversifying multi-aspect search results using Simpson's diversity index,2020,https://dl.acm.org/doi/abs/10.1145/3340531.3412163,"In search and recommendation, diversifying the multi-aspect search results could help with reducing redundancy, and promoting results that might not be shown otherwise. Many previous methods have been proposed for this task. However, previous methods do not explicitly consider the uniformity of the number of the items' classes, or evenness, which could degrade the search and recommendation quality. To address this problem, we introduce a novel method by adapting the Simpson's Diversity Index from biology, which enables a more effective and efficient quadratic search result diversification algorithm. We also extend the method to balance the diversity between multiple aspects through weighted factors and further improve computational complexity by developing a fast approximation algorithm. We demonstrate the feasibility of the proposed method using the openly available Kaggle shoes competition …"
Eugene Agichtein,Wizard of tasks: A novel conversational dataset for solving real-world tasks in conversational settings,2022,https://aclanthology.org/2022.coling-1.310/,"Conversational Task Assistants (CTAs) are conversational agents whose goal is to help humans perform real-world tasks. CTAs can help in exploring available tasks, answering task-specific questions and guiding users through step-by-step instructions. In this work, we present Wizard of Tasks, the first corpus of such conversations in two domains: Cooking and Home Improvement. We crowd-sourced a total of 549 conversations (18,077 utterances) with an asynchronous Wizard-of-Oz setup, relying on recipes from WholeFoods Market for the cooking domain, and WikiHow articles for the home improvement domain. We present a detailed data analysis and show that the collected data can be a valuable and challenging resource for CTAs in two tasks: Intent Classification (IC) and Abstractive Question Answering (AQA). While on IC we acquired a high performing model (> 85% F1), on AQA the performance is far from being satisfactory (~ 27% BertScore-F1), suggesting that more work is needed to solve the task of low-resource AQA."
Eugene Agichtein,Domain-guided task decomposition with self-training for detecting personal events in social media,2020,https://dl.acm.org/doi/abs/10.1145/3366423.3380304,"Mining social media content for tasks such as detecting personal experiences or events, suffer from lexical sparsity, insufficient training data, and inventive lexicons. To reduce the burden of creating extensive labeled data and improve classification performance, we propose to perform these tasks in two steps: 1. Decomposing the task into domain-specific sub-tasks by identifying key concepts, thus utilizing human domain understanding; and 2. Combining the results of learners for each key concept using co-training to reduce the requirements for labeled training data. We empirically show the effectiveness and generality of our approach, Co-Decomp, using three representative social media mining tasks, namely Personal Health Mention detection, Crisis Report detection, and Adverse Drug Reaction monitoring. The experiments show that our model is able to outperform the state-of-the-art text classification models …"
Eugene Agichtein,Genqrensemble: Zero-shot llm ensemble prompting for generative query reformulation,2024,https://link.springer.com/chapter/10.1007/978-3-031-56063-7_24,"Query Reformulation(QR) is a set of techniques used to transform a user’s original search query to a text that better aligns with the user’s intent and improves their search experience. Recently, zero-shot QR has been shown to be a promising approach due to its ability to exploit knowledge inherent in large language models. By taking inspiration from the success of ensemble prompting strategies which have benefited many tasks, we investigate if they can help improve query reformulation. In this context, we propose an ensemble based prompting technique, GenQREnsemble which leverages paraphrases of a zero-shot instruction to generate multiple sets of keywords ultimately improving retrieval performance. We further introduce its post-retrieval variant, GenQREnsembleRF to incorporate pseudo relevant feedback. On evaluations over four IR benchmarks, we find that GenQREnsemble generates better …"
Eugene Agichtein,"Alexa, let's work together: Introducing the first alexa prize taskbot challenge on conversational task assistance",2022,https://arxiv.org/abs/2209.06321,"Since its inception in 2016, the Alexa Prize program has enabled hundreds of university students to explore and compete to develop conversational agents through the SocialBot Grand Challenge. The goal of the challenge is to build agents capable of conversing coherently and engagingly with humans on popular topics for 20 minutes, while achieving an average rating of at least 4.0/5.0. However, as conversational agents attempt to assist users with increasingly complex tasks, new conversational AI techniques and evaluation platforms are needed. The Alexa Prize TaskBot challenge, established in 2021, builds on the success of the SocialBot challenge by introducing the requirements of interactively assisting humans with real-world Cooking and Do-It-Yourself tasks, while making use of both voice and visual modalities. This challenge requires the TaskBots to identify and understand the user's need, identify and integrate task and domain knowledge into the interaction, and develop new ways of engaging the user without distracting them from the task at hand, among other challenges. This paper provides an overview of the TaskBot challenge, describes the infrastructure support provided to the teams with the CoBot Toolkit, and summarizes the approaches the participating teams took to overcome the research challenges. Finally, it analyzes the performance of the competing TaskBots during the first year of the competition."
Eugene Agichtein,Jointmap: joint query intent understanding for modeling intent hierarchies in e-commerce search,2020,https://dl.acm.org/doi/abs/10.1145/3397271.3401184,"An accurate understanding of a user's query intent can help improve the performance of downstream tasks such as query scoping and ranking. In the e-commerce domain, recent work in query understanding focuses on the query to product-category mapping. But, a small yet significant percentage of queries (in our website 1.5% or 33M queries in 2019) have non-commercial intent associated with them. These intents are usually associated with non-commercial information seeking needs such as discounts, store hours, installation guides, etc. In this paper, we introduce Joint Query Intent Understanding (JointMap), a deep learning model to simultaneously learn two different high-level user intent tasks: 1) identifying a query's commercial vs. non-commercial intent, and 2) associating a set of relevant product categories in taxonomy to a product query. JointMap model works by leveraging the transfer bias that exists …"
Eugene Agichtein,Semantic product search for matching structured product catalogs in e-commerce,2020,https://arxiv.org/abs/2008.08180,"Retrieving all semantically relevant products from the product catalog is an important problem in E-commerce. Compared to web documents, product catalogs are more structured and sparse due to multi-instance fields that encode heterogeneous aspects of products (e.g. brand name and product dimensions). In this paper, we propose a new semantic product search algorithm that learns to represent and aggregate multi-instance fields into a document representation using state of the art transformers as encoders. Our experiments investigate two aspects of the proposed approach: (1) effectiveness of field representations and structured matching; (2) effectiveness of adding lexical features to semantic search. After training our models using user click logs from a well-known E-commerce platform, we show that our results provide useful insights for improving product search. Lastly, we present a detailed error analysis to show which types of queries benefited the most by fielded representations and structured matching."
Eugene Agichtein,CoSearcher: studying the effectiveness of conversational search refinement and clarification through user simulation,2022,https://link.springer.com/article/10.1007/s10791-022-09404-z,"A key application of conversational search is refining a user’s search intent by asking a series of clarification questions, aiming to improve the relevance of search results. Training and evaluating such conversational systems currently requires human participation, making it infeasible to examine a wide range of user behaviors. To support robust training/evaluation of such systems, we propose a simulation framework called CoSearcher Information about code/resources available at https://github.com/amzn/cosearcher that includes a parameterized user simulator controlling key behavioral factors like cooperativeness and patience. To evaluate our approach, we use both a standard conversational query clarification benchmark and develop an extended dataset using query suggestions from a popular Web search engine as a source of additional refinement candidates. Using these datasets, we investigate the impact …"
Eugene Agichtein,De-biased modeling of search click behavior with reinforcement learning,2021,https://dl.acm.org/doi/abs/10.1145/3404835.3463228,"Users' clicks on Web search results are one of the key signals for evaluating and improving web search quality and have been widely used as part of current state-of-the-art Learning-To-Rank(LTR) models. With a large volume of search logs available for major search engines, effective models of searcher click behavior have emerged to evaluate and train LTR models. However, when modeling the users' click behavior, considering the bias of the behavior is imperative. In particular, when a search result is not clicked, it is not necessarily chosen as not relevant by the user, but instead could have been simply missed, especially for lower-ranked results. These kinds of biases in the click log data can be incorporated into the click models, propagating the errors to the resulting LTR ranking models or evaluation metrics. In this paper, we propose the De-biased Reinforcement Learning Click model (DRLC). The DRLC …"
Eugene Agichtein,Would You Like to Hear the News? Investigating Voice-Based Suggestions for Conversational News Recommendation,2020,https://dl.acm.org/doi/abs/10.1145/3343413.3378013,"One of the key benefits of voice-based personal assistants is the potential to proactively recommend relevant and interesting information. One of the most valuable sources of such information is the News. However, in order for the user to hear the news that is useful and relevant to them, it must be recommended in an interesting and informative way. However, to the best of our knowledge, \em how to present a news item for a voice-based recommendation remains an open question. In this paper, we empirically compare different ways of recommending news, or specific news items, in a voice-based conversational setting. Specifically, we study the user engagement and satisfaction with five different variants of presenting news recommendations: (1) a generic news briefing; (2) news about a specific entity relevant to the current conversation; (3) news about an entity from a past conversation; (4) news on a trending …"
Eugene Agichtein,An interactive query generation assistant using llm-based prompt modification and user feedback,2023,https://arxiv.org/abs/2311.11226,"While search is the predominant method of accessing information, formulating effective queries remains a challenging task, especially for situations where the users are not familiar with a domain, or searching for documents in other languages, or looking for complex information such as events, which are not easily expressible as queries. Providing example documents or passages of interest, might be easier for a user, however, such query-by-example scenarios are prone to concept drift, and are highly sensitive to the query generation method. This demo illustrates complementary approaches of using LLMs interactively, assisting and enabling the user to provide edits and feedback at all stages of the query formulation process. The proposed Query Generation Assistant is a novel search interface which supports automatic and interactive query generation over a mono-linguial or multi-lingual document collection. Specifically, the proposed assistive interface enables the users to refine the queries generated by different LLMs, to provide feedback on the retrieved documents or passages, and is able to incorporate the users' feedback as prompts to generate more effective queries. The proposed interface is a valuable experimental tool for exploring fine-tuning and prompting of LLMs for query generation to qualitatively evaluate the effectiveness of retrieval and ranking models, and for conducting Human-in-the-Loop (HITL) experiments for complex search tasks where users struggle to formulate queries without such assistance."
Eugene Agichtein,Generating explainable product comparisons for online shopping,2023,https://dl.acm.org/doi/abs/10.1145/3539597.3570489,"An essential part of making shopping purchase decisions is to compare and contrast products based on key differentiating features, but doing this manually can be overwhelming. Prior methods offer limited product comparison capabilities, e.g., via pre-defined common attributes that may be difficult to understand, or irrelevant to a particular product or user. Automatically generating an informative, natural-sounding, and factually consistent comparative text for multiple product and attribute types is a challenging research problem. We describe HCPC (Human Centered Product Comparison), to tackle two kinds of comparisons for online shopping: (i) product-specific, to describe and compare products based on their key attributes; and (ii) attribute-specific comparisons, to compare similar products on a specific attribute. To ensure that comparison text is faithful to the input product data, we introduce a novel multi-decoder …"
Eugene Agichtein,Would you like to talk about sports now? towards contextual topic suggestion for open-domain conversational agents,2020,https://dl.acm.org/doi/abs/10.1145/3343413.3377974,"To hold a true conversation, an intelligent agent should be able to occasionally take initiative and recommend the next natural conversation topic. This is a challenging task. A topic suggested by the agent should be relevant to the person, appropriate for the conversation context, and the agent should have something interesting to say about it. Thus, a scripted, or one-size-fits-all, popularity-based topic suggestion is doomed to fail. Instead, we explore different methods for a personalized, contextual topic suggestion for open-domain conversations. We formalize the Conversational Topic Suggestion problem (CTS) to more clearly identify the assumptions and requirements. We also explore three possible approaches to solve this problem: (1) model-based sequential topic suggestion to capture the conversation context (CTS-Seq), (2) Collaborative Filtering-based suggestion to capture previous successful …"
Eugene Agichtein,ConvERSe'20: the WSDM 2020 workshop on conversational systems for e-commerce recommendations and search,2020,https://dl.acm.org/doi/abs/10.1145/3336191.3371882,"Conversational systems have improved dramatically recently, and are receiving increasing attention in academic literature. These systems are also becoming adapted in E-Commerce due to increased integration of E-Commerce search and recommendation source with virtual assistants such as Alexa, Siri, and Google assistant. However, significant research challenges remain spanning areas of dialogue systems, spoken natural language processing, human-computer interaction, and search and recommender systems, which all are exacerbated with demanding requirements of E-Commerce.The purpose of this workshop is to bring together researchers and practitioners in the areas of conversational systems, human-computer interaction, information retrieval, and recommender systems. Bringing diverse research areas together into a single workshop would accelerate progress on adapting conversation systems …"
Eugene Agichtein,Quantifying the effects of prosody modulation on user engagement and satisfaction in conversational systems,2020,https://dl.acm.org/doi/abs/10.1145/3343413.3378009,"As voice-based assistants such as Alexa, Siri, and Google Assistant become ubiquitous, users increasingly expect to maintain natural and informative conversations with such systems. However, for an open-domain conversational system to be coherent and engaging, it must be able to maintain the user's interest for extended periods, without sounding ""boring"" or ""annoying"". In this paper, we investigate one natural approach to this problem of modulating response prosody, i.e., changing the pitch and cadence of the response to indicate delight, sadness or other common emotions, as well as using pre-recorded interjections. Intuitively, this approach should improve the naturalness of the conversation, but attempts to quantify the effects of prosodic modulation on user satisfaction and engagement remain challenging. To accomplish this, we report results obtained from a large-scale empirical study that measures the …"
Eugene Agichtein,Advancing conversational task assistance: the second Alexa Prize TaskBot challenge,2023,https://www.amazon.science/alexa-prize/proceedings/alexa-lets-work-together-introducing-the-second-alexa-prize-taskbot-challenge,"Since its inception in 2016, the Alexa Prize program has enabled hundreds of university students and faculty to explore and compete in the development of conversational agents through the SocialBot Grand Challenge, whose goal is to build agents capable of conversing coherently and engagingly with humans on popular topics. As conversational agents attempt to assist users with increasingly complex tasks, new conversational AI techniques and evaluation platforms are needed. The Alexa Prize TaskBot Challenge, now in its second year, introduced the requirements of interactively assisting humans with real-world tasks, while making use of both voice and visual modalities. This challenge requires the TaskBots to identify and understand the user’s need, identify and integrate task and domain knowledge into the interaction, and develop new ways of engaging the user without distracting them from the task at hand, among other challenges. This paper provides an overview of the second TaskBot challenge, in which both new and returning teams participated. We describe the infrastructure support and the new models provided to the teams with the CoBot Toolkit. We then summarize the approaches the participating teams took to address research challenges, including changes and improvements from the previous year. Finally, we analyze the performance of the competing TaskBots and discuss some of the lessons learned."
Eugene Agichtein,Learning to enrich query representation with pseudo-relevance feedback for cross-lingual retrieval,2022,https://dl.acm.org/doi/abs/10.1145/3477495.3532013,"Cross-lingual information retrieval (CLIR) aims to provide access to information across languages. Recent pre-trained multilingual language models brought large improvements to the natural language tasks, including cross-lingual adhoc retrieval. However, pseudo-relevance feedback (PRF), a family of techniques for improving ranking using the contents of top initially retrieved items, has not been explored with neural CLIR retrieval models. Two of the challenges are incorporating feedback from long documents, and cross-language knowledge transfer. To address these challenges, we propose a novel neural CLIR architecture, NCLPRF, capable of incorporating PRF feedback from multiple potentially long documents, which enables improvements to query representation in the shared semantic space between query and document languages. The additional information that the feedback documents provide in a …"
Eugene Agichtein,"Generative query reformulation using ensemble prompting, document fusion, and relevance feedback",2024,https://arxiv.org/abs/2405.17658,"Query Reformulation (QR) is a set of techniques used to transform a user's original search query to a text that better aligns with the user's intent and improves their search experience. Recently, zero-shot QR has been a promising approach due to its ability to exploit knowledge inherent in large language models. Inspired by the success of ensemble prompting strategies which have benefited other tasks, we investigate if they can improve query reformulation. In this context, we propose two ensemble-based prompting techniques, GenQREnsemble and GenQRFusion which leverage paraphrases of a zero-shot instruction to generate multiple sets of keywords to improve retrieval performance ultimately. We further introduce their post-retrieval variants to incorporate relevance feedback from a variety of sources, including an oracle simulating a human user and a ""critic"" LLM. We demonstrate that an ensemble of query reformulations can improve retrieval effectiveness by up to 18% on nDCG@10 in pre-retrieval settings and 9% on post-retrieval settings on multiple benchmarks, outperforming all previously reported SOTA results. We perform subsequent analyses to investigate the effects of feedback documents, incorporate domain-specific instructions, filter reformulations, and generate fluent reformulations that might be more beneficial to human searchers. Together, the techniques and the results presented in this paper establish a new state of the art in automated query reformulation for retrieval and suggest promising directions for future research."
Eugene Agichtein,What matters for shoppers: Investigating key attributes for online product comparison,2022,https://link.springer.com/chapter/10.1007/978-3-030-99739-7_27,"Before making high-consideration purchase decisions, shoppers generally need to identify and evaluate products’ key differentiating features or attributes. Many customers, however, lack the knowledge required to do so for all product domains. In this work, we investigate and analyze alternatives for identifying important product attributes, which customers can then use to compare candidate products. We propose an unsupervised attribute-ranking approach ReBARC, that combines both objective data from structured product catalogs, and subjective information from unstructured customer reviews, to suggest to the shopper the most important attributes to consider. Our detailed analysis of product attribute importance across various domains on a shopping website shows that ReBARC significantly outperforms prior efforts judged by both automated and human evaluation metrics. We also analyze the correlation and …"
Eugene Agichtein,Deepcat: Deep category representation for query understanding in e-commerce search,2021,https://arxiv.org/abs/2104.11760,"Mapping a search query to a set of relevant categories in the product taxonomy is a significant challenge in e-commerce search for two reasons: 1) Training data exhibits severe class imbalance problem due to biased click behavior, and 2) queries with little customer feedback (e.g., tail queries) are not well-represented in the training set, and cause difficulties for query understanding. To address these problems, we propose a deep learning model, DeepCAT, which learns joint word-category representations to enhance the query understanding process. We believe learning category interactions helps to improve the performance of category mapping on minority classes, tail and torso queries. DeepCAT contains a novel word-category representation model that trains the category representations based on word-category co-occurrences in the training set. The category representation is then leveraged to introduce a new loss function to estimate the category-category co-occurrences for refining joint word-category embeddings. To demonstrate our model's effectiveness on minority categories and tail queries, we conduct two sets of experiments. The results show that DeepCAT reaches a 10% improvement on minority classes and a 7.1% improvement on tail queries over a state-of-the-art label embedding model. Our findings suggest a promising direction for improving e-commerce search by semantic modeling of taxonomy hierarchies."
Eugene Agichtein,Searching for products in virtual reality: Understanding the impact of context and result presentation on user experience,2023,https://dl.acm.org/doi/abs/10.1145/3539618.3592057,"Immersive technologies such as virtual reality (VR) and head-mounted displays (HMD) have seen increased adoption in recent years. In this work, we study two factors that influence users' experience when shopping in VR through voice queries: (1) context alignment of the search environment and (2) the level of detail on the Search Engine Results Page (SERP). To this end, we developed a search system for VR and conducted a within-subject exploratory study (N=18) to understand the impact of the two experimental conditions. Our results suggest that both context alignment and SERP are important factors for information-seeking in VR, which present unique opportunities and challenges. More specifically, based on our findings, we suggest that search systems for VR must be able to: (1) provide cues for information-seeking in both the VR environment and SERP, (2) distribute attention between the VR …"
Eugene Agichtein,Augmenting graph convolutional networks with textual data for recommendations,2023,https://link.springer.com/chapter/10.1007/978-3-031-28238-6_58,"Graph Convolutional Networks have recently shown state-of-the-art performance for collaborative filtering-based recommender systems. However, many systems use a pure user-item bipartite interaction graph, ignoring available additional information about the items and users. This paper proposes an effective and general method, TextGCN, that utilizes rich textual information about the graph nodes, specifically user reviews and item descriptions, using pre-trained text embeddings. We integrate those reviews and descriptions into item recommendations to augment graph embeddings obtained using LightGCN, a SOTA graph network. Our model achieves a 7–23% statistically significant improvement over this SOTA baseline when evaluated on several diverse large-scale review datasets. Furthermore, our method captures semantic signals from the text, which are not available when using graph connections alone."
Eugene Agichtein,Generating and validating contextually relevant justifications for conversational recommendation,2022,https://dl.acm.org/doi/abs/10.1145/3498366.3505789," Providing a justification or explanation for a recommendation has been shown to improve the users’ experience with recommender systems, in particular by increasing confidence in the recommendations. However, in order to be effective in a conversational setting, the justifications have to be appropriate for the conversation so far. Previous approaches rely on a user history of reviews and ratings of related items to personalize the recommendation, but this information is not generally available when conversing with a new user, and as such a cold-start problem imposes a challenge in generating suitable justifications. To address this problem, we propose and validate a new method, CONJURE (CONversational JUstificatons for REcommendations) to generate contextually relevant justifications for conversational recommendations. Specifically, we investigate whether the conversation itself can be used effectively to …"
Eugene Agichtein,You sound like someone who watches drama movies: Towards predicting movie preferences from conversational interactions,2021,https://aclanthology.org/2021.naacl-main.246/,"The increasing popularity of voice-based personal assistants provides new opportunities for conversational recommendation. One particularly interesting area is movie recommendation, which can benefit from an open-ended interaction with the user, through a natural conversation. We explore one promising direction for conversational recommendation: mapping a conversational user, for whom there is limited or no data available, to most similar external reviewers, whose preferences are known, by representing the conversation as a user’s interest vector, and adapting collaborative filtering techniques to estimate the current user’s preferences for new movies. We call our proposed method ConvExtr (Conversational Collaborative Filtering using External Data), which 1) infers a user’s sentiment towards an entity from the conversation context, and 2) transforms the ratings of “similar” external reviewers to predict the current user’s preferences. We implement these steps by adapting contextual sentiment prediction techniques, and domain adaptation, respectively. To evaluate our method, we develop and make available a finely annotated dataset of movie recommendation conversations, which we call MovieSent. Our results demonstrate that ConvExtr can improve the accuracy of predicting users’ ratings for new movies by exploiting conversation content and external data."
Eugene Agichtein,QueryExplorer: An Interactive Query Generation Assistant for Search and Exploration,2024,https://arxiv.org/abs/2403.15667,"Formulating effective search queries remains a challenging task, particularly when users lack expertise in a specific domain or are not proficient in the language of the content. Providing example documents of interest might be easier for a user. However, such query-by-example scenarios are prone to concept drift, and the retrieval effectiveness is highly sensitive to the query generation method, without a clear way to incorporate user feedback. To enable exploration and to support Human-In-The-Loop experiments we propose QueryExplorer -- an interactive query generation, reformulation, and retrieval interface with support for HuggingFace generation models and PyTerrier's retrieval pipelines and datasets, and extensive logging of human feedback. To allow users to create and modify effective queries, our demo supports complementary approaches of using LLMs interactively, assisting the user with edits and feedback at multiple stages of the query formulation process. With support for recording fine-grained interactions and user annotations, QueryExplorer can serve as a valuable experimental and research platform for annotation, qualitative evaluation, and conducting Human-in-the-Loop (HITL) experiments for complex search tasks where users struggle to formulate queries."
Eugene Agichtein,Contextual Response Interpretation for Automated Structured Interviews: A Case Study in Market Research,2023,https://dl.acm.org/doi/abs/10.1145/3543873.3587657," Structured interviews are used in many settings, importantly in market research on topics such as brand perception, customer habits, or preferences, which are critical to product development, marketing, and e-commerce at large. Such interviews generally consist of a series of questions that are asked to a participant. These interviews are typically conducted by skilled interviewers, who interpret the responses from the participants and can adapt the interview accordingly. Using automated conversational agents to conduct such interviews would enable reaching a much larger and potentially more diverse group of participants than currently possible. However, the technical challenges involved in building such a conversational system are relatively unexplored. To learn more about these challenges, we convert a market research multiple-choice questionnaire to a conversational format and conduct a user study. We …"
Eugene Agichtein,VoiSeR: A new benchmark for voice-based search refinement,2021,https://aclanthology.org/2021.eacl-main.197/,"Voice assistants, eg, Alexa or Google Assistant, have dramatically improved in recent years. Supporting voice-based search, exploration, and refinement are fundamental tasks for voice assistants, and remain an open challenge. For example, when using voice to search an online shopping site, a user often needs to refine their search by some aspect or facet. This common user intent is usually available through a “filter-by” interface on online shopping websites, but is challenging to support naturally via voice, as the intent of refinements must be interpreted in the context of the original search, the initial results, and the available product catalogue facets. To our knowledge, no benchmark dataset exists for training or validating such contextual search understanding models. To bridge this gap, we introduce the first large-scale dataset of voice-based search refinements, VoiSeR, consisting of about 10,000 search refinement utterances, collected using a novel crowdsourcing task. These utterances are intended to refine a previous search, with respect to a search facet or attribute (eg, brand, color, review rating, etc.), and are manually annotated with the specific intent. This paper reports qualitative and empirical insights into the most common and challenging types of refinements that a voice-based conversational search system must support. As we show, VoiSeR can support research in conversational query understanding, contextual user intent prediction, and other conversational search topics to facilitate the development of conversational search systems."
Eugene Agichtein,ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges,2024,https://arxiv.org/abs/2412.05206,"Computational argumentation, which involves generating answers or summaries for controversial topics like abortion bans and vaccination, has become increasingly important in today's polarized environment. Sophisticated LLM capabilities offer the potential to provide nuanced, evidence-based answers to such questions through Retrieval-Augmented Argumentation (RAArg), leveraging real-world evidence for high-quality, grounded arguments. However, evaluating RAArg remains challenging, as human evaluation is costly and difficult for complex, lengthy answers on complicated topics. At the same time, re-using existing argumentation datasets is no longer sufficient, as they lack long, complex arguments and realistic evidence from potentially misleading sources, limiting holistic evaluation of retrieval effectiveness and argument quality. To address these gaps, we investigate automated evaluation methods using multiple fine-grained LLM judges, providing better and more interpretable assessments than traditional single-score metrics and even previously reported human crowdsourcing. To validate the proposed techniques, we introduce ConQRet, a new benchmark featuring long and complex human-authored arguments on debated topics, grounded in real-world websites, allowing an exhaustive evaluation across retrieval effectiveness, argument quality, and groundedness. We validate our LLM Judges on a prior dataset and the new ConQRet benchmark. Our proposed LLM Judges and the ConQRet benchmark can enable rapid progress in computational argumentation and can be naturally extended to other complex retrieval-augmented …"
Eugene Agichtein,DUQGen: Effective unsupervised domain adaptation of neural rankers by diversifying synthetic query generation,2024,https://arxiv.org/abs/2404.02489,"State-of-the-art neural rankers pre-trained on large task-specific training data such as MS-MARCO, have been shown to exhibit strong performance on various ranking tasks without domain adaptation, also called zero-shot. However, zero-shot neural ranking may be sub-optimal, as it does not take advantage of the target domain information. Unfortunately, acquiring sufficiently large and high quality target training data to improve a modern neural ranker can be costly and time-consuming. To address this problem, we propose a new approach to unsupervised domain adaptation for ranking, DUQGen, which addresses a critical gap in prior literature, namely how to automatically generate both effective and diverse synthetic training data to fine tune a modern neural ranker for a new domain. Specifically, DUQGen produces a more effective representation of the target domain by identifying clusters of similar documents; and generates a more diverse training dataset by probabilistic sampling over the resulting document clusters. Our extensive experiments, over the standard BEIR collection, demonstrate that DUQGen consistently outperforms all zero-shot baselines and substantially outperforms the SOTA baselines on 16 out of 18 datasets, for an average of 4% relative improvement across all datasets. We complement our results with a thorough analysis for more in-depth understanding of the proposed method's performance and to identify promising areas for further improvements."
Eugene Agichtein,Graph Neural Network Modeling of Web Search Activity for Real-time Pandemic Forecasting,2023,https://ieeexplore.ieee.org/abstract/document/10337253/,"The utilization of web search activity for pandemic forecasting has significant implications for managing disease spread and informing policy decisions. However, web search records tend to be noisy and influenced by geographical location, making it difficult to develop large-scale models. While regularized linear models have been effective in predicting the spread of respiratory illnesses like COVID-19, they are limited to specific locations. The lack of incorporation of neighboring areas’ data and the inability to transfer models to new locations with limited data has impeded further progress.To address these limitations, this study proposes a novel self-supervised message-passing neural network (SMPNN) framework for modeling local and cross-location dynamics in pandemic forecasting. The SMPNN framework utilizes an MPNN module to learn cross-location dependencies through self-supervised learning and …"
Eugene Agichtein,Detecting elevated air pollution levels by monitoring web search queries: Algorithm development and validation,2022,https://formative.jmir.org/2022/12/e23422/,"Background: Real-time air pollution monitoring is a valuable tool for public health and environmental surveillance. In recent years, there has been a dramatic increase in air pollution forecasting and monitoring research using artificial neural networks. Most prior work relied on modeling pollutant concentrations collected from ground-based monitors and meteorological data for long-term forecasting of outdoor ozone (O 3), oxides of nitrogen, and fine particulate matter (PM 2.5). Given that traditional, highly sophisticated air quality monitors are expensive and not universally available, these models cannot adequately serve those not living near pollutant monitoring sites. Furthermore, because prior models were built based on physical measurement data collected from sensors, they may not be suitable for predicting the public health effects of pollution exposure.Objective: This study aimed to develop and validate models to nowcast the observed pollution levels using web search data, which are publicly available in near real time from major search engines.Methods: We developed novel machine learning–based models using both traditional supervised classification methods and state-of-the-art deep learning methods to detect elevated air pollution levels at the US city level by using generally available meteorological data and aggregate web-based search volume data derived from Google Trends. We validated the performance of these methods by predicting 3 critical air pollutants (O 3, nitrogen dioxide, and PM 2.5) across 10 major US metropolitan statistical areas in 2017 and 2018. We also explore different variations of the long short-term memory …"
Eugene Agichtein,Making Large Language Models Interactive: A Pioneer Study on Supporting Complex Information-Seeking Tasks with Implicit Constraints,2022,https://arxiv.org/abs/2205.00584,"Current interactive systems with natural language interfaces lack the ability to understand a complex information-seeking request which expresses several implicit constraints at once, and there is no prior information about user preferences e.g.,""find hiking trails around San Francisco which are accessible with toddlers and have beautiful scenery in summer"", where output is a list of possible suggestions for users to start their exploration. In such scenarios, user requests can be issued in one shot in the form of a complex and long query, unlike conversational and exploratory search models, where require short utterances or queries are often presented to the system step by step. We have designed and deployed a platform to collect the data from approaching such complex interactive systems. Moreover, despite with the current advancement of generative language models these models suffer from hallucination in providing accurate factual knowledge. All language models are mostly trained in large part on web-scraped data from the past, which usually is not useful for immediate users' needs. In this article, we propose an IA that leverages Large Language Models (LLM) for complex request understanding and makes it interactive using Reinforcement learning that allows intricately refine user requests by making them complete, leading to better retrieval and reduce LLMs hallucination problems for current user needs. To demonstrate the performance of the proposed modeling paradigm, we have adopted various pre-retrieval metrics that capture the extent to which guided interactions with our system yield better retrieval results. Through extensive …"
Eugene Agichtein,Alexa Prize TaskBot Challenge,2022,https://www.amazon.science/alexa-prize/proceedings/alexa-prize-taskbot-challenge?0000017e-8b12-dcf6-a9fe-ff93c16f0001-page=2,"As people learn to interact with AI assistants such as Alexa, their needs change and become more complex. Alexa must evolve accordingly, and offer more sophisticated experiences, which require addressing increasingly complex AI research challenges. In the last few years, Amazon has offered university teams a chance to partner with Amazon scientists in order push the boundaries of the state of the art in conversational AI via the Alexa Prize challenge. This competition gives a framework for selected student teams to build agents, or “bots”, served by Alexa, which can converse with real Alexa users."
Eugene Agichtein,Cross-modal Memory Fusion Network for Multimodal Sequential Learning with Missing Values,2021,https://link.springer.com/chapter/10.1007/978-3-030-72240-1_30,"Information in many real-world applications is inherently multi-modal, sequential and characterized by a variety of missing values. Existing imputation methods mainly focus on the recurrent dynamics in one modality while ignoring the complementary property from other modalities. In this paper, we propose a novel method called cross-modal memory fusion network (CMFN) that explicitly learns both modal-specific and cross-modal dynamics for imputing the missing values in multi-modal sequential learning tasks. Experiments on two datasets demonstrate that our method outperforms state-of-the-art methods and show its potential to better impute missing values in complex multi-modal datasets."
Eugene Agichtein,EM_Mixers at MEDIQA-CORR 2024: Knowledge-Enhanced Few-Shot In-Context Learning for Medical Error Detection and Correction,2024,https://aclanthology.org/2024.clinicalnlp-1.56/,"This paper describes our submission to MEDIQA-CORR 2024 shared task for automatic identification and correction of medical errors in a given clinical text. We report results from two approaches: the first uses a few-shot in-context learning (ICL) with a Large Language Model (LLM) and the second approach extends the idea by using a knowledge-enhanced few-shot ICL approach. We used Azure OpenAI GPT-4 API as the LLM and Wikipedia as the external knowledge source. We report evaluation metrics (accuracy, ROUGE, BERTScore, BLEURT) across both approaches for validation and test datasets. Of the two approaches implemented, our experimental results show that the knowledge-enhanced few-shot ICL approach with GPT-4 performed better with error flag (subtask A) and error sentence detection (subtask B) with accuracies of 68% and 64%, respectively on the test dataset. These results positioned us fourth in subtask A and second in subtask B, respectively in the shared task."
Eugene Agichtein,Ericson: An interactive open-domain conversational search agent,2023,https://arxiv.org/abs/2304.02233,"Open-domain conversational search (ODCS) aims to provide valuable, up-to-date information, while maintaining natural conversations to help users refine and ultimately answer information needs. However, creating an effective and robust ODCS agent is challenging. In this paper, we present a fully functional ODCS system, Ericson, which includes state-of-the-art question answering and information retrieval components, as well as intent inference and dialogue management models for proactive question refinement and recommendations. Our system was stress-tested in the Amazon Alexa Prize, by engaging in live conversations with thousands of Alexa users, thus providing empirical basis for the analysis of the ODCS system in real settings. Our interaction data analysis revealed that accurate intent classification, encouraging user engagement, and careful proactive recommendations contribute most to the users satisfaction. Our study further identifies limitations of the existing search techniques, and can serve as a building block for the next generation of ODCS agents."
Eugene Agichtein,Detecting Elevated Air Pollution Levels by Monitoring Web Search Queries: Deep Learning-Based Time Series Forecasting,2022,https://arxiv.org/abs/2211.05267,"Real-time air pollution monitoring is a valuable tool for public health and environmental surveillance. In recent years, there has been a dramatic increase in air pollution forecasting and monitoring research using artificial neural networks (ANNs). Most of the prior work relied on modeling pollutant concentrations collected from ground-based monitors and meteorological data for long-term forecasting of outdoor ozone, oxides of nitrogen, and PM2.5. Given that traditional, highly sophisticated air quality monitors are expensive and are not universally available, these models cannot adequately serve those not living near pollutant monitoring sites. Furthermore, because prior models were built on physical measurement data collected from sensors, they may not be suitable for predicting public health effects experienced from pollution exposure. This study aims to develop and validate models to nowcast the observed pollution levels using Web search data, which is publicly available in near real-time from major search engines. We developed novel machine learning-based models using both traditional supervised classification methods and state-of-the-art deep learning methods to detect elevated air pollution levels at the US city level, by using generally available meteorological data and aggregate Web-based search volume data derived from Google Trends. We validated the performance of these methods by predicting three critical air pollutants (ozone (O3), nitrogen dioxide (NO2), and fine particulate matter (PM2.5)), across ten major U.S. metropolitan statistical areas (MSAs) in 2017 and 2018."
Eugene Agichtein,Proceedings of the Fifth Workshop on e-Commerce and NLP (ECNLP 5),2022,https://aclanthology.org/2022.ecnlp-1.0.pdf,"It is our great pleasure to welcome you to the Fifth Workshop on e-Commerce and NLP (ECNLP).This workshop focuses on intersection of Natural Language Processing (NLP) and e-Commerce. NLP and information retrieval (IR) have been powering e-Commerce applications since the early days of the fields. Today, NLP and IR already play a significant role in e-Commerce tasks, including product search, recommender systems, product question answering, machine translation, sentiment analysis, product description and review summarization, and customer review processing. With the exploding popularity of chatbots and shopping assistants-–both text-and voice-based-–NLP, IR, question answering, and dialogue systems research is poised to transform e-Commerce once again."
Eugene Agichtein,Collecting high-quality multi-modal conversational search data for e-commerce,2024,https://aclanthology.org/2024.knowledgenlp-1.3/,"Continued improvement of conversational assistants in knowledge-rich domains like E-Commerce requires large volumes of realistic high-quality conversation data to power increasingly sophisticated large language model chatbots, dialogue managers, response rankers, and recommenders. The problem is exacerbated for multi-modal interactions in realistic conversational product search and recommendation. Here, an artificial sales agent must interact intelligently with a customer using both textual and visual information and incorporate results from external search systems, such as a product catalog. Yet, it remains an open question how to best crowd-source large-scale, naturalistic multi-modal dialogue and action data, required to train such an artificial agent. We describe our crowd-sourced task where one worker (the Buyer) plays the role of the customer, and another (the Seller) plays the role of the sales agent. We identify subtle interactions between one worker’s environment and their partner’s behavior mediated by workers’ word choice. We find that limiting information presented to the Buyer, both in their backstory and by the Seller, improves conversation quality. We also show how conversations are improved through minimal automated Seller “coaching”. While typed and spoken messages are slightly different, the differences are not as large as frequently assumed. We plan to release our platform code and the resulting dialogues to advance research on conversational search agents."
Eugene Agichtein,Combining Multiple Metrics for Evaluating Retrieval-Augmented Conversations,2024,https://aclanthology.org/2024.hcinlp-1.4/,"Conversational AI is a subtype of Human Computer Interaction that has gained wide adoption. These systems are typically powered by Large Language Models (LLMs) that use Retrieval Augmented Generation (RAG) to infuse external knowledge, which is effective against issues like hallucination. However, automatically evaluating retrieval augmented conversations with minimal human effort remains challenging, particularly in online settings. We address this challenge by proposing a lexical metric, and a novel method for combining it with other metrics, including semantic models. Our approach involves:(1) Conversational Information Utility (CIU), a new automated metric inspired by prior user studies on web search evaluation, to compute information overlap between conversation context and grounded information in an unsupervised, purely lexical way; and (2) a generalized reward model through Mixture-of-Experts (MoE-CIU) that dynamically ensembles CIU with other metrics, including learned ones, into a single reward. Evaluation against human ratings on two public datasets (Topical Chat and Persona Chat) shows that CIU improves correlation against human judgments by 2.0% and 0.9% respectively compared to the second best metric. When MoE is applied to combine lexical and learned semantic metrics, correlations further improve by 9.9% and 5.0%, suggesting that unified reward models are a promising approach."
Eugene Agichtein,Proceedings of the Seventh Workshop on e-Commerce and NLP@ LREC-COLING 2024,2024,https://aclanthology.org/2024.ecnlp-1.pdf,"It is our great pleasure to welcome you to the Seventh Workshop on e-Commerce and NLP (ECNLP).This workshop focuses on intersection of Natural Language Processing (NLP) and e-Commerce. NLP and information retrieval (IR) have been powering e-Commerce applications since the early days of the fields. Today, NLP and IR already play a significant role in e-Commerce tasks, including product search, recommender systems, product question answering, machine translation, sentiment analysis, product description and review summarization, and customer review processing. With the exploding popularity of chatbots and shopping assistants-–both text-and voice-based-–NLP, IR, question answering, and dialogue systems research is poised to transform e-Commerce once again."
Eugene Agichtein,Attentive pseudo-relevance feedback network for query categorization,2024,https://patents.google.com/patent/US11960555B2/en,"A method of providing results from a search engine comprises generating an initial set based on a query received from a user; generating an attention value based on the query and on the initial set; applying the attention value to the initial set; and presenting a set of results in response to the query, wherein the results are generated according to the application of the attention value to the initial set."
Eugene Agichtein,User click modelling in search queries,2024,https://patents.google.com/patent/US20240119059A1/en,"A method for ranking documents in search results includes defining a first training data set, the first training data set including, for each of a plurality of user queries, information respective of a document selected by a user from results responsive to the query and information respective of one or more documents within an observation window after the selected document in the results, and defining a second training data set, the second training data set including, for each of the plurality of user queries, information respective of the selected document. The method further includes training a first machine learning model with the first training data set, training a second machine learning model with the second training data set, and ranking documents of a further search result set according to the output of the first machine learning model and the output of the second machine learning model."
Eugene Agichtein,Leveraging interesting facts to enhance user engagement with conversational interfaces,2024,https://arxiv.org/abs/2404.06659,"Conversational Task Assistants (CTAs) guide users in performing a multitude of activities, such as making recipes. However, ensuring that interactions remain engaging, interesting, and enjoyable for CTA users is not trivial, especially for time-consuming or challenging tasks. Grounded in psychological theories of human interest, we propose to engage users with contextual and interesting statements or facts during interactions with a multi-modal CTA, to reduce fatigue and task abandonment before a task is complete. To operationalize this idea, we train a high-performing classifier (82% F1-score) to automatically identify relevant and interesting facts for users. We use it to create an annotated dataset of task-specific interesting facts for the domain of cooking. Finally, we design and validate a dialogue policy to incorporate the identified relevant and interesting facts into a conversation, to improve user engagement and task completion. Live testing on a leading multi-modal voice assistant shows that 66% of the presented facts were received positively, leading to a 40% gain in the user satisfaction rating, and a 37% increase in conversation length. These findings emphasize that strategically incorporating interesting facts into the CTA experience can promote real-world user participation for guided task interactions."
Eugene Agichtein,User click modelling in search queries,2023,https://patents.google.com/patent/US11853309B2/en,"(57) ABSTRACT A method for ranking documents in search results includes defining a first training data set, the first training data set including, for each of a plurality of user queries, information respective of a document selected by a user from results responsive to the query and information respective of one or more documents within an observation window after the selected document in the results, and defining a second training data set, the second training data set including, for each of the plurality of user queries, information respective of the selected document. The method further includes training a first machine learning model with the first training data set, training a second machine learning model with the second training data set, and ranking documents of a further search result set according to the output of the first machine learning model and the output of the second machine learning model."
Eugene Agichtein,Evaluation Metrics of Language Generation Models for Synthetic Traffic Generation Tasks,2023,https://arxiv.org/abs/2311.12534,"Many Natural Language Generation (NLG) tasks aim to generate a single output text given an input prompt. Other settings require the generation of multiple texts, e.g., for Synthetic Traffic Generation (STG). This generation task is crucial for training and evaluating QA systems as well as conversational agents, where the goal is to generate multiple questions or utterances resembling the linguistic variability of real users. In this paper, we show that common NLG metrics, like BLEU, are not suitable for evaluating STG. We propose and evaluate several metrics designed to compare the generated traffic to the distribution of real user texts. We validate our metrics with an automatic procedure to verify whether they capture different types of quality issues of generated data; we also run human annotations to verify the correlation with human judgements. Experiments on three tasks, i.e., Shopping Utterance Generation, Product Question Generation and Query Auto Completion, demonstrate that our metrics are effective for evaluating STG tasks, and improve the agreement with human judgement up to 20% with respect to common NLG metrics. We believe these findings can pave the way towards better solutions for estimating the representativeness of synthetic text data."
Eugene Agichtein,A Deep Reinforcement Learning Approach for Interactive Search with Sentence-level Feedback,2023,https://arxiv.org/abs/2310.03043,"Interactive search can provide a better experience by incorporating interaction feedback from the users. This can significantly improve search accuracy as it helps avoid irrelevant information and captures the users' search intents. Existing state-of-the-art (SOTA) systems use reinforcement learning (RL) models to incorporate the interactions but focus on item-level feedback, ignoring the fine-grained information found in sentence-level feedback. Yet such feedback requires extensive RL action space exploration and large amounts of annotated data. This work addresses these challenges by proposing a new deep Q-learning (DQ) approach, DQrank. DQrank adapts BERT-based models, the SOTA in natural language processing, to select crucial sentences based on users' engagement and rank the items to obtain more satisfactory responses. We also propose two mechanisms to better explore optimal actions. DQrank further utilizes the experience replay mechanism in DQ to store the feedback sentences to obtain a better initial ranking performance. We validate the effectiveness of DQrank on three search datasets. The results show that DQRank performs at least 12% better than the previous SOTA RL approaches. We also conduct detailed ablation studies. The ablation results demonstrate that each model component can efficiently extract and accumulate long-term engagement effects from the users' sentence-level feedback. This structure offers new technologies with promised performance to construct a search system with sentence-level interaction."
Eugene Agichtein,The 6th Workshop on e-eommerce and NLP (ECNLP 6),2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599212,"Natural Language Processing (NLP) technology plays a key role in e-commerce today, where this technology can be used for a range of tasks, such as improving search results, providing recommendations, and powering virtual assistants. The ECNLP workshop series focuses on NLP and Machine Learning methods for e-commerce, with a focus on applied and fundamental machine learning and NLP methods that can be leveraged in applied settings. The workshop aims to being together researchers from both industry and academia, with the goal of fostering greater knowledge sharing and collaboration between researchers and practitioners in this field."
Eugene Agichtein,FCC: Fusing Conversation History and Candidate Provenance for Contextual Response Ranking in Dialogue Systems,2023,https://arxiv.org/abs/2304.00180,"Response ranking in dialogues plays a crucial role in retrieval-based conversational systems. In a multi-turn dialogue, to capture the gist of a conversation, contextual information serves as essential knowledge to achieve this goal. In this paper, we present a flexible neural framework that can integrate contextual information from multiple channels. Specifically for the current task, our approach is to provide two information channels in parallel, Fusing Conversation history and domain knowledge extracted from Candidate provenance (FCC), where candidate responses are curated, as contextual information to improve the performance of multi-turn dialogue response ranking. The proposed approach can be generalized as a module to incorporate miscellaneous contextual features for other context-oriented tasks. We evaluate our model on the MSDialog dataset widely used for evaluating conversational response ranking tasks. Our experimental results show that our framework significantly outperforms the previous state-of-the-art models, improving Recall@1 by 7% and MAP by 4%. Furthermore, we conduct ablation studies to evaluate the contributions of each information channel, and of the framework components, to the overall ranking performance, providing additional insights and directions for further improvements."
Eugene Agichtein,"Alexa, Let’s Work Together: Introducing the First Alexa Prize TaskBot Challenge on Conversational Task Assistance",2022,https://www.academia.edu/download/96053109/2209.06321.pdf,"Since its inception in 2016, the Alexa Prize program has enabled hundreds of university students to explore and compete to develop conversational agents through the SocialBot Grand Challenge. The goal of the challenge is to build agents capable of conversing coherently and engagingly with humans on popular topics for 20 minutes, while achieving an average rating of at least 4.0/5.0. However, as conversational agents attempt to assist users with increasingly complex tasks, new conversational AI techniques and evaluation platforms are needed. The Alexa Prize TaskBot challenge, established in 2021, builds on the success of the SocialBot challenge by introducing the requirements of interactively assisting humans with real-world Cooking and Do-It-Yourself tasks, while making use of both voice and visual modalities. This challenge requires the TaskBots to identify and understand the user’s need, identify and integrate task and domain knowledge into the interaction, and develop new ways of engaging the user without distracting them from the task at hand, among other challenges. This paper provides an overview of the TaskBot challenge, describes the infrastructure support provided to the teams with the CoBot Toolkit, and summarizes the approaches the participating teams took to overcome the research challenges. Finally, it analyzes the performance of the competing TaskBots during the first year of the competition."
Eugene Agichtein,WSDM'21: The 14th ACM International Conference on Web Search and Data Mining,2021,https://dl.acm.org/doi/abs/10.1145/3473044.3473045,"The ACM International Conference on Web Search and Data Mining (WSDM) is one of the premier conferences on web-related research involving web search and data mining, with a dynamic and growing community from academia and industry. This year, WSDM was held virtually on March 8th -- 12th, 2021, due to the Covid-19 pandemic, instead of the originally-planned location in Jerusalem, Israel. WSDM'21 program reflects the breadth and diversity of research in the field and showcases the latest developments in these domains."
Eugene Agichtein,Proceedings of the 4th Workshop on e-Commerce and NLP,2021,https://aclanthology.org/2021.ecnlp-1.0.pdf,"It is our great pleasure to welcome you to the Fourth Workshop on e-Commerce and NLP (ECNLP).This workshop focuses on intersection of Natural Language Processing (NLP) and e-Commerce. NLP and information retrieval (IR) have been powering e-Commerce applications since the early days of the fields. Today, NLP and IR already play a significant role in e-Commerce tasks, including product search, recommender systems, product question answering, machine translation, sentiment analysis, product description and review summarization, and customer review processing. With the exploding popularity of chatbots and shopping assistants–both text-and voice-based–NLP, IR, question answering, and dialogue systems research is poised to transform e-Commerce once again."
Eugene Agichtein,APRF-Net: Attentive Pseudo-Relevance Feedback Network for Query Categorization,2021,https://dl.acm.org/doi/abs/10.1145/3404835.3463041,"Query categorization is an essential part of query intent understanding in e-commerce search. A common query categorization task is to select the relevant fine-grained product categories in a product taxonomy. For frequent queries, rich customer behavior (e.g., click-through data) can be used to infer the relevant product categories. However, for more rare queries, which cover a large volume of search traffic, relying solely on customer behavior may not suffice due to the lack of this signal. To improve categorization of rare queries, we adapt the Pseudo-Relevance Feedback (PRF) approach to utilize the latent knowledge embedded in semantically or lexically similar product documents to enrich the representation of the more rare queries. To this end, we propose a novel deep neural model named Attentive Pseudo Relevance Feedback Network (APRF-Net) to enhance the representation of rare queries for query …"
Eugene Agichtein,Development and Validation of a Crowd-Generated Indicator of Air Pollution Exposures and Health Response using Web Search Log Mining.,2020,https://ehp.niehs.nih.gov/doi/abs/10.1289/isee.2020.virtual.P-1037," BackgroundTraditional air pollution epidemiologic models use ground-based monitors and/or satellite estimates of ozone and PM2.5 concentrations as surrogates of exposure. It is possible that crowd-sourced or online data may be more effective at reflecting population exposures than these traditional indicators. Here, we constructed models to “nowcast” observed elevated pollution levels, using online search queries to create a Crowd-Generated Air Pollution (CGAP) metric and compared the output to monitoring data. We then used the CGAP metric to examine short-term associations of ED visits for pediatric asthma. MethodsA search term Dictionary Learner-Long-Short Term Memory (DL-LSTM) composite model was developed to combine meteorological data, air pollution measures, and pollution-related search data for Atlanta, and daily CGAP index was generated for ozone and PM2.5 from 2007 to 2008. Daily …"
Eugene Agichtein,Semantic Product Search for Matching Structured Product Catalogs in E-Commerce,2020,https://ui.adsabs.harvard.edu/abs/2020arXiv200808180I/abstract,"Retrieving all semantically relevant products from the product catalog is an important problem in E-commerce. Compared to web documents, product catalogs are more structured and sparse due to multi-instance fields that encode heterogeneous aspects of products (eg brand name and product dimensions). In this paper, we propose a new semantic product search algorithm that learns to represent and aggregate multi-instance fields into a document representation using state of the art transformers as encoders. Our experiments investigate two aspects of the proposed approach:(1) effectiveness of field representations and structured matching;(2) effectiveness of adding lexical features to semantic search. After training our models using user click logs from a well-known E-commerce platform, we show that our results provide useful insights for improving product search. Lastly, we present a detailed error analysis to …"
Dorian Arnold,On the memory attribution problem: A solution and case study using MPI,2020,https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5159,"As parallel applications running on large‐scale computing systems become increasingly memory constrained, the ability to attribute memory usage to the various components of the application is becoming increasingly important. We present the design and implementation of memnesia, a novel memory usage profiler for parallel and distributed message‐passing applications. Our approach captures both application– and message‐passing library–specific memory usage statistics from unmodified binaries dynamically linked to a message‐passing communication library. Using microbenchmarks and proxy applications, we evaluated our profiler across three Message Passing Interface (MPI) implementations and two hardware platforms. The results show that our approach and the corresponding implementation can accurately quantify memory resource usage as a function of time, scale, communication workload, and …"
Dorian Arnold,APE: Metrics for understanding application performance efficiency under power caps,2022,https://www.sciencedirect.com/science/article/pii/S2210537922000439,"As supercomputers continue to grow in size and power consumption, the ability to understand application run time performance and energy/power usage is of growing importance. In the future it may be necessary for systems to operate under power caps imposed by facilities due to external influences such as renewable power generation (e.g. solar) impacting energy availability at an affordable cost during certain times of day and more frequent natural disasters due to climate change causing power transmission disruptions. However, current energy consumption and power characterization metrics like energy-delay products do not express all of the characteristics of an application that are relevant to understanding the impact of power capping on performance.In this study, we (1) characterize the useful features of a metric that effectively captures time-to-solution and power performance dynamics; and (2) design …"
Dorian Arnold,"Diversity, Equity, and Inclusion for Computer and Information Science and Engineering Conferences: How Change Happens and Four Things You Can Do Now",2023,https://ieeexplore.ieee.org/abstract/document/10197481/,"The revitalized interest in ensuring that computer and information science and engineering (CISE) is a fair and equitable professional path is one of our grandest opportunities. As professionals who have championed diversity, equity, and inclusion over decades, we are pleased to offer four actions that you, our colleagues, can take to help. In this article, we spotlight the opportunities that exist within conferences to create fair and equitable participation for all members of the CISE profession. We focus on leveraging committee structures, developing new leaders, revising policies and procedures, and learning from successful innovations. Creating cultural and structural changes becomes possible when we take these steps together."
Dorian Arnold,Departmental BPC Plans 1-Getting Started: Selecting Goals and Activities for Broadening Participation in Computing,2023,https://dl.acm.org/doi/abs/10.1145/3545947.3569625,"A hands-on session for creating department-level plans to coordinate Broadening Participation in Computing (BPC) work. Departmental BPC Plans can help provide continuity and greater impact in BPC work and provide opportunities for more faculty to engage. The workshop is organized around a series of guided hands-on activities selecting and refining specific goals and activities with the final result being an outline of a full BPC plan. We also include some discussion of next steps and invite participants to join our active Slack workspace. Individuals interested in this workshop may also be interested in the follow-on workshop, Departmental BPC Plans 2 - Finalizing your Plan."
Dorian Arnold,Challenges and Successes in Writing BPC Plans for NSF Proposals: A Panel of Peers Discuss Their Approaches,2023,https://dl.acm.org/doi/abs/10.1145/3545947.3569598,"In 2021, National Science Foundation (NSF) Computer and Information Science and Engineering (CISE) directorate implemented a Broadening Participation in Computing (BPC) plan requirement for all medium and larger research proposals in Core, CPS, and SaTC. This panel comprises faculty and administrators from US computing departments who have participated in the writing of Departmental or Project BPC plans, two in response to NSF's encouragement and one prior. Panelists represent a range of institutions as well as departmental awareness of BPC prior to writing their plans. Regardless of where they or their departments lie in the spectrum of knowing about and implementing BPC activities, and regardless of the current demographic makeup of the students in their major, they all encountered challenges as they wrote their plans. They all also experienced successes, not the least of which is that they …"
Dorian Arnold,"Departmental BPC Plans 2-Finalizing your Plan: Context, Style, Formatting, and Verification on BPCnet. org",2023,https://dl.acm.org/doi/abs/10.1145/3545947.3569626,"A hands-on session for finalizing a Departmental BPC Plans for verification on BPCnet.org. Verification of a Departmental BPC Plan enables faculty from an institution to use it as part of a grant submission to the National Science Foundation (NSF). This workshop is intended for people from the United States who have an existing Departmental BPC Plan or who will have created one in the workshop ""Departmental BPC Plans 1."" The workshop is organized around a series of guided hands-on activities to help participants complete a draft of a Departmental BPC Plan that can be Verified by BPCnet.org."
Dorian Arnold,Workshop 16: SNACS Scalable Networks for Advanced Computing Systems,2020,https://ieeexplore.ieee.org/abstract/document/9150437/,"Summary form only given, as follows. The complete presentation was not made available for publication as part of the conference proceedings. The Workshop on Scalable Networks for Advanced Computing Systems is a venue for discussions in the networks community that encompasses the full networks stack, ranging from high-level tools and interfaces, down to low-level hardware. The goal of this workshop is to bring together researchers to present research on the next-generation of large scale interconnects for scientific applications. In particular, our aim is to provide a venue for discussion of the full network stack from user level interfaces (i.e., MPI, PGAS) to the hardware level (i.e., network offload, hardware support for active messages, routing protocols). Workshop topics include: networks for exascale systems, networks for multi-facility workflows, new communication models and architectures for large scale …"
Yana Bromberg,PredictProtein-predicting protein structure and function for 29 years,2021,https://academic.oup.com/nar/article-abstract/49/W1/W535/6276913,"Since 1992 PredictProtein (https://predictprotein.org) is a one-stop online resource for protein sequence analysis with its main site hosted at the Luxembourg Centre for Systems Biomedicine (LCSB) and queried monthly by over 3,000 users in 2020. PredictProtein was the first Internet server for protein predictions. It pioneered combining evolutionary information and machine learning. Given a protein sequence as input, the server outputs multiple sequence alignments, predictions of protein structure in 1D and 2D (secondary structure, solvent accessibility, transmembrane segments, disordered regions, protein flexibility, and disulfide bridges) and predictions of protein function (functional effects of sequence variation or point mutations, Gene Ontology (GO) terms, subcellular localization, and protein-, RNA-, and DNA binding). PredictProtein's infrastructure has moved to the LCSB increasing throughput; the use of …"
Yana Bromberg,Amino acid encoding for deep learning applications,2020,https://link.springer.com/article/10.1186/s12859-020-03546-x,"The number of applications of deep learning algorithms in bioinformatics is increasing as they usually achieve superior performance over classical approaches, especially, when bigger training datasets are available. In deep learning applications, discrete data, e.g. words or n-grams in language, or amino acids or nucleotides in bioinformatics, are generally represented as a continuous vector through an embedding matrix. Recently, learning this embedding matrix directly from the data as part of the continuous iteration of the model to optimize the target prediction – a process called ‘end-to-end learning’ – has led to state-of-the-art results in many fields. Although usage of embeddings is well described in the bioinformatics literature, the potential of end-to-end learning for single amino acids, as compared to more classical manually-curated encoding strategies, has not been systematically addressed. To …"
Yana Bromberg,Evolution of the SARS‐CoV‐2 proteome in three dimensions (3D) during the first 6 months of the COVID‐19 pandemic,2022,https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.26250,"Understanding the molecular evolution of the SARS‐CoV‐2 virus as it continues to spread in communities around the globe is important for mitigation and future pandemic preparedness. Three‐dimensional structures of SARS‐CoV‐2 proteins and those of other coronavirusess archived in the Protein Data Bank were used to analyze viral proteome evolution during the first 6 months of the COVID‐19 pandemic. Analyses of spatial locations, chemical properties, and structural and energetic impacts of the observed amino acid changes in >48 000 viral isolates revealed how each one of 29 viral proteins have undergone amino acid changes. Catalytic residues in active sites and binding residues in protein–protein interfaces showed modest, but significant, numbers of substitutions, highlighting the mutational robustness of the viral proteome. Energetics calculations showed that the impact of substitutions on the …"
Yana Bromberg,Deep learning of a bacterial and archaeal universal language of life enables transfer learning and illuminates microbial dark matter,2022,https://www.nature.com/articles/s41467-022-30070-8,"The majority of microbial genomes have yet to be cultured, and most proteins identified in microbial genomes or environmental sequences cannot be functionally annotated. As a result, current computational approaches to describe microbial systems rely on incomplete reference databases that cannot adequately capture the functional diversity of the microbial tree of life, limiting our ability to model high-level features of biological sequences. Here we present LookingGlass, a deep learning model encoding contextually-aware, functionally and evolutionarily relevant representations of short DNA reads, that distinguishes reads of disparate function, homology, and environmental origin. We demonstrate the ability of LookingGlass to be fine-tuned via transfer learning to perform a range of diverse tasks: to identify novel oxidoreductases, to predict enzyme optimal temperature, and to recognize the reading frames of DNA …"
Yana Bromberg,Quantifying structural relationships of metal-binding sites suggests origins of biological electron transfer,2022,https://www.science.org/doi/abs/10.1126/sciadv.abj3984,"Biological redox reactions drive planetary biogeochemical cycles. Using a novel, structure-guided sequence analysis of proteins, we explored the patterns of evolution of enzymes responsible for these reactions. Our analysis reveals that the folds that bind transition metal–containing ligands have similar structural geometry and amino acid sequences across the full diversity of proteins. Similarity across folds reflects the availability of key transition metals over geological time and strongly suggests that transition metal–ligand binding had a small number of common peptide origins. We observe that structures central to our similarity network come primarily from oxidoreductases, suggesting that ancestral peptides may have also facilitated electron transfer reactions. Last, our results reveal that the earliest biologically functional peptides were likely available before the assembly of fully functional protein domains over 3.8 …"
Yana Bromberg,"CAGI, the Critical Assessment of Genome Interpretation, establishes progress and prospects for computational genetic variant interpretation methods*",2024,https://iris.uniroma1.it/handle/11573/1703621,"Background: The Critical Assessment of Genome Interpretation (CAGI) aims to advance the state-of-the-art for computational prediction of genetic variant impact, particularly where relevant to disease. The five complete editions of the CAGI community experiment comprised 50 challenges, in which participants made blind predictions of phenotypes from genetic data, and these were evaluated by independent assessors. Results: Performance was particularly strong for clinical pathogenic variants, including some difficult-to-diagnose cases, and extends to interpretation of cancer-related variants. Missense variant interpretation methods were able to estimate biochemical effects with increasing accuracy. Assessment of methods for regulatory variants and complex trait disease risk was less definitive and indicates performance potentially suitable for auxiliary use in the clinic. Conclusions: Results show that while current methods are imperfect, they have major utility for research and clinical applications. Emerging methods and increasingly large, robust datasets for training and assessment promise further progress ahead.Critical assessment of genome interpretation consortium. CAGI, the critical assessment of genome interpretation, establishes progress and pprospects for computational genetic variant interpretation methods/Jain, Shantanu; Bakolitsa, Constantina; E Brenner, Steven; Radivojac, Predrag; Moult, John; Repo, Susanna; A Hoskins, Roger; Andreoletti, Gaia; Barsky, Daniel; Chellapan, Ajithavalli; Chu, Hoyin; Dabbiru, Navya; K Kollipara, Naveen; Ly, Melissa; J Neumann, Andrew; R Pal, Lipika; Odell, Eric; Pandey, Gaurav; C Peters …"
Yana Bromberg,Decoding the effects of synonymous variants,2021,https://academic.oup.com/nar/article-abstract/49/22/12673/6446531,"Synonymous single nucleotide variants (sSNVs) are common in the human genome but are often overlooked. However, sSNVs can have significant biological impact and may lead to disease. Existing computational methods for evaluating the effect of sSNVs suffer from the lack of gold-standard training/evaluation data and exhibit over-reliance on sequence conservation signals. We developed synVep (synonymous Variant effect predictor), a machine learning-based method that overcomes both of these limitations. Our training data was a combination of variants reported by gnomAD (observed) and those unreported, but possible in the human genome (generated). We used positive-unlabeled learning to purify the generated variant set of any likely unobservable variants. We then trained two sequential extreme gradient boosting models to identify subsets of the remaining variants putatively enriched and …"
Yana Bromberg,mebipred: identifying metal-binding potential in protein sequence,2022,https://academic.oup.com/bioinformatics/article-abstract/38/14/3532/6594112,"metal-binding proteins have a central role in maintaining life processes. Nearly one-third of known protein structures contain metal ions that are used for a variety of needs, such as catalysis, DNA/RNA binding, protein structure stability, etc. Identifying metal-binding proteins is thus crucial for understanding the mechanisms of cellular activity. However, experimental annotation of protein metal-binding potential is severely lacking, while computational techniques are often imprecise and of limited applicability.we developed a novel machine learning-based method, mebipred, for identifying metal-binding proteins from sequence-derived features. This method is over 80% accurate in recognizing proteins that bind metal ion-containing ligands; the specific identity of 11 ubiquitously present metal ions can also be annotated. mebipred is reference-free, i.e. no …"
Yana Bromberg,Impact of vitamin A transport and storage on intestinal retinoid homeostasis and functions,2021,https://www.sciencedirect.com/science/article/pii/S0022227521000262,"Lecithin:retinol acyltransferase and retinol-binding protein enable vitamin A (VA) storage and transport, respectively, maintaining tissue homeostasis of retinoids (VA derivatives). The precarious VA status of the lecithin:retinol acyltransferase–deficient (Lrat−/−) retinol-binding protein–deficient (Rbp−/−) mice rapidly deteriorates upon dietary VA restriction, leading to signs of severe vitamin A deficiency (VAD). As retinoids impact gut morphology and functions, VAD is often linked to intestinal pathological conditions and microbial dysbiosis. Thus, we investigated the contribution of VA storage and transport to intestinal retinoid homeostasis and functionalities. We showed the occurrence of intestinal VAD in Lrat−/−Rbp−/− mice, demonstrating the critical role of both pathways in preserving gut retinoid homeostasis. Moreover, in the mutant colon, VAD resulted in a compromised intestinal barrier as manifested by reduced …"
Yana Bromberg,Snow microbiome functional analyses reveal novel aspects of microbial metabolism of complex organic compounds,2020,https://onlinelibrary.wiley.com/doi/abs/10.1002/mbo3.1100,"Microbes active in extreme cold are not as well explored as those of other extreme environments. Studies have revealed a substantial microbial diversity and identified cold‐specific microbiome molecular functions. We analyzed the metagenomes and metatranscriptomes of 20 snow samples collected in early and late spring in Svalbard, Norway using mi‐faser, our read‐based computational microbiome function annotation tool. Our results reveal a more diverse microbiome functional capacity and activity in the early‐ vs. late‐spring samples. We also find that functional dissimilarity between the same‐sample metagenomes and metatranscriptomes is significantly higher in early than late spring samples. These findings suggest that early spring samples may contain a larger fraction of DNA of dormant (or dead) organisms, while late spring samples reflect a new, metabolically active community. We further show that …"
Yana Bromberg,DNA based methods in intelligence-moving towards metagenomics,2020,https://researchnow.flinders.edu.au/en/publications/dna-based-methods-in-intelligence-moving-towards-metagenomics,"Advancements in DNA methods and biotechnology have enabled forensic scientists to explore the DNA evidence found as part of a criminal investigation on a much more comprehensive and predictive level. This has led to a rise in research into DNA intelligence tools such as phenotypic prediction (ie, eye and hair colour) and inference of biogeographical ancestry. Both of which can be applied to gain further insights about a scene or sample in question. Although microorganisms have played a role in forensics for decades, investigations were focused on the pathogenicity aspect, mainly to determine the cause and time of death. Recent progress in studying the human microbiome has implicated the potential use of this data in forensics. Since each individual, place, or item has its own microbial pattern, a new suite of tools are now available to be exploited in criminal investigations. Although there is much interest and potential for these emerging metagenomic and microbial forensic tools, best practices and reference ranges need to be established before they are implemented. Here, we discuss existing DNA intelligence tools applied to forensic science, the application of microbial forensics and metagenomics along with the challenges and concerns that future developments entail."
Yana Bromberg,Predicting embryonic aneuploidy rate in IVF patients using whole-exome sequencing,2022,https://link.springer.com/article/10.1007/s00439-022-02450-z,"Infertility is a major reproductive health issue that affects about 12% of women of reproductive age in the United States. Aneuploidy in eggs accounts for a significant proportion of early miscarriage and in vitro fertilization failure. Recent studies have shown that genetic variants in several genes affect chromosome segregation fidelity and predispose women to a higher incidence of egg aneuploidy. However, the exact genetic causes of aneuploid egg production remain unclear, making it difficult to diagnose infertility based on individual genetic variants in mother’s genome. In this study, we evaluated machine learning-based classifiers for predicting the embryonic aneuploidy risk in female IVF patients using whole-exome sequencing data. Using two exome datasets, we obtained an area under the receiver operating curve of 0.77 and 0.68, respectively. High precision could be traded off for high specificity in classifying …"
Yana Bromberg,Virtual Boot Camp: COVID‐19 evolution and structural biology,2020,https://pmc.ncbi.nlm.nih.gov/articles/PMC7590104/,"Biochem Mol Biol Educ. 2020; 48: 511–513. wileyonlinelibrary. com/journal/bmb 511 build a foundation for studying the SARS-CoV-2 Main Protease (Nsp5) to understand how the protein evolved during the first 6 months of the COVID-19 pandemic by exploring amino acid sequence and 3D atomic-level structure using various structural bioinformatics tools. Participants analyzed how the protein changed as the virus spread around the world, comparing Nsp5 from the original viral isolate to 161 unique sequence/structure variants. Hosted by the RCSB Protein Data Bank (RCSB. org) 1, 2 and the Rutgers University Institute for Quantitative Biomedicine (IQB; iqb. rutgers. edu), the course met daily for 5 days, utilizing local expertise to present topics related to COVID-19 function and evolution (eg, evolution of RNA viruses), introductions to tools (eg, Clustal Omega3 for sequence alignments and phylogenetic trees; Mol …"
Yana Bromberg,Inferring potential cancer driving synonymous variants,2022,https://www.mdpi.com/2073-4425/13/5/778,"Synonymous single nucleotide variants (sSNVs) are often considered functionally silent, but a few cases of cancer-causing sSNVs have been reported. From available databases, we collected four categories of sSNVs: germline, somatic in normal tissues, somatic in cancerous tissues, and putative cancer drivers. We found that screening sSNVs for recurrence among patients, conservation of the affected genomic position, and synVep prediction (synVep is a machine learning-based sSNV effect predictor) recovers cancer driver variants (termed proposed drivers) and previously unknown putative cancer genes. Of the 2.9 million somatic sSNVs found in the COSMIC database, we identified 2111 proposed cancer driver sSNVs. Of these, 326 sSNVs could be further tagged for possible RNA splicing effects, RNA structural changes, and affected RBP motifs. This list of proposed cancer driver sSNVs provides computational guidance in prioritizing the experimental evaluation of synonymous mutations found in cancers. Furthermore, our list of novel potential cancer genes, galvanized by synonymous mutations, may highlight yet unexplored cancer mechanisms."
Yana Bromberg,Computational approaches for unraveling the effects of variation in the human genome and microbiome,2020,https://www.annualreviews.org/content/journals/10.1146/annurev-biodatasci-030320-041014,"The past two decades of analytical efforts have highlighted how much more remains to be learned about the human genome and, particularly, its complex involvement in promoting disease development and progression. While numerous computational tools exist for the assessment of the functional and pathogenic effects of genome variants, their precision is far from satisfactory, particularly for clinical use. Accumulating evidence also suggests that the human microbiome's interaction with the human genome plays a critical role in determining health and disease states. While numerous microbial taxonomic groups and molecular functions of the human microbiome have been associated with disease, the reproducibility of these findings is lacking. The human microbiome–genome interaction in healthy individuals is even less well understood. This review summarizes the available computational methods built to …"
Yana Bromberg,Learning from the unknown: exploring the range of bacterial functionality,2023,https://academic.oup.com/nar/article-abstract/51/19/10162/7280541,"Determining the repertoire of a microbe's molecular functions is a central question in microbial biology. Modern techniques achieve this goal by comparing microbial genetic material against reference databases of functionally annotated genes/proteins or known taxonomic markers such as 16S rRNA. Here, we describe a novel approach to exploring bacterial functional repertoires without reference databases. Our Fusion scheme establishes functional relationships between bacteria and assigns organisms to Fusion-taxa that differ from otherwise defined taxonomic clades. Three key findings of our work stand out. First, bacterial functional comparisons outperform marker genes in assigning taxonomic clades. Fusion profiles are also better for this task than other functional annotation schemes. Second, Fusion-taxa are robust to addition of novel organisms and are, arguably, able to capture the environment-driven …"
Yana Bromberg,Variant effect prediction in the age of machine learning,2024,https://cshperspectives.cshlp.org/content/16/7/a041467.short,"Over the years, many computational methods have been created for the analysis of the impact of single amino acid substitutions resulting from single-nucleotide variants in genome coding regions. Historically, all methods have been supervised and thus limited by the inadequate sizes of experimentally curated data sets and by the lack of a standardized definition of variant effect. The emergence of unsupervised, deep learning (DL)-based methods raised an important question: Can machines learn the language of life from the unannotated protein sequence data well enough to identify significant errors in the protein “sentences”? Our analysis suggests that some unsupervised methods perform as well or better than existing supervised methods. Unsupervised methods are also faster and can, thus, be useful in large-scale variant evaluations. For all other methods, however, their performance varies by both evaluation …"
Yana Bromberg,Functional profiling of the sequence stockpile: a protein pair-based assessment of in silico prediction tools,2025,https://academic.oup.com/bioinformatics/article-abstract/41/2/btaf035/7978914," In silico functional annotation of proteins is crucial to narrowing the sequencing-accelerated gap in our understanding of protein activities. Numerous function annotation methods exist, and their ranks have been growing, particularly so with the recent deep learning-based developments. However, it is unclear if these tools are truly predictive. As we are not aware of any methods that can identify new terms in functional ontologies, we ask if they can, at least, identify molecular functions of proteins that are non-homologous to or far-removed from known protein families.Here, we explore the potential and limitations of the existing methods in predicting the molecular functions of thousands of such proteins. Lacking the “ground truth” functional annotations, we transformed the assessment of function prediction into evaluation of functional similarity of protein …"
Yana Bromberg,Low diversity of human variation despite mostly mild functional impact of de novo variants,2021,https://www.frontiersin.org/articles/10.3389/fmolb.2021.635382/full,"Non-synonymous Single Nucleotide Variants (nsSNVs), resulting in single amino acid variants (SAVs), are important drivers of evolutionary adaptation across the tree of life. Humans carry on average over 10,000 SAVs per individual genome, many of which likely have little to no impact on the function of the protein they affect. Experimental evidence for protein function changes as a result of SAVs remain sparse – a situation that can be somewhat alleviated by predicting their impact using computational methods. Here, we used SNAP to examine both observed and in silico generated human variation in a set of 1,265 proteins that are consistently found across a number of diverse species. The number of SAVs that are predicted to have any functional effect on these proteins is smaller than expected, suggesting sequence/function optimization over evolutionary timescales. Additionally, we find that only a few of the yet-unobserved SAVs could drastically change the function of these proteins, while nearly a quarter would have only a mild functional effect. We observed that variants common in the human population localized to less conserved protein positions and carried mild to moderate functional effects more frequently than rare variants. As expected, rare variants carried severe effects more frequently than common variants. In line with current assumptions, we demonstrated that the change of the human reference sequence amino acid to the reference of another species (a cross-species variant) is unlikely to significantly impact protein function. However, we also observed that many cross-species variants may be weakly non-neutral for the …"
Yana Bromberg,In the twilight zone of protein sequence homology: do protein language models learn protein structure?,2024,https://academic.oup.com/bioinformaticsadvances/article-abstract/4/1/vbae119/7735315,"Protein language models based on the transformer architecture are increasingly improving performance on protein prediction tasks, including secondary structure, subcellular localization, and more. Despite being trained only on protein sequences, protein language models appear to implicitly learn protein structure. This paper investigates whether sequence representations learned by protein language models encode structural information and to what extent.We address this by evaluating protein language models on remote homology prediction, where identifying remote homologs from sequence information alone requires structural knowledge, especially in the “twilight zone” of very low sequence identity. Through rigorous testing at progressively lower sequence identities, we profile the performance of protein language models ranging from millions to …"
Yana Bromberg,A new paradigm for pandemic preparedness,2023,https://link.springer.com/article/10.1007/s40471-023-00336-w,"Preparing for pandemics requires a degree of interdisciplinary work that is challenging under the current paradigm. This review summarizes the challenges faced by the field of pandemic science and proposes how to address them.The structure of current siloed systems of research organizations hinders effective interdisciplinary pandemic research. Moreover, effective pandemic preparedness requires stakeholders in public policy and health to interact and integrate new findings rapidly, relying on a robust, responsive, and productive research domain. Neither of these requirements are well supported under the current system.We propose a new paradigm for pandemic preparedness wherein interdisciplinary research and close collaboration with public policy and health practitioners can improve our ability to prevent, detect, and treat pandemics through tighter integration …"
Yana Bromberg,Computational interpretation of human genetic variation,2022,https://link.springer.com/article/10.1007/s00439-022-02483-4,"Computational interpretation of human genetic variants comprises the development and application of analysis and prediction techniques aimed at elucidating the impact of variants in an individual’s genome on different organismal, cellular, and molecular phenotypes. A distinguishing characteristic of this interdisciplinary field is a remarkable breadth of the phenotypes of interest and their genetic architectures, biological and environmental contexts, data modalities and data generating platforms, as well as computational techniques developed to make sense of all available data. Even further contributing to the complexity of the field are the issues of safe deployment of the newly developed tools and mitigation of ethical challenges necessary for societal acceptance of both the research process and clinical application (Szabo 2019; McInnes et al. 2021). In the clinic, computational tools often incorporate patient, and …"
Yana Bromberg,Baseline Prevalence of Oral Human Papillomavirus in Mother-Child Pairs With and Without HIV Infection,2024,https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2828119,"People with HIV have increased risk of persistent oral human papillomavirus (HPV) infection and associated cancers, including oropharyngeal cancer. 1 Sub-Saharan Africa has among the highest burden of HIV, with a growing population of children perinatally exposed to and/or infected with HIV. 2 Little is known about prevalence and concordance of oral HPV subtypes in women with HIV and their children in this region. This cohort study evaluated oral HPV prevalence in mother-child dyads by HIV history."
Yana Bromberg,Assembling bacterial puzzles: piecing together functions into microbial pathways,2024,https://academic.oup.com/nargab/article-abstract/6/3/lqae109/7740577,"Functional metagenomics enables the study of unexplored bacterial diversity, gene families, and pathways essential to microbial communities. However, discovering biological insights with these data is impeded by the scarcity of quality annotations. Here, we use a co-occurrence-based analysis of predicted microbial protein functions to uncover pathways in genomic and metagenomic biological systems. Our approach, based on phylogenetic profiles, improves the identification of functional relationships, or participation in the same biochemical pathway, between enzymes over a comparable homology-based approach. We optimized the design of our profiles to identify potential pathways using minimal data, clustered functionally related enzyme pairs into multi-enzymatic pathways, and evaluated our predictions against reference pathways in the KEGG database. We then demonstrated a novel extension of this …"
Yana Bromberg,"Human Papillomavirus, Human Immunodeficiency Virus, and Oral Microbiota Interplay in Nigerian Youth (HOMINY): A Prospective Cohort Study Protocol",2025,https://bmjopen.bmj.com/content/15/2/e091017.abstract,"Persistent oral infections with high-risk human papillomavirus (HR-HPV) are a potential cause of most oropharyngeal cancers (OPCs). Oral HR-HPV infection and persistence are significantly higher in people living with HIV (PLWH). Most data on oral HR-HPV in PLWH come from developed countries or adult cohorts. This study aims to investigate oral HR-HPV susceptibility and persistence among children and adolescents living with HIV (CALHIV) and to understand the roles of perinatal HIV exposure, infection, antiretroviral treatment, and the oral microbiome.This prospective cohort study is ongoing at the University of Benin Teaching Hospital (UBTH), Nigeria, involving mother-child pairs followed at 6-month intervals for 2 years. Participants include children aged 9–18 and their mothers aged 18 and above. The study targets 690 adolescents in three groups: 230 CALHIV, 230 HIV …"
Yana Bromberg,An interdisciplinary perspective of the built-environment microbiome,2024,https://academic.oup.com/femsec/advance-article/doi/10.1093/femsec/fiae166/7929019,"The built environment provides an excellent setting for interdisciplinary research on the dynamics of microbial communities. The system is simplified compared to many natural settings, and to some extent the entire environment can be manipulated, from architectural design to materials use, air flow, human traffic, and capacity to disrupt microbial communities through cleaning. Here, we provide an overview of the ecology of the microbiome in the built environment. We address niche space and refugia, population, and community (metagenomic) dynamics, spatial ecology within a building, including the major microbial transmission mechanisms, as well as evolution. We also address landscape ecology, connecting microbiomes between physically separated buildings. At each stage, we pay particular attention to the actual and potential interface between disciplines, such as ecology, epidemiology, materials …"
Yana Bromberg,Deciphering enzymatic potential in metagenomic reads through DNA language model,2024,https://www.biorxiv.org/content/10.1101/2024.12.10.627786.abstract,"The microbial world plays a fundamental role in shaping Earth’s biosphere, steering global processes such as carbon and nitrogen cycling, soil rejuvenation, and ecological fortification. An overwhelming majority of microbial entities, however, remain unstudied. Metagenomics stands to elucidate this microbial “dark matter” by directly sequencing the microbial community DNA from environmental samples. Yet, our ability to explore these metagenomic sequences is limited to establishing their similarity to curated datasets of organisms or genes/proteins. Aside from the difficulties in establishing such similarity, the reference-based approaches, by definition, forgo discovery of any entities sufficiently unlike the reference collection.Presenting a paradigm shift, language model-based methods, offer promising avenues for reference-free analysis of meta-genomic reads. Here, we introduce two language models, a pretrained foundation model REMME, aimed at understanding the DNA context of metagenomic reads, and the finetuned REBEAN model for predicting the enzymatic potential encoded within the read-corresponding genes. By emphasizing function over gene identification, REBEAN is able to label known functions carried both by previously explored genes and by new (orphan) sequences. Furthermore, even though it is not explicitly trained to do so, REBEAN identifies the functionally relevant parts of a gene. Our comprehensive analysis highlights our models’ potential for metagenomic read annotation and unearthing of novel enzymes, thus enriching our understanding of microbial communities."
Yana Bromberg,Session Introduction: Precision Medicine: Multi-modal and multi-scale methods to promote mechanistic understanding of disease,2024,https://www.worldscientific.com/doi/abs/10.1142/9789819807024_0027,"Precision medicine focuses on developing treatments and preventative strategies tailored to an individual’s genomic profile, lifestyle, and environmental context. The Precision Medicine sessions at the Pacific Symposium on Biocomputing (PSB) have consistently spotlighted progress in this domain. Our 2025 manuscript collection features algorithmic innovations that integrate data across scales and diverse data modalities, presenting novel techniques to derive clinically relevant insights from molecular datasets. These studies highlight recent advances in technology and analytics and their application toward realizing the potential of precision medicine to enhance human health outcomes and extend lifespan."
Yana Bromberg,Session Introduction: Precision Medicine: Innovative methods for advanced understanding of molecular underpinnings of disease,2023,https://www.worldscientific.com/doi/abs/10.1142/9789811286421_0034,"Precision medicine, also often referred to as personalized medicine, targets the development of treatments and preventative measures specific to the individual’s genomic signatures, lifestyle, and environmental conditions. The series of Precision Medicine sessions in PSB has continuously highlighted the advances in this field. Our 2024 collection of manuscripts showcases algorithmic advances that integrate data from distinct modalities and introduce innovative approaches to extract new, medically relevant information from existing data. These evolving technology and analytical methods promise to bring closer the goals of precision medicine to improve health and increase lifespan."
Yana Bromberg,Tightening the (neural) net for protein structure prediction,2022,https://www.nature.com/articles/s41576-022-00481-w,"In this Journal Club article, Yana Bromberg discusses an early application of machine learning for protein structure prediction — a paper that shaped her career. It illustrates the value of ensuring that machine learning approaches are rooted in known biological principles."
Jinho D. Choi,The stem cell hypothesis: Dilemma behind multi-task learning with transformer encoders,2021,https://arxiv.org/abs/2109.06939,"Multi-task learning with transformer encoders (MTL) has emerged as a powerful technique to improve performance on closely-related tasks for both accuracy and efficiency while a question still remains whether or not it would perform as well on tasks that are distinct in nature. We first present MTL results on five NLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over single-task learning. We then conduct an extensive pruning analysis to show that a certain set of attention heads get claimed by most tasks during MTL, who interfere with one another to fine-tune those heads for their own objectives. Based on this finding, we propose the Stem Cell Hypothesis to reveal the existence of attention heads naturally talented for many tasks that cannot be jointly trained to create adequate embeddings for all of those tasks. Finally, we design novel parameter-free probes to justify our hypothesis and demonstrate how attention heads are transformed across the five tasks during MTL through label analysis."
Jinho D. Choi,Revealing the myth of higher-order inference in coreference resolution,2020,https://arxiv.org/abs/2009.12013,"This paper analyzes the impact of higher-order inference (HOI) on the task of coreference resolution. HOI has been adapted by almost all recent coreference resolution models without taking much investigation on its true effectiveness over representation learning. To make a comprehensive analysis, we implement an end-to-end coreference system as well as four HOI approaches, attended antecedent, entity equalization, span clustering, and cluster merging, where the latter two are our original methods. We find that given a high-performing encoder such as SpanBERT, the impact of HOI is negative to marginal, providing a new perspective of HOI to this task. Our best model using cluster merging shows the Avg-F1 of 80.2 on the CoNLL 2012 shared task dataset in English."
Jinho D. Choi,Nl-augmenter: A framework for task-sensitive natural language augmentation,2021,https://arxiv.org/abs/2112.02721,"Data augmentation is an important component in the robustness evaluation of models in natural language processing (NLP) and in enhancing the diversity of the data they are trained on. In this paper, we present NL-Augmenter, a new participatory Python-based natural language augmentation framework which supports the creation of both transformations (modifications to the data) and filters (data splits according to specific features). We describe the framework and an initial set of 117 transformations and 23 filters for a variety of natural language tasks. We demonstrate the efficacy of NL-Augmenter by using several of its transformations to analyze the robustness of popular natural language models. The infrastructure, datacards and robustness analysis results are available publicly on the NL-Augmenter repository (https://github.com/GEM-benchmark/NL-Augmenter)."
Jinho D. Choi,Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols,2020,https://arxiv.org/abs/2006.06110,"As conversational AI-based dialogue management has increasingly become a trending topic, the need for a standardized and reliable evaluation procedure grows even more pressing. The current state of affairs suggests various evaluation protocols to assess chat-oriented dialogue management systems, rendering it difficult to conduct fair comparative studies across different approaches and gain an insightful understanding of their values. To foster this research, a more robust evaluation protocol must be set in place. This paper presents a comprehensive synthesis of both automated and human evaluation methods on dialogue systems, identifying their shortcomings while accumulating evidence towards the most effective evaluation dimensions. A total of 20 papers from the last two years are surveyed to analyze three types of evaluation protocols: automated, static, and interactive. Finally, the evaluation dimensions used in these papers are compared against our expert evaluation on the system-user dialogue data collected from the Alexa Prize 2020."
Jinho D. Choi,Automatic text-based personality recognition on monologues and multiparty dialogues using attentive networks and contextual embeddings (student abstract),2020,https://aaai.org/ojs/index.php/AAAI/article/view/7182,"Previous works related to automatic personality recognition focus on using traditional classification models with linguistic features. However, attentive neural networks with contextual embeddings, which have achieved huge success in text classification, are rarely explored for this task. In this project, we have two major contributions. First, we create the first dialogue-based personality dataset, FriendsPersona, by annotating 5 personality traits of speakers from Friends TV Show through crowdsourcing. Second, we present a novel approach to automatic personality recognition using pre-trained contextual embeddings (BERT and RoBERTa) and attentive neural networks. Our models largely improve the state-of-art results on the monologue Essays dataset by 2.49%, and establish a solid benchmark on our FriendsPersona. By comparing results in two datasets, we demonstrate the challenges of modeling personality in multi-party dialogue."
Jinho D. Choi,Artificial intelligence chatbot performance in triage of ophthalmic conditions,2024,https://www.sciencedirect.com/science/article/pii/S000841822300234X,"Timely access to human expertise for affordable and efficient triage of ophthalmic conditions is inconsistent. With recent advancements in publicly available artificial intelligence (AI) chatbots, the lay public may turn to these tools for triage of ophthalmic complaints. Validation studies are necessary to evaluate the performance of AI chatbots as triage tools and inform the public regarding their safety.To evaluate the triage performance of AI chatbots for ophthalmic conditions.Cross-sectional study.Single centre.Ophthalmology trainees, OpenAI ChatGPT (GPT-4), Bing Chat, and WebMD Symptom Checker.Forty-four clinical vignettes representing common ophthalmic complaints were developed, and a standardized pathway of prompts was presented to each tool in March 2023. Primary outcomes were proportion of responses with the correct diagnosis listed in the …"
Jinho D. Choi,"Establishing Strong Baselines for the New Decade: Sequence Tagging, Syntactic and Semantic Parsing with BERT.",2020,https://cdn.aaai.org/ocs/18438/18438-79378-1-PB.pdf,"This paper presents new state-of-the-art models for three tasks, part-of-speech tagging, syntactic parsing, and semantic parsing, using the cutting-edge contextualized embedding framework known as BERT. For each task, we first replicate and simplify the current state-of-the-art approach to enhance its model efficiency. We then evaluate our simplified approaches on those three tasks using token embeddings generated by BERT. 12 datasets in both English and Chinese are used for our experiments. The BERT models outperform the previously best-performing models by 2.5% on average (7.5% for the most significant case). All models and source codes are available in public so that researchers can improve upon and utilize them to establish strong baselines for the next decade. We also provide a dedicated error analysis and extensive dissections in https://arxiv. org/abs/1908.04943."
Jinho D. Choi,"Development of digital voice biomarkers and associations with cognition, cerebrospinal biomarkers, and neural representation in early Alzheimer's disease",2023,https://alz-journals.onlinelibrary.wiley.com/doi/abs/10.1002/dad2.12393,"Advances in natural language processing (NLP), speech recognition, and machine learning (ML) allow the exploration of linguistic and acoustic changes previously difficult to measure. We developed processes for deriving lexical‐semantic and acoustic measures as Alzheimer's disease (AD) digital voice biomarkers.We collected connected speech, neuropsychological, neuroimaging, and cerebrospinal fluid (CSF) AD biomarker data from 92 cognitively unimpaired (40 Aβ+) and 114 impaired (63 Aβ+) participants. Acoustic and lexical‐semantic features were derived from audio recordings using ML approaches.Lexical‐semantic (area under the curve [AUC] = 0.80) and acoustic (AUC = 0.77) scores demonstrated higher diagnostic performance for detecting MCI compared to Boston Naming Test (AUC = 0.66). Only lexical‐semantic scores detected amyloid‐β status (p = 0.0003 …"
Jinho D. Choi,SMAT: An attention-based deep learning solution to the automation of schema matching,2021,https://link.springer.com/chapter/10.1007/978-3-030-82472-3_19,"Schema matching aims to identify the correspondences among attributes of database schemas. It is frequently considered as the most challenging and decisive stage existing in many contemporary web semantics and database systems. Low-quality algorithmic matchers fail to provide improvement while manually annotation consumes extensive human efforts. Further complications arise from data privacy in certain domains such as healthcare, where only schema-level matching should be used to prevent data leakage. For this problem, we propose SMAT, a new deep learning model based on state-of-the-art natural language processing techniques to obtain semantic mappings between source and target schemas using only the attribute name and description. SMAT avoids directly encoding domain knowledge about the source and target systems, which allows it to be more easily deployed across …"
Jinho D. Choi,Transformers to learn hierarchical contexts in multiparty dialogue for span-based question answering,2020,https://arxiv.org/abs/2004.03561,"We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue. First, three language modeling tasks are used to pre-train the transformers, token- and utterance-level language modeling and utterance order prediction, that learn both token and utterance embeddings for better understanding in dialogue contexts. Then, multi-task learning between the utterance prediction and the token span prediction is applied to fine-tune for span-based question answering (QA). Our approach is evaluated on the FriendsQA dataset and shows improvements of 3.8% and 1.4% over the two state-of-the-art transformer models, BERT and RoBERTa, respectively."
Jinho D. Choi,Emora: An inquisitive social chatbot who cares for you,2020,https://arxiv.org/abs/2009.04617,"Inspired by studies on the overwhelming presence of experience-sharing in human-human conversations, Emora, the social chatbot developed by Emory University, aims to bring such experience-focused interaction to the current field of conversational AI. The traditional approach of information-sharing topic handlers is balanced with a focus on opinion-oriented exchanges that Emora delivers, and new conversational abilities are developed that support dialogues that consist of a collaborative understanding and learning process of the partner's life experiences. We present a curated dialogue system that leverages highly expressive natural language templates, powerful intent classification, and ontology resources to provide an engaging and interesting conversational experience to every user."
Jinho D. Choi,Transformer-based context-aware sarcasm detection in conversation threads from social media,2020,https://arxiv.org/abs/2005.11424,"We present a transformer-based sarcasm detection model that accounts for the context from the entire conversation thread for more robust predictions. Our model uses deep transformer layers to perform multi-head attentions among the target utterance and the relevant context in the thread. The context-aware models are evaluated on two datasets from social media, Twitter and Reddit, and show 3.1% and 7.0% improvements over their baselines. Our best models give the F1-scores of 79.0% and 75.0% for the Twitter and Reddit datasets respectively, becoming one of the highest performing systems among 36 participants in this shared task."
Jinho D. Choi,Competence-level prediction and resume & job description matching using context-aware transformer models,2020,https://arxiv.org/abs/2011.02998,"This paper presents a comprehensive study on resume classification to reduce the time and labor needed to screen an overwhelming number of applications significantly, while improving the selection of suitable candidates. A total of 6,492 resumes are extracted from 24,933 job applications for 252 positions designated into four levels of experience for Clinical Research Coordinators (CRC). Each resume is manually annotated to its most appropriate CRC position by experts through several rounds of triple annotation to establish guidelines. As a result, a high Kappa score of 61% is achieved for inter-annotator agreement. Given this dataset, novel transformer-based classification models are developed for two tasks: the first task takes a resume and classifies it to a CRC level (T1), and the second task takes both a resume and a job description to apply and predicts if the application is suited to the job T2. Our best models using section encoding and multi-head attention decoding give results of 73.3% to T1 and 79.2% to T2. Our analysis shows that the prediction errors are mostly made among adjacent CRC levels, which are hard for even experts to distinguish, implying the practical value of our models in real HR platforms."
Jinho D. Choi,Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems,2022,https://arxiv.org/abs/2212.09180,"Despite tremendous advancements in dialogue systems, stable evaluation still requires human judgments producing notoriously high-variance metrics due to their inherent subjectivity. Moreover, methods and labels in dialogue evaluation are not fully standardized, especially for open-domain chats, with a lack of work to compare and assess the validity of those approaches. The use of inconsistent evaluation can misinform the performance of a dialogue system, which becomes a major hurdle to enhance it. Thus, a dimensional evaluation of chat-oriented open-domain dialogue systems that reliably measures several aspects of dialogue capabilities is desired. This paper presents a novel human evaluation method to estimate the rates of many dialogue system behaviors. Our method is used to evaluate four state-of-the-art open-domain dialogue systems and compared with existing approaches. The analysis demonstrates that our behavior method is more suitable than alternative Likert-style or comparative approaches for dimensional evaluation of these systems."
Jinho D. Choi,"Fabrice Harel-Canada, Antoine Honore, Ishan Jindal, Przemyslaw K",2021,https://scholar.google.com/scholar?cluster=16912720996457143833&hl=en&oi=scholarr,
Jinho D. Choi,Boosting cross-lingual transfer via self-learning with uncertainty estimation,2021,https://arxiv.org/abs/2109.00194,"Recent multilingual pre-trained language models have achieved remarkable zero-shot performance, where the model is only finetuned on one source language and directly evaluated on target languages. In this work, we propose a self-learning framework that further utilizes unlabeled data of target languages, combined with uncertainty estimation in the process to select high-quality silver labels. Three different uncertainties are adapted and analyzed specifically for the cross lingual transfer: Language Heteroscedastic/Homoscedastic Uncertainty (LEU/LOU), Evidential Uncertainty (EVI). We evaluate our framework with uncertainties on two cross-lingual tasks including Named Entity Recognition (NER) and Natural Language Inference (NLI) covering 40 languages in total, which outperforms the baselines significantly by 10 F1 on average for NER and 2.5 accuracy score for NLI."
Jinho D. Choi,Leveraging large language models for automated dialogue analysis,2023,https://arxiv.org/abs/2309.06490,"Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses. However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities."
Jinho D. Choi,Modeling task interactions in document-level joint entity and relation extraction,2022,https://arxiv.org/abs/2205.01909,"We target on the document-level relation extraction in an end-to-end setting, where the model needs to jointly perform mention extraction, coreference resolution (COREF) and relation extraction (RE) at once, and gets evaluated in an entity-centric way. Especially, we address the two-way interaction between COREF and RE that has not been the focus by previous work, and propose to introduce explicit interaction namely Graph Compatibility (GC) that is specifically designed to leverage task characteristics, bridging decisions of two tasks for direct task interference. Our experiments are conducted on DocRED and DWIE; in addition to GC, we implement and compare different multi-task settings commonly adopted in previous work, including pipeline, shared encoders, graph propagation, to examine the effectiveness of different interactions. The result shows that GC achieves the best performance by up to 2.3/5.1 F1 improvement over the baseline."
Jinho D. Choi,Emora stdm: A versatile framework for innovative dialogue system development,2020,https://arxiv.org/abs/2006.06143,"This demo paper presents Emora STDM (State Transition Dialogue Manager), a dialogue system development framework that provides novel workflows for rapid prototyping of chat-based dialogue managers as well as collaborative development of complex interactions. Our framework caters to a wide range of expertise levels by supporting interoperability between two popular approaches, state machine and information state, to dialogue management. Our Natural Language Expression package allows seamless integration of pattern matching, custom NLP modules, and database querying, that makes the workflows much more efficient. As a user study, we adopt this framework to an interdisciplinary undergraduate course where students with both technical and non-technical backgrounds are able to develop creative dialogue managers in a short period of time."
Jinho D. Choi,An approach to inference-driven dialogue management within a social chatbot,2021,https://arxiv.org/abs/2111.00570,"We present a chatbot implementing a novel dialogue management approach based on logical inference. Instead of framing conversation a sequence of response generation tasks, we model conversation as a collaborative inference process in which speakers share information to synthesize new knowledge in real time. Our chatbot pipeline accomplishes this modelling in three broad stages. The first stage translates user utterances into a symbolic predicate representation. The second stage then uses this structured representation in conjunction with a larger knowledge base to synthesize new predicates using efficient graph matching. In the third and final stage, our bot selects a small subset of predicates and translates them into an English response. This approach lends itself to understanding latent semantics of user inputs, flexible initiative taking, and responses that are novel and coherent with the dialogue context."
Jinho D. Choi,Adapted end-to-end coreference resolution system for anaphoric identities in dialogues,2021,https://arxiv.org/abs/2109.00185,"We present an effective system adapted from the end-to-end neural coreference resolution model, targeting on the task of anaphora resolution in dialogues. Three aspects are specifically addressed in our approach, including the support of singletons, encoding speakers and turns throughout dialogue interactions, and knowledge transfer utilizing existing resources. Despite the simplicity of our adaptation strategies, they are shown to bring significant impact to the final performance, with up to 27 F1 improvement over the baseline. Our final system ranks the 1st place on the leaderboard of the anaphora resolution track in the CRAC 2021 shared task, and achieves the best evaluation results on all four datasets."
Jinho D. Choi,Fantasycoref: Coreference resolution on fantasy literature through omniscient writer’s point of view,2021,https://aclanthology.org/2021.crac-1.3/,"This paper presents a new corpus and annotation guideline for a novel coreference resolution task on fictional texts, and analyzes its unique characteristics. FantasyCoref contains 211 stories of Grimms’ Fairy Tales and 3 other fantasy literature annotated in the omniscient writer’s point of view (OWV) to handle distinctive aspects in this genre. This task is more challenging than general coreference resolution in two ways. First, documents in our corpus are 2.5 times longer than the ones in OntoNotes, raising a new layer of difficulty in resolving long-distant referents. Second, annotation of literary styles and concepts raise several issues which are not sufficiently addressed in the existing annotation guidelines. Hence, considerations on such issues and the concept of OWV are necessary to achieve high inter-annotator agreement (IAA) in coreference resolution of fictional texts. We carefully conduct annotation tasks in four stages to ensure the quality of our annotation. As a result, a high IAA score of 87% is achieved using the standard coreference evaluation metric. Finally, state-of-the-art coreference resolution approaches are evaluated on our corpus. After training with our annotated dataset, there was a 2.59% and 3.06% improvement over the model trained on the OntoNotes dataset. Also, we observe that the portion of errors specific to fictional texts declines after the training."
Jinho D. Choi,UMR-writer: A web application for annotating uniform meaning representations,2021,https://aclanthology.org/2021.emnlp-demo.19/,"We present UMR-Writer, a web-based application for annotating Uniform Meaning Representations (UMR), a graph-based, cross-linguistically applicable semantic representation developed recently to support the development of interpretable natural language applications that require deep semantic analysis of texts. We present the functionalities of UMR-Writer and discuss the challenges in developing such a tool and how they are addressed."
Jinho D. Choi,Adaptation of multilingual transformer encoder for robust enhanced universal dependency parsing,2020,https://aclanthology.org/2020.iwpt-1.19/,"This paper presents our enhanced dependency parsing approach using transformer encoders, coupled with a simple yet powerful ensemble algorithm that takes advantage of both tree and graph dependency parsing. Two types of transformer encoders are compared, a multilingual encoder and language-specific encoders. Our dependency tree parsing (DTP) approach generates only primary dependencies to form trees whereas our dependency graph parsing (DGP) approach handles both primary and secondary dependencies to form graphs. Since DGP does not guarantee the generated graphs are acyclic, the ensemble algorithm is designed to add secondary arcs predicted by DGP to primary arcs predicted by DTP. Our results show that models using the multilingual encoder outperform ones using the language specific encoders for most languages. The ensemble models generally show higher labeled attachment score on enhanced dependencies (ELAS) than the DTP and DGP models. As the result, our best models rank the third place on the macro-average ELAS over 17 languages."
Jinho D. Choi,Fedtherapist: Mental health monitoring with user-generated linguistic expressions on smartphones via federated learning,2023,https://arxiv.org/abs/2310.16538,"Psychiatrists diagnose mental disorders via the linguistic use of patients. Still, due to data privacy, existing passive mental health monitoring systems use alternative features such as activity, app usage, and location via mobile devices. We propose FedTherapist, a mobile mental health monitoring system that utilizes continuous speech and keyboard input in a privacy-preserving way via federated learning. We explore multiple model designs by comparing their performance and overhead for FedTherapist to overcome the complex nature of on-device language model training on smartphones. We further propose a Context-Aware Language Learning (CALL) methodology to effectively utilize smartphones' large and noisy text for mental health signal sensing. Our IRB-approved evaluation of the prediction of self-reported depression, stress, anxiety, and mood from 46 participants shows higher accuracy of FedTherapist compared with the performance with non-language features, achieving 0.15 AUROC improvement and 8.21% MAE reduction."
Jinho D. Choi,A cognitive approach to annotating causal constructions in a cross-genre corpus,2022,https://aclanthology.org/2022.law-1.18/,"We present a scheme for annotating causal language in various genres of text. Our annotation scheme is built on the popular categories of cause, enable, and prevent. These vague categories have many edge cases in natural language, and as such can prove difficult for annotators to consistently identify in practice. We introduce a decision based annotation method for handling these edge cases. We demonstrate that, by utilizing this method, annotators are able to achieve inter-annotator agreement which is comparable to that of previous studies. Furthermore, our method performs equally well across genres, highlighting the robustness of our annotation scheme. Finally, we observe notable variation in usage and frequency of causal language across different genres."
Jinho D. Choi,"Ingyu, Choi, Xiangjue Dong, Ruixiang Qi, Harshita Sahijwani, Sergey Volokhin, Zihan Wang, Zihao Wang, and Jinho D",2020,https://scholar.google.com/scholar?cluster=11709530071459045207&hl=en&oi=scholarr,
Jinho D. Choi,ConvoSense: Overcoming Monotonous Commonsense Inferences for Conversational AI,2024,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00659/120913,"Mastering commonsense understanding and reasoning is a pivotal skill essential for conducting engaging conversations. While there have been several attempts to create datasets that facilitate commonsense inferences in dialogue contexts, existing datasets tend to lack in-depth details, restate information already present in the conversation, and often fail to capture the multifaceted nature of commonsense reasoning. In response to these limitations, we compile a new synthetic dataset for commonsense reasoning in dialogue contexts using GPT, ℂonvoense, that boasts greater contextual novelty, offers a higher volume of inferences per example, and substantially enriches the detail conveyed by the inferences. Our dataset contains over 500,000 inferences across 12,000 dialogues with 10 popular inference types, which empowers the training of generative commonsense models for dialogue that are superior in …"
Jinho D. Choi,Evaluation of unsupervised entity and event salience estimation,2021,https://arxiv.org/abs/2104.06924,"Salience Estimation aims to predict term importance in documents. Due to few existing human-annotated datasets and the subjective notion of salience, previous studies typically generate pseudo-ground truth for evaluation. However, our investigation reveals that the evaluation protocol proposed by prior work is difficult to replicate, thus leading to few follow-up studies existing. Moreover, the evaluation process is problematic: the entity linking tool used for entity matching is very noisy, while the ignorance of event argument for event evaluation leads to boosted performance. In this work, we propose a light yet practical entity and event salience estimation evaluation protocol, which incorporates the more reliable syntactic dependency parser. Furthermore, we conduct a comprehensive analysis among popular entity and event definition standards, and present our own definition for the Salience Estimation task to reduce noise during the pseudo-ground truth generation process. Furthermore, we construct dependency-based heterogeneous graphs to capture the interactions of entities and events. The empirical results show that both baseline methods and the novel GNN method utilizing the heterogeneous graph consistently outperform the previous SOTA model in all proposed metrics."
Jinho D. Choi,ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models,2024,https://arxiv.org/abs/2407.07313,"The task of Text-to-SQL enables anyone to retrieve information from SQL databases using natural language. Despite several challenges, recent models have made remarkable advancements in this task using large language models (LLMs). Interestingly, we find that LLM-based models without fine-tuning exhibit distinct natures compared to their fine-tuned counterparts, leading to inadequacies in current evaluation metrics to accurately convey their performance. Thus, we analyze the two primary metrics, Test Suite Execution Accuracy (EXE) and Exact Set Matching Accuracy (ESM), to examine their robustness for this task and address shortcomings. We compare the performance of 9 LLM-based models using EXE, the original ESM, and our improved ESM (called ESM+). Our results show that EXE and ESM have high false positive and negative rates of 11.3% and 13.9%, while ESM+ gives those of 0.1% and 2.6% respectively, providing a significantly more stable evaluation. We release the ESM+ script as open-source for the community to contribute, while enjoying a more reliable assessment of Text-to-SQL."
Jinho D. Choi,Towards open-world product attribute mining: A lightly-supervised approach,2023,https://arxiv.org/abs/2305.18350,"We present a new task setting for attribute mining on e-commerce products, serving as a practical solution to extract open-world attributes without extensive human intervention. Our supervision comes from a high-quality seed attribute set bootstrapped from existing resources, and we aim to expand the attribute vocabulary of existing seed types, and also to discover any new attribute types automatically. A new dataset is created to support our setting, and our approach Amacer is proposed specifically to tackle the limited supervision. Especially, given that no direct supervision is available for those unseen new attributes, our novel formulation exploits self-supervised heuristic and unsupervised latent attributes, which attains implicit semantic signals as additional supervision by leveraging product context. Experiments suggest that our approach surpasses various baselines by 12 F1, expanding attributes of existing types significantly by up to 12 times, and discovering values from 39% new types."
Jinho D. Choi,Predicting kidney transplant recipient cohorts’ 30-day rehospitalization using clinical notes and electronic health care record data,2023,https://www.sciencedirect.com/science/article/pii/S2468024922019015,"Rehospitalization after kidney transplant is costly to patients and health care systems and is associated with poor outcomes. Few prediction model studies have examined whether inclusion of clinical notes data from the electronic medical record (EMR) enhances prediction of rehospitalization.In a retrospective, observational study of first-time, adult kidney transplant recipients at a large, urban hospital in southeastern United States (2005−2015), we examined 30-day rehospitalization (30DR) using structured EMR and unstructured (i.e., clinical notes) data. We used natural language processing (NLP) methods on 8 types of clinical notes and included terms in predictive models using unsupervised machine learning approaches. Both the area under the receiver operating curve and precision-recall curve (ROC and PRC, respectively) were used to determine and compare model accuracy, and 5 …"
Jinho D. Choi,Analysis of hierarchical multi-content text classification model on B-SHARP dataset for early detection of Alzheimer’s disease,2020,https://aclanthology.org/2020.aacl-main.38/,"This paper presents a new dataset, B-SHARP, that can be used to develop NLP models for the detection of Mild Cognitive Impairment (MCI) known as an early sign of Alzheimer’s disease. Our dataset contains 1-2 min speech segments from 326 human subjects for 3 topics,(1) daily activity,(2) room environment, and (3) picture description, and their transcripts so that a total of 650 speech segments are collected. Given the B-SHARP dataset, several hierarchical text classification models are developed that jointly learn combinatory features across all 3 topics. The best performance of 74.1% is achieved by an ensemble model that adapts 3 types of transformer encoders. To the best of our knowledge, this is the first work that builds deep learning-based text classification models on multiple contents for the detection of MCI."
Jinho D. Choi,Analysis of the Penn Korean Universal Dependency treebank (PKT-UD): Manual revision to build robust parsing model in Korean,2020,https://arxiv.org/abs/2005.12898,"In this paper, we first open on important issues regarding the Penn Korean Universal Treebank (PKT-UD) and address these issues by revising the entire corpus manually with the aim of producing cleaner UD annotations that are more faithful to Korean grammar. For compatibility to the rest of UD corpora, we follow the UDv2 guidelines, and extensively revise the part-of-speech tags and the dependency relations to reflect morphological features and flexible word-order aspects in Korean. The original and the revised versions of PKT-UD are experimented with transformer-based parsing models using biaffine attention. The parsing model trained on the revised corpus shows a significant improvement of 3.0% in labeled attachment score over the model trained on the previous corpus. Our error analysis demonstrates that this revision allows the parsing model to learn relations more robustly, reducing several critical errors that used to be made by the previous model."
Jinho D. Choi,Unleashing the true potential of sequence-to-sequence models for sequence tagging and structure parsing,2023,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00557/116469,"Sequence-to-Sequence (S2S) models have achieved remarkable success on various text generation tasks. However, learning complex structures with S2S models remains challenging as external neural modules and additional lexicons are often supplemented to predict non-textual outputs. We present a systematic study of S2S modeling using contained decoding on four core tasks: part-of-speech tagging, named entity recognition, constituency, and dependency parsing, to develop efficient exploitation methods costing zero extra parameters. In particular, 3 lexically diverse linearization schemas and corresponding constrained decoding methods are designed and evaluated. Experiments show that although more lexicalized schemas yield longer output sequences that require heavier training, their sequences being closer to natural language makes them easier to learn. Moreover, S2S models using our …"
Jinho D. Choi,Online coreference resolution for dialogue processing: Improving mention-linking on real-time conversations,2022,https://arxiv.org/abs/2205.10670,"This paper suggests a direction of coreference resolution for online decoding on actively generated input such as dialogue, where the model accepts an utterance and its past context, then finds mentions in the current utterance as well as their referents, upon each dialogue turn. A baseline and four incremental-updated models adapted from the mention-linking paradigm are proposed for this new setting, which address different aspects including the singletons, speaker-grounded encoding and cross-turn mention contextualization. Our approach is assessed on three datasets: Friends, OntoNotes, and BOLT. Results show that each aspect brings out steady improvement, and our best models outperform the baseline by over 10%, presenting an effective system for this setting. Further analysis highlights the task characteristics, such as the significance of addressing the mention recall."
Jinho D. Choi,Noise pollution in hospital readmission prediction: long document classification with reinforcement learning,2020,https://arxiv.org/abs/2005.01259,"This paper presents a reinforcement learning approach to extract noise in long clinical documents for the task of readmission prediction after kidney transplant. We face the challenges of developing robust models on a small dataset where each document may consist of over 10K tokens with full of noise including tabular text and task-irrelevant sentences. We first experiment four types of encoders to empirically decide the best document representation, and then apply reinforcement learning to remove noisy text from the long documents, which models the noise extraction process as a sequential decision problem. Our results show that the old bag-of-words encoder outperforms deep learning-based encoders on this task, and reinforcement learning is able to improve upon baseline while pruning out 25% text segments. Our analysis depicts that reinforcement learning is able to identify both typical noisy tokens and task-specific noisy text."
Jinho D. Choi,Widely interpretable semantic representation: Frameless meaning representation for broader applicability,2023,https://arxiv.org/abs/2309.06460,"This paper presents a novel semantic representation, WISeR, that overcomes challenges for Abstract Meaning Representation (AMR). Despite its strengths, AMR is not easily applied to languages or domains without predefined semantic frames, and its use of numbered arguments results in semantic role labels, which are not directly interpretable and are semantically overloaded for parsers. We examine the numbered arguments of predicates in AMR and convert them to thematic roles that do not require reference to semantic frames. We create a new corpus of 1K English dialogue sentences annotated in both WISeR and AMR. WISeR shows stronger inter-annotator agreement for beginner and experienced annotators, with beginners becoming proficient in WISeR annotation more quickly. Finally, we train a state-of-the-art parser on the AMR 3.0 corpus and a WISeR corpus converted from AMR 3.0. The parser is evaluated on these corpora and our dialogue corpus. The WISeR model exhibits higher accuracy than its AMR counterpart across the board, demonstrating that WISeR is easier for parsers to learn."
Jinho D. Choi,Automatic generation of large-scale multi-turn dialogues from reddit,2022,https://aclanthology.org/2022.coling-1.297/,"This paper presents novel methods to automatically convert posts and their comments from discussion forums such as Reddit into multi-turn dialogues. Our methods are generalizable to any forums; thus, they allow us to generate a massive amount of dialogues for diverse topics that can be used to pretrain language models. Four methods are introduced, Greedy_Baseline, Greedy_Advanced, Beam Search and Threading, which are applied to posts from 10 subreddits and assessed. Each method makes a noticeable improvement over its predecessor such that the best method shows an improvement of 36.3% over the baseline for appropriateness. Our best method is applied to posts from those 10 subreddits for the creation of a corpus comprising 10,098 dialogues (3.3 M tokens), 570 of which are compared against dialogues in three other datasets, Blended Skill Talk, Daily Dialogue, and Topical Chat. Our dialogues are found to be more engaging but slightly less natural than the ones in the other datasets, while it costs a fraction of human labor and money to generate our corpus compared to the others. To the best of our knowledge, it is the first work to create a large multi-turn dialogue corpus from Reddit that can advance neural dialogue systems."
Jinho D. Choi,Analysis of zero-shot crosslingual learning between English and Korean for named entity recognition,2021,https://aclanthology.org/2021.mrl-1.19/,"This paper presents a English-Korean parallel dataset that collects 381K news articles where 1,400 of them, comprising 10K sentences, are manually labeled for crosslingual named entity recognition (NER). The annotation guidelines for the two languages are developed in parallel, that yield the inter-annotator agreement scores of 91 and 88% for English and Korean respectively, indicating sublime quality annotation in our dataset. Three types of crosslingual learning approaches, direct model transfer, embedding projection, and annotation projection, are used to develop zero-shot Korean NER models. Our best model gives the F1-score of 51% that is very encouraging, considering the extremely distinct natures of these two languages. This is pioneering work that explores zero-shot cross-lingual learning between English and Korean and provides rich parallel annotation for a core NLP task such as named entity recognition."
Jinho D. Choi,Intensionalizing Abstract Meaning Representations: Non-Veridicality and Scope,2021,https://arxiv.org/abs/2109.09858,"Meaning Representation (AMR) is a graphical meaning representation language designed to represent propositional information about argument structure. However, at present it is unable to satisfyingly represent non-veridical intensional contexts, often licensing inappropriate inferences. In this paper, we show how to resolve the problem of non-veridicality without appealing to layered graphs through a mapping from AMRs into Simply-Typed Lambda Calculus (STLC). At least for some cases, this requires the introduction of a new role :content which functions as an intensional operator. The translation proposed is inspired by the formal linguistics literature on the event semantics of attitude reports. Next, we address the interaction of quantifier scope and intensional operators in so-called de re/de dicto ambiguities. We adopt a scope node from the literature and provide an explicit multidimensional semantics utilizing Cooper storage which allows us to derive the de re and de dicto scope readings as well as intermediate scope readings which prove difficult for accounts without a scope node."
Jinho D. Choi,Streamside: A fully-customizable open-source toolkit for efficient annotation of meaning representations,2021,https://arxiv.org/abs/2109.09853,"This demonstration paper presents StreamSide, an open-source toolkit for annotating multiple kinds of meaning representations. StreamSide supports frame-based annotation schemes e.g., Abstract Meaning Representation (AMR) and frameless annotation schemes e.g., Widely Interpretable Semantic Representation (WISeR). Moreover, it supports both sentence-level and document-level annotation by allowing annotators to create multi-rooted graphs for input text. It can open and automatically convert between several types of input formats including plain text, Penman notation, and its own JSON format enabling richer annotation. It features reference frames for AMR predicate argument structures, and also concept-to-text alignment. StreamSide is released under the Apache 2.0 license, and is completely open-source so that it can be customized to annotate enriched meaning representations in different languages (e.g., Uniform Meaning Representations). All StreamSide resources are publicly distributed through our open source project at: https://github.com/emorynlp/StreamSide."
Jinho D. Choi,Elit: Emory language and information toolkit,2021,https://arxiv.org/abs/2109.03903,"We introduce ELIT, the Emory Language and Information Toolkit, which is a comprehensive NLP framework providing transformer-based end-to-end models for core tasks with a special focus on memory efficiency while maintaining state-of-the-art accuracy and speed. Compared to existing toolkits, ELIT features an efficient Multi-Task Learning (MTL) model with many downstream tasks that include lemmatization, part-of-speech tagging, named entity recognition, dependency parsing, constituency parsing, semantic role labeling, and AMR parsing. The backbone of ELIT's MTL framework is a pre-trained transformer encoder that is shared across tasks to speed up their inference. ELIT provides pre-trained models developed on a remix of eight datasets. To scale up its service, ELIT also integrates a RESTful Client/Server combination. On the server side, ELIT extends its functionality to cover other tasks such as tokenization and coreference resolution, providing an end user with agile research experience. All resources including the source codes, documentation, and pre-trained models are publicly available at https://github.com/emorynlp/elit."
Jinho D. Choi,Levi graph AMR parser using heterogeneous attention,2021,https://arxiv.org/abs/2107.04152,"Coupled with biaffine decoders, transformers have been effectively adapted to text-to-graph transduction and achieved state-of-the-art performance on AMR parsing. Many prior works, however, rely on the biaffine decoder for either or both arc and label predictions although most features used by the decoder may be learned by the transformer already. This paper presents a novel approach to AMR parsing by combining heterogeneous data (tokens, concepts, labels) as one input to a transformer to learn attention, and use only attention matrices from the transformer to predict all elements in AMR graphs (concepts, arcs, labels). Although our models use significantly fewer parameters than the previous state-of-the-art graph parser, they show similar or better accuracy on AMR 2.0 and 3.0."
Jinho D. Choi,Automating PTSD Diagnostics in Clinical Interviews: Leveraging Large Language Models for Trauma Assessments,2024,https://arxiv.org/abs/2405.11178,"The shortage of clinical workforce presents significant challenges in mental healthcare, limiting access to formal diagnostics and services. We aim to tackle this shortage by integrating a customized large language model (LLM) into the workflow, thus promoting equity in mental healthcare for the general population. Although LLMs have showcased their capability in clinical decision-making, their adaptation to severe conditions like Post-traumatic Stress Disorder (PTSD) remains largely unexplored. Therefore, we collect 411 clinician-administered diagnostic interviews and devise a novel approach to obtain high-quality data. Moreover, we build a comprehensive framework to automate PTSD diagnostic assessments based on interview contents by leveraging two state-of-the-art LLMs, GPT-4 and Llama-2, with potential for broader clinical diagnoses. Our results illustrate strong promise for LLMs, tested on our dataset, to aid clinicians in diagnostic validation. To the best of our knowledge, this is the first AI system that fully automates assessments for mental illness based on clinician-administered interviews."
Jinho D. Choi,Exploring a multi-layered cross-genre corpus of document-level semantic relations,2023,https://www.mdpi.com/2078-2489/14/8/431,"This paper introduces a multi-layered cross-genre corpus, annotated for coreference resolution, causal relations, and temporal relations, comprising a variety of genres, from news articles and children’s stories to Reddit posts. Our results reveal distinctive genre-specific characteristics at each layer of annotation, highlighting unique challenges for both annotators and machine learning models. Children’s stories feature linear temporal structures and clear causal relations. In contrast, news articles employ non-linear temporal sequences with minimal use of explicit causal or conditional language and few first-person pronouns. Lastly, Reddit posts are author-centered explanations of ongoing situations, with occasional meta-textual reference. Our annotation schemes are adapted from existing work to better suit a broader range of text types. We argue that our multi-layered cross-genre corpus not only reveals genre-specific semantic characteristics but also indicates a rich contextual interplay between the various layers of semantic information. Our MLCG corpus is shared under the open-source Apache 2.0 license."
Jinho D. Choi,COVID-19 pandemic-associated changes in the acuity of brain MRI findings: a secondary analysis of reports using natural language processing,2022,https://www.sciencedirect.com/science/article/pii/S0363018821001894,"Rationale and ObjectivesWe aimed to assess early COVID-19 pandemic-associated changes in brain MRI examination frequency and acuity of imaging findings acuity.MethodsUsing a natural language processing model, we retrospectively categorized reported findings of 12,346 brain MRI examinations performed during 6-month pre-pandemic and early pandemic time periods across a large metropolitan health system into 3 acuity levels: (1) normal or near normal; (2) incidental or chronic findings not requiring a management change; and (3) new or progressive findings requiring a management change. Brain MRI frequency and imaging finding acuity level were compared over time.ResultsBetween March and August of 2019 (pre-pandemic) and 2020 (early pandemic), our health system brain MRI examination volumes decreased 17.0% (6745 vs 5601). Comparing calendar-matched 6-month periods, the …"
Jinho D. Choi,Zero-shot cross-lingual machine reading comprehension via inter-sentence dependency graph,2022,https://ojs.aaai.org/index.php/AAAI/article/view/21407,"We target the task of cross-lingual Machine Reading Comprehension (MRC) in the direct zero-shot setting, by incorporating syntactic features from Universal Dependencies (UD), and the key features we use are the syntactic relations within each sentence. While previous work has demonstrated effective syntax-guided MRC models, we propose to adopt the inter-sentence syntactic relations, in addition to the rudimentary intra-sentence relations, to further utilize the syntactic dependencies in the multi-sentence input of the MRC task. In our approach, we build the Inter-Sentence Dependency Graph (ISDG) connecting dependency trees to form global syntactic relations across sentences. We then propose the ISDG encoder that encodes the global dependency graph, addressing the inter-sentence relations via both one-hop and multi-hop dependency paths explicitly. Experiments on three multilingual MRC datasets (XQuAD, MLQA, TyDiQA-GoldP) show that our encoder that is only trained on English is able to improve the zero-shot performance on all 14 test sets covering 8 languages, with up to 3.8 F1/5.2 EM improvement on-average, and 5.2 F1/11.2 EM on certain languages. Further analysis shows the improvement can be attributed to the attention on the cross-linguistically consistent syntactic path. Our code is available at https://github. com/lxucs/multilingual-mrc-isdg."
Jinho D. Choi,View distillation with unlabeled data for extracting adverse drug effects from user-generated data,2021,https://arxiv.org/abs/2105.11354,"We present an algorithm based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data. Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents. Then a classifier is trained on each view to label a set of unlabeled documents to be used as an initializer for a new classifier in the other view. Finally, the initialized classifier in each view is further trained using the initial training examples. We evaluated our model in the largest publicly available ADR dataset. The experiments testify that our model significantly outperforms the transformer-based models pretrained on domain-specific data."
Jinho D. Choi,"What Is Your Favorite Gender, MLM? Gender Bias Evaluation in Multilingual Masked Language Models",2024,https://www.mdpi.com/2078-2489/15/9/549,"Bias is a disproportionate prejudice in favor of one side against another. Due to the success of transformer-based masked language models (MLMs) and their impact on many NLP tasks, a systematic evaluation of bias in these models is now needed more than ever. While many studies have evaluated gender bias in English MLMs, only a few have explored gender bias in other languages. This paper proposes a multilingual approach to estimating gender bias in MLMs from five languages: Chinese, English, German, Portuguese, and Spanish. Unlike previous work, our approach does not depend on parallel corpora coupled with English to detect gender bias in other languages using multilingual lexicons. Moreover, a novel model-based method is presented to generate sentence pairs for a more robust analysis of gender bias. For each language, lexicon-based and model-based methods are applied to create two datasets, which are used to evaluate gender bias in an MLM specifically trained for that language using one existing and three new scoring metrics. Our results show that the previous approach is data-sensitive and unstable, suggesting that gender bias should be assessed on a large dataset using multiple evaluation metrics for best practice."
Jinho D. Choi,Aligning Speakers: Evaluating and Visualizing Text-based Speaker Diarization Using Efficient Multiple Sequence Alignment,2023,https://ieeexplore.ieee.org/abstract/document/10356536/,"This paper presents a novel evaluation approach to text-based speaker diarization (SD), tackling the limitations of traditional metrics that do not account for any contextual information in text. Two new metrics are proposed, Text-based Diarization Error Rate and Diarization F1, which perform utterance- and word-level evaluations by aligning tokens in reference and hypothesis transcripts. Our metrics encompass more types of errors compared to existing ones, allowing us to make a more comprehensive analysis in SD. To align tokens, a multiple sequence alignment algorithm is introduced that supports multiple sequences in the reference while handling high-dimensional alignment to the hypothesis using dynamic programming. Our work is packaged into two tools, align4d, providing an API for our alignment algorithm and TranscribeView for visualizing and evaluating SD errors, which can greatly aid in the creation of …"
Jinho D. Choi,Condition-Treatment Relation Extraction on Disease-related Social Media Data,2022,https://aclanthology.org/2022.louhi-1.24/,"Social media has become a popular platform where people share information about personal healthcare conditions, diagnostic histories, and medical plans. Analyzing posts on social media depicting such realistic information can help improve quality and clinical decision-making; however, the lack of structured resources in this genre limits us to build robust NLP models for meaningful analysis. This paper presents a new corpus annotating relations among many types of conditions, treatments, and their attributes illustrated in social media posts by patients and caregivers. For experiments, a transformer encoder is pretrained on 1M raw posts and used to train several document-level relation extraction models using our corpus. Our best-performing model achieves the F1 scores of 70.9 and 51.7 for Entity Recognition and Relation Extraction, respectively. These results are encouraging as it is the first neural model extracting complex relations of this kind on social media data."
Jinho D. Choi,Automatic Enrichment of Abstract Meaning Representations,2022,https://aclanthology.org/2022.law-1.19/,"Meaning Representation (AMR) is a semantic graph framework which inadequately represent a number of important semantic features including number,(in) definiteness, quantifiers, and intensional contexts. Several proposals have been made to improve the representational adequacy of AMR by enriching its graph structure. However, these modifications are rarely added to existing AMR corpora due to the labor costs associated with manual annotation. In this paper, we develop an automated annotation tool which algorithmically enriches AMR graphs to better represent number,(in) definite articles, quantificational determiners, and intensional arguments. We compare our automatically produced annotations to gold-standard manual annotations and show that our automatic annotator achieves impressive results. All code for this paper, including our automatic annotation tool, is made publicly available."
Jinho D. Choi,Finding A Voice: Evaluating African American Dialect Generation for Chatbot Technology,2025,https://arxiv.org/abs/2501.03441,"As chatbots become increasingly integrated into everyday tasks, designing systems that accommodate diverse user populations is crucial for fostering trust, engagement, and inclusivity. This study investigates the ability of contemporary Large Language Models (LLMs) to generate African American Vernacular English (AAVE) and evaluates the impact of AAVE usage on user experiences in chatbot applications. We analyze the performance of three LLM families (Llama, GPT, and Claude) in producing AAVE-like utterances at varying dialect intensities and assess user preferences across multiple domains, including healthcare and education. Despite LLMs' proficiency in generating AAVE-like language, findings indicate that AAVE-speaking users prefer Standard American English (SAE) chatbots, with higher levels of AAVE correlating with lower ratings for a variety of characteristics, including chatbot trustworthiness and role appropriateness. These results highlight the complexities of creating inclusive AI systems and underscore the need for further exploration of diversity to enhance human-computer interactions."
Jinho D. Choi,Enhancing Task-Oriented Dialogue Systems through Synchronous Multi-Party Interaction and Multi-Group Virtual Simulation,2024,https://www.mdpi.com/2078-2489/15/9/580,"This paper presents two innovative approaches: a synchronous multi-party dialogue system that engages in simultaneous interactions with multiple users, and multi-group simulations involving virtual user groups to evaluate the resilience of this system. Unlike most other chatbots that communicate with each user independently, our system facilitates information gathering from multiple users and executes 17 administrative tasks for group requests adeptly by leveraging a state machine-based framework for complete control over dialogue flow and a large language model (LLM) for robust context understanding. Assessing such a unique dialogue system poses challenges, as it requires many groups of users to interact with the system concurrently for an extended duration. To address this, we simulate various virtual groups using an LLM, each comprising 10–30 users who may belong to multiple groups, in order to evaluate the efficacy of our system; each user is assigned a persona and allowed to interact freely without scripts. As a result, our system shows average success rates of 87% for task completion and 89% for natural language understanding. Comparatively, our virtual simulation, which has an average success rate of 80%, is juxtaposed with a group of 15 human users, depicting similar task diversity and error trends. To our knowledge, it is the first work to show the LLM’s potential in both task execution and the simulation of a synchronous dialogue system to fully automate administrative tasks."
Jinho D. Choi,Transforming slot schema induction with generative dialogue state inference,2024,https://arxiv.org/abs/2408.01638,"The challenge of defining a slot schema to represent the state of a task-oriented dialogue system is addressed by Slot Schema Induction (SSI), which aims to automatically induce slots from unlabeled dialogue data. Whereas previous approaches induce slots by clustering value spans extracted directly from the dialogue text, we demonstrate the power of discovering slots using a generative approach. By training a model to generate slot names and values that summarize key dialogue information with no prior task knowledge, our SSI method discovers high-quality candidate information for representing dialogue state. These discovered slot-value candidates can be easily clustered into unified slot schemas that align well with human-authored schemas. Experimental comparisons on the MultiWOZ and SGD datasets demonstrate that Generative Dialogue State Inference (GenDSI) outperforms the previous state-of-the-art on multiple aspects of the SSI task."
Jinho D. Choi,Leveraging Explicit Reasoning for Inference Integration in Commonsense-Augmented Dialogue Models,2024,https://arxiv.org/abs/2406.09138,"Open-domain dialogue systems need to grasp social commonsense to understand and respond effectively to human users. Commonsense-augmented dialogue models have been proposed that aim to infer commonsense knowledge from dialogue contexts in order to improve response quality. However, existing approaches to commonsense-augmented dialogue rely on implicit reasoning to integrate commonsense inferences during response generation. In this study, we explore the impact of explicit reasoning against implicit reasoning over commonsense for dialogue response generation. Our findings demonstrate that separating commonsense reasoning into explicit steps for generating, selecting, and integrating commonsense into responses leads to better dialogue interactions, improving naturalness, engagement, specificity, and overall quality. Subsequent analyses of these findings unveil insights into the effectiveness of various types of commonsense in generating responses and the particular response traits enhanced through explicit reasoning for commonsense integration. Our work advances research in open-domain dialogue by achieving a new state-of-the-art in commonsense-augmented response generation."
Jinho D. Choi,Diverse and effective synthetic data generation for adaptable zero-shot dialogue state tracking,2024,https://arxiv.org/abs/2405.12468,"We demonstrate substantial performance gains in zero-shot dialogue state tracking (DST) by enhancing training data diversity through synthetic data generation. Existing DST datasets are severely limited in the number of application domains and slot types they cover due to the high costs of data collection, restricting their adaptability to new domains. This work addresses this challenge with a novel, fully automatic data generation approach that creates synthetic zero-shot DST datasets. Distinguished from previous methods, our approach can generate dialogues across a massive range of application domains, complete with silver-standard dialogue state annotations and slot descriptions. This technique is used to create the D0T dataset for training zero-shot DST models, encompassing an unprecedented 1,000+ domains. Experiments on the MultiWOZ benchmark show that training models on diverse synthetic data improves Joint Goal Accuracy by 6.7%, achieving results competitive with models 13.5 times larger than ours."
Jinho D. Choi,Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue State Tracking,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240512468F/abstract,"This work demonstrates that substantial gains in zero-shot dialogue state tracking (DST) accuracy can be achieved by increasing the diversity of training data using synthetic data generation techniques. Current DST training resources are severely limited in the number of application domains and slot types they cover due to the high costs of data collection, resulting in limited adaptability to new domains. The presented work overcomes this challenge using a novel, fully automatic data generation approach to create synthetic zero-shot DST training resources. Unlike previous approaches for generating DST data, the presented approach generates entirely new application domains to generate dialogues, complete with silver dialogue state annotations and slot descriptions. This approach is used to create the D0T dataset for training zero-shot DST models, which covers an unprecedented 1,000+ domains. Experiments …"
Jinho D. Choi,Aligning speakers: Evaluating and visualizing text-based diarization using efficient multiple sequence alignment (extended version),2023,https://arxiv.org/abs/2309.07677,"This paper presents a novel evaluation approach to text-based speaker diarization (SD), tackling the limitations of traditional metrics that do not account for any contextual information in text. Two new metrics are proposed, Text-based Diarization Error Rate and Diarization F1, which perform utterance- and word-level evaluations by aligning tokens in reference and hypothesis transcripts. Our metrics encompass more types of errors compared to existing ones, allowing us to make a more comprehensive analysis in SD. To align tokens, a multiple sequence alignment algorithm is introduced that supports multiple sequences in the reference while handling high-dimensional alignment to the hypothesis using dynamic programming. Our work is packaged into two tools, align4d providing an API for our alignment algorithm and TranscribeView for visualizing and evaluating SD errors, which can greatly aid in the creation of high-quality data, fostering the advancement of dialogue systems."
Jinho D. Choi,What went wrong? explaining overall dialogue quality through utterance-level impacts,2021,https://arxiv.org/abs/2111.00572,"Improving user experience of a dialogue system often requires intensive developer effort to read conversation logs, run statistical analyses, and intuit the relative importance of system shortcomings. This paper presents a novel approach to automated analysis of conversation logs that learns the relationship between user-system interactions and overall dialogue quality. Unlike prior work on utterance-level quality prediction, our approach learns the impact of each interaction from the overall user rating without utterance-level annotation, allowing resultant model conclusions to be derived on the basis of empirical evidence and at low cost. Our model identifies interactions that have a strong correlation with the overall dialogue quality in a chatbot setting. Experiments show that the automated analysis from our model agrees with expert judgments, making this work the first to show that such weakly-supervised learning of utterance-level quality prediction is highly achievable."
Jinho D. Choi,XD at SemEval-2020 Task 12: Ensemble approach to offensive language identification in social media using transformer encoders,2020,https://arxiv.org/abs/2007.10945,"This paper presents six document classification models using the latest transformer encoders and a high-performing ensemble model for a task of offensive language identification in social media. For the individual models, deep transformer layers are applied to perform multi-head attentions. For the ensemble model, the utterance representations taken from those individual models are concatenated and fed into a linear decoder to make the final decisions. Our ensemble model outperforms the individual models and shows up to 8.6% improvement over the individual models on the development set. On the test set, it achieves macro-F1 of 90.9% and becomes one of the high performing systems among 85 participants in the sub-task A of this shared task. Our analysis shows that although the ensemble model significantly improves the accuracy on the development set, the improvement is not as evident on the test set."
Jinho D. Choi,"Trustworthy Answers, Messier Data: Bridging the Gap in Low-Resource Retrieval-Augmented Generation for Domain Expert Systems",2025,https://arxiv.org/abs/2502.19596,"RAG has become a key technique for enhancing LLMs by reducing hallucinations, especially in domain expert systems where LLMs may lack sufficient inherent knowledge. However, developing these systems in low-resource settings introduces several challenges: (1) handling heterogeneous data sources, (2) optimizing retrieval phase for trustworthy answers, and (3) evaluating generated answers across diverse aspects. To address these, we introduce a data generation pipeline that transforms raw multi-modal data into structured corpus and Q&A pairs, an advanced re-ranking phase improving retrieval precision, and a reference matching algorithm enhancing answer traceability. Applied to the automotive engineering domain, our system improves factual correctness (+1.94), informativeness (+1.16), and helpfulness (+1.67) over a non-RAG baseline, based on a 1-5 scale by an LLM judge. These results highlight the effectiveness of our approach across distinct aspects, with strong answer grounding and transparency."
Jinho D. Choi,Exploring the Impact of Human Evaluator Group on Chat-Oriented Dialogue Evaluation,2023,https://arxiv.org/abs/2309.07998,"Human evaluation has been widely accepted as the standard for evaluating chat-oriented dialogue systems. However, there is a significant variation in previous work regarding who gets recruited as evaluators. Evaluator groups such as domain experts, university students, and professional annotators have been used to assess and compare dialogue systems, although it is unclear to what extent the choice of an evaluator group can affect results. This paper analyzes the evaluator group impact on dialogue system evaluation by testing 4 state-of-the-art dialogue systems using 4 distinct evaluator groups. Our analysis reveals a robustness towards evaluator groups for Likert evaluations that is not seen for Pairwise, with only minor differences observed when changing evaluator groups. Furthermore, two notable limitations to this robustness are observed, which reveal discrepancies between evaluators with different levels of chatbot expertise and indicate that evaluator objectivity is beneficial for certain dialogue metrics."
Jinho D. Choi,InterviewBot: Real-Time End-to-End Dialogue System for Interviewing Students for College Admission,2023,https://www.mdpi.com/2078-2489/14/8/460,"We present the InterviewBot, which dynamically integrates conversation history and customized topics into a coherent embedding space to conduct 10 min hybrid-domain (open and closed) conversations with foreign students applying to U.S. colleges to assess their academic and cultural readiness. To build a neural-based end-to-end dialogue model, 7361 audio recordings of human-to-human interviews are automatically transcribed, where 440 are manually corrected for finetuning and evaluation. To overcome the input/output size limit of a transformer-based encoder–decoder model, two new methods are proposed, context attention and topic storing, allowing the model to make relevant and consistent interactions. Our final model is tested both statistically by comparing its responses to the interview data and dynamically by inviting professional interviewers and various students to interact with it in real-time, finding it highly satisfactory in fluency and context awareness."
Jinho D. Choi,Incremental Sense Weight Training for In-Depth Interpretation of Contextualized Word Embeddings (Student Abstract),2020,https://ojs.aaai.org/index.php/AAAI/article/view/7183,"We present a novel online algorithm that learns the essence of each dimension in word embeddings. We first mask dimensions determined unessential by our algorithm, apply the masked word embeddings to a word sense disambiguation task (WSD), and compare its performance against the one achieved by the original embeddings. Our results show that the masked word embeddings do not hurt the performance and can improve it by 3%."
Nosayba El-Sayed,OLTP In Real Life: A Large-scale Study of Database Behavior in Modern Online Retail,2021,https://ieeexplore.ieee.org/abstract/document/9614295/,"E-commerce is a multi-trillion US dollar industry and a major user of online transaction processing (OLTP) systems. Yet, we do not have a good understanding of the real-world properties that characterize hardware usage in database systems serving online retail. One key reason is the difficulty of obtaining monitoring logs from production retail datacenters, as large retailers typically consider such data to be highly sensitive. Additionally, resource-usage patterns in OLTP systems and their correlations with the workload are generally challenging to model (not just in retail), due to high levels of transaction concurrency and complexity in OLTP applications. Relying on synthetic benchmarks alone to simulate and study these systems is not sufficient. Instead, this paper takes an empirical approach.We present the first large-scale study of OLTP systems in real life, using traces from two large retailers. The first trace …"
Davide Fossati,Unlimited trace tutor: Learning code tracing with automatically generated programs,2020,https://dl.acm.org/doi/abs/10.1145/3328778.3366939,"Previous research showed that creating specific types of tracing tables helps students learn code tracing, a fundamental skill in computer programming. This paper introduces Unlimited Trace Tutor, the first version of a code tracing tutoring system that can automatically generate tracing problems and create such tracing tables. We conducted a pilot experiment with volunteer students from an introductory level Computer Science course. We found that our software effectively helps student learn tracing ""for"" loops, ""while"" loops, and ""if"" statements. In this paper we describe the system's architecture, our algorithms for generating code and tracing tables, and the promising results of our pilot experiment."
Davide Fossati,Intelligent support for computer science education: Pedagogy enhanced by artificial intelligence,2021,https://books.google.com/books?hl=en&lr=&id=kwA8EAAAQBAJ&oi=fnd&pg=PP1&dq=info:YA0ibrSMMEcJ:scholar.google.com&ots=7BDslZX6Gb&sig=4kdwqnz74uNdjR0KRDmoOnHw-IE,"Intelligent Support for Computer Science Education presents the authors’ research journey into the effectiveness of human tutoring, with the goal of developing educational technology that can be used to improve introductory Computer Science education at the undergraduate level. Nowadays, Computer Science education is central to the concerns of society, as attested by the penetration of information technology in all aspects of our lives; consequently, in the last few years interest in Computer Science at all levels of schooling, especially at the college level, has been flourishing. However, introductory concepts in Computer Science such as data structures and recursion are difficult for novices to grasp. Key Features: Includes a comprehensive and succinct overview of the Computer Science education landscape at all levels of education. Provides in-depth analysis of one-on-one human tutoring dialogues in introductory Computer Science at college level. Describes a scalable, plug-in based Intelligent Tutoring System architecture, portable to different topics and pedagogical strategies. Presents systematic, controlled evaluation of different versions of the system in ecologically valid settings (18 actual classes and their laboratory sessions). Provides a time-series analysis of student behavior when interacting with the system. This book will be of special interest to the Computer Science education community, specifically instructors of introductory courses at the college level, and Advanced Placement (AP) courses at the high school level. Additionally, all the authors’ work is relevant to the Educational Technology community, especially to those working …"
Davide Fossati,A Code Distance Approach to Measure Originality in Computer Programming.,2024,https://www.scitepress.org/Papers/2024/126321/126321.pdf,"We propose a novel approach to measure student originality in computer programming. We collected two sets of programming problems in Java and Python, and their solutions submitted by multiple students. We parsed the students’ code into abstract syntax trees, and calculated the distance among code submissions within problem groups using a tree edit distance algorithm. We estimated each student’s originality as the normalized average distance between their code and the other students’ codes. Pearson correlation analysis revealed a negative correlation between students’ coding performance (ie, the degree of correctness of their code) and students’ programming originality. Further analysis comparing state (features of the problem set) and trait (features of the students) for this measure revealed a correlation with trait and no correlation with state. This suggests that we are likely measuring some trait that a student has, possibly originality, and not some coincidental feature of our problem set. We also examined the validity of our proposed measure by observing the agreement between human graders and our measure in ranking the originality of pairs of code."
Davide Fossati,Learning Recursion: Insights from the ChiQat Intelligent Tutoring System.,2020,https://pdfs.semanticscholar.org/4f90/86456f1638fb94338314ac2336d68c041531.pdf,"Recursion is a difficult concept to teach, and novice programmers struggle Learning it. The reasons include unfamiliarity with activities associated with analyzing recursion, such as visualizing program execution and difficulty understanding its back flow of control. In this paper we discuss approaches to teaching recursion that includes conceptual and program visualization methods. We also describe the recursion module of our ChiQat-Tutor system which relies on ideas from both approaches. We designed several activities that allow students to work on recursive problems: answering questions, animations, code tracing, validation, and construction tasks. We conducted four evaluation experiments at two different institutions, with a total of 89 students taking introductory Computer Science courses. We hypothesized that ChiQat-Tutor can help novice Computer Science students learn recursion, develop accurate mental models of recursion, and serve as an effective visualization tool with which hidden features of recursion can become evident. Our results showed some evidence that the animation, answering questions, code tracing, and validation tasks exhibit a trend towards significant learning gains."
Davide Fossati,Measuring creativity in computer programming: A clustering approach,2024,https://library.iated.org/view/THEODORE2024MEA,"Creative thinking is a valuable skill in professional and academic settings. Being able to quantitatively define and measure creativity is a fundamental step towards helping students improve it. However, in the context of computer programming, effectively measuring creativity is still an open problem.   In this paper, we present a framework based on clustering to assess the creativity of computer programmers from the code they wrote. In particular, we focus on measuring two dimensions of creativity:  (1) originality, i.e., how much an individual programmer's solution differs from other solutions to the same problem written by other programmers; and  (2) flexibility, i.e., how many substantially different solutions to the same problem an individual programmer is able to write.  First, we train a machine learning model to transform computer programs into code embeddings, which are numerical vectors summarizing the …"
Davide Fossati,PEER EVALUATIONS: DATA DRIVEN LEARNING OF DEBUGGING SKILLS,2024,https://library.iated.org/view/FOSSATI2024PEE,"Detecting and correcting errors in computer code, also known as debugging, is a fundamental skill for computer programmers. Novice programmers often find this skill difficult to learn. However, explicit and deliberate teaching of this skill is often overlooked in introductory programming courses, and students are left to learn it indirectly through trial and error while solving traditional code writing assignments.  To address this issue, we designed and implemented a course activity named ""Peer Evaluations"" which helps students practice their debugging skills by exposing them to hundreds of faulty programs written by their peers.  During the semester, students regularly attempt to solve many programming problems, and all these attempts are stored in our course submission system. Incorrect submissions are anonymized and distributed to multiple students in the form of grading tasks. Each student (peer grader) solves a …"
Davide Fossati,A Practical Guide to Extending ChiQat-Tutor,2021,https://www.taylorfrancis.com/chapters/edit/10.1201/9781315168067-10/practical-guide-extending-chiqat-tutor-barbara-di-eugenio-davide-fossati-nick-green,"This chapter shows how to extend ChiQat-Tutor by implementing additional plugin modules. Such extension is exemplified with the detailed presentation, including full code, of a novel lesson module about Stack data structures. The reader will be able to use this example Stack module as a template to write new lesson plugins for ChiQat-Tutor."
Davide Fossati,Practice Exams and Student Performance in Introductory Programming,2020,https://dl.acm.org/doi/abs/10.1145/3328778.3372676,"Introductory Computer Science courses are often challenging, and students who do not consistently practice the material tend to struggle the most. Weekly exams are an excellent strategy to make students review and practice the course material frequently and consistently. Providing practice exams a few days in advance is a way to help students better prepare and succeed in weekly tests. In this study, we looked at three aspects of how practice exams could correlate with students' performance in actual tests. First, we compared the performance of students who attempted the practice exams with those who did not. Second, we looked at how early students started the practice exam with respect to the date of the actual exam. Third, we calculated the total amount of time spent on each practice exam. Our preliminary results indicate superior performance of students who attempted the practice exams; no effect of …"
Zhichun Guo,Few-shot Graph Learning for Molecular Property Prediction,2021,https://dl.acm.org/doi/abs/10.1145/3442381.3450112,"The recent success of graph neural networks has significantly boosted molecular property prediction, advancing activities such as drug discovery. The existing deep neural network methods usually require large training dataset for each property, impairing their performance in cases (especially for new molecular properties) with a limited amount of experimental data, which are common in real situations. To this end, we propose Meta-MGNN, a novel model for few-shot molecular property prediction. Meta-MGNN applies molecular graph neural network to learn molecular representations and builds a meta-learning framework for model optimization. To exploit unlabeled molecular information and address task heterogeneity of different molecular properties, Meta-MGNN further incorporates molecular structures, attribute based self-supervised modules and self-attentive task weights into the former framework …"
Zhichun Guo,What can large language models do in chemistry? a comprehensive benchmark on eight tasks,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/bbb330189ce02be00cf7346167028ab1-Abstract-Datasets_and_Benchmarks.html,"Large Language Models (LLMs) with strong abilities in natural language processing tasks have emerged and have been applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper, rather than pursuing state-of-the-art performance, we aim to evaluate capabilities of LLMs in a wide range of tasks across the chemistry domain. We identify three key chemistry-related capabilities including understanding, reasoning and explaining to explore in LLMs and establish a benchmark containing eight chemistry tasks. Our analysis draws on widely recognized datasets facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Five LLMs (GPT-4, GPT-3.5, Davinci-003, Llama and Galactica) are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstration examples and specially crafted prompts. Our investigation found that GPT-4 outperformed other models and LLMs exhibit different competitive levels in eight chemistry tasks. In addition to the key findings from the comprehensive benchmark analysis, our work provides insights into the limitation of current LLMs and the impact of in-context learning settings on LLMs’ performance across various chemistry tasks. The code and datasets used in this study are available at https://github. com/ChemFoundationModels/ChemLLMBench."
Zhichun Guo,Graph-based molecular representation learning,2023,https://arxiv.org/abs/2207.04869,"Molecular representation learning (MRL) is a key step to build the connection between machine learning and chemical science. In particular, it encodes molecules as numerical vectors preserving the molecular structures and features, on top of which the downstream tasks (e.g., property prediction) can be performed. Recently, MRL has achieved considerable progress, especially in methods based on deep molecular graph learning. In this survey, we systematically review these graph-based molecular representation techniques, especially the methods incorporating chemical domain knowledge. Specifically, we first introduce the features of 2D and 3D molecular graphs. Then we summarize and categorize MRL methods into three groups based on their input. Furthermore, we discuss some typical chemical applications supported by MRL. To facilitate studies in this fast-developing area, we also list the benchmarks and commonly used datasets in the paper. Finally, we share our thoughts on future research directions."
Zhichun Guo,On the use of real-world datasets for reaction yield prediction,2023,https://pubs.rsc.org/en/content/articlehtml/2023/sc/d2sc06041h,"The lack of publicly available, large, and unbiased datasets is a key bottleneck for the application of machine learning (ML) methods in synthetic chemistry. Data from electronic laboratory notebooks (ELNs) could provide less biased, large datasets, but no such datasets have been made publicly available. The first real-world dataset from the ELNs of a large pharmaceutical company is disclosed and its relationship to high-throughput experimentation (HTE) datasets is described. For chemical yield predictions, a key task in chemical synthesis, an attributed graph neural network (AGNN) performs as well as or better than the best previous models on two HTE datasets for the Suzuki–Miyaura and Buchwald–Hartwig reactions. However, training the AGNN on an ELN dataset does not lead to a predictive model. The implications of using ELN data for training ML-based models are discussed in the context of yield predictions."
Zhichun Guo,A Survey of Multi-task Learning in Natural Language Processing: Regarding Task Relatedness and Training Methods,2023,https://arxiv.org/abs/2204.03508,"Multi-task learning (MTL) has become increasingly popular in natural language processing (NLP) because it improves the performance of related tasks by exploiting their commonalities and differences. Nevertheless, it is still not understood very well how multi-task learning can be implemented based on the relatedness of training tasks. In this survey, we review recent advances of multi-task learning methods in NLP, with the aim of summarizing them into two general multi-task training methods based on their task relatedness: (i) joint training and (ii) multi-step training. We present examples in various NLP downstream applications, summarize the task relationships and discuss future directions of this promising topic."
Zhichun Guo,"Learning MLPs on graphs: A unified view of effectiveness, robustness, and efficiency",2022,https://openreview.net/forum?id=Cs3r5KLdoj,"While Graph Neural Networks (GNNs) have demonstrated their efficacy in dealing with non-Euclidean structural data, they are difficult to be deployed in real applications due to the scalability constraint imposed by the multi-hop data dependency. Existing methods attempt to address this scalability issue by training student multi-layer perceptrons (MLPs) exclusively on node content features using labels derived from the teacher GNNs. However, the trained MLPs are neither effective nor robust. In this paper, we ascribe the lack of effectiveness and robustness to three significant challenges: 1) the misalignment between content feature and label spaces, 2) the strict hard matching to teacher's output, and 3) the sensitivity to node feature noises. To address the challenges, we propose NOSMOG, a novel method to learn NOise-robust Structure-aware MLPs On Graphs, with remarkable effectiveness, robustness, and efficiency. Specifically, we first address the misalignment by complementing node content with position features to capture the graph structural information. We then design an innovative representational similarity distillation strategy to inject soft node similarities into MLPs. Finally, we introduce adversarial feature augmentation to ensure stable learning against feature noises. Extensive experiments and theoretical analyses demonstrate the superiority of NOSMOG by comparing it to GNNs and the state-of-the-art method in both transductive and inductive settings across seven datasets. Codes are available at https://github.com/meettyj/NOSMOG."
Zhichun Guo,Linkless link prediction via relational distillation,2023,https://proceedings.mlr.press/v202/guo23f.html,"Graph Neural Networks (GNNs) have shown exceptional performance in the task of link prediction. Despite their effectiveness, the high latency brought by non-trivial neighborhood data dependency limits GNNs in practical deployments. Conversely, the known efficient MLPs are much less effective than GNNs due to the lack of relational knowledge. In this work, to combine the advantages of GNNs and MLPs, we start with exploring direct knowledge distillation (KD) methods for link prediction, ie, predicted logit-based matching and node representation-based matching. Upon observing direct KD analogs do not perform well for link prediction, we propose a relational KD framework, Linkless Link Prediction (LLP), to distill knowledge for link prediction with MLPs. Unlike simple KD methods that match independent link logits or node representations, LLP distills relational knowledge that is centered around each (anchor) node to the student MLP. Specifically, we propose rank-based matching and distribution-based matching strategies that complement each other. Extensive experiments demonstrate that LLP boosts the link prediction performance of MLPs with significant margins and even outperforms the teacher GNNs on 7 out of 8 benchmarks. LLP also achieves a 70.68 x speedup in link prediction inference compared to GNNs on the large-scale OGB dataset."
Zhichun Guo,GraSeq: Graph and Sequence Fusion Learning for Molecular Property Prediction,2020,https://dl.acm.org/doi/abs/10.1145/3340531.3411981,"With the recent advancement of deep learning, molecular representation learning -- automating the discovery of feature representation of molecular structure, has attracted significant attention from both chemists and machine learning researchers. Deep learning can facilitate a variety of downstream applications, including bio-property prediction, chemical reaction prediction, etc. Despite the fact that current SMILES string or molecular graph molecular representation learning algorithms (via sequence modeling and graph neural networks, respectively) have achieved promising results, there is no work to integrate the capabilities of both approaches in preserving molecular characteristics (e.g, atomic cluster, chemical bond) for further improvement. In this paper, we propose GraSeq, a joint graph and sequence representation learning model for molecular property prediction. Specifically, GraSeq makes a …"
Zhichun Guo,What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks,2023,https://www.researchgate.net/profile/Zhichun-Guo/publication/371163433_What_indeed_can_GPT_models_do_in_chemistry_A_comprehensive_benchmark_on_eight_tasks/links/647e762c2cad460a1bf896f0/What-indeed-can-GPT-models-do-in-chemistry-A-comprehensive-benchmark-on-eight-tasks.pdf,"Large Language Models (LLMs) with strong abilities in natural language processing tasks have emerged and have been rapidly applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper, we establish a comprehensive benchmark containing 8 practical chemistry tasks, including 1) name prediction, 2) property prediction, 3) yield prediction, 4) reaction prediction, 5) retrosynthesis (prediction of reactants from products), 6) text-based molecule design, 7) molecule captioning, and 8) reagent selection. Our analysis draws on widely recognized datasets including BBBP, Tox21, PubChem, USPTO, and ChEBI, facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Three GPT models (GPT-4, GPT-3.5, and Davinci-003) are evaluated for each chemistry task in zero-shot and fewshot in-context learning settings with carefully selected demonstration examples and specially crafted prompts. The key results of our investigation are 1) GPT-4 outperforms the other two models among the three evaluated; 2) GPT models exhibit less competitive performance in tasks demanding precise understanding of molecular SMILES representation, such as reaction prediction and retrosynthesis; 3) GPT models demonstrate strong capabilities in text-related explanation tasks such as molecule captioning; and 4) GPT models exhibit comparable or better performance to classical machine learning models when applied to chemical problems that can be transformed into classification or ranking tasks, such as …"
Zhichun Guo,RecipeRec: a heterogeneous graph learning model for recipe recommendation,2022,https://arxiv.org/abs/2205.14005,"Recipe recommendation systems play an essential role in helping people decide what to eat. Existing recipe recommendation systems typically focused on content-based or collaborative filtering approaches, ignoring the higher-order collaborative signal such as relational structure information among users, recipes and food items. In this paper, we formalize the problem of recipe recommendation with graphs to incorporate the collaborative signal into recipe recommendation through graph modeling. In particular, we first present URI-Graph, a new and large-scale user-recipe-ingredient graph. We then propose RecipeRec, a novel heterogeneous graph learning model for recipe recommendation. The proposed model can capture recipe content and collaborative signal through a heterogeneous graph neural network with hierarchical attention and an ingredient set transformer. We also introduce a graph contrastive augmentation strategy to extract informative graph knowledge in a self-supervised manner. Finally, we design a joint objective function of recommendation and contrastive learning to optimize the model. Extensive experiments demonstrate that RecipeRec outperforms state-of-the-art methods for recipe recommendation. Dataset and codes are available at https://github.com/meettyj/RecipeRec."
Zhichun Guo,Boosting Graph Neural Networks via Adaptive Knowledge Distillation,2023,https://ojs.aaai.org/index.php/AAAI/article/view/25944,"Graph neural networks (GNNs) have shown remarkable performance on diverse graph mining tasks. While sharing the same message passing framework, our study shows that different GNNs learn distinct knowledge from the same graph. This implies potential performance improvement by distilling the complementary knowledge from multiple models. However, knowledge distillation (KD) transfers knowledge from high-capacity teachers to a lightweight student, which deviates from our scenario: GNNs are often shallow. To transfer knowledge effectively, we need to tackle two challenges: how to transfer knowledge from compact teachers to a student with the same capacity; and, how to exploit student GNN's own learning ability. In this paper, we propose a novel adaptive KD framework, called BGNN, which sequentially transfers knowledge from multiple GNNs into a student GNN. We also introduce an adaptive temperature module and a weight boosting module. These modules guide the student to the appropriate knowledge for effective learning. Extensive experiments have demonstrated the effectiveness of BGNN. In particular, we achieve up to 3.05% improvement for node classification and 6.35% improvement for graph classification over vanilla GNNs."
Zhichun Guo,Action Sequence Augmentation for Early Graph-based Anomaly Detection,2021,https://dl.acm.org/doi/abs/10.1145/3459637.3482313,"The proliferation of web platforms has created incentives for online abuse. Many graph-based anomaly detection techniques are proposed to identify the suspicious accounts and behaviors. However, most of them detect the anomalies once the users have performed many such behaviors. Their performance is substantially hindered when the users' observed data is limited at an early stage, which needs to be improved to minimize financial loss. In this work, we propose Eland, a novel framework that uses action sequence augmentation for early anomaly detection. Eland utilizes a sequence predictor to predict next actions of every user and exploits the mutual enhancement between action sequence augmentation and user-action graph anomaly detection. Experiments on three real-world datasets show that Eland improves the performance of a variety of graph-based anomaly detection methods. With Eland, anomaly …"
Zhichun Guo,Link prediction with non-contrastive learning,2023,https://arxiv.org/abs/2211.14394,"A recent focal area in the space of graph neural networks (GNNs) is graph self-supervised learning (SSL), which aims to derive useful node representations without labeled data. Notably, many state-of-the-art graph SSL methods are contrastive methods, which use a combination of positive and negative samples to learn node representations. Owing to challenges in negative sampling (slowness and model sensitivity), recent literature introduced non-contrastive methods, which instead only use positive samples. Though such methods have shown promising performance in node-level tasks, their suitability for link prediction tasks, which are concerned with predicting link existence between pairs of nodes (and have broad applicability to recommendation systems contexts) is yet unexplored. In this work, we extensively evaluate the performance of existing non-contrastive methods for link prediction in both transductive and inductive settings. While most existing non-contrastive methods perform poorly overall, we find that, surprisingly, BGRL generally performs well in transductive settings. However, it performs poorly in the more realistic inductive settings where the model has to generalize to links to/from unseen nodes. We find that non-contrastive models tend to overfit to the training graph and use this analysis to propose T-BGRL, a novel non-contrastive framework that incorporates cheap corruptions to improve the generalization ability of the model. This simple modification strongly improves inductive performance in 5/6 of our datasets, with up to a 120% improvement in Hits@50--all with comparable speed to other non-contrastive baselines and up …"
Zhichun Guo,Hierarchical spatio-temporal graph neural networks for pandemic forecasting,2022,https://dl.acm.org/doi/abs/10.1145/3511808.3557350,"The spread of COVID-19 throughout the world has led to cataclysmic consequences on the global community, which poses an urgent need to accurately understand and predict the trajectories of the pandemic. Existing research has relied on graph-structured human mobility data for the task of pandemic forecasting. To perform pandemic forecasting of COVID-19 in the United States, we curate Large-MG, a large-scale mobility dataset that contains 66 dynamic mobility graphs, with each graph having over 3k nodes and an average of 540k edges. One drawback with existing Graph Neural Networks (GNNs) for pandemic forecasting is that they generally perform information propagation in a flat way and thus ignore the inherent community structure in a mobility graph. To bridge this gap, we propose a Hierarchical Spatio-Temporal Graph Neural Network (HiSTGNN) to perform pandemic forecasting, which learns both …"
Zhichun Guo,Nosmog: Learning noise-robust and structure-aware mlps on graphs,2022,https://arxiv.org/abs/2208.10010,"While Graph Neural Networks (GNNs) have demonstrated their efficacy in dealing with non-Euclidean structural data, they are difficult to be deployed in real applications due to the scalability constraint imposed by multi-hop data dependency. Existing methods attempt to address this scalability issue by training multi-layer perceptrons (MLPs) exclusively on node content features using labels derived from trained GNNs. Even though the performance of MLPs can be significantly improved, two issues prevent MLPs from outperforming GNNs and being used in practice: the ignorance of graph structural information and the sensitivity to node feature noises. In this paper, we propose to learn NOise-robust Structure-aware MLPs On Graphs (NOSMOG) to overcome the challenges. Specifically, we first complement node content with position features to help MLPs capture graph structural information. We then design a novel representational similarity distillation strategy to inject structural node similarities into MLPs. Finally, we introduce the adversarial feature augmentation to ensure stable learning against feature noises and further improve performance. Extensive experiments demonstrate that NOSMOG outperforms GNNs and the state-of-the-art method in both transductive and inductive settings across seven datasets, while maintaining a competitive inference efficiency. Codes are available at https://github.com/meettyj/NOSMOG."
Zhichun Guo,Recipe2vec: Multi-modal recipe representation learning with graph neural networks,2022,https://arxiv.org/abs/2205.12396,"Learning effective recipe representations is essential in food studies. Unlike what has been developed for image-based recipe retrieval or learning structural text embeddings, the combined effect of multi-modal information (i.e., recipe images, text, and relation data) receives less attention. In this paper, we formalize the problem of multi-modal recipe representation learning to integrate the visual, textual, and relational information into recipe embeddings. In particular, we first present Large-RG, a new recipe graph data with over half a million nodes, making it the largest recipe graph to date. We then propose Recipe2Vec, a novel graph neural network based recipe embedding model to capture multi-modal information. Additionally, we introduce an adversarial attack strategy to ensure stable learning and improve performance. Finally, we design a joint objective function of node classification and adversarial learning to optimize the model. Extensive experiments demonstrate that Recipe2Vec outperforms state-of-the-art baselines on two classic food study tasks, i.e., cuisine category classification and region prediction. Dataset and codes are available at https://github.com/meettyj/Recipe2Vec."
Zhichun Guo,Improving generalizability of fake news detection methods using propensity score matching,2020,https://arxiv.org/abs/2002.00838,"Recently, due to the booming influence of online social networks, detecting fake news is drawing significant attention from both academic communities and general public. In this paper, we consider the existence of confounding variables in the features of fake news and use Propensity Score Matching (PSM) to select generalizable features in order to reduce the effects of the confounding variables. Experimental results show that the generalizability of fake news method is significantly better by using PSM than using raw frequency to select features. We investigate multiple types of fake news methods (classifiers) such as logistic regression, random forests, and support vector machines. We have consistent observations of performance improvement."
Zhichun Guo,Fakeedge: Alleviate dataset shift in link prediction,2022,https://proceedings.mlr.press/v198/dong22a.html,"Link prediction is a crucial problem in graph-structured data. Due to the recent success of graph neural networks (GNNs), a variety of GNN-based models were proposed to tackle the link prediction task. Specifically, GNNs leverage the message passing paradigm to obtain node representation, which relies on link connectivity. However, in a link prediction task, links in the training set are always present while ones in the testing set are not yet formed, resulting in a discrepancy of the connectivity pattern and bias of the learned representation. It leads to a problem of dataset shift which degrades the model performance. In this paper, we first identify the dataset shift problem in the link prediction task and provide theoretical analyses on how existing link prediction methods are vulnerable to it. We then propose FakeEdge, a model-agnostic technique, to address the problem by mitigating the graph topological gap between training and testing sets. Extensive experiments demonstrate the applicability and superiority of FakeEdge on multiple datasets across various domains."
Zhichun Guo,Sentence-permuted Paragraph Generation,2021,https://arxiv.org/abs/2104.07228,"Generating paragraphs of diverse contents is important in many applications. Existing generation models produce similar contents from homogenized contexts due to the fixed left-to-right sentence order. Our idea is permuting the sentence orders to improve the content diversity of multi-sentence paragraph. We propose a novel framework PermGen whose objective is to maximize the expected log-likelihood of output paragraph distributions with respect to all possible sentence orders. PermGen uses hierarchical positional embedding and designs new procedures for training, decoding, and candidate ranking in the sentence-permuted generation. Experiments on three paragraph generation benchmarks demonstrate PermGen generates more diverse outputs with a higher quality than existing models."
Zhichun Guo,Visual analysis of steady-state human mobility in cities,2021,http://leishidata.com/leishi/paper/UrbanFACET_HCIS.pdf,"Cities are living systems where urban infrastructures and their functions are defined by and evolved with population behavior. Visualizing, profiling, and comparing the mobility behavior of the population has been challenging because of the enormous population size in modern cities (tens of millions in our dataset). This paper proposes a steady-state visual analysis of human mobility that abstracts the longitudinal trajectory of each city resident into five information-theoretic metrics: Fluidity, vibrAncy, Commutation, divErsity, and densiTy (FACET). The metrics characterize the long-term mobility behavior of residents concerning municipal structures and points of interest in the city and can also be aggregated to profile underlying city regions. Based on the steady-state analysis method, we develop a visualization system, namely UrbanFACET, which provides a multifaceted panorama of human mobilities in cities and helps to compare urban functions among cities and time. We evaluate the proposed method and system through case studies in real-world big cities. Our result demonstrates the effectiveness of the steady-state analysis in several target domains such as urban planning, business site configuration, and city security surveillance."
Zhichun Guo,Flashlight: Scalable link prediction with effective decoders,2022,https://proceedings.mlr.press/v198/wang22a.html,"Link prediction (LP) has been recognized as an important task in graph learning with its broad practical applications. A typical application of LP is to retrieve the top scoring neighbors for a given source node, such as the friend recommendation. These services desire the high inference scalability to find the top scoring neighbors from many candidate nodes at low latencies. There are two popular decoders that the recent LP models mainly use to compute the edge scores from node embeddings: the\textbf {HadamardMLP} and\textbf {Dot Product} decoders. After theoretical and empirical analysis, we find that the HadamardMLP decoders are generally more effective for LP. However, HadamardMLP lacks the scalability for retrieving top scoring neighbors on large graphs, since to the best of our knowledge, there does not exist an algorithm to retrieve the top scoring neighbors for HadamardMLP decoders in sublinear complexity. To make HadamardMLP scalable, we propose the\textit {Flashlight} algorithm to accelerate the top scoring neighbor retrievals for HadamardMLP: a sublinear algorithm that progressively applies approximate maximum inner product search (MIPS) techniques with adaptively adjusted query embeddings. Empirical results show that Flashlight improves the inference speed of LP by more than 100 times on the large OGBL-CITATION2 dataset without sacrificing effectiveness. Our work paves the way for large-scale LP applications with the effective HadamardMLP decoders by greatly accelerating their inference."
Zhichun Guo,Can llms solve molecule puzzles? a multimodal benchmark for molecular structure elucidation,2024,https://proceedings.neurips.cc/paper_files/paper/2024/hash/f2b9e8e7a36d43ddfd3d55113d56b1e0-Abstract-Datasets_and_Benchmarks_Track.html,"Large Language Models (LLMs) have shown significant problem-solving capabilities across predictive and generative tasks in chemistry. However, their proficiency in multi-step chemical reasoning remains underexplored. We introduce a new challenge: molecular structure elucidation, which involves deducing a molecule’s structure from various types of spectral data. Solving such a molecular puzzle, akin to solving crossword puzzles, poses reasoning challenges that require integrating clues from diverse sources and engaging in iterative hypothesis testing. To address this challenging problem with LLMs, we present\textbf {MolPuzzle}, a benchmark comprising 217 instances of structure elucidation, which feature over 23,000 QA samples presented in a sequential puzzle-solving process, involving three interlinked sub-tasks: molecule understanding, spectrum interpretation, and molecule construction. Our evaluation of 12 LLMs reveals that the best-performing LLM, GPT-4o, performs significantly worse than humans, with only a small portion (1.4\%) of its answers exactly matching the ground truth. However, it performs nearly perfectly in the first subtask of molecule understanding, achieving accuracy close to 100\%. This discrepancy highlights the potential of developing advanced LLMs with improved chemical reasoning capabilities in the other two sub-tasks. Our MolPuzzle dataset and evaluation code are available at this\href {https://github. com/KehanGuo2/MolPuzzle}{link}."
Zhichun Guo,Pure message passing can estimate common neighbor for link prediction,2024,https://proceedings.neurips.cc/paper_files/paper/2024/hash/85970f7bbc821852c1d17052b88c2451-Abstract-Conference.html,"Message Passing Neural Networks (MPNNs) have emerged as the {\em de facto} standard in graph representation learning. However, when it comes to link prediction, they are not always superior to simple heuristics such as Common Neighbor (CN). This discrepancy stems from a fundamental limitation: while MPNNs excel in node-level representation, they stumble with encoding the joint structural features essential to link prediction, like CN. To bridge this gap, we posit that, by harnessing the orthogonality of input vectors, pure message-passing can indeed capture joint structural features. Specifically, we study the proficiency of MPNNs in approximating CN heuristics. Based on our findings, we introduce the Message Passing Link Predictor (MPLP), a novel link prediction model. MPLP taps into quasi-orthogonal vectors to estimate link-level structural features, all while preserving the node-level complexities. We conduct experiments on benchmark datasets from various domains, where our method consistently outperforms the baseline methods, establishing new state-of-the-arts."
Zhichun Guo,Molx: Enhancing large language models for molecular learning with a multi-modal extension,2024,https://arxiv.org/abs/2406.06777,"Large Language Models (LLMs) with their strong task-handling capabilities have shown remarkable advancements across a spectrum of fields, moving beyond natural language understanding. However, their proficiency within the chemistry domain remains restricted, especially in solving professional molecule-related tasks. This challenge is attributed to their inherent limitations in comprehending molecules using only common textual representations, i.e., SMILES strings. In this study, we seek to enhance the ability of LLMs to comprehend molecules by equipping them with a multi-modal external module, namely MolX. In particular, instead of directly using a SMILES string to represent a molecule, we utilize specific encoders to extract fine-grained features from both SMILES string and 2D molecular graph representations for feeding into an LLM. Moreover, a handcrafted molecular fingerprint is incorporated to leverage its embedded domain knowledge. Then, to establish an alignment between MolX and the LLM's textual input space, the whole model in which the LLM is frozen, is pre-trained with a versatile strategy including a diverse set of tasks. Experimental evaluations show that our proposed method outperforms baselines across 4 downstream molecule-related tasks ranging from molecule-to-text translation to retrosynthesis, with and without fine-tuning the LLM, while only introducing a small number of trainable parameters 0.53% and 0.82%, respectively."
Zhichun Guo,How Does Message Passing Improve Collaborative Filtering?,2024,https://arxiv.org/abs/2404.08660,"Collaborative filtering (CF) has exhibited prominent results for recommender systems and been broadly utilized for real-world applications. A branch of research enhances CF methods by message passing used in graph neural networks, due to its strong capabilities of extracting knowledge from graph-structured data, like user-item bipartite graphs that naturally exist in CF. They assume that message passing helps CF methods in a manner akin to its benefits for graph-based learning tasks in general. However, even though message passing empirically improves CF, whether or not this assumption is correct still needs verification. To address this gap, we formally investigate why message passing helps CF from multiple perspectives and show that many assumptions made by previous works are not entirely accurate. With our curated ablation studies and theoretical analyses, we discover that (1) message passing improves the CF performance primarily by additional representations passed from neighbors during the forward pass instead of additional gradient updates to neighbor representations during the model back-propagation and (ii) message passing usually helps low-degree nodes more than high-degree nodes. Utilizing these novel findings, we present Test-time Aggregation for CF, namely TAG-CF, a test-time augmentation framework that only conducts message passing once at inference time. The key novelty of TAG-CF is that it effectively utilizes graph knowledge while circumventing most of notorious computational overheads of message passing. Besides, TAG-CF is extremely versatile can be used as a plug-and-play module to enhance …"
Zhichun Guo,Node duplication improves cold-start link prediction,2024,https://arxiv.org/abs/2402.09711,"Graph Neural Networks (GNNs) are prominent in graph machine learning and have shown state-of-the-art performance in Link Prediction (LP) tasks. Nonetheless, recent studies show that GNNs struggle to produce good results on low-degree nodes despite their overall strong performance. In practical applications of LP, like recommendation systems, improving performance on low-degree nodes is critical, as it amounts to tackling the cold-start problem of improving the experiences of users with few observed interactions. In this paper, we investigate improving GNNs' LP performance on low-degree nodes while preserving their performance on high-degree nodes and propose a simple yet surprisingly effective augmentation technique called NodeDup. Specifically, NodeDup duplicates low-degree nodes and creates links between nodes and their own duplicates before following the standard supervised LP training scheme. By leveraging a ''multi-view'' perspective for low-degree nodes, NodeDup shows significant LP performance improvements on low-degree nodes without compromising any performance on high-degree nodes. Additionally, as a plug-and-play augmentation module, NodeDup can be easily applied to existing GNNs with very light computational cost. Extensive experiments show that NodeDup achieves 38.49%, 13.34%, and 6.76% improvements on isolated, low-degree, and warm nodes, respectively, on average across all datasets compared to GNNs and state-of-the-art cold-start methods."
Zhichun Guo,SD: Slicing and Dicing Scholarly Data for Interactive Evaluation of Academic Performance,2022,https://ieeexplore.ieee.org/abstract/document/9747941/,"Comprehensively evaluating and comparing researchers’ academic performance is complicated due to the intrinsic complexity of scholarly data. Different scholarly evaluation tasks often require the publication and citation data to be investigated in various manners. In this article, we present an interactive visualization framework, SD, to enable flexible data partition and composition to support various analysis requirements within a single system. SD features the hierarchical histogram, a novel visual representation for flexibly slicing and dicing the data, allowing different aspects of scholarly performance to be studied and compared. We also leverage the state-of-the-art set visualization technique to select individual researchers or combine multiple scholars for comprehensive visual comparison. We conduct multiple rounds of expert evaluation to study the effectiveness and usability of SD and revise the design and …"
Zhichun Guo,Universal link predictor by in-context learning,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240207738D/abstract,"Link prediction is a crucial task in graph machine learning, where the goal is to infer missing or future links within a graph. Traditional approaches leverage heuristic methods based on widely observed connectivity patterns, offering broad applicability and generalizability without the need for model training. Despite their utility, these methods are limited by their reliance on human-derived heuristics and lack the adaptability of data-driven approaches. Conversely, parametric link predictors excel in automatically learning the connectivity patterns from data and achieving state-of-the-art but fail short to directly transfer across different graphs. Instead, it requires the cost of extensive training and hyperparameter optimization to adapt to the target graph. In this work, we introduce the Universal Link Predictor (UniLP), a novel model that combines the generalizability of heuristic approaches with the pattern learning capabilities …"
Zhichun Guo,You do not have to train Graph Neural Networks at all on text-attributed graphs,2024,https://arxiv.org/abs/2404.11019,"Graph structured data, specifically text-attributed graphs (TAG), effectively represent relationships among varied entities. Such graphs are essential for semi-supervised node classification tasks. Graph Neural Networks (GNNs) have emerged as a powerful tool for handling this graph-structured data. Although gradient descent is commonly utilized for training GNNs for node classification, this study ventures into alternative methods, eliminating the iterative optimization processes. We introduce TrainlessGNN, a linear GNN model capitalizing on the observation that text encodings from the same class often cluster together in a linear subspace. This model constructs a weight matrix to represent each class's node attribute subspace, offering an efficient approach to semi-supervised node classification on TAG. Extensive experiments reveal that our trainless models can either match or even surpass their conventionally trained counterparts, demonstrating the possibility of refraining from gradient descent in certain configurations."
Zhichun Guo,Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond,2025,https://arxiv.org/abs/2502.09897,"The rapid advent of machine learning (ML) and artificial intelligence (AI) has catalyzed major transformations in chemistry, yet the application of these methods to spectroscopic and spectrometric data, referred to as Spectroscopy Machine Learning (SpectraML), remains relatively underexplored. Modern spectroscopic techniques (MS, NMR, IR, Raman, UV-Vis) generate an ever-growing volume of high-dimensional data, creating a pressing need for automated and intelligent analysis beyond traditional expert-based workflows. In this survey, we provide a unified review of SpectraML, systematically examining state-of-the-art approaches for both forward tasks (molecule-to-spectrum prediction) and inverse tasks (spectrum-to-molecule inference). We trace the historical evolution of ML in spectroscopy, from early pattern recognition to the latest foundation models capable of advanced reasoning, and offer a taxonomy of representative neural architectures, including graph-based and transformer-based methods. Addressing key challenges such as data quality, multimodal integration, and computational scalability, we highlight emerging directions such as synthetic data generation, large-scale pretraining, and few- or zero-shot learning. To foster reproducible research, we also release an open-source repository containing recent papers and their corresponding curated datasets (https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers). Our survey serves as a roadmap for researchers, guiding progress at the intersection of spectroscopy and AI."
Zhichun Guo,Can LLMs Solve Molecule Puzzles? A MultimodalCan MultimodalBenchmark for Molecular Structure ElucidationBenchmark Elucidation,2025,https://par.nsf.gov/biblio/10570107,
Zhichun Guo,YOSO: You-Only-Sample-Once via Compressed Sensing for Graph Neural Network Training,2024,https://arxiv.org/abs/2411.05693,"Graph neural networks (GNNs) have become essential tools for analyzing non-Euclidean data across various domains. During training stage, sampling plays an important role in reducing latency by limiting the number of nodes processed, particularly in large-scale applications. However, as the demand for better prediction performance grows, existing sampling algorithms become increasingly complex, leading to significant overhead. To mitigate this, we propose YOSO (You-Only-Sample-Once), an algorithm designed to achieve efficient training while preserving prediction accuracy. YOSO introduces a compressed sensing (CS)-based sampling and reconstruction framework, where nodes are sampled once at input layer, followed by a lossless reconstruction at the output layer per epoch. By integrating the reconstruction process with the loss function of specific learning tasks, YOSO not only avoids costly computations in traditional compressed sensing (CS) methods, such as orthonormal basis calculations, but also ensures high-probability accuracy retention which equivalent to full node participation. Experimental results on node classification and link prediction demonstrate the effectiveness and efficiency of YOSO, reducing GNN training by an average of 75\% compared to state-of-the-art methods, while maintaining accuracy on par with top-performing baselines."
Zhichun Guo,CORE: Data Augmentation for Link Prediction via Information Bottleneck,2024,https://arxiv.org/abs/2404.11032,"Link prediction (LP) is a fundamental task in graph representation learning, with numerous applications in diverse domains. However, the generalizability of LP models is often compromised due to the presence of noisy or spurious information in graphs and the inherent incompleteness of graph data. To address these challenges, we draw inspiration from the Information Bottleneck principle and propose a novel data augmentation method, COmplete and REduce (CORE) to learn compact and predictive augmentations for LP models. In particular, CORE aims to recover missing edges in graphs while simultaneously removing noise from the graph structures, thereby enhancing the model's robustness and performance. Extensive experiments on multiple benchmark datasets demonstrate the applicability and superiority of CORE over state-of-the-art methods, showcasing its potential as a leading approach for robust LP in graph representation learning."
Zhichun Guo,Empowering Graph Neural Networks for Real-World Tasks,2024,https://search.proquest.com/openview/79f34d897343e389d66d2d1a881ac8e1/1?pq-origsite=gscholar&cbl=18750&diss=y,"Numerous types of real-world data can be naturally represented as graphs, such as social networks, trading networks, and biological molecules. This highlights the need for effective graph representations to support various tasks. In recent years, graph neural networks (GNNs) have demonstrated remarkable success in extracting information from graphs and enabling graph-related tasks. However, they still face a series of challenges in solving real-world problems, including scarcity of labeled data, scalability issues, potential bias, etc. These challenges stem from both domain-specific issues and inherent limitations of GNNs. This thesis introduces various strategies to tackle these challenges and empower GNNs on real-world tasks."
Joyce C Ho,Taste: temporal and static tensor factorization for phenotyping electronic health records,2020,https://dl.acm.org/doi/abs/10.1145/3368555.3384464,"Phenotyping electronic health records (EHR)focuses on defining meaningful patient groups (e.g., heart failure group and diabetes group) and identifying the temporal evolution of patients in those groups. Tensor factorization has been an effective tool for phenotyping. Most of the existing works assume either a static patient representation with aggregate data or only model temporal data. However, real EHR data contain both temporal (e.g., longitudinal clinical visits) and static information (e.g., patient demographics), which are difficult to model simultaneously. In this paper, we propose Temporal And Static TEnsor factorization (TASTE) that jointly models both static and temporal information to extract phenotypes.TASTE combines the PARAFAC2 model with non-negative matrix factorization to model a temporal and a static tensor. To fit the proposed model, we transform the original problem into simpler ones which …"
Joyce C Ho,SMAT: An attention-based deep learning solution to the automation of schema matching,2021,https://link.springer.com/chapter/10.1007/978-3-030-82472-3_19,"Schema matching aims to identify the correspondences among attributes of database schemas. It is frequently considered as the most challenging and decisive stage existing in many contemporary web semantics and database systems. Low-quality algorithmic matchers fail to provide improvement while manually annotation consumes extensive human efforts. Further complications arise from data privacy in certain domains such as healthcare, where only schema-level matching should be used to prevent data leakage. For this problem, we propose SMAT, a new deep learning model based on state-of-the-art natural language processing techniques to obtain semantic mappings between source and target schemas using only the attribute name and description. SMAT avoids directly encoding domain knowledge about the source and target systems, which allows it to be more easily deployed across …"
Joyce C Ho,LogPar: Logistic PARAFAC2 factorization for temporal binary data with missing values,2020,https://dl.acm.org/doi/abs/10.1145/3394486.3403213,"Binary data with one-class missing values are ubiquitous in real-world applications. They can be represented by irregular tensors with varying sizes in one dimension, where value one means presence of a feature while zero means unknown (i.e., either presence or absence of a feature). Learning accurate low-rank approximations from such binary irregular tensors is a challenging task. However, none of the existing models developed for factorizing irregular tensors take the missing values into account, and they assume Gaussian distributions, resulting in a distribution mismatch when applied to binary data. In this paper, we propose Logistic PARAFAC2 (LogPar) by modeling the binary irregular tensor with Bernoulli distribution parameterized by an underlying real-valued tensor. Then we approximate the underlying tensor with a positive-unlabeled learning loss function to account for the missing values. We also …"
Joyce C Ho,Communication efficient federated generalized tensor factorization for collaborative health data analytics,2021,https://dl.acm.org/doi/abs/10.1145/3442381.3449832," Modern healthcare systems knitted by a web of entities (e.g., hospitals, clinics, pharmacy companies) are collecting a huge volume of healthcare data from a large number of individuals with various medical procedures, medications, diagnosis, and lab tests. To extract meaningful medical concepts (i.e., phenotypes) from such higher-arity relational healthcare data, tensor factorization has been proven to be an effective approach and received increasing research attention, due to their intrinsic capability to represent the high-dimensional data. Recently, federated learning offers a privacy-preserving paradigm for collaborative learning among different entities, which seemingly provides an ideal potential to further enhance the tensor factorization-based collaborative phenotyping to handle sensitive personal health data. However, existing attempts to federated tensor factorization come with various limitations, including …"
Joyce C Ho,Knowledge-infused prompting: Assessing and advancing clinical text data generation with large language models,2023,https://arxiv.org/abs/2311.00287,"Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the diversity of generated training instances. We will publish our code and all the generated data in \url{https://github.com/ritaranx/ClinGen}."
Joyce C Ho,Meddiff: Generating electronic health records using accelerated denoising diffusion model,2023,https://arxiv.org/abs/2302.04355,"Due to patient privacy protection concerns, machine learning research in healthcare has been undeniably slower and limited than in other application domains. High-quality, realistic, synthetic electronic health records (EHRs) can be leveraged to accelerate methodological developments for research purposes while mitigating privacy concerns associated with data sharing. The current state-of-the-art model for synthetic EHR generation is generative adversarial networks, which are notoriously difficult to train and can suffer from mode collapse. Denoising Diffusion Probabilistic Models, a class of generative models inspired by statistical thermodynamics, have recently been shown to generate high-quality synthetic samples in certain domains. It is unknown whether these can generalize to generation of large-scale, high-dimensional EHRs. In this paper, we present a novel generative model based on diffusion models that is the first successful application on electronic health records. Our model proposes a mechanism to perform class-conditional sampling to preserve label information. We also introduce a new sampling strategy to accelerate the inference speed. We empirically show that our model outperforms existing state-of-the-art synthetic EHR generation methods."
Joyce C Ho,Counterfactual and factual reasoning over hypergraphs for interpretable clinical predictions on ehr,2022,https://proceedings.mlr.press/v193/xu22a.html,"Electronic Health Record modeling is crucial for digital medicine. However, existing models ignore higher-order interactions among medical codes and their causal relations towards downstream clinical predictions. To address such limitations, we propose a novel framework CACHE, to provide effective and insightful clinical predictions based on hypergraph representation learning and counterfactual and factual reasoning techniques. Experiments on two real EHR datasets show the superior performance of CACHE. Case studies with a domain expert illustrate a preferred capability of CACHE in generating clinically meaningful interpretations towards the correct predictions."
Joyce C Ho,Ehragent: Code empowers large language models for few-shot complex tabular reasoning on electronic health records,2024,https://arxiv.org/abs/2401.07128,"Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on three real-world multi-tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.6% in success rate. EHRAgent leverages the emerging few-shot learning capabilities of LLMs, enabling autonomous code generation and execution to tackle complex clinical tasks with minimal demonstrations."
Joyce C Ho,Neighborhood-regularized self-training for learning with few labels,2023,https://ojs.aaai.org/index.php/AAAI/article/view/26260,"Training deep neural networks (DNNs) with limited supervision has been a popular research topic as it can significantly alleviate the annotation burden. Self-training has been successfully applied in semi-supervised learning tasks, but one drawback of self-training is that it is vulnerable to the label noise from incorrect pseudo labels. Inspired by the fact that samples with similar labels tend to share similar representations, we develop a neighborhood-based sample selection approach to tackle the issue of noisy pseudo labels. We further stabilize self-training via aggregating the predictions from different rounds during sample selection. Experiments on eight tasks show that our proposed method outperforms the strongest self-training baseline with 1.83% and 2.51% performance gain for text and graph datasets on average. Our further analysis demonstrates that our proposed data selection strategy reduces the noise of pseudo labels by 36.8% and saves 57.3% of the time when compared with the best baseline. Our code and appendices will be uploaded to: https://github. com/ritaranx/NeST."
Joyce C Ho,Predictors of progression through the cascade of care to a cure for hepatitis C patients using decision trees and random forests,2021,https://www.sciencedirect.com/science/article/pii/S0010482521002559,"BackgroundThis study uses machine learning techniques to identify sociodemographic and clinical predictors of progression through the hepatitis C (HCV) cascade of care for patients in the 1945–1965 birth cohort in the Southern United States.MethodsWe compared sociodemographic and clinical variables between groups of patients for three care outcomes: linkage to care, initiation of antiviral treatment, and virologic cure. A decision tree model and random forest model were built for each outcome.ResultsPatients were primarily male, African American/Black or Caucasian/White, non-Hispanic or Latino, and insured. The average age at first HCV screening was 60 years old, and common medical diagnoses included chronic kidney disease, fibrosis and/or cirrhosis, transplanted liver, diabetes mellitus, and liver cell carcinoma. Variables used in predicting linkage to care included age at first HCV screening …"
Joyce C Ho,Controlled molecule generator for optimizing multiple chemical properties,2021,https://dl.acm.org/doi/abs/10.1145/3450439.3451879,"Generating a novel and optimized molecule with desired chemical properties is an essential part of the drug discovery process. Failure to meet one of the required properties can frequently lead to failure in a clinical test which is costly. In addition, optimizing these multiple properties is a challenging task because the optimization of one property is prone to changing other properties. In this paper, we pose this multi-property optimization problem as a sequence translation process and propose a new optimized molecule generator model based on the Transformer with two constraint networks: property prediction and similarity prediction. We further improve the model by incorporating score predictions from these constraint networks in a modified beam search algorithm. The experiments demonstrate that our proposed model, Controlled Molecule Generator (CMG), outperforms state-of-the-art models by a significant …"
Joyce C Ho,Weakly-supervised scientific document classification via retrieval-augmented multi-stage training,2023,https://dl.acm.org/doi/abs/10.1145/3539618.3592085,"Scientific document classification is a critical task for a wide range of applications, but the cost of collecting human-labeled data can be prohibitive. We study scientific document classification using label names only. In scientific domains, label names often include domain-specific concepts that may not appear in the document corpus, making it difficult to match labels and documents precisely. To tackle this issue, we propose WanDeR, which leverages dense retrieval to perform matching in the embedding space to capture the semantics of label names. We further design the label name expansion module to enrich its representations. Lastly, a self-training step is used to refine the predictions. The experiments on three datasets show that WanDeR outperforms the best baseline by 11.9%. Our code will be published at https://github.com/ritaranx/wander."
Joyce C Ho,Robust irregular tensor factorization and completion for temporal health data analysis,2020,https://dl.acm.org/doi/abs/10.1145/3340531.3411982,"Electronic health records (EHR) are often generated and collected across a large number of patients featuring distinctive medical conditions and clinical progress over a long period of time, which results in unaligned records along the time dimension. EHR is also prone to missing and erroneous data due to various practical reasons. Recently, PARAFAC2 has been re-popularized for successfully extracting meaningful medical concepts (phenotypes) from such temporal EHR by irregular tensor factorization. Despite recent advances, existing PARAFAC2 methods are unable to robustly handle erroneousness and missing data which are prevalent in clinical practice. We propose REPAIR, a Robust tEmporal PARAFAC2 method for IRregular tensor factorization and completion method, to complete an irregular tensor and extract phenotypes in the presence of missing and erroneous values. To achieve this, REPAIR …"
Joyce C Ho,Profiles of intraday glucose in type 2 diabetes and their association with complications: an analysis of continuous glucose monitoring data,2021,https://www.liebertpub.com/doi/abs/10.1089/dia.2020.0672,"Aims: To identify profiles of type 2 diabetes from continuous glucose monitoring (CGM) data using ambulatory glucose profile (AGP) indicators and examine the association with prevalent complications.Methods: Two weeks of CGM data, collected between 2015 and 2019, from 5901 adult type 2 diabetes patients were retrieved from a clinical database in Chennai, India. Non-negative matrix factorization was used to identify profiles as per AGP indicators. The association of profiles with existing complications was examined using multinomial and logistic regressions adjusted for glycated hemoglobin (HbA1c; %), sex, age at onset, and duration of diabetes.Results: Three profiles of glycemic variability (GV) were identified based on CGM data—Profile 1 [“TIR Profile”] (n = 2271), Profile 2 [“Hypo”] (n = 1471), and Profile 3 [“Hyper”] (n = 2159). Compared with time in range (TIR) profile, those belonging to Hyper had …"
Joyce C Ho,Ram-ehr: Retrieval augmentation meets clinical predictions on electronic health records,2024,https://arxiv.org/abs/2403.00815,"We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \url{https://github.com/ritaranx/RAM-EHR}."
Joyce C Ho,Ehragent: Code empowers large language models for complex tabular reasoning on electronic health records,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240107128S/abstract,"Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent1, an LLM agent empowered with a code interface, to autonomously generate and execute code for complex clinical tasks within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on …"
Joyce C Ho,Swift: Scalable wasserstein factorization for sparse nonnegative tensors,2021,https://ojs.aaai.org/index.php/AAAI/article/view/16811,"Existing tensor factorization methods assume that the input tensor follows some specific distribution (ie Poisson, Bernoulli, and Gaussian), and solve the factorization by minimizing some empirical loss functions defined based on the corresponding distribution. However, it suffers from several drawbacks: 1) In reality, the underlying distributions are complicated and unknown, making it infeasible to be approximated by a simple distribution. 2) The correlation across dimensions of the input tensor is not well utilized, leading to sub-optimal performance. Although heuristics were proposed to incorporate such correlation as side information under Gaussian distribution, they can not easily be generalized to other distributions. Thus, a more principled way of utilizing the correlation in tensor factorization models is still an open challenge. Without assuming any explicit distribution, we formulate the tensor factorization as an optimal transport problem with Wasserstein distance, which can handle non-negative inputs. We introduce SWIFT, which minimizes the Wasserstein distance that measures the distance between the input tensor and that of the reconstruction. In particular, we define the N-th order tensor Wasserstein loss for the widely used tensor CP factorization and derive the optimization algorithm that minimizes it. By leveraging sparsity structure and different equivalent formulations for optimizing computational efficiency, SWIFT is as scalable as other well-known CP algorithms. Using the factor matrices as features, SWIFT achieves up to 9.65% and 11.31% relative improvement over baselines for downstream prediction tasks. Under the noisy conditions …"
Joyce C Ho,Domain-guided task decomposition with self-training for detecting personal events in social media,2020,https://dl.acm.org/doi/abs/10.1145/3366423.3380304,"Mining social media content for tasks such as detecting personal experiences or events, suffer from lexical sparsity, insufficient training data, and inventive lexicons. To reduce the burden of creating extensive labeled data and improve classification performance, we propose to perform these tasks in two steps: 1. Decomposing the task into domain-specific sub-tasks by identifying key concepts, thus utilizing human domain understanding; and 2. Combining the results of learners for each key concept using co-training to reduce the requirements for labeled training data. We empirically show the effectiveness and generality of our approach, Co-Decomp, using three representative social media mining tasks, namely Personal Health Mention detection, Crisis Report detection, and Adverse Drug Reaction monitoring. The experiments show that our model is able to outperform the state-of-the-art text classification models …"
Joyce C Ho,Hypergraph transformers for ehr-based clinical predictions,2023,https://pmc.ncbi.nlm.nih.gov/articles/PMC10283128/,"Electronic health records (EHR) data contain rich information about patients’ health conditions including diagnosis, procedures, medications and etc., which have been widely used to facilitate digital medicine. Despite its importance, it is often non-trivial to learn useful representations for patients’ visits that support downstream clinical predictions, as each visit contains massive and diverse medical codes. As a result, the complex interactions among medical codes are often not captured, which leads to substandard predictions. To better model these complex relations, we leverage hypergraphs, which go beyond pairwise relations to jointly learn the representations for visits and medical codes. We also propose to use the self-attention mechanism to automatically identify the most relevant medical codes for each visit based on the downstream clinical predictions with better generalization power. Experiments on two …"
Joyce C Ho,Bmretriever: Tuning large language models as better biomedical text retrievers,2024,https://arxiv.org/abs/2404.18443,"Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the deficiency of sufficient publicly annotated biomedical data and computational resources. We present BMRetriever, a series of dense retrievers for enhancing biomedical retrieval via unsupervised pre-training on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify BMRetriever's efficacy on various biomedical applications. BMRetriever also exhibits strong parameter efficiency, with the 410M variant outperforming baselines up to 11.7 times larger, and the 2B variant matching the performance of models with over 5B parameters. The training data and model checkpoints are released at \url{https://huggingface.co/BMRetriever} to ensure transparency, reproducibility, and application to new domains."
Joyce C Ho,Califorest: calibrated random forest for health data,2020,https://dl.acm.org/doi/abs/10.1145/3368555.3384461,"Real-world predictive models in healthcare should be evaluated in terms of discrimination, the ability to differentiate between high and low risk events, and calibration, or the accuracy of the risk estimates. Unfortunately, calibration is often neglected and only discrimination is analyzed. Calibration is crucial for personalized medicine as they play an increasing role in the decision making process. Since random forest is a popular model for many healthcare applications, we propose CaliForest, a new calibrated random forest. Unlike existing calibration methodologies, CaliForest utilizes the out-of-bag samples to avoid the explicit construction of a calibration set. We evaluated CaliForest on two risk prediction tasks obtained from the publicly-available MIMIC-III database. Evaluation on these binary prediction tasks demonstrates that CaliForest can achieve the same discriminative power as random forest while obtaining …"
Joyce C Ho,"A survey on knowledge graphs for healthcare: Resources, applications, and promises",2023,https://scholar.google.com/scholar?cluster=10795607586935336120&hl=en&oi=scholarr,
Joyce C Ho,GDA-AM: On the effectiveness of solving min-imax optimization via anderson mixing,2022,https://par.nsf.gov/servlets/purl/10382665,"Many modern machine learning algorithms such as generative adversarial networks (GANs) and adversarial training can be formulated as minimax optimization. Gradient descent ascent (GDA) is the most commonly used algorithm due to its simplicity. However, GDA can converge to non-optimal minimax points. We propose a new minimax optimization framework, GDA-AM, that views the GDA dynamics as a fixed-point iteration and solves it using Anderson Mixing to converge to the local minimax. It addresses the diverging issue of simultaneous GDA and accelerates the convergence of alternating GDA. We show theoretically that the algorithm can achieve global convergence for bilinear problems under mild conditions. We also empirically show that GDA-AM solves a variety of minimax problems and improves adversarial training on several datasets. Codes are available on Github 1."
Joyce C Ho,Extracting medication information from unstructured public health data: a demonstration on data from population-based and tertiary-based samples,2020,https://link.springer.com/article/10.1186/s12874-020-01131-7,"Unstructured data from clinical epidemiological studies can be valuable and easy to obtain. However, it requires further extraction and processing for data analysis. Doing this manually is labor-intensive, slow and subject to error. In this study, we propose an automation framework for extracting and processing unstructured data.The proposed automation framework consisted of two natural language processing (NLP) based tools for unstructured text data for medications and reasons for medication use. We first checked spelling using a spell-check program trained on publicly available knowledge sources and then applied NLP techniques. We mapped medication names into generic names using vocabulary from publicly available knowledge sources. We used WHO’s Anatomical Therapeutic Chemical (ATC) classification system to map generic medication names to medication classes. We …"
Joyce C Ho,Llms-based few-shot disease predictions using ehr: A novel approach combining predictive agent reasoning and critical agent instruction,2024,https://arxiv.org/abs/2403.15464,"Electronic health records (EHRs) contain valuable patient data for health-related prediction tasks, such as disease prediction. Traditional approaches rely on supervised learning methods that require large labeled datasets, which can be expensive and challenging to obtain. In this study, we investigate the feasibility of applying Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives. We evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies. Furthermore, we propose a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent. Our results demonstrate that with the proposed approach, LLMs can achieve decent few-shot performance compared to traditional supervised learning methods in EHR-based disease predictions, suggesting its potential for health-oriented applications."
Joyce C Ho,Privacy-preserving sequential pattern mining in distributed EHRs for predicting cardiovascular disease,2021,https://pmc.ncbi.nlm.nih.gov/articles/PMC8378625/,"From electronic health records (EHRs), the relationship between patients' conditions, treatments, and outcomes can be discovered and used in various healthcare research tasks such as risk prediction. In practice, EHRs can be stored in one or more data warehouses, and mining from distributed data sources becomes challenging. Another challenge arises from privacy laws because patient data cannot be used without some patient privacy guarantees. Thus, in this paper, we propose a privacy-preserving framework using sequential pattern mining in distributed data sources. Our framework extracts patterns from each source and shares patterns with other sources to discover discriminative and representative patterns that can be used for risk prediction while preserving privacy. We demonstrate our framework using a case study of predicting Cardiovascular Disease in patients with type 2 diabetes and show the …"
Joyce C Ho,Pressure ulcer injury in unstructured clinical notes: detection and interpretation,2021,https://pmc.ncbi.nlm.nih.gov/articles/PMC8075497/,"Hospital-acquired pressure ulcer injury (PUI) is a primary nursing quality metric, reflecting the caliber of nursing care within a hospital. Prior studies have used the Braden scale and structured data from the electronic health records to detect/predict PUI while the informative unstructured clinical notes have not been used. We propose automated PUI detection using a novel negation-detection algorithm applied to unstructured clinical notes. Our detection framework is on-demand, requiring minimal cost. In application to the MIMIC-III dataset, the text features produced using our algorithm resulted in improved PUI detection when evaluated using logistic regression, random forests, and neural networks compared to text features without negation detection. Exploratory analysis reveals substantial overlap between key classifier features and leading clinical attributes of PUI, adding interpretability to our solution. Our method …"
Joyce C Ho,"A survey on knowledge graphs for healthcare: Resources, application progress, and promise",2023,https://openreview.net/forum?id=CZCktJoBRh,"Healthcare knowledge graphs (HKGs) have emerged as a promising tool for organizing medical knowledge in a structured and interpretable way, which provides a comprehensive view of medical concepts and their relationships. However, challenges such as data heterogeneity and limited coverage remain, emphasizing the need for further research in the field of HKGs. This survey paper serves as the first comprehensive overview of HKGs. We summarize the pipeline and key techniques for HKG construction (i.e., from scratch and through integration), as well as the common utilization approaches (i.e., model-free and model-based). To provide researchers with valuable resources, we organize existing HKGs based on the data types they capture and application domains, supplemented with pertinent statistical information. In the application section, we delve into the transformative impact of HKGs across various healthcare domains, spanning from fine-grained basic science research to high-level clinical decision support. Lastly, we shed light on the opportunities for creating comprehensive and accurate HKGs in the era of large language models, presenting the potential to revolutionize healthcare delivery and enhance the interpretability and reliability of clinical prediction."
Joyce C Ho,Solve minimax optimization by Anderson acceleration,2022,https://par.nsf.gov/servlets/purl/10358815,"Many modern machine learning algorithms such as generative adversarial networks (GANs) and adversarial training can be formulated as minimax optimization. Gradient descent ascent (GDA) is the most commonly used algorithm due to its simplicity. However, GDA can converge to non-optimal minimax points. We propose a new minimax optimization framework, GDA-AM, that views the GDA dynamics as a fixed-point iteration and solves it using Anderson Mixing to converge to the local minimax. It addresses the diverging issue of simultaneous GDA and accelerates the convergence of alternating GDA. We show theoretically that the algorithm can achieve global convergence for bilinear problems under mild conditions. We also empirically show that GDA-AM solves a variety of minimax problems and improves adversarial training on several datasets. Codes are available on Github 1."
Joyce C Ho,Temporal network embedding via tensor factorization,2021,https://dl.acm.org/doi/abs/10.1145/3459637.3482200,"Representation learning on static graph-structured data has shown a significant impact on many real-world applications. However, less attention has been paid to the evolving nature of temporal networks, in which the edges are often changing over time. The embeddings of such temporal networks should encode both graph-structured information and the temporally evolving pattern. Existing approaches in learning temporally evolving network representations fail to capture the temporal interdependence. In this paper, we propose Toffee, a novel approach for temporal network representation learning based on tensor decomposition. Our method exploits the tensor-tensor product operator to encode the cross-time information, so that the periodic changes in the evolving networks can be captured. Experimental results demonstrate that Toffee outperforms existing methods on multiple real-world temporal networks in …"
Joyce C Ho,Word centrality constrained representation for keyphrase extraction,2021,https://pmc.ncbi.nlm.nih.gov/articles/PMC9208728/,"To keep pace with the increased generation and digitization of documents, automated methods that can improve search, discovery and mining of the vast body of literature are essential. Keyphrases provide a concise representation by identifying salient concepts in a document. Various supervised approaches model keyphrase extraction using local context to predict the label for each token and perform much better than the unsupervised counterparts. Unfortunately, this method fails for short documents where the context is unclear. Moreover, keyphrases, which are usually the gist of a document, need to be the central theme. We propose a new extraction model that introduces a centrality constraint to enrich the word representation of a Bidirectional long short-term memory. Performance evaluation on two publicly available datasets demonstrate our model outperforms existing state-of-the art approaches. Our model …"
Joyce C Ho,Fast and accurate tensor decomposition without a high performance computing machine,2020,https://ieeexplore.ieee.org/abstract/document/9378111/,"The rapid growth in the collection of high-dimensional data has led to the emergence of tensor decomposition, a powerful analysis method for the exploration of such data. Since tensor decomposition can extract hidden structures and capture underlying relationships between variables, it has been used successfully across a broad range of applications. However, tensor decomposition is a computationally expensive task, and most existing methods developed to decompose large tensors require expensive computing hardware or high-performance computing environment. Moreover, existing approaches focus solely on numeric data, and may not yield desirable results for binary or count data. Therefore, we propose FAST-CP, a novel algorithm to accelerate the convergence of the stochastic gradient descent based CANDECOMP/PARAFAC (CP) decomposition model through a new extrapolation method. Our …"
Joyce C Ho,"A review on knowledge graphs for healthcare: Resources, applications, and promises",2023,https://arxiv.org/abs/2306.04802,"Healthcare knowledge graphs (HKGs) are valuable tools for organizing biomedical concepts and their relationships with interpretable structures. The recent advent of large language models (LLMs) has paved the way for building more comprehensive and accurate HKGs. This, in turn, can improve the reliability of generated content and enable better evaluation of LLMs. However, the challenges of HKGs such as regarding data heterogeneity and limited coverage are not fully understood, highlighting the need for detailed reviews. This work provides the first comprehensive review of HKGs. It summarizes the pipeline and key techniques for HKG construction, as well as the common utilization approaches, i.e., model-free and model-based. The existing HKG resources are also organized based on the data types they capture and application domains they cover, along with relevant statistical information (Resource available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase). At the application level, we delve into the successful integration of HKGs across various health domains, ranging from fine-grained basic science research to high-level clinical decision support and public health. Lastly, the paper highlights the opportunities for HKGs in the era of LLMs. This work aims to serve as a valuable resource for understanding the potential and opportunities of HKG in health research."
Joyce C Ho,Evaluation of available risk scores to predict multiple cardiovascular complications for patients with type 2 diabetes mellitus using electronic health records,2023,https://www.sciencedirect.com/science/article/pii/S2666990022000386,"AimsVarious cardiovascular risk prediction models have been developed for patients with type 2 diabetes mellitus. Yet few models have been validated externally. We perform a comprehensive validation of existing risk models on a heterogeneous population of patients with type 2 diabetes using secondary analysis of electronic health record data.MethodsElectronic health records of 47,988 patients with type 2 diabetes between 2013 and 2017 were used to validate 16 cardiovascular risk models, including 5 that had not been compared previously, to estimate the 1-year risk of various cardiovascular outcomes. Discrimination and calibration were assessed by the c-statistic and the Hosmer-Lemeshow goodness-of-fit statistic, respectively. Each model was also evaluated based on the missing measurement rate. Sub-analysis was performed to determine the impact of race on discrimination performance.ResultsThere …"
Joyce C Ho,Multimodal fusion of ehr in structures and semantics: Integrating clinical records and notes with hypergraph and llm,2024,https://arxiv.org/abs/2403.08818,"Electronic Health Records (EHRs) have become increasingly popular to support clinical decision-making and healthcare in recent decades. EHRs usually contain heterogeneous information, such as structural data in tabular form and unstructured data in textual notes. Different types of information in EHRs can complement each other and provide a more complete picture of the health status of a patient. While there has been a lot of research on representation learning of structured EHR data, the fusion of different types of EHR data (multimodal fusion) is not well studied. This is mostly because of the complex medical coding systems used and the noise and redundancy present in the written notes. In this work, we propose a new framework called MINGLE, which integrates both structures and semantics in EHR effectively. Our framework uses a two-level infusion strategy to combine medical concept semantics and clinical note semantics into hypergraph neural networks, which learn the complex interactions between different types of data to generate visit representations for downstream prediction. Experiment results on two EHR datasets, the public MIMIC-III and private CRADLE, show that MINGLE can effectively improve predictive performance by 11.83% relatively, enhancing semantic integration as well as multimodal fusion for structural and textual EHR data."
Joyce C Ho,AGE: Enhancing the convergence on GANs using alternating extra-gradient with gradient extrapolation,2021,https://openreview.net/forum?id=Kyx64ssj1j,"Generative adversarial networks (GANs) are notably difficult to train since the parameters can get stuck in a local optimum. As a result, methods often suffer not only from degeneration of the convergence speed but also from limitations in the representational power of the trained network. Existing optimization methods to stabilize convergence require multiple gradient computations per iteration. We propose AGE, an alternating extra-gradient method with nonlinear gradient extrapolation, that overcomes these computational inefficiencies and exhibits better convergence properties. It estimates the lookahead step using a nonlinear mixing of past gradient sequences. Empirical results on CIFAR10, CelebA, and several synthetic datasets demonstrate that the introduced approach significantly improves convergence and yields better generative models."
Joyce C Ho,Spatio-temporal tensor sketching via adaptive sampling,2021,https://link.springer.com/chapter/10.1007/978-3-030-67658-2_28,"Mining massive spatio-temporal data can help a variety of real-world applications such as city capacity planning, event management, and social network analysis. The tensor representation can be used to capture the correlation between space and time and simultaneously exploit the latent structure of the spatial and temporal patterns in an unsupervised fashion. However, the increasing volume of spatio-temporal data has made it prohibitively expensive to store and analyze using tensor factorization.In this paper, we propose SkeTenSmooth, a novel tensor factorization framework that uses adaptive sampling to compress the tensor in a temporally streaming fashion and preserves the underlying global structure. SkeTenSmooth adaptively samples incoming tensor slices according to the detected data dynamics. Thus, the sketches are more representative and informative of the tensor dynamic …"
Joyce C Ho,MMiDaS-AE: multi-modal missing data aware stacked autoencoder for biomedical abstract screening,2020,https://dl.acm.org/doi/abs/10.1145/3368555.3384463,"Systematic review (SR) is an essential process to identify, evaluate, and summarize the findings of all relevant individual studies concerning health-related questions. However, conducting a SR is labor-intensive, as identifying relevant studies is a daunting process that entails multiple researchers screening thousands of articles for relevance. In this paper, we propose MMiDaS-AE, a Multi-modal Missing Data aware Stacked Autoencoder, for semi-automating screening for SRs. We use a multi-modal view that exploits three representations, of: 1) documents, 2) topics, and 3) citation networks. Documents that contain similar words will be nearby in the document embedding space. Models can also exploit the relationship between documents and the associated SR MeSH terms to capture article relevancy. Finally, related works will likely share the same citations, and thus closely related articles would, intuitively, be …"
Joyce C Ho,A flexible generative model for heterogeneous tabular EHR with missing modality,2024,https://openreview.net/forum?id=W2tCmRrj7H,"Realistic synthetic electronic health records (EHRs) can be leveraged to acceler- ate methodological developments for research purposes while mitigating privacy concerns associated with data sharing. However, the training of Generative Ad- versarial Networks remains challenging, often resulting in issues like mode col- lapse. While diffusion models have demonstrated progress in generating qual- ity synthetic samples for tabular EHRs given ample denoising steps, their perfor- mance wanes when confronted with missing modalities in heterogeneous tabular EHRs data. For example, some EHRs contain solely static measurements, and some contain only contain temporal measurements, or a blend of both data types. To bridge this gap, we introduce FLEXGEN-EHR– a versatile diffusion model tai- lored for heterogeneous tabular EHRs, equipped with the capability of handling missing modalities in an integrative learning framework. We define an optimal transport module to align and accentuate the common feature space of hetero- geneity of EHRs. We empirically show that our model consistently outperforms existing state-of-the-art synthetic EHR generation methods both in fidelity by up to 3.10% and utility by up to 7.16%. Additionally, we show that our method can be successfully used in privacy-sensitive settings, where the original patient-level data cannot be shared."
Joyce C Ho,An AdaBoost-based algorithm to detect hospital-acquired pressure injury in the presence of conflicting annotations,2024,https://www.sciencedirect.com/science/article/pii/S0010482523012192,"Hospital-acquired pressure injury is one of the most harmful events in clinical settings. Patients who do not receive early prevention and treatment can experience a significant financial burden and physical trauma. Several hospital-acquired pressure injury prediction algorithms have been developed to tackle this problem, but these models assume a consensus, gold-standard label (i.e., presence of pressure injury or not) is present for all training data. Existing definitions for identifying hospital-acquired pressure injuries are inconsistent due to the lack of high-quality documentation surrounding pressure injuries. To address this issue, we propose in this paper an ensemble-based algorithm that leverages truth inference methods to resolve label inconsistencies between various case definitions and the level of disagreements in annotations. Application of our method to MIMIC-III, a publicly available intensive care unit …"
Joyce C Ho,A comprehensive and improved definition for hospital-acquired pressure injury classification based on electronic health records: comparative study,2023,https://medinform.jmir.org/2023/1/e40672/,"Background: Patients develop pressure injuries (PIs) in the hospital owing to low mobility, exposure to localized pressure, circulatory conditions, and other predisposing factors. Over 2.5 million Americans develop PIs annually. The Center for Medicare and Medicaid considers hospital-acquired PIs (HAPIs) as the most frequent preventable event, and they are the second most common claim in lawsuits. With the growing use of electronic health records (EHRs) in hospitals, an opportunity exists to build machine learning models to identify and predict HAPI rather than relying on occasional manual assessments by human experts. However, accurate computational models rely on high-quality HAPI data labels. Unfortunately, the different data sources within EHRs can provide conflicting information on HAPI occurrence in the same patient. Furthermore, the existing definitions of HAPI disagree with each other, even within the same patient population. The inconsistent criteria make it impossible to benchmark machine learning methods to predict HAPI.Objective: The objective of this project was threefold. We aimed to identify discrepancies in HAPI sources within EHRs, to develop a comprehensive definition for HAPI classification using data from all EHR sources, and to illustrate the importance of an improved HAPI definition.Methods: We assessed the congruence among HAPI occurrences documented in clinical notes, diagnosis codes, procedure codes, and chart events from the Medical Information Mart for Intensive Care III database. We analyzed the criteria used for the 3 existing HAPI definitions and their adherence to the regulatory guidelines. We …"
Joyce C Ho,Diabetes and hypertension among South Asians in New York and Atlanta leveraging hospital electronic health records,2021,https://link.springer.com/article/10.1186/s13098-021-00766-w,"Diabetes and hypertension disparities are pronounced among South Asians. There is regional variation in the prevalence of diabetes and hypertension in the US, but it is unknown whether there is variation among South Asians living in the US. The objective of this study was to compare the burden of diabetes and hypertension between South Asian patients receiving care in the health systems of two US cities.Cross-sectional analyses were performed using electronic health records (EHR) for 90,137 South Asians receiving care at New York University Langone in New York City (NYC) and 28,868 South Asians receiving care at Emory University (Atlanta). Diabetes was defined as having 2 + encounters with a diagnosis of diabetes, having a diabetes medication prescribed (excluding Acarbose/Metformin), or having 2 + abnormal …"
Joyce C Ho,Uncertainty-based self-training for biomedical keyphrase extraction,2021,https://ieeexplore.ieee.org/abstract/document/9508592/,"To keep pace with the increased generation and digitization of documents, automated methods that can improve search, discovery and mining of the vast body of literature are essential. Keyphrases provide a concise representation by identifying salient concepts in a document. Various supervised approaches model keyphrase extraction using local context to predict the label for each token and perform much better than the unsupervised counterparts. However, existing supervised datasets have limited annotated examples to train better deep learning models. In contrast, many domains have large amount of un-annotated data that can be leveraged to improve model performance in keyphrase extraction. We introduce a self- learning based model that incorporates uncertainty estimates to select instances from large-scale unlabeled data to augment the small labeled training set. Performance evaluation on a publicly …"
Joyce C Ho,GASP: Graph-based approximate sequential pattern mining for electronic health records,2021,https://link.springer.com/chapter/10.1007/978-3-030-85082-1_5,"Sequential pattern mining can be used to extract meaningful sequences from electronic health records. However, conventional sequential pattern mining algorithms that discover all frequent sequential patterns can incur a high computational and be susceptible to noise in the observations . Approximate sequential pattern mining techniques have been introduced to address these shortcomings yet, existing approximate methods fail to reflect the true frequent sequential patterns or only target single-item event sequences. Multi-item event sequences are prominent in healthcare as a patient can have multiple interventions for a single visit. To alleviate these issues, we propose GASP, a graph-based approximate sequential pattern mining, that discovers frequent patterns for multi-item event sequences. Our approach compresses the sequential information into a concise graph structure which has computational benefits …"
Joyce C Ho,PromptLink: Leveraging large language models for cross-source biomedical concept linking,2024,https://dl.acm.org/doi/abs/10.1145/3626772.3657904,"Linking (aligning) biomedical concepts across diverse data sources enables various integrative analyses, but it is challenging due to the discrepancies in concept naming conventions. Various strategies have been developed to overcome this challenge, such as those based on string-matching rules, manually crafted thesauri, and machine learning models. However, these methods are constrained by limited prior biomedical knowledge and can hardly generalize beyond the limited amounts of rules, thesauri, or training samples. Recently, large language models (LLMs) have exhibited impressive results in diverse biomedical NLP tasks due to their unprecedentedly rich prior knowledge and strong zero-shot prediction abilities. However, LLMs suffer from issues including high costs, limited context length, and unreliable predictions. In this research, we propose PromptLink, a novel biomedical concept linking …"
Joyce C Ho,PubMed Author-assigned Keyword Extraction (PubMedAKE) Benchmark,2022,https://dl.acm.org/doi/abs/10.1145/3511808.3557675,"With the ever-increasing abundance of biomedical articles, improving the accuracy of keyword search results becomes crucial for ensuring reproducible research. However, keyword extraction for biomedical articles is hard due to the existence of obscure keywords and the lack of a comprehensive benchmark. PubMedAKE is an author-assigned keyword extraction dataset that contains the title, abstract, and keywords of over 843,269 articles from the PubMed open access subset database. This dataset, publicly available on Zenodo, is the largest keyword extraction benchmark with sufficient samples to train neural networks. Experimental results using state-of-the-art baseline methods illustrate the need for developing automatic keyword extraction methods for biomedical literature."
Joyce C Ho,Communication efficient tensor factorization for decentralized healthcare networks,2021,https://ieeexplore.ieee.org/abstract/document/9679154/,"Tensor factorization has been proved as an efficient unsupervised learning approach for health data analysis, especially for computational phenotyping, where the high-dimensional Electronic Health Records (EHRs) with patients history of medical procedures, medications, diagnosis, lab tests, etc., are converted to meaningful and interpretable medical concepts. Federated tensor factorization distributes the tensor computation to multiple workers under the coordination of a central server, which enables jointly learning the phenotypes across multiple hospitals while preserving the privacy of the patient information. However, existing federated tensor factorization algorithms encounter the single-point-failure issue with the involvement of the central server, which is not only easily exposed to external attacks, but also limits the number of clients sharing information with the server under restricted uplink bandwidth. In this …"
Joyce C Ho,"Examining the concordance in the documented pressure injury site, stage, and count in medical information mart for intensive care-III",2021,https://www.thieme-connect.com/products/ejournals/html/10.1055/s-0041-1735179," Objectives This study aimed to compare the concordance of pressure injury (PI) site, stage, and count documented in electronic health records (EHRs); explore if PI count during each patient hospitalization is consistent based on PI site or stage count in the diagnosis or chart event records; and examine if discrepancies in PI count were associated with patient characteristics. Methods Hospitalization records with the International Classification of Diseases ninth edition (ICD-9) codes, chart events from two systems (CareVue, MetaVision), and clinical notes on PI were extracted from the Medical Information Mart for Intensive Care (MIMIC)-III database. PI site and stage counts from individual hospitalization were computed. Hospitalizations with the same or different counts of site and stage according to ICD-9 codes (site and stage), CareVue (site and stage), or MetaVision (stage) charts were defined as consistent or …"
Joyce C Ho,You sound like someone who watches drama movies: Towards predicting movie preferences from conversational interactions,2021,https://aclanthology.org/2021.naacl-main.246/,"The increasing popularity of voice-based personal assistants provides new opportunities for conversational recommendation. One particularly interesting area is movie recommendation, which can benefit from an open-ended interaction with the user, through a natural conversation. We explore one promising direction for conversational recommendation: mapping a conversational user, for whom there is limited or no data available, to most similar external reviewers, whose preferences are known, by representing the conversation as a user’s interest vector, and adapting collaborative filtering techniques to estimate the current user’s preferences for new movies. We call our proposed method ConvExtr (Conversational Collaborative Filtering using External Data), which 1) infers a user’s sentiment towards an entity from the conversation context, and 2) transforms the ratings of “similar” external reviewers to predict the current user’s preferences. We implement these steps by adapting contextual sentiment prediction techniques, and domain adaptation, respectively. To evaluate our method, we develop and make available a finely annotated dataset of movie recommendation conversations, which we call MovieSent. Our results demonstrate that ConvExtr can improve the accuracy of predicting users’ ratings for new movies by exploiting conversation content and external data."
Joyce C Ho,Knowledge-infused prompting improves clinical text generation with large language models,2023,https://openreview.net/forum?id=wK2y7ZhPvU,"Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts.  Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources.  To address this challenge, we propose ClinGen, which infuses knowledge into synthetic clinical text generation using LLMs for clinical NLP tasks. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation.  Extensive studies across 7 clinical NLP tasks and 16 datasets reveal that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and enriching the diversity of generated training instances."
Joyce C Ho,Simrag: Self-improving retrieval-augmented generation for adapting large language models to specialized domains,2024,https://arxiv.org/abs/2410.17952,"Retrieval-augmented generation (RAG) enhances the question-answering (QA) abilities of large language models (LLMs) by integrating external knowledge. However, adapting general-purpose RAG systems to specialized fields such as science and medicine poses unique challenges due to distribution shifts and limited access to domain-specific data. To tackle this, we propose SimRAG, a self-training approach that equips the LLM with joint capabilities of question answering and question generation for domain adaptation. Our method first fine-tunes the LLM on instruction-following, question-answering, and search-related data. Then, it prompts the same LLM to generate diverse domain-relevant questions from unlabeled corpora, with an additional filtering strategy to retain high-quality synthetic examples. By leveraging these self-generated synthetic examples, the LLM can improve their performance on domain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three domains, demonstrate that SimRAG outperforms baselines by 1.2\%--8.6\%."
Joyce C Ho,HypMix: Hyperbolic Representation Learning for Graphs with Mixed Hierarchical and Non-hierarchical Structures,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679940,"Heterogeneous networks contain multiple types of nodes and links, with some link types encapsulating hierarchical structure over entities. Hierarchical relationships can codify information such as subcategories or one entity being subsumed by another and are often used for organizing conceptual knowledge into a tree-structured graph. Hyperbolic embedding models learn node representations in a hyperbolic space suitable for preserving the hierarchical structure. Unfortunately, current hyperbolic embedding models only implicitly capture the hierarchical structure, failing to distinguish between node types, and they only assume a single tree. In practice, many networks contain a mixture of hierarchical and non-hierarchical structures, and the hierarchical relations may be represented as multiple trees with complex structures, such as sharing certain entities. In this work, we propose a new hyperbolic representation …"
Joyce C Ho,Evaluating Natural Language Processing Packages for Predicting Hospital-Acquired Pressure Injuries From Clinical Notes,2024,https://journals.lww.com/cinjournal/fulltext/2024/03000/evaluating_natural_language_processing_packages.5.aspx,"Incidence of hospital-acquired pressure injury, a key indicator of nursing quality, is directly proportional to adverse outcomes, increased hospital stays, and economic burdens on patients, caregivers, and society. Thus, predicting hospital-acquired pressure injury is important. Prediction models use structured data more often than unstructured notes, although the latter often contain useful patient information. We hypothesize that unstructured notes, such as nursing notes, can predict hospital-acquired pressure injury. We evaluate the impact of using various natural language processing packages to identify salient patient information from unstructured text. We use named entity recognition to identify keywords, which comprise the feature space of our classifier for hospital-acquired pressure injury prediction. We compare scispaCy and Stanza, two different named entity recognition models, using unstructured notes in …"
Joyce C Ho,MULTIPAR: Supervised Irregular Tensor Factorization with Multi-task Learning for Computational Phenotyping,2023,https://proceedings.mlr.press/v225/ren23a.html,"Tensor factorization has received increasing interest due to its intrinsic ability to capture latent factors in multi-dimensional data with many applications including Electronic Health Records (EHR) mining. PARAFAC2 and its variants have been proposed to address irregular tensors where one of the tensor modes is not aligned, eg, different patients in EHRs may have different length of records. PARAFAC2 has been successfully applied to EHRs for extracting meaningful medical concepts (phenotypes). Despite recent advancements, current models’ predictability and interpretability are not satisfactory, which limits its utility for downstream analysis. In this paper, we propose MULTIPAR: a supervised irregular tensor factorization with multi-task learning for computational phenotyping. MULTIPAR is flexible to incorporate both static (eg in-hospital mortality prediction) and continuous or dynamic (eg the need for ventilation) tasks. By supervising the tensor factorization with downstream prediction tasks and leveraging information from multiple related predictive tasks, MULTIPAR can yield not only more meaningful phenotypes but also better predictive performance for downstream tasks. We conduct extensive experiments on two real-world temporal EHR datasets to demonstrate that MULTIPAR is scalable and achieves better tensor fit with more meaningful subgroups and stronger predictive performance compared to existing state-of-the-art methods. The implementation of MULTIPAR is available https://github. com/yifeiren13/MULTIPAR."
Joyce C Ho,PGB: A PubMed Graph Benchmark for Heterogeneous Network Representation Learning,2023,https://dl.acm.org/doi/abs/10.1145/3583780.3615128,"There has been rapid growth in biomedical literature, yet capturing the heterogeneity of the bibliographic information of these articles remains relatively understudied. Graph neural networks have gained popularity, however, they may not fully capture the information available in the PubMed database, a biomedical literature repository containing over 33 million articles. We introduce PubMed Graph Benchmark (PGB), a new benchmark dataset for evaluating heterogeneous graph representations. PGB is one of the largest heterogeneous networks to date and aggregates the rich metadata into a unified source including abstract, authors, citations, keywords, and the associated keyword hierarchy. The benchmark contains an evaluation task of 21 systematic review topics, an essential knowledge translation tool."
Joyce C Ho,An Efficient Nonlinear Acceleration method that Exploits Symmetry of the Hessian,2022,https://arxiv.org/abs/2210.12573,"Nonlinear acceleration methods are powerful techniques to speed up fixed-point iterations. However, many acceleration methods require storing a large number of previous iterates and this can become impractical if computational resources are limited. In this paper, we propose a nonlinear Truncated Generalized Conjugate Residual method (nlTGCR) whose goal is to exploit the symmetry of the Hessian to reduce memory usage. The proposed method can be interpreted as either an inexact Newton or a quasi-Newton method. We show that, with the help of global strategies like residual check techniques, nlTGCR can converge globally for general nonlinear problems and that under mild conditions, nlTGCR is able to achieve superlinear convergence. We further analyze the convergence of nlTGCR in a stochastic setting. Numerical results demonstrate the superiority of nlTGCR when compared with several other competitive baseline approaches on a few problems. Our code will be available in the future."
Joyce C Ho,MULTIPAR: Supervised irregular tensor factorization with multi-task learning,2022,https://arxiv.org/abs/2208.00993,"Tensor factorization has received increasing interest due to its intrinsic ability to capture latent factors in multi-dimensional data with many applications such as recommender systems and Electronic Health Records (EHR) mining. PARAFAC2 and its variants have been proposed to address irregular tensors where one of the tensor modes is not aligned, e.g., different users in recommender systems or patients in EHRs may have different length of records. PARAFAC2 has been successfully applied on EHRs for extracting meaningful medical concepts (phenotypes). Despite recent advancements, current models' predictability and interpretability are not satisfactory, which limits its utility for downstream analysis. In this paper, we propose MULTIPAR: a supervised irregular tensor factorization with multi-task learning. MULTIPAR is flexible to incorporate both static (e.g. in-hospital mortality prediction) and continuous or dynamic (e.g. the need for ventilation) tasks. By supervising the tensor factorization with downstream prediction tasks and leveraging information from multiple related predictive tasks, MULTIPAR can yield not only more meaningful phenotypes but also better predictive performance for downstream tasks. We conduct extensive experiments on two real-world temporal EHR datasets to demonstrate that MULTIPAR is scalable and achieves better tensor fit with more meaningful subgroups and stronger predictive performance compared to existing state-of-the-art methods."
Joyce C Ho,CATAN: Chart-aware temporal attention network for adverse outcome prediction,2021,https://ieeexplore.ieee.org/abstract/document/9565794/,"There is an increased adoption of electronic health record systems by a variety of hospitals and medical centers. This provides an opportunity to leverage automated computer systems in assisting healthcare workers. One of the least utilized but rich source of patient information is the unstructured clinical text. In this work, we develop CATAN, a chart-aware temporal attention network for learning patient representations from clinical notes. We introduce a novel representation where each note is considered a single unit, like a sentence, and composed of attention-weighted words. The notes in turn are aggregated into a patient representation using a second weighting unit, note attention. Unlike standard attention computations which focus only on the content of the note, we incorporate the chart-time for each note as a constraint for attention calculation. This allows our model to focus on notes closer to the prediction …"
Joyce C Ho,Cross-modal Memory Fusion Network for Multimodal Sequential Learning with Missing Values,2021,https://link.springer.com/chapter/10.1007/978-3-030-72240-1_30,"Information in many real-world applications is inherently multi-modal, sequential and characterized by a variety of missing values. Existing imputation methods mainly focus on the recurrent dynamics in one modality while ignoring the complementary property from other modalities. In this paper, we propose a novel method called cross-modal memory fusion network (CMFN) that explicitly learns both modal-specific and cross-modal dynamics for imputing the missing values in multi-modal sequential learning tasks. Experiments on two datasets demonstrate that our method outperforms state-of-the-art methods and show its potential to better impute missing values in complex multi-modal datasets."
Joyce C Ho,Llmsyn: Generating synthetic electronic health records without patient-level data,2024,https://raw.githubusercontent.com/mlresearch/v252/main/assets/hao24a/hao24a.pdf,"Recent advancements in large language models (LLMs) have shown promise in tasks like question answering, text summarization, and code generation. However, their effectiveness within the healthcare sector remains uncertain. This study investigates LLMs’ potential to generating synthetic, structured electronic health records (EHRs). Unfortunately, employing LLMs directly resulted in poor statistical similarity and utility. Although feeding real-world data to LLMs can potentially mitigate this issue, it also raises privacy concerns as this transmits patients’ information to the LLM API. To address these challenges and unleash the potential of LLMs for synthetic EHR generation, we present a new generation pipeline called LLMSYN. Our pipeline utilizes only high-level statistical information from datasets and publicly available medical knowledge. Our results demonstrate that the generated EHRs by LLMSYN exhibit improved statistical similarity and utility in downstream tasks and achieve predictive performance comparable to training with real data with minimal privacy risks. Our findings suggest that LLMSYN offers a promising approach to enhance the utility of LLM models in synthetic structured EHR generation."
Joyce C Ho,A Feasibility Study of Thermography for Detecting Pressure Injuries Across Diverse Skin Tones,2024,https://pmc.ncbi.nlm.nih.gov/articles/PMC11527050/,"Pressure injury (PI) detection is challenging, especially in dark skin tones, due to the unreliability of visual inspection. Thermography may serve as a viable alternative as temperature differences in the skin can indicate impending tissue damage. Although deep learning models hold considerable promise toward reliably detecting PI, existing work fails to evaluate performance on diverse skin tones and varying data collection protocols. We collected a new dataset of 35 participants focused on darker skin tones where temperature differences are induced through cooling and cupping protocols. The dataset includes different cameras, lighting, patient pose, and camera distance. We compare the performance of three convolutional neural network (CNN) models trained on either the thermal or the optical images on all skin tones. Our results suggest thermography-based CNN is robust to data collection protocols …"
Joyce C Ho,Large Language Models for Integrating Social Determinant of Health Data: A Case Study on Heart Failure 30-Day Readmission Prediction,2024,https://arxiv.org/abs/2407.09688,"Social determinants of health (SDOH)  the myriad of circumstances in which people live, grow, and age  play an important role in health outcomes. However, existing outcome prediction models often only use proxies of SDOH as features. Recent open data initiatives present an opportunity to construct a more comprehensive view of SDOH, but manually integrating the most relevant data for individual patients becomes increasingly challenging as the volume and diversity of public SDOH data grows. Large language models (LLMs) have shown promise at automatically annotating structured data. Here, we conduct an end-to-end case study evaluating the feasibility of using LLMs to integrate SDOH data, and the utility of these SDOH features for clinical prediction. We first manually label 700+ variables from two publicly-accessible SDOH data sources to one of five semantic SDOH categories. Then, we benchmark performance of 9 open-source LLMs on this classification task. Finally, we train ML models to predict 30-day hospital readmission among 39k heart failure (HF) patients, and we compare the prediction performance of the categorized SDOH variables with standard clinical variables. Additionally, we investigate the impact of few-shot LLM prompting on LLM annotation performance, and perform a metadata ablation study on prompts to evaluate which information helps LLMs accurately annotate these variables. We find that some open-source LLMs can effectively, accurately annotate SDOH variables with zero-shot prompting without the need for fine-tuning. Crucially, when combined with standard clinical features, the LLM-annotated …"
Joyce C Ho,From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR,2024,https://arxiv.org/abs/2406.05682,"Electronic Health Records (EHRs) contain rich patient information and are crucial for clinical research and practice. In recent years, deep learning models have been applied to EHRs, but they often rely on massive features, which may not be readily available for all patients. We propose HTP-Star, which leverages hypergraph structures with a pretrain-then-finetune framework for modeling EHR data, enabling seamless integration of additional features. Additionally, we design two techniques, namely (1) Smoothness-inducing Regularization and (2) Group-balanced Reweighting, to enhance the model's robustness during fine-tuning. Through experiments conducted on two real EHR datasets, we demonstrate that HTP-Star consistently outperforms various baselines while striking a balance between patients with basic and extra features."
Joyce C Ho,EMBA: Entity Matching using Multi-Task Learning of BERT with Attention-over-Attention.,2024,https://openproceedings.org/2024/conf/edbt/paper-76.pdf,"Entity matching is a crucial data integration process as it identifies whether two records refer to the same real-world object. Since shared identifiers are not always available, learning to match based on entity descriptions is an important task. While deep learning methods based on pre-trained transformers have been proposed to automate the entity matching process, these models only utilize the special token representation (ie,[CLS]) to predict matches. However, this can ignore rich and nuanced contextual information in the descriptions, thereby yielding suboptimal matching performance. We propose EMBA, a multi-task learning method with an attention-over-attention mechanism that leverages the individual token representations for the downstream tasks to better capture the information present in the descriptions of the two entities. Our evaluation across 7 entity matching benchmark datasets shows that EMBA achieves state-ofthe-art performance, including up to an 8% improvement in F1 performance, over the existing dual-objective model. Our ablation study highlights the importance of using individual token representations. We also analyze the matching decision using both LIME explanations and attention score visualizations on a case study to illustrate the potential of EMBA."
Joyce C Ho,CONSchema: Schema matching with semantics and constraints,2023,https://link.springer.com/chapter/10.1007/978-3-031-42941-5_21,"Schema matching aims to establish the correspondence between the attributes of database schemas. It has been regarded as the most difficult and crucial stage in the development of many contemporary database and web semantic systems. Manual mapping is a lengthy and laborious process, yet a low-quality algorithmic matcher may cause more trouble. Moreover, the issue of data privacy in certain domains, such as healthcare, poses further challenges, as the use of instance-level data should be avoided to prevent the leakage of sensitive information. To address this issue, we propose CONSchema, a model that combines both the textual attribute description and constraints of the schemas to learn a better matcher. We also propose a new experimental setting to assess the practical performance of schema matching models. Our results on 6 benchmark datasets across various domains including healthcare and …"
Joyce C Ho,"Hepatitis C care cascade in a large academic healthcare system, 2012 to 2018",2023,https://journals.lww.com/md-journal/fulltext/2023/03100/Hepatitis_C_care_cascade_in_a_large_academic.51.aspx,"To determine the hepatitis C virus (HCV) care cascade among persons who were born during 1945 to 1965 and received outpatient care on or after January 2014 at a large academic healthcare system. Deidentified electronic health record data in an existing research database were analyzed for this study. Laboratory test results for HCV antibody and HCV ribonucleic acid (RNA) indicated seropositivity and confirmatory testing. HCV genotyping was used as a proxy for linkage to care. A direct-acting antiviral (DAA) prescription indicated treatment initiation, an undetectable HCV RNA at least 20 weeks after initiation of antiviral treatment indicated a sustained virologic response. Of the 121,807 patients in the 1945 to 1965 birth cohort who received outpatient care between January 1, 2014 and June 30, 2017, 3399 (3%) patients were screened for HCV; 540 (16%) were seropositive. Among the seropositive, 442 (82 …"
Joyce C Ho,Accelerated SGD for Tensor Decomposition of Sparse Count Data,2020,https://ieeexplore.ieee.org/abstract/document/9346447/,"The rapid growth in the collection of high-dimensional data has led to the emergence of tensor decomposition, a powerful analysis method for the exploration of multidimensional data. Since tensor decomposition can extract hidden structures and capture underlying relationships between variables, it has been used successfully across a broad range of applications. However, tensor decomposition is a computationally expensive task, and existing methods developed to decompose large sparse tensors of count data are not efficient enough when being performed with limited computing resources. Therefore, we propose AS-CP, a novel algorithm to accelerate convergence of the stochastic gradient descent based CANDECOMP/PARAFAC (CP) decomposition model through an extrapolation method. The proposed framework can be easily parallelized in an asynchronous way. Our empirical results on three real-world …"
Joyce C Ho,Machine Learning-Based Identification of High-Risk Patterns in Atrial Fibrillation Ablation Outcomes,2024,https://www.medrxiv.org/content/10.1101/2024.11.27.24318097.abstract,"Background Atrial fibrillation (AF) is one of the most common types of cardiac arrhythmias, often leading to serious health issues such as stroke, heart failure, and higher mortality rates. Its global impact is rising due to aging populations and growing comorbidities, creating an urgent need for more effective treatment methods. AF ablation, a key treatment option, has success rates that vary widely among patients. Conventional predictors of ablation outcomes, which primarily rely on sociodemographic and clinical factors, fall short of capturing the heterogeneity within patient populations, highlighting the potential for data-driven methods to provide deeper insights into procedural success. Objectives To uncover meaningful patient subgroups based on AF ablation outcomes and identify diagnostic codes associated with failure. Methods Machine learning clustering with must-link and cannot-link constraints was applied to electronic health records to discover meaningful clusters, revealing patient-specific factors influencing procedural success or failure. Statistical analyses, including chi-square tests, were used to identify diagnostic codes significantly associated with ablation failure. Results Out of the 145 diagnostic codes examined, thirteen significant codes were identified and categorized into four primary risk groups, ranked by their impact on procedural outcomes: (1) direct contributors affecting cardiovascular health, (2) indirect factors that contribute to systemic stress, (3) complications related to anticoagulation and hemorrhagic risks that can impact bleeding management, and (4) broader health indicators reflecting a general health burden that …"
Joyce C Ho,Predicting Atrial Fibrillation Ablation Outcomes: A Machine Learning Approach Leveraging a Large Administrative Claims Database,2024,https://www.medrxiv.org/content/10.1101/2024.11.16.24317420.abstract,"Atrial fibrillation (AF) ablation is an effective treatment for reducing episodes and improving quality of life in patients with AF. However, in some patients there are only modest long-term AF-free rates after AF ablation. There is a need to address the limited benefits some patients experience by developing predictive algorithms to improve AF ablation outcomes.The authors aim to utilize machine learning models on claims data to explore if innovative coding models may lead to better patient outcomes than use of traditional stroke risk score prediction.The Merative MarketScan® Research Medicare data was used to examine claims for AF ablation. To predict 1-year AF-free outcomes after AF ablation, logistic regression and XGBoost models were used. Model predictions were compared with established risk scores CHADS2 and CHA2DS2-VASC. These models were also assessed on subgroups of patients with paroxysmal AF, persistent AF, and both AF and atrial flutter from October 2015 onwards.The sample included 14,521 patients with claims for AF ablation. XGBoost achieved an area under the receiver operating characteristic curve (AUC) of 0.525, 0.521, and 0.527 for the entire AF ablation population, female, and male, respectively. Within the subgroups, machine learning models performed the best for the paroxysmal AF subgroup using ICD codes, demographic information, and comorbidity indexes, achieving an AUC of 0.546.Machine learning models outperformed CHADS2 and CHA2DS2-VASC in all AF ablation patient groups (whole population, female, and male). Using patient data for …"
Joyce C Ho,Is thermography a viable solution for detecting pressure injuries in dark skin patients?,2024,https://arxiv.org/abs/2411.10627,"Pressure injury (PI) detection is challenging, especially in dark skin tones, due to the unreliability of visual inspection. Thermography has been suggested as a viable alternative as temperature differences in the skin can indicate impending tissue damage. Although deep learning models have demonstrated considerable promise toward reliably detecting PI, the existing work fails to evaluate the performance on darker skin tones and varying data collection protocols. In this paper, we introduce a new thermal and optical imaging dataset of 35 participants focused on darker skin tones where temperature differences are induced through cooling and cupping protocols. We vary the image collection process to include different cameras, lighting, patient pose, and camera distance. We compare the performance of a small convolutional neural network (CNN) trained on either the thermal or the optical images on all skin tones. Our preliminary results suggest that thermography-based CNN is robust to data collection protocols for all skin tones."
Joyce C Ho,Translating Subphenotypes of Newly Diagnosed Type 2 Diabetes from Cohort Studies to Electronic Health Records in the United States,2024,https://www.medrxiv.org/content/10.1101/2024.10.08.24315128.abstract,"Novel subphenotypes of type 2 diabetes mellitus (T2DM) are associated with differences in response to treatment and risk of complications. The most widely replicated approach identified four subphenotypes (severe insulin-deficient diabetes [SIDD], severe insulin-resistant diabetes [SIRD], mild obesity-related diabetes [MOD], and mild age-related diabetes [MARD]). However, the widespread clinical application of this model is hindered by the limited availability of fasting insulin and glucose measurements in routine clinical settings. To address this, we pooled data of adults (≥18 years) with newly diagnosed T2DM from six cohort studies (n = 3,377) to perform de novo clustering and developed classification algorithms for each of the four subphenotypes using nine variables routinely collected in electronic health records (EHRs). After operationalizing the classification algorithms on the Epic Cosmos Research Platform, we identified that among the 727,076 newly diagnosed diabetes cases, 21.6% were classified as SIDD, 23.8% as MOD, and 40.9% as MARD. Individuals classified as SIDD were more likely to receive insulin and incretin mimetics treatment and had higher risks for microvascular complications (retinopathy, neuropathy, nephropathy). Our findings underscore the heterogeneity in newly diagnosed T2DM and validated T2DM subphenotypes in routine EHR systems. This offers possibilities for the subsequent development of treatment strategies tailored to subphenotypes."
Joyce C Ho,TACCO: Task-guided Co-clustering of Clinical Concepts and Patient Visits for Disease Subtyping based on EHR Data,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671594,"The growing availability of well-organized Electronic Health Records (EHR) data has enabled the development of various machine learning models towards disease risk prediction. However, existing risk prediction methods overlook the heterogeneity of complex diseases, failing to model the potential disease subtypes regarding their corresponding patient visits and clinical concept subgroups. In this work, we introduce TACCO, a novel framework that jointly discovers clusters of clinical concepts and patient visits based on a hypergraph modeling of EHR data. Specifically, we develop a novel self-supervised co-clustering framework that can be guided by the risk prediction task of specific diseases. Furthermore, we enhance the hypergraph model of EHR data with textual embeddings and enforce the alignment between the clusters of clinical concepts and patient visits through a contrastive objective. Comprehensive …"
Joyce C Ho,Machine learning is more accurate and biased than risk scoring tools in the prediction of postoperative atrial fibrillation after cardiac surgery,2024,https://www.medrxiv.org/content/10.1101/2024.07.05.24310013.abstract,"Incidence of postoperative atrial fibrillation (POAF) after cardiac surgery remains high and is associated with adverse patient outcomes. Risk scoring tools have been developed to predict POAF, yet discrimination performance remains moderate. Machine learning (ML) models can achieve better performance but may exhibit performance heterogeneity across race and sex subpopulations. We evaluate 8 risk scoring tools and 6 ML models on a heterogeneous cohort derived from electronic health records. Our results suggest that ML models achieve higher discrimination yet are less fair, especially with respect to race. Our findings highlight the need for building accurate and fair ML models to facilitate consistent and equitable assessment of POAF risk."
Joyce C Ho,SOCIAL DETERMINANTS IMPROVE PREDICTION OF 30-DAY READMISSION IN BLACK AND WHITE PATIENTS HOSPITALIZED FOR HEART FAILURE,2024,https://www.jacc.org/doi/full/10.1016/S0735-1097%2824%2902679-2,"BackgroundNeighborhood deprivation indices have been linked to 30-day (30d) readmission in patients hospitalized with heart failure (HF). However, they may not fully capture neighborhood characteristics nor improve 30d readmission risk prediction.MethodsWe compared the logistic regression model performance of 4 neighborhood deprivation indices for predicting 30d readmissions in 28,753 Emory Healthcare patients hospitalized for acute HF from 2010 to 2018. Three traditional indices, Area Deprivation Index (ADI), Social Deprivation Index (SDI), and Social Vulnerability Index (SVI), are compared with the comprehensive SDOH Database from Agency for Healthcare Research and Quality (AHRQ) which captures social, economic, education, and healthcare context as well as physical infrastructure. The adjusted association between each index and risk of 30d readmission was compared in the entire cohort …"
Joyce C Ho,LogicPrpBank: A Corpus for Logical Implication and Equivalence,2024,https://arxiv.org/abs/2402.09609,"Logic reasoning has been critically needed in problem-solving and decision-making. Although Language Models (LMs) have demonstrated capabilities of handling multiple reasoning tasks (e.g., commonsense reasoning), their ability to reason complex mathematical problems, specifically propositional logic, remains largely underexplored. This lack of exploration can be attributed to the limited availability of annotated corpora. Here, we present a well-labeled propositional logic corpus, LogicPrpBank, containing 7093 Propositional Logic Statements (PLSs) across six mathematical subjects, to study a brand-new task of reasoning logical implication and equivalence. We benchmark LogicPrpBank with widely-used LMs to show that our corpus offers a useful resource for this challenging task and there is ample room for model improvement."
Joyce C Ho,Evaluating Safety of Large Language Models for Patient-facing Medical Question Answering,2024,https://raw.githubusercontent.com/mlresearch/v259/main/assets/diekmann25a/diekmann25a.pdf,"Large language models (LLMs) have revolutionized the question answering (QA) domain by achieving near-human performance across a broad range of tasks. Recent studies have suggested LLMs can answer clinical questions and provide medical advice. Although LLMs’ answers must be safe, existing evaluations of medical QA systems often only focus on the accuracy of the content. However, a critical, underexplored aspect is whether variations in patient inquiries–rephrasing the same question–lead to inconsistent or unsafe LLM responses. We propose a new evaluation methodology leveraging synthetic question generation to rigorously assess the safety of LLMs in patient-facing medical QA. In benchmarking 8 LLMs, we observe a weak correlation between standard automated quality metrics and human evaluations, underscoring the need for enhanced sensitivity analysis in evaluating patient medical QA safety."
Joyce C Ho,A Deep Reinforcement Learning Approach for Interactive Search with Sentence-level Feedback,2023,https://arxiv.org/abs/2310.03043,"Interactive search can provide a better experience by incorporating interaction feedback from the users. This can significantly improve search accuracy as it helps avoid irrelevant information and captures the users' search intents. Existing state-of-the-art (SOTA) systems use reinforcement learning (RL) models to incorporate the interactions but focus on item-level feedback, ignoring the fine-grained information found in sentence-level feedback. Yet such feedback requires extensive RL action space exploration and large amounts of annotated data. This work addresses these challenges by proposing a new deep Q-learning (DQ) approach, DQrank. DQrank adapts BERT-based models, the SOTA in natural language processing, to select crucial sentences based on users' engagement and rank the items to obtain more satisfactory responses. We also propose two mechanisms to better explore optimal actions. DQrank further utilizes the experience replay mechanism in DQ to store the feedback sentences to obtain a better initial ranking performance. We validate the effectiveness of DQrank on three search datasets. The results show that DQRank performs at least 12% better than the previous SOTA RL approaches. We also conduct detailed ablation studies. The ablation results demonstrate that each model component can efficiently extract and accumulate long-term engagement effects from the users' sentence-level feedback. This structure offers new technologies with promised performance to construct a search system with sentence-level interaction."
Joyce C Ho,"Conference on Health, Inference, and Learning (CHIL) 2023",2023,https://proceedings.mlr.press/v209/mortazavi23a/mortazavi23a.pdf,"This volume contains the proceedings of the third Conference on Health, Inference, and Learning (CHIL), held in Cambridge, MA, United States on June 22–24, 2023. This is the second year of the conference being part of the Association for Health Learning and Inference (AHLI). This has continued to enable CHIL to provide access to our proceedings through open publication models. Research in machine learning and health requires a cross-disciplinary representation of clinicians and researchers in machine learning, health policy, causality, fairness, and related areas. The goal of the conference is to foster excellent research that addresses the unique challenges and opportunities that arise at the intersection of machine learning and health."
Joyce C Ho,SPLIT: Stance and Persuasion Prediction with Multi-modal on Image and Textual Information,2023,https://par.nsf.gov/biblio/10516973,"Persuasiveness is a prominent personality trait that measures the extent to which a speaker can impact the beliefs, attitudes, intentions, motivations, and actions of their audience. The ImageArg task is a featured challenge at the 10th ArgMining Workshop during EMNLP 2023, focusing on harnessing the potential of the ImageArg dataset to advance techniques in multimodal persuasion. In this study, we investigate the utilization of dual-modality datasets and evaluate three distinct multi-modality models. By enhancing multi-modality datasets, we demonstrate both the advantages and constraints of cutting-edge models."
Joyce C Ho,SR-CoMbEr: Heterogeneous Network Embedding Using Community Multi-view Enhanced Graph Convolutional Network for Automating Systematic Reviews,2023,https://link.springer.com/chapter/10.1007/978-3-031-28244-7_35,"Systematic reviews (SRs) are a crucial component of evidence-based clinical practice. Unfortunately, SRs are labor-intensive and unscalable with the exponential growth in literature. Automating evidence synthesis using machine learning models has been proposed but solely focuses on the text and ignores additional features like citation information. Recent work demonstrated that citation embeddings can outperform the text itself, suggesting that better network representation may expedite SRs. Yet, how to utilize the rich information in heterogeneous information networks (HIN) for network embeddings is understudied. Existing HIN models fail to produce a high-quality embedding compared to simply running state-of-the-art homogeneous network models. To address existing HIN model limitations, we propose SR-CoMbEr, a community-based multi-view graph convolutional network for learning better embeddings …"
Joyce C Ho,Comparative Performance of Recurrent Heart Failure Prediction Models: Incorporating Social Determinants and Applying Machine Learning,2022,https://www.ahajournals.org/doi/abs/10.1161/circ.146.suppl_1.15358,"Introduction: Improving performance of predictive algorithms for 30-d readmission following heart failure (HF) hospitalization may enhance clinical management decisions. Applying novel data (social determinants of health; SDOH) and novel methods (machine learning) have been proposed. We compared performance to predict 30-d HF readmission using models with and without SDOH and under traditional and machine learning techniques.Hypothesis and Methods: We used data on 27,071 admissions within Emory Healthcare (mean age: 66 , 48% female, 51% black). We categorized 69 covariates as patient-level clinical (e.g., diastolic blood pressure), patient-level demographic (e.g. gender, age), and zip code SDOH (e.g. percent unemployed). Logistic regression under generalized linear model (GLM) and gradient boosted model (GBM) frameworks were applied to test all combinations of covariate sets. We …"
Joyce C Ho,Deriving and Validating Novel Neighborhood Data for Investigation of Adverse Outcomes in Patients Hospitalized for Heart Failure: A Feasibility Study,2022,https://www.ahajournals.org/doi/abs/10.1161/circ.146.suppl_1.15011,"Introduction: Census-based measures of population-level neighborhood deprivation have been linked to adverse outcomes in patients with heart failure (HF). However, limited data exist to examine the impact of neighborhood environmental characteristics on HF outcomes.Objective: Derive novel measures of the patient built environment using multiple databases and compare their performance with traditional Census-based measure of population deprivation to predict 30-day readmission following hospitalization with HF.Methods: We identified the 17 census tracts in the metropolitan Atlanta area from the lowest, middle, and highest tertiles of the Social Deprivation Index (SDI), a neighborhood deprivation measure derived from US Census data. Three novel data sources—Twitter, Foursquare, and Google Places—were used to compute 6 environmental scores in each census tract: accessibility to parks …"
Joyce C Ho,"Conference on Health, Inference, and Learning (CHIL) 2022",2022,https://proceedings.mlr.press/v174/flores22a/flores22a.pdf,"This volume contains the proceedings of the third Conference on Health, Inference, and Learning (CHIL), held virtually on April 7–8, 2022. Among the changes made this year was a transition from Association for Computing Machinery (ACM) to Association for Health Learning and Inference (AHLI). This change enabled CHIL to provide access to our proceedings through open publication models. Research in machine learning and health requires a cross-disciplinary representation of clinicians and researchers in machine learning, health policy, causality, fairness, and related areas. The goal of the conference is to foster excellent research that addresses the unique challenges and opportunities that arise at the intersection of machine learning and health."
Joyce C Ho,"A collection of invited non-archival papers for the Conference on Health, Inference, and Learning (CHIL) 2022",2022,https://arxiv.org/abs/2205.02752,"A collection of invited non-archival papers for the Conference on Health, Inference, and Learning (CHIL) 2022. This index is incomplete as some authors of invited non-archival presentations opted not to include their papers in this index."
Joyce C Ho,Exploring the Temporal Dynamics of County-Level Vulnerability Factors on COVID-19 Outcomes,2021,https://www.medrxiv.org/content/10.1101/2021.11.24.21266757.abstract,"As the outbreak of COVID-19 has become a severe worldwide pandemic, every country fights against the spread of this deadly disease with incredible efforts. There are numerous researches along with every conceivable dimension for COVID-19. Among these researches, different demographic and contextual factors of populations and communities also play an essential role in providing more information for decision-makers. This paper mainly utilizes existing data on county contextual factors at the United States county-level to develop a model that can capture the dynamic trajectory of COVID-19 (i.e., cases) and its impacts across the United States. Moreover, our methods applied to contextual data achieves better results compared with existing measures of vulnerability."
Joyce C Ho,GDA-AM: On the effectiveness of solving minimax optimization via Anderson Acceleration,2021,https://arxiv.org/abs/2110.02457,"Many modern machine learning algorithms such as generative adversarial networks (GANs) and adversarial training can be formulated as minimax optimization. Gradient descent ascent (GDA) is the most commonly used algorithm due to its simplicity. However, GDA can converge to non-optimal minimax points. We propose a new minimax optimization framework, GDA-AM, that views the GDAdynamics as a fixed-point iteration and solves it using Anderson Mixing to con-verge to the local minimax. It addresses the diverging issue of simultaneous GDAand accelerates the convergence of alternating GDA. We show theoretically that the algorithm can achieve global convergence for bilinear problems under mild conditions. We also empirically show that GDA-AMsolves a variety of minimax problems and improves GAN training on several datasets"
Joyce C Ho,CrowdTeacher: Robust Co-teaching with Noisy Answers and Sample-Specific Perturbations for Tabular Data,2021,https://link.springer.com/chapter/10.1007/978-3-030-75765-6_15,"Samples with ground truth labels may not always be available in numerous domains. While learning from crowdsourcing labels has been explored, existing models can still fail in the presence of sparse, unreliable, or differing annotations. Co-teaching methods have shown promising improvements for computer vision problems with noisy labels by employing two classifiers trained on each others’ confident samples in each batch. Inspired by the idea of separating confident and uncertain samples during the training process, we extend it for the crowdsourcing problem. Our model, CrowdTeacher, uses the idea that perturbation in the input space model can improve the robustness of the classifier for noisy labels. Treating crowdsourcing annotations as a source of noisy labeling, we perturb samples based on the certainty from the aggregated annotations. The perturbed samples are fed to a Co-teaching algorithm tuned …"
Wei Jin,Graph Structure Learning for Robust Graph Neural Networks,2020,https://dl.acm.org/doi/abs/10.1145/3394486.3403049,"Graph Neural Networks (GNNs) are powerful tools in representation learning for graphs. However, recent studies show that GNNs are vulnerable to carefully-crafted perturbations, called adversarial attacks. Adversarial attacks can easily fool GNNs in making predictions for downstream tasks. The vulnerability to adversarial attacks has raised increasing concerns for applying GNNs in safety-critical applications. Therefore, developing robust algorithms to defend adversarial attacks is of great significance. A natural idea to defend adversarial attacks is to clean the perturbed graph. It is evident that real-world graphs share some intrinsic properties. For example, many real-world graphs are low-rank and sparse, and the features of two adjacent nodes tend to be similar. In fact, we find that adversarial attacks are likely to violate these graph properties. Therefore, in this paper, we explore these properties to defend …"
Wei Jin,Traffic flow prediction via spatial temporal graph neural network,2020,https://dl.acm.org/doi/abs/10.1145/3366423.3380186,"Traffic flow analysis, prediction and management are keystones for building smart cities in the new era. With the help of deep neural networks and big traffic data, we can better understand the latent patterns hidden in the complex transportation networks. The dynamic of the traffic flow on one road not only depends on the sequential patterns in the temporal dimension but also relies on other roads in the spatial dimension. Although there are existing works on predicting the future traffic flow, the majority of them have certain limitations on modeling spatial and temporal dependencies. In this paper, we propose a novel spatial temporal graph neural network for traffic flow prediction, which can comprehensively capture spatial and temporal patterns. In particular, the framework offers a learnable positional attention mechanism to effectively aggregate information from adjacent roads. Meanwhile, it provides a sequential …"
Wei Jin,Exploring the potential of large language models (llms) in learning on graphs,2023,https://dl.acm.org/doi/abs/10.1145/3655103.3655110,"Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions …"
Wei Jin,Adversarial attacks and defenses on graphs,2021,https://dl.acm.org/doi/abs/10.1145/3447556.3447566,"Deep neural networks (DNNs) have achieved significant performance in various tasks. However, recent studies have shown that DNNs can be easily fooled by small perturbation on the input, called adversarial attacks."
Wei Jin,Node Similarity Preserving Graph Convolutional Networks,2021,https://dl.acm.org/doi/abs/10.1145/3437963.3441735,"Graph Neural Networks (GNNs) have achieved tremendous success in various real-world applications due to their strong ability in graph representation learning. GNNs explore the graph structure and node features by aggregating and transforming information within node neighborhoods. However, through theoretical and empirical analysis, we reveal that the aggregation process of GNNs tends to destroy node similarity in the original feature space. There are many scenarios where node similarity plays a crucial role. Thus, it has motivated the proposed framework SimP-GCN that can effectively and efficiently preserve node similarity while exploiting graph structure. Specifically, to balance information from graph structure and node features, we propose a feature similarity preserving aggregation which adaptively integrates graph structure and node features. Furthermore, we employ self-supervised learning to …"
Wei Jin,Self-supervised learning on graphs: Deep insights and new direction,2021,https://arxiv.org/abs/2006.10141,"The success of deep learning notoriously requires larger amounts of costly annotated data. This has led to the development of self-supervised learning (SSL) that aims to alleviate this limitation by creating domain specific pretext tasks on unlabeled data. Simultaneously, there are increasing interests in generalizing deep learning to the graph domain in the form of graph neural networks (GNNs). GNNs can naturally utilize unlabeled nodes through the simple neighborhood aggregation that is unable to thoroughly make use of unlabeled nodes. Thus, we seek to harness SSL for GNNs to fully exploit the unlabeled data. Different from data instances in the image and text domains, nodes in graphs present unique structure information and they are inherently linked indicating not independent and identically distributed (or i.i.d.). Such complexity is a double-edged sword for SSL on graphs. On the one hand, it determines that it is challenging to adopt solutions from the image and text domains to graphs and dedicated efforts are desired. On the other hand, it provides rich information that enables us to build SSL from a variety of perspectives. Thus, in this paper, we first deepen our understandings on when, why, and which strategies of SSL work with GNNs by empirically studying numerous basic SSL pretext tasks on graphs. Inspired by deep insights from the empirical studies, we propose a new direction SelfTask to build advanced pretext tasks that are able to achieve state-of-the-art performance on various real-world datasets. The specific experimental settings to reproduce our results can be found in \url{https://github.com/ChandlerBang/SelfTask-GNN}."
Wei Jin,From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness,2022,https://arxiv.org/abs/2110.03753,"Message Passing Neural Networks (MPNNs) are a common type of Graph Neural Network (GNN), in which each node's representation is computed recursively by aggregating representations (messages) from its immediate neighbors akin to a star-shaped pattern. MPNNs are appealing for being efficient and scalable, how-ever their expressiveness is upper-bounded by the 1st-order Weisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose highly expressive models at the cost of scalability and sometimes generalization performance. Our work stands between these two regimes: we introduce a general framework to uplift any MPNN to be more expressive, with limited scalability overhead and greatly improved practical performance. We achieve this by extending local aggregation in MPNNs from star patterns to general subgraph patterns (e.g.,k-egonets):in our framework, each node representation is computed as the encoding of a surrounding induced subgraph rather than encoding of immediate neighbors only (i.e. a star). We choose the subgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design a general framework that serves as a wrapper to up-lift any GNN. We call our proposed method GNN-AK(GNN As Kernel), as the framework resembles a convolutional neural network by replacing the kernel with GNNs. Theoretically, we show that our framework is strictly more powerful than 1&2-WL, and is not less powerful than 3-WL. We also design subgraph sampling strategies which greatly reduce memory footprint and improve speed while maintaining performance. Our method sets new state-of-the-art …"
Wei Jin,Graph Condensation for Graph Neural Networks,2022,https://arxiv.org/abs/2110.07580,"Given the prevalence of large-scale graphs in real-world applications, the storage and time for training neural models have raised increasing concerns. To alleviate the concerns, we propose and study the problem of graph condensation for graph neural networks (GNNs). Specifically, we aim to condense the large, original graph into a small, synthetic and highly-informative graph, such that GNNs trained on the small graph and large graph have comparable performance. We approach the condensation problem by imitating the GNN training trajectory on the original graph through the optimization of a gradient matching loss and design a strategy to condense node futures and structural information simultaneously. Extensive experiments have demonstrated the effectiveness of the proposed framework in condensing different graph datasets into informative smaller graphs. In particular, we are able to approximate the original test accuracy by 95.3% on Reddit, 99.8% on Flickr and 99.0% on Citeseer, while reducing their graph size by more than 99.9%, and the condensed graphs can be used to train various GNN architectures.Code is released at https://github.com/ChandlerBang/GCond."
Wei Jin,Deeprobust: A pytorch library for adversarial attacks and defenses,2020,https://arxiv.org/abs/2005.06149,"DeepRobust is a PyTorch adversarial learning library which aims to build a comprehensive and easy-to-use platform to foster this research field. It currently contains more than 10 attack algorithms and 8 defense algorithms in image domain and 9 attack algorithms and 4 defense algorithms in graph domain, under a variety of deep learning architectures. In this manual, we introduce the main contents of DeepRobust with detailed instructions. The library is kept updated and can be found at https://github.com/DSE-MSU/DeepRobust."
Wei Jin,Elastic graph neural networks,2021,https://proceedings.mlr.press/v139/liu21k.html,"While many existing graph neural networks (GNNs) have been proven to perform -based graph smoothing that enforces smoothness globally, in this work we aim to further enhance the local smoothness adaptivity of GNNs via -based graph smoothing. As a result, we introduce a family of GNNs (Elastic GNNs) based on  and -based graph smoothing. In particular, we propose a novel and general message passing scheme into GNNs. This message passing algorithm is not only friendly to back-propagation training but also achieves the desired smoothing properties with a theoretical convergence guarantee. Experiments on semi-supervised learning tasks demonstrate that the proposed Elastic GNNs obtain better adaptivity on benchmark datasets and are significantly robust to graph adversarial attacks. The implementation of Elastic GNNs is available at\url {https://github. com/lxiaorui/ElasticGNN}."
Wei Jin,Graph trend filtering networks for recommendation,2022,https://dl.acm.org/doi/abs/10.1145/3477495.3531985,"Recommender systems aim to provide personalized services to users and are playing an increasingly important role in our daily lives. The key of recommender systems is to predict how likely users will interact with items based on their historical online behaviors, e.g., clicks, add-to-cart, purchases, etc. To exploit these user-item interactions, there are increasing efforts on considering the user-item interactions as a user-item bipartite graph and then performing information propagation in the graph via Graph Neural Networks (GNNs). Given the power of GNNs in graph representation learning, these GNNs-based recommendation methods have remarkably boosted the recommendation performance. Despite their success, most existing GNNs-based recommender systems overlook the existence of interactions caused by unreliable behaviors (e.g., random/bait clicks) and uniformly treat all the interactions, which can …"
Wei Jin,Graph Data Augmentation for Graph Machine Learning: A Survey,2023,https://arxiv.org/abs/2202.08871,"Data augmentation has recently seen increased interest in graph machine learning given its demonstrated ability to improve model performance and generalization by added training data. Despite this recent surge, the area is still relatively under-explored, due to the challenges brought by complex, non-Euclidean structure of graph data, which limits the direct analogizing of traditional augmentation operations on other types of image, video or text data. Our work aims to give a necessary and timely overview of existing graph data augmentation methods; notably, we present a comprehensive and systematic survey of graph data augmentation approaches, summarizing the literature in a structured manner. We first introduce three different taxonomies for categorizing graph data augmentation methods from the data, task, and learning perspectives, respectively. Next, we introduce recent advances in graph data augmentation, differentiated by their methodologies and applications. We conclude by outlining currently unsolved challenges and directions for future research. Overall, our work aims to clarify the landscape of existing literature in graph data augmentation and motivates additional work in this area, providing a helpful resource for researchers and practitioners in the broader graph machine learning domain. Additionally, we provide a continuously updated reading list at https://github.com/zhao-tong/graph-data-augmentation-papers."
Wei Jin,Towards Robust Graph Neural Networks for Noisy Graphs with Sparse Labels,2022,https://dl.acm.org/doi/abs/10.1145/3488560.3498408,"Graph Neural Networks (GNNs) have shown their great ability in modeling graph structured data. However, real-world graphs usually contain structure noises and have limited labeled nodes. The performance of GNNs would drop significantly when trained on such graphs, which hinders the adoption of GNNs on many applications. Thus, it is important to develop noise-resistant GNNs with limited labeled nodes. However, the work on this is rather limited. Therefore, we study a novel problem of developing robust GNNs on noisy graphs with limited labeled nodes. Our analysis shows that both the noisy edges and limited labeled nodes could harm the message-passing mechanism of GNNs. To mitigate these issues, we propose a novel framework which adopts the noisy edges as supervision to learn a denoised and dense graph, which can down-weight or eliminate noisy edges and facilitate message passing of …"
Wei Jin,Condensing Graphs via One-Step Gradient Matching,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539429,"As training deep learning models on large dataset takes a lot of time and resources, it is desired to construct a small synthetic dataset with which we can train deep learning models sufficiently. There are recent works that have explored solutions on condensing image datasets through complex bi-level optimization. For instance, dataset condensation (DC) matches network gradients w.r.t. large-real data and small-synthetic data, where the network weights are optimized for multiple steps at each outer iteration. However, existing approaches have their inherent limitations: (1) they are not directly applicable to graphs where the data is discrete; and (2) the condensation process is computationally expensive due to the involved nested optimization. To bridge the gap, we investigate efficient dataset condensation tailored for graph datasets where we model the discrete graph structure as a probabilistic model. We further …"
Wei Jin,Automated self-supervised learning for graphs,2022,https://arxiv.org/abs/2106.05470,"Graph self-supervised learning has gained increasing attention due to its capacity to learn expressive node representations. Many pretext tasks, or loss functions have been designed from distinct perspectives. However, we observe that different pretext tasks affect downstream tasks differently cross datasets, which suggests that searching pretext tasks is crucial for graph self-supervised learning. Different from existing works focusing on designing single pretext tasks, this work aims to investigate how to automatically leverage multiple pretext tasks effectively. Nevertheless, evaluating representations derived from multiple pretext tasks without direct access to ground truth labels makes this problem challenging. To address this obstacle, we make use of a key principle of many real-world graphs, i.e., homophily, or the principle that ""like attracts like,"" as the guidance to effectively search various self-supervised pretext tasks. We provide theoretical understanding and empirical evidence to justify the flexibility of homophily in this search task. Then we propose the AutoSSL framework which can automatically search over combinations of various self-supervised tasks. By evaluating the framework on 7 real-world datasets, our experimental results show that AutoSSL can significantly boost the performance on downstream tasks including node clustering and node classification compared with training under individual tasks. Code is released at https://github.com/ChandlerBang/AutoSSL."
Wei Jin,Graph neural networks with adaptive residual,2021,https://proceedings.neurips.cc/paper/2021/hash/50abc3e730e36b387ca8e02c26dc0a22-Abstract.html,"Graph neural networks (GNNs) have shown the power in graph representation learning for numerous tasks. In this work, we discover an interesting phenomenon that although residual connections in the message passing of GNNs help improve the performance, they immensely amplify GNNs' vulnerability against abnormal node features. This is undesirable because in real-world applications, node features in graphs could often be abnormal such as being naturally noisy or adversarially manipulated. We analyze possible reasons to understand this phenomenon and aim to design GNNs with stronger resilience to abnormal features. Our understandings motivate us to propose and derive a simple, efficient, interpretable, and adaptive message passing scheme, leading to a novel GNN with Adaptive Residual, AirGNN. Extensive experiments under various abnormal feature scenarios demonstrate the effectiveness of the proposed algorithm."
Wei Jin,Graph Neural Networks for Multimodal Single-Cell Data Integration,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539213,"Recent advances in multimodal single-cell technologies have enabled simultaneous acquisitions of multiple omics data from the same cell, providing deeper insights into cellular states and dynamics. However, it is challenging to learn the joint representations from the multimodal data, model the relationship between modalities, and, more importantly, incorporate the vast amount of single-modality datasets into the downstream analyses. To address these challenges and correspondingly facilitate multimodal single-cell data analyses, three key tasks have been introduced: Modality prediction, Modality matching andJoint embedding. In this work, we present a general Graph Neural Network framework scMoGNN to tackle these three tasks and show that scMoGNN demonstrates superior results in all three tasks compared with the state-of-the-art and conventional approaches. Our method is an official winner in the …"
Wei Jin,Empowering graph representation learning with test-time graph transformation,2022,https://arxiv.org/abs/2210.03561,"As powerful tools for representation learning on graphs, graph neural networks (GNNs) have facilitated various applications from drug discovery to recommender systems. Nevertheless, the effectiveness of GNNs is immensely challenged by issues related to data quality, such as distribution shift, abnormal features and adversarial attacks. Recent efforts have been made on tackling these issues from a modeling perspective which requires additional cost of changing model architectures or re-training model parameters. In this work, we provide a data-centric view to tackle these issues and propose a graph transformation framework named GTrans which adapts and refines graph data at test time to achieve better performance. We provide theoretical analysis on the design of the framework and discuss why adapting graph data works better than adapting the model. Extensive experiments have demonstrated the effectiveness of GTrans on three distinct scenarios for eight benchmark datasets where suboptimal data is presented. Remarkably, GTrans performs the best in most cases with improvements up to 2.8%, 8.2% and 3.8% over the best baselines on three experimental settings. Code is released at https://github.com/ChandlerBang/GTrans."
Wei Jin,Label-free node classification on graphs with large language models (llms),2024,https://arxiv.org/abs/2310.04668,"In recent years, there have been remarkable advancements in node classification achieved by Graph Neural Networks (GNNs). However, they necessitate abundant high-quality labels to ensure promising performance. In contrast, Large Language Models (LLMs) exhibit impressive zero-shot proficiency on text-attributed graphs. Yet, they face challenges in efficiently processing structural data and suffer from high inference costs. In light of these observations, this work introduces a label-free node classification on graphs with LLMs pipeline, LLM-GNN. It amalgamates the strengths of both GNNs and LLMs while mitigating their limitations. Specifically, LLMs are leveraged to annotate a small portion of nodes and then GNNs are trained on LLMs' annotations to make predictions for the remaining large portion of nodes. The implementation of LLM-GNN faces a unique challenge: how can we actively select nodes for LLMs to annotate and consequently enhance the GNN training? How can we leverage LLMs to obtain annotations of high quality, representativeness, and diversity, thereby enhancing GNN performance with less cost? To tackle this challenge, we develop an annotation quality heuristic and leverage the confidence scores derived from LLMs to advanced node selection. Comprehensive experimental results validate the effectiveness of LLM-GNN. In particular, LLM-GNN can achieve an accuracy of 74.9% on a vast-scale dataset \products with a cost less than 1 dollar."
Wei Jin,Demystifying structural disparity in graph neural networks: Can one size fit all?,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/74f1edadbdf495e7258ee8db7b1d3acd-Abstract-Conference.html,"Recent studies on Graph Neural Networks (GNNs) provide both empirical and theoretical evidence supporting their effectiveness in capturing structural patterns on both homophilic and certain heterophilic graphs. Notably, most real-world homophilic and heterophilic graphs are comprised of a mixture of nodes in both homophilic and heterophilic structural patterns, exhibiting a structural disparity. However, the analysis of GNN performance with respect to nodes exhibiting different structural patterns, eg, homophilic nodes in heterophilic graphs, remains rather limited. In the present study, we provide evidence that Graph Neural Networks (GNNs) on node classification typically perform admirably on homophilic nodes within homophilic graphs and heterophilic nodes within heterophilic graphs while struggling on the opposite node set, exhibiting a performance disparity. We theoretically and empirically identify effects of GNNs on testing nodes exhibiting distinct structural patterns. We then propose a rigorous, non-iid PAC-Bayesian generalization bound for GNNs, revealing reasons for the performance disparity, namely the aggregated feature distance and homophily ratio difference between training and testing nodes. Furthermore, we demonstrate the practical implications of our new findings via (1) elucidating the effectiveness of deeper GNNs; and (2) revealing an over-looked distribution shift factor on graph out-of-distribution problem and proposing a new scenario accordingly."
Wei Jin,Deeprobust: a platform for adversarial attacks and defenses,2021,https://ojs.aaai.org/index.php/AAAI/article/view/18017,"DeepRobust is a PyTorch platform for generating adversarial examples and building robust machine learning models for different data domains. Users can easily evaluate the attack performance against different defense methods with DeepRobust and get performance analyzing visualization. In this paper, we introduce the functions of DeepRobust with detailed instructions. We believe that DeepRobust is a useful tool to measure deep learning model robustness and to find the suitable countermeasures against adversarial attacks. The platform is kept updated and can be found at https://github. com/DSE-MSU/DeepRobust. More details of instruction can be found in the documentation at https://deeprobust. readthedocs. io/en/latest/."
Wei Jin,Feature overcorrelation in deep graph neural networks: A new perspective,2022,https://arxiv.org/abs/2206.07743,"Recent years have witnessed remarkable success achieved by graph neural networks (GNNs) in many real-world applications such as recommendation and drug discovery. Despite the success, oversmoothing has been identified as one of the key issues which limit the performance of deep GNNs. It indicates that the learned node representations are highly indistinguishable due to the stacked aggregators. In this paper, we propose a new perspective to look at the performance degradation of deep GNNs, i.e., feature overcorrelation. Through empirical and theoretical study on this matter, we demonstrate the existence of feature overcorrelation in deeper GNNs and reveal potential reasons leading to this issue. To reduce the feature correlation, we propose a general framework DeCorr which can encourage GNNs to encode less redundant information. Extensive experiments have demonstrated that DeCorr can help enable deeper GNNs and is complementary to existing techniques tackling the oversmoothing issue."
Wei Jin,A review of graph neural networks in epidemic modeling,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671455,"Since the onset of the COVID-19 pandemic, there has been a growing interest in studying epidemiological models. Traditional mechanistic models mathematically describe the transmission mechanisms of infectious diseases. However, they often fall short when confronted with the growing challenges of today. Consequently, Graph Neural Networks (GNNs) have emerged as a progressively popular tool in epidemic research. In this paper, we endeavor to furnish a comprehensive review of GNNs in epidemic tasks and highlight potential future directions. To accomplish this objective, we introduce hierarchical taxonomies for both epidemic tasks and methodologies, offering a trajectory of development within this domain. For epidemic tasks, we establish a taxonomy akin to those typically employed within the epidemic domain. For methodology, we categorize existing work into Neural Models and Hybrid Models …"
Wei Jin,Amazon-m2: A multilingual multi-locale shopping session dataset for recommendation and text generation,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/193df57a2366d032fb18dcac0698d09a-Abstract-Datasets_and_Benchmarks.html,"Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, which can benefit various existing tasks as well as enable new tasks. To test the potential of the dataset, we introduce three tasks in this work:(1) next-product recommendation,(2) next-product recommendation with domain shifts, and (3) next-product title generation. With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice. In addition, based on the proposed dataset and tasks, we hosted a competition in the KDD CUP 2023 https://www. aicrowd. com/challenges/amazon-kdd-cup-23-multilingual-recommendation-challenge and have attracted thousands of users and …"
Wei Jin,"A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation",2024,https://arxiv.org/abs/2402.03358,"Many real-world datasets can be naturally represented as graphs, spanning a wide range of domains. However, the increasing complexity and size of graph datasets present significant challenges for analysis and computation. In response, graph reduction, or graph summarization, has gained prominence for simplifying large graphs while preserving essential properties. In this survey, we aim to provide a comprehensive understanding of graph reduction methods, including graph sparsification, graph coarsening, and graph condensation. Specifically, we establish a unified definition for these methods and introduce a hierarchical taxonomy to categorize the challenges they address. Our survey then systematically reviews the technical details of these methods and emphasizes their practical applications across diverse scenarios. Furthermore, we outline critical research directions to ensure the continued effectiveness of graph reduction techniques, as well as provide a comprehensive paper list at \url{https://github.com/Emory-Melody/awesome-graph-reduction}. We hope this survey will bridge literature gaps and propel the advancement of this promising field."
Wei Jin,The Authors Matter: Understanding and Mitigating Implicit Bias in Deep Text Classification,2021,https://arxiv.org/abs/2105.02778,"It is evident that deep text classification models trained on human data could be biased. In particular, they produce biased outcomes for texts that explicitly include identity terms of certain demographic groups. We refer to this type of bias as explicit bias, which has been extensively studied. However, deep text classification models can also produce biased outcomes for texts written by authors of certain demographic groups. We refer to such bias as implicit bias of which we still have a rather limited understanding. In this paper, we first demonstrate that implicit bias exists in different text classification tasks for different demographic groups. Then, we build a learning-based interpretation method to deepen our knowledge of implicit bias. Specifically, we verify that classifiers learn to make predictions based on language features that are related to the demographic attributes of the authors. Next, we propose a framework Debiased-TC to train deep text classifiers to make predictions on the right features and consequently mitigate implicit bias. We conduct extensive experiments on three real-world datasets. The results show that the text classification models trained under our proposed framework outperform traditional models significantly in terms of fairness, and also slightly in terms of classification performance."
Wei Jin,Jointly attacking graph neural network and its explanations,2021,https://ieeexplore.ieee.org/abstract/document/10184589/,"Graph Neural Networks (GNNs) have boosted the performance for many graph-related tasks. Despite the great success, recent studies have shown that GNNs are still vulnerable to adversarial attacks, where adversaries can mislead the GNNs' prediction by modifying graphs. On the other hand, the explanation of GNNs (GnnExplainer for short) provides a better understanding of a trained GNN model by generating a small subgraph and features that are most influential for its prediction. In this paper, we first perform empirical studies to validate that GnnExplainer can act as an inspection tool and have the potential to detect the adversarial perturbations for graphs. This finding motivates us to further investigate a new problem: Whether a graph neural network and its explanations can be jointly attacked by modifying graphs with malicious desires? It is challenging to answer this question since the goals of adversarial …"
Wei Jin,Deep learning in single-cell analysis,2024,https://dl.acm.org/doi/abs/10.1145/3641284,"Single-cell technologies are revolutionizing the entire field of biology. The large volumes of data generated by single-cell technologies are high dimensional, sparse, and heterogeneous and have complicated dependency structures, making analyses using conventional machine learning approaches challenging and impractical. In tackling these challenges, deep learning often demonstrates superior performance compared to traditional machine learning methods. In this work, we give a comprehensive survey on deep learning in single-cell analysis. We first introduce background on single-cell technologies and their development, as well as fundamental concepts of deep learning including the most popular deep architectures. We present an overview of the single-cell analytic pipeline pursued in research applications while noting divergences due to data sources or specific applications. We then review seven …"
Wei Jin,Toward Degree Bias in Embedding-Based Knowledge Graph Completion,2023,https://dl.acm.org/doi/abs/10.1145/3543507.3583544," A fundamental task for knowledge graphs (KGs) is knowledge graph completion (KGC). It aims to predict unseen edges by learning representations for all the entities and relations in a KG. A common concern when learning representations on traditional graphs is degree bias. It can affect graph algorithms by learning poor representations for lower-degree nodes, often leading to low performance on such nodes. However, there has been limited research on whether there exists degree bias for embedding-based KGC and how such bias affects the performance of KGC. In this paper, we validate the existence of degree bias in embedding-based KGC and identify the key factor to degree bias. We then introduce a novel data augmentation method, KG-Mixup, to generate synthetic triples to mitigate such bias. Extensive experiments have demonstrated that our method can improve various embedding-based KGC …"
Wei Jin,Graph neural networks: Self-supervised learning,2022,https://link.springer.com/chapter/10.1007/978-981-16-6054-2_18,"Although deep learning has achieved state-of-the-art performance across numerous domains, these models generally require large annotated datasets to reach their full potential and avoid overfitting. However, obtaining such datasets can have high associated costs or even be impossible to procure. Self-supervised learning (SSL) seeks to create and utilize specific pretext tasks on unlabeled data to aid in alleviating this fundamental limitation of deep learning models. Although initially applied in the image and text domains, recent interest has been in leveraging SSL in the graph domain to improve the performance of graph neural networks (GNNs). For node-level tasks, GNNs can inherently incorporate unlabeled node data through the neighborhood aggregation unlike in the image or text domains; but they can still benefit by applying novel pretext tasks to encode richer information and numerous such …"
Wei Jin,Knowledge-infused prompting: Assessing and advancing clinical text data generation with large language models,2024,https://arxiv.org/abs/2311.00287,"Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the diversity of generated training instances. We will publish our code and all the generated data in \url{https://github.com/ritaranx/ClinGen}."
Wei Jin,Navigating Complexity: Toward Lossless Graph Condensation via Expanding Window Matching,2024,https://arxiv.org/abs/2402.05011,"Graph condensation aims to reduce the size of a large-scale graph dataset by synthesizing a compact counterpart without sacrificing the performance of Graph Neural Networks (GNNs) trained on it, which has shed light on reducing the computational cost for training GNNs. Nevertheless, existing methods often fall short of accurately replicating the original graph for certain datasets, thereby failing to achieve the objective of lossless condensation. To understand this phenomenon, we investigate the potential reasons and reveal that the previous state-of-the-art trajectory matching method provides biased and restricted supervision signals from the original graph when optimizing the condensed one. This significantly limits both the scale and efficacy of the condensed graph. In this paper, we make the first attempt toward \textit{lossless graph condensation} by bridging the previously neglected supervision signals. Specifically, we employ a curriculum learning strategy to train expert trajectories with more diverse supervision signals from the original graph, and then effectively transfer the information into the condensed graph with expanding window matching. Moreover, we design a loss function to further extract knowledge from the expert trajectories. Theoretical analysis justifies the design of our method and extensive experiments verify its superiority across different datasets. Code is released at https://github.com/NUS-HPC-AI-Lab/GEOM."
Wei Jin,"Adversarial attacks and defenses: Frontiers, advances and practice",2020,https://dl.acm.org/doi/abs/10.1145/3394486.3406467,"Deep neural networks (DNN) have achieved unprecedented success in numerous machine learning tasks in various domains. However, the existence of adversarial examples leaves us a big hesitation when applying DNN models on safety-critical tasks such as autonomous vehicles and malware detection. These adversarial examples are intentionally crafted instances, either appearing in the train or test phase, which can fool the DNN models to make severe mistakes. Therefore, people are dedicated to devising more robust models to resist adversarial examples, but usually they are broken by new stronger attacks. This arms-race between adversarial attacks and defenses has been drawn increasing attention in recent years. In this tutorial, we provide a comprehensive overview on the frontiers and advances of adversarial attacks and their countermeasures. In particular, we give a detailed introduction of different …"
Wei Jin,CellPLM: pre-training of cell language model beyond single cells,2023,https://www.biorxiv.org/content/10.1101/2023.10.03.560734.abstract,"The current state-of-the-art single-cell pre-trained models are greatly inspired by the success of large language models. They trained transformers by treating genes as tokens and cells as sentences. However, three fundamental differences between single-cell data and natural language data are overlooked: (1) scRNA-seq data are presented as bag-of-genes instead of sequences of RNAs; (2) Cell-cell relations are more intricate and important than inter-sentence relations; and (3) The quantity of single-cell data is considerably inferior to text data, and they are very noisy. In light of these characteristics, we propose a new pre-trained model CellPLM, which takes cells as tokens and tissues as sentences. In addition, we leverage spatially-resolved transcriptomic data in pre-training to facilitate learning cell-cell relationships and introduce a Gaussian mixture prior distribution as an additional inductive bias to overcome data limitation. CellPLM is the first single-cell pre-trained transformer that encodes cell-cell relations and it consistently outperforms existing pre-trained and non-pre-trained models in diverse downstream tasks, with 100x times higher inference speed compared to existing pre-trained models."
Wei Jin,Test-time training for graph neural networks,2022,https://arxiv.org/abs/2210.08813,"Graph Neural Networks (GNNs) have made tremendous progress in the graph classification task. However, a performance gap between the training set and the test set has often been noticed. To bridge such gap, in this work we introduce the first test-time training framework for GNNs to enhance the model generalization capacity for the graph classification task. In particular, we design a novel test-time training strategy with self-supervised learning to adjust the GNN model for each test graph sample. Experiments on the benchmark datasets have demonstrated the effectiveness of the proposed framework, especially when there are distribution shifts between training set and test set. We have also conducted exploratory studies and theoretical analysis to gain deeper understandings on the rationality of the design of the proposed graph test time training framework (GT3)."
Wei Jin,INS-GNN: Improving graph imbalance learning with self-supervision,2023,https://www.sciencedirect.com/science/article/pii/S0020025523005042,"Graph Neural Networks (GNNs) have achieved tremendous success in various applications, such as node classification, link prediction and graph classification. However, graph-structured data is usually imbalanced in many real-world scenarios. When trained on an imbalanced dataset, the performance of GNNs is distant from satisfactory for nodes of minority classes. Due to the small population, these minority nodes have less engagement in the objective function of training and the message passing mechanism behind GNNs exacerbates this problem further, as the information from minority nodes can be overwhelmed by majority nodes in the process of information propagation. To tackle the problems of imbalanced node classification based on GNNs, the most effective way is to promote the engagement of minority nodes during propagation. Therefore, inspired by self-supervised learning on exploring useful …"
Wei Jin,DANCE: a deep learning library and benchmark platform for single-cell analysis,2024,https://link.springer.com/article/10.1186/s13059-024-03211-z,"DANCE is the first standard, generic, and extensible benchmark platform for accessing and evaluating computational methods across the spectrum of benchmark datasets for numerous single-cell analysis tasks. Currently, DANCE supports 3 modules and 8 popular tasks with 32 state-of-art methods on 21 benchmark datasets. People can easily reproduce the results of supported algorithms across major benchmark datasets via minimal efforts, such as using only one command line. In addition, DANCE provides an ecosystem of deep learning architectures and tools for researchers to facilitate their own model development. DANCE is an open-source Python package that welcomes all kinds of contributions."
Wei Jin,Localized Graph Collaborative Filtering,2021,https://epubs.siam.org/doi/abs/10.1137/1.9781611977172.61,"User-item interactions in recommendations can be naturally denoted as a user-item bipartite graph. Given the success of graph neural networks (GNNs) in graph representation learning, GNN-based Collaborative Filtering (CF) methods have been proposed to advance recommender systems. These methods often make recommendations based on the learned user and item embeddings. However, we found that they do not perform well with sparse user-item graphs which are quite common in real-world recommendations. Therefore, in this work, we introduce a novel perspective to build GNN-based CF methods for recommendations which leads to the proposed framework Localized Graph Collaborative Filtering (LGCF). One key advantage of LGCF is that it does not need to learn embeddings for each user and item, which is challenging in sparse scenarios. Alternatively, LGCF aims at encoding useful CF …"
Wei Jin,Learning Representations for Hyper-Relational Knowledge Graphs,2022,https://dl.acm.org/doi/abs/10.1145/3625007.3627591,"Knowledge graphs (KGs) have gained prominence for their ability to learn representations for uni-relational facts. Recently, research has focused on modeling hyper-relational facts, which move beyond the restriction of uni-relational facts and allow us to represent more complex and real-world information. However, existing approaches for learning representations on hyper-relational KGs majorly focus on enhancing the communication from qualifiers to base triples while overlooking the flow of information from base triple to qualifiers. This can lead to suboptimal qualifier representations, especially when a large amount of qualifiers are presented. It motivates us to design a framework that utilizes multiple aggregators to learn representations for hyper-relational facts: one from the perspective of the base triple and the other one from the perspective of the qualifiers. Experiments demonstrate the effectiveness of our …"
Wei Jin,Text-space graph foundation models: Comprehensive benchmarks and new insights,2024,https://arxiv.org/abs/2406.10727,"Given the ubiquity of graph data and its applications in diverse domains, building a Graph Foundation Model (GFM) that can work well across different graphs and tasks with a unified backbone has recently garnered significant interests. A major obstacle to achieving this goal stems from the fact that graphs from different domains often exhibit diverse node features. Inspired by multi-modal models that align different modalities with natural language, the text has recently been adopted to provide a unified feature space for diverse graphs. Despite the great potential of these text-space GFMs, current research in this field is hampered by two problems. First, the absence of a comprehensive benchmark with unified problem settings hinders a clear understanding of the comparative effectiveness and practical value of different text-space GFMs. Second, there is a lack of sufficient datasets to thoroughly explore the methods' full potential and verify their effectiveness across diverse settings. To address these issues, we conduct a comprehensive benchmark providing novel text-space datasets and comprehensive evaluation under unified problem settings. Empirical results provide new insights and inspire future research directions. Our code and data are publicly available from \url{https://github.com/CurryTang/TSGFM}."
Wei Jin,Single-cell multimodal prediction via transformers,2023,https://dl.acm.org/doi/abs/10.1145/3583780.3615061,"The recent development of multimodal single-cell technology has made the possibility of acquiring multiple omics data from individual cells, thereby enabling a deeper understanding of cellular states and dynamics. Nevertheless, the proliferation of multimodal single-cell data also introduces tremendous challenges in modeling the complex interactions among different modalities. The recently advanced methods focus on constructing static interaction graphs and applying graph neural networks (GNNs) to learn from multimodal data. However, such static graphs can be suboptimal as they do not take advantage of the downstream task information; meanwhile GNNs also have some inherent limitations when deeply stacking GNN layers. To tackle these issues, in this work, we investigate how to leverage transformers for multimodal single-cell data in an end-to-end manner while exploiting downstream task information …"
Wei Jin,Single cells are spatial tokens: Transformers for spatial transcriptomic data imputation,2023,https://arxiv.org/abs/2302.03038,"Spatially resolved transcriptomics brings exciting breakthroughs to single-cell analysis by providing physical locations along with gene expression. However, as a cost of the extremely high spatial resolution, the cellular level spatial transcriptomic data suffer significantly from missing values. While a standard solution is to perform imputation on the missing values, most existing methods either overlook spatial information or only incorporate localized spatial context without the ability to capture long-range spatial information. Using multi-head self-attention mechanisms and positional encoding, transformer models can readily grasp the relationship between tokens and encode location information. In this paper, by treating single cells as spatial tokens, we study how to leverage transformers to facilitate spatial tanscriptomics imputation. In particular, investigate the following two key questions: (1) $\textit{how to encode spatial information of cells in transformers}$, and (2) $\textit{ how to train a transformer for transcriptomic imputation}$. By answering these two questions, we present a transformer-based imputation framework, SpaFormer, for cellular-level spatial transcriptomic data. Extensive experiments demonstrate that SpaFormer outperforms existing state-of-the-art imputation algorithms on three large-scale datasets while maintaining superior computational efficiency."
Wei Jin,Globally interpretable graph learning via distribution matching,2024,https://dl.acm.org/doi/abs/10.1145/3589334.3645674,"Graph neural networks (GNNs) have emerged as a powerful model to capture critical graph patterns. Instead of treating them as black boxes in an end-to-end fashion, attempts are arising to explain the model behavior. Existing works mainly focus on local interpretation to reveal the discriminative pattern for each individual instance, which however cannot directly reflect the high-level model behavior across instances. To gain global insights, we aim to answer an important question that is not yet well studied: how to provide a global interpretation for the graph learning procedure? We formulate this problem as globally interpretable graph learning, which targets on distilling high-level and human-intelligible patterns that dominate the learning procedure, such that training on this pattern can recover a similar model. As a start, we propose a novel model fidelity metric, tailored for evaluating the fidelity of the resulting …"
Wei Jin,Investigating Out-of-Distribution Generalization of GNNs: An Architecture Perspective,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671792,"Graph neural networks (GNNs) have exhibited remarkable performance under the assumption that test data comes from the same distribution of training data. However, in real-world scenarios, this assumption may not always be valid. Consequently, there is a growing focus on exploring the Out-of-Distribution (OOD) problem in the context of graphs. Most existing efforts have primarily concentrated on improving graph OOD generalization from two model-agnostic perspectives: data-driven methods and strategy-based learning. However, there has been limited attention dedicated to investigating the impact of well-known GNN model architectures on graph OOD generalization, which is orthogonal to existing research. In this work, we provide the first comprehensive investigation of OOD generalization on graphs from an architecture perspective, by examining the common building blocks of modern GNNs. Through …"
Wei Jin,Enhancing graph representations learning with decorrelated propagation,2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599334,"In recent years, graph neural networks (GNNs) have been widely used in many domains due to their powerful capability in representation learning on graph-structured data. While a majority of extant studies focus on mitigating the over-smoothing problem, recent works also reveal the limitation of GNN from a new over-correlation perspective which states that the learned representation becomes highly correlated after feature transformation and propagation in GNNs. In this paper, we thoroughly re-examine the issue of over-correlation in deep GNNs, both empirically and theoretically. We demonstrate that the propagation operator in GNNs exacerbates the feature correlation. In addition, we discovered through empirical study that existing decorrelation solutions fall short of maintaining a low feature correlation, potentially encoding redundant information. Thus, to more effectively address the over-correlation problem …"
Wei Jin,"Graph representation learning: foundations, methods, applications and systems",2021,https://dl.acm.org/doi/abs/10.1145/3447548.3470824,"Graphs such as social networks and molecular graphs are ubiquitous data structures in the real world. Due to their prevalence, it is of great research importance to extract meaningful patterns from graph structured data so that downstream tasks can be facilitated. Instead of designing hand-engineered features, graph representation learning has emerged to learn representations that can encode the abundant information about the graph. It has achieved tremendous success in various tasks such as node classification, link prediction, and graph classification and has attracted increasing attention in recent years.In this tutorial, we systematically review the foundations, techniques, applications and advances in graph representation learning. We first introduce the foundations on graph theory and graph Fourier analysis. We then cover the key achievements of graph representation learning in recent years. Concretely …"
Wei Jin,Spectral-Aware Augmentation for Enhanced Graph Representation Learning,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679762,"Graph Contrastive Learning (GCL) has demonstrated remarkable effectiveness in learning representations on graphs in recent years. To generate ideal augmentation views, the augmentation generation methods should preserve essential information while discarding less relevant details for downstream tasks. However, current augmentation methods usually involve random topology corruption in the spatial domain, which fails to adequately address information spread across different frequencies in the spectral domain. Our preliminary study highlights this issue, demonstrating that spatial random perturbations impact all frequency bands almost uniformly. Given that task-relevant information typically resides in specific spectral regions that vary across graphs, this one-size-fits-all approach can pose challenges. We argue that indiscriminate spatial random perturbation might unintentionally weaken task-relevant …"
Wei Jin,Epidemiology-aware neural ode with continuous disease transmission graph,2024,https://arxiv.org/abs/2410.00049,"Effective epidemic forecasting is critical for public health strategies and efficient medical resource allocation, especially in the face of rapidly spreading infectious diseases. However, existing deep-learning methods often overlook the dynamic nature of epidemics and fail to account for the specific mechanisms of disease transmission. In response to these challenges, we introduce an innovative end-to-end framework called Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph (EARTH) in this paper. To learn continuous and regional disease transmission patterns, we first propose EANO, which seamlessly integrates the neural ODE approach with the epidemic mechanism, considering the complex spatial spread process during epidemic evolution. Additionally, we introduce GLTG to model global infection trends and leverage these signals to guide local transmission dynamically. To accommodate both the global coherence of epidemic trends and the local nuances of epidemic transmission patterns, we build a cross-attention approach to fuse the most meaningful information for forecasting. Through the smooth synergy of both components, EARTH offers a more robust and flexible approach to understanding and predicting the spread of infectious diseases. Extensive experiments show EARTH superior performance in forecasting real-world epidemics compared to state-of-the-art methods. The code will be available at https://github.com/Emory-Melody/EpiLearn."
Wei Jin,Gc-bench: A benchmark framework for graph condensation with new insights,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240616715G/abstract,"Graph condensation (GC) is an emerging technique designed to learn a significantly smaller graph that retains the essential information of the original graph. This condensed graph has shown promise in accelerating graph neural networks while preserving performance comparable to those achieved with the original, larger graphs. Additionally, this technique facilitates downstream applications such as neural architecture search and enhances our understanding of redundancy in large graphs. Despite the rapid development of GC methods, a systematic evaluation framework remains absent, which is necessary to clarify the critical designs for particular evaluative aspects. Furthermore, several meaningful questions have not been investigated, such as whether GC inherently preserves certain graph properties and offers robustness even without targeted design efforts. In this paper, we introduce GC-Bench, a …"
Wei Jin,Graph mining with graph neural networks,2021,https://dl.acm.org/doi/abs/10.1145/3437963.3441673,"Graphs are ubiquitous data structures in various fields, such as social media, transportation, linguistics and chemistry. To solve downstream graph-related tasks, it is of great significance to learn effective representations for graphs. My research strives to help meet this demand; due to the huge success of deep learning methods, especially graph neural networks, in graph-related problems, my emphasis has primarily been on improving their power for graph representation learning. More specifically, my research spans across the following three main areas: (1) robustness of graph neural networks, where we seek to study the performance of them under random noise and carefully-crafted attacks; (2) self-supervised learning in graph neural networks, where we aim to alleviate their need for costly annotated data by constructing self-supervision to help them fully exploit unlabeled data; and (3) applications of graph …"
Wei Jin,SpatialCTD: A Large-Scale Tumor Microenvironment Spatial Transcriptomic Dataset to Evaluate Cell Type Deconvolution for Immuno-Oncology,2024,https://www.liebertpub.com/doi/abs/10.1089/cmb.2024.0532,"Recent technological advancements have enabled spatially resolved transcriptomic profiling but at a multicellular resolution that is more cost-effective. The task of cell type deconvolution has been introduced to disentangle discrete cell types from such multicellular spots. However, existing benchmark datasets for cell type deconvolution are either generated from simulation or limited in scale, predominantly encompassing data on mice and are not designed for human immuno-oncology. To overcome these limitations and promote comprehensive investigation of cell type deconvolution for human immuno-oncology, we introduce a large-scale spatial transcriptomic deconvolution benchmark dataset named SpatialCTD, encompassing 1.8 million cells and 12,900 pseudo spots from the human tumor microenvironment across the lung, kidney, and liver. In addition, SpatialCTD provides more realistic reference than those …"
Wei Jin,A pure transformer pretraining framework on text-attributed graphs,2024,https://arxiv.org/abs/2406.13873,"Pretraining plays a pivotal role in acquiring generalized knowledge from large-scale data, achieving remarkable successes as evidenced by large models in CV and NLP. However, progress in the graph domain remains limited due to fundamental challenges such as feature heterogeneity and structural heterogeneity. Recently, increasing efforts have been made to enhance node feature quality with Large Language Models (LLMs) on text-attributed graphs (TAGs), demonstrating superiority to traditional bag-of-words or word2vec techniques. These high-quality node features reduce the previously critical role of graph structure, resulting in a modest performance gap between Graph Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs). Motivated by this, we introduce a feature-centric pretraining perspective by treating graph structure as a prior and leveraging the rich, unified feature space to learn refined interaction patterns that generalizes across graphs. Our framework, Graph Sequence Pretraining with Transformer (GSPT), samples node contexts through random walks and employs masked feature reconstruction to capture pairwise proximity in the LLM-unified feature space using a standard Transformer. By utilizing unified text representations rather than varying structures, our framework achieves significantly better transferability among graphs within the same domain. GSPT can be easily adapted to both node classification and link prediction, demonstrating promising empirical success on various datasets."
Wei Jin,Graph Feature Gating Networks,2021,https://arxiv.org/abs/2105.04493,"Graph neural networks (GNNs) have received tremendous attention due to their power in learning effective representations for graphs. Most GNNs follow a message-passing scheme where the node representations are updated by aggregating and transforming the information from the neighborhood. Meanwhile, they adopt the same strategy in aggregating the information from different feature dimensions. However, suggested by social dimension theory and spectral embedding, there are potential benefits to treat the dimensions differently during the aggregation process. In this work, we investigate to enable heterogeneous contributions of feature dimensions in GNNs. In particular, we propose a general graph feature gating network (GFGN) based on the graph signal denoising problem and then correspondingly introduce three graph filters under GFGN to allow different levels of contributions from feature dimensions. Extensive experiments on various real-world datasets demonstrate the effectiveness and robustness of the proposed frameworks."
Wei Jin,Learning on Graphs with Large Language Models (LLMs): A Deep Dive into Model Robustness,2024,https://arxiv.org/abs/2407.12068,"Large Language Models (LLMs) have demonstrated remarkable performance across various natural language processing tasks. Recently, several LLMs-based pipelines have been developed to enhance learning on graphs with text attributes, showcasing promising performance. However, graphs are well-known to be susceptible to adversarial attacks and it remains unclear whether LLMs exhibit robustness in learning on graphs. To address this gap, our work aims to explore the potential of LLMs in the context of adversarial attacks on graphs. Specifically, we investigate the robustness against graph structural and textual perturbations in terms of two dimensions: LLMs-as-Enhancers and LLMs-as-Predictors. Through extensive experiments, we find that, compared to shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior robustness against structural and textual attacks.Based on these findings, we carried out additional analyses to investigate the underlying causes. Furthermore, we have made our benchmark library openly available to facilitate quick and fair evaluations, and to encourage ongoing innovative research in this field."
Wei Jin,Dcai: Data-centric artificial intelligence,2024,https://dl.acm.org/doi/abs/10.1145/3589335.3641297,"The emergence of Data-centric AI (DCAI) represents a pivotal shift in AI development, redirecting focus from model refinement to prioritizing data quality. This paradigmatic transition emphasizes the critical role of data in AI. While past approaches centered on refining models, they often overlooked potential data imperfections, raising questions about the true potential of enhanced model performance. DCAI advocates the systematic engineering of data, complementing existing efforts and playing a vital role in driving AI success. This transition has spurred innovation in various machine learning and data mining algorithms and their applications on the Web. Therefore, we propose the DCAI Workshop at WWW'24, which offers a platform for academic researchers and industry practitioners to showcase the latest advancements in DCAI research and their practical applications in the real world."
Wei Jin,Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation,2024,https://arxiv.org/abs/2402.08921,"Session-based recommendation has gained increasing attention in recent years, with its aim to offer tailored suggestions based on users' historical behaviors within sessions. To advance this field, a variety of methods have been developed, with ID-based approaches typically demonstrating promising performance. However, these methods often face challenges with long-tail items and overlook other rich forms of information, notably valuable textual semantic information. To integrate text information, various methods have been introduced, mostly following a naive fusion framework. Surprisingly, we observe that fusing these two modalities does not consistently outperform the best single modality by following the naive fusion framework. Further investigation reveals an potential imbalance issue in naive fusion, where the ID dominates and text modality is undertrained. This suggests that the unexpected observation may stem from naive fusion's failure to effectively balance the two modalities, often over-relying on the stronger ID modality. This insight suggests that naive fusion might not be as effective in combining ID and text as previously expected. To address this, we propose a novel alternative training strategy AlterRec. It separates the training of ID and text, thereby avoiding the imbalance issue seen in naive fusion. Additionally, AlterRec designs a novel strategy to facilitate the interaction between the two modalities, enabling them to mutually learn from each other and integrate the text more effectively. Comprehensive experiments demonstrate the effectiveness of AlterRec in session-based recommendation. The implementation is available at …"
Wei Jin,Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs. CoRR abs/2307.03393 (2023),2023,https://scholar.google.com/scholar?cluster=3825623683177462468&hl=en&oi=scholarr,
Wei Jin,STRUX: An LLM for Decision-Making with Structured Explanations,2025,https://arxiv.org/abs/2410.12583,"Countless decisions shape our daily lives, and it is paramount to understand the how and why behind these choices. In this paper, we introduce a new LLM decision-making framework called STRUX, which enhances LLM decision-making by providing structured explanations. These include favorable and adverse facts related to the decision, along with their respective strengths. STRUX begins by distilling lengthy information into a concise table of key facts. It then employs a series of self-reflection steps to determine which of these facts are pivotal, categorizing them as either favorable or adverse in relation to a specific decision. Lastly, we fine-tune an LLM to identify and prioritize these key facts to optimize decision-making. STRUX has been evaluated on the challenging task of forecasting stock investment decisions based on earnings call transcripts and demonstrated superior performance against strong baselines. It enhances decision transparency by allowing users to understand the impact of different factors, representing a meaningful step towards practical decision-making with LLMs."
Wei Jin,GC4NC: A Benchmark Framework for Graph Condensation on Node Classification with New Insights,2024,https://arxiv.org/abs/2406.16715,"Graph condensation (GC) is an emerging technique designed to learn a significantly smaller graph that retains the essential information of the original graph. This condensed graph has shown promise in accelerating graph neural networks while preserving performance comparable to those achieved with the original, larger graphs. Additionally, this technique facilitates downstream applications like neural architecture search and deepens our understanding of redundancies in large graphs. Despite the rapid development of GC methods, particularly for node classification, a unified evaluation framework is still lacking to systematically compare different GC methods or clarify key design choices for improving their effectiveness. To bridge these gaps, we introduce \textbf{GC4NC}, a comprehensive framework for evaluating diverse GC methods on node classification across multiple dimensions including performance, efficiency, privacy preservation, denoising ability, NAS effectiveness, and transferability. Our systematic evaluation offers novel insights into how condensed graphs behave and the critical design choices that drive their success. These findings pave the way for future advancements in GC methods, enhancing both performance and expanding their real-world applications. Our code is available at \url{https://github.com/Emory-Melody/GraphSlim/tree/main/benchmark}."
Wei Jin,Epilearn: A python library for machine learning in epidemic modeling,2024,https://arxiv.org/abs/2406.06016,"EpiLearn is a Python toolkit developed for modeling, simulating, and analyzing epidemic data. Although there exist several packages that also deal with epidemic modeling, they are often restricted to mechanistic models or traditional statistical tools. As machine learning continues to shape the world, the gap between these packages and the latest models has become larger. To bridge the gap and inspire innovative research in epidemic modeling, EpiLearn not only provides support for evaluating epidemic models based on machine learning, but also incorporates comprehensive tools for analyzing epidemic data, such as simulation, visualization, transformations, etc. For the convenience of both epidemiologists and data scientists, we provide a unified framework for training and evaluation of epidemic models on two tasks: Forecasting and Source Detection. To facilitate the development of new models, EpiLearn follows a modular design, making it flexible and easy to use. In addition, an interactive web application is also developed to visualize the real-world or simulated epidemic data. Our package is available at https://github.com/Emory-Melody/EpiLearn."
Wei Jin,Precedence-Constrained Winter Value for Effective Graph Data Valuation,2024,https://arxiv.org/abs/2402.01943,"Data valuation is essential for quantifying data's worth, aiding in assessing data quality and determining fair compensation. While existing data valuation methods have proven effective in evaluating the value of Euclidean data, they face limitations when applied to the increasingly popular graph-structured data. Particularly, graph data valuation introduces unique challenges, primarily stemming from the intricate dependencies among nodes and the exponential growth in value estimation costs. To address the challenging problem of graph data valuation, we put forth an innovative solution, Precedence-Constrained Winter (PC-Winter) Value, to account for the complex graph structure. Furthermore, we develop a variety of strategies to address the computational challenges and enable efficient approximation of PC-Winter. Extensive experiments demonstrate the effectiveness of PC-Winter across diverse datasets and tasks."
Wei Jin,SpatialCTD: a large-scale TME spatial transcriptomic dataset to evaluate cell type deconvolution for immuno-oncology,2023,https://www.biorxiv.org/content/10.1101/2023.04.11.536333.abstract,"Recent technological advancements have enabled spatially resolved transcriptomic profiling but at multi-cellular resolution. The task of cell type deconvolution has been introduced to disentangle discrete cell types from such multi-cellular spots. However, existing datasets for cell type deconvolution are limited in scale, predominantly encompassing data on mice, and are not designed for human immuno-oncology. In order to overcome these limitations and promote comprehensive investigation of cell type deconvolution for human immuno-oncology, we introduce a large-scale spatial transcriptomic dataset named SpatialCTD, encompassing 1.8 million cells from the human tumor microenvironment across the lung, kidney, and liver. Distinct from existing approaches that primarily depend on single-cell RNA sequencing data as a reference without incorporating spatial information, we introduce Graph Neural Network-based method (i.e., GNNDeconvolver) that effectively utilize the spatial information from reference samples, and extensive experiments show that GNNDeconvolver often outperforms existing state-of-the-art methods by a substantial margin, without requiring single-cell RNA-seq data. To enable comprehensive evaluations on spatial transcriptomics data from flexible protocols, we provide an online tool capable of converting spatial transcriptomic data from other platforms (e.g., 10x Visium, MERFISH and sci-Space) into pseudo spots, featuring adjustable spot size. The SpatialCTD dataset and GNNDeconvolver implementation are available at https://github.com/OmicsML/SpatialCTD, and the online converter tool can be accessed at https …"
Wei Jin,Customized graph neural networks,2020,https://arxiv.org/abs/2005.12386,"Recently, Graph Neural Networks (GNNs) have greatly advanced the task of graph classification. Typically, we first build a unified GNN model with graphs in a given training set and then use this unified model to predict labels of all the unseen graphs in the test set. However, graphs in the same dataset often have dramatically distinct structures, which indicates that a unified model may be sub-optimal given an individual graph. Therefore, in this paper, we aim to develop customized graph neural networks for graph classification. Specifically, we propose a novel customized graph neural network framework, i.e., Customized-GNN. Given a graph sample, Customized-GNN can generate a sample-specific model for this graph based on its structure. Meanwhile, the proposed framework is very general that can be applied to numerous existing graph neural network models. Comprehensive experiments on various graph classification benchmarks demonstrate the effectiveness of the proposed framework."
Wei Jin,DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses. arXiv 2020,2020,https://scholar.google.com/scholar?cluster=7067835830342307402&hl=en&oi=scholarr,
Wei Jin,Deep neural networks for endemic measles dynamics: Comparative analysis and integration with mechanistic models,2024,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012616,"Measles is an important infectious disease system both for its burden on public health and as an opportunity for studying nonlinear spatio-temporal disease dynamics. Traditional mechanistic models often struggle to fully capture the complex nonlinear spatio-temporal dynamics inherent in measles outbreaks. In this paper, we first develop a high-dimensional feed-forward neural network model with spatial features (SFNN) to forecast endemic measles outbreaks and systematically compare its predictive power with that of a classical mechanistic model (TSIR). We illustrate the utility of our model using England and Wales measles data from 1944-1965. These data present multiple modeling challenges due to the interplay between metapopulations, seasonal trends, and nonlinear dynamics related to demographic changes. Our results show that while the TSIR model yields similarly performant short-term (1 to 2 biweeks ahead) forecasts for highly populous cities, our neural network model (SFNN) consistently achieves lower root mean squared error (RMSE) across other forecasting windows. Furthermore, we show that our spatial-feature neural network model, without imposing mechanistic assumptions a priori, can uncover gravity-model-like spatial hierarchy of measles spread in which major cities play an important role in driving regional outbreaks. We then turn our attention to integrative approaches that combine mechanistic and machine learning models. Specifically, we investigate how the TSIR can be utilized to improve a state-of-the-art approach known as Physics-Informed-Neural-Networks (PINN) which explicitly combines compartmental …"
Wei Jin,Empowering Graph Neural Networks From a Data-Centric View,2023,https://search.proquest.com/openview/9811c9ea83faf416731b80744bce44bc/1?pq-origsite=gscholar&cbl=18750&diss=y,"Many learning tasks in Artificial Intelligence (AI) require dealing with graph data, ranging from biology and chemistry to finance and education. As powerful learning tools for graph inputs, graph neural networks (GNNs) have demonstrated remarkable performance in various applications such as recommender systems and drug discovery. Recent research has primarily focused on model-centric approaches to enhance GNN performance by modifying model architectures while keeping the dataset fixed. However, these approaches have limitations, particularly in terms of robustness and scalability. For example, these approaches often yield suboptimal performance when confronted with limited high-quality data. Moreover, training GNNs is often computationally expensive on large-scale data; and such cost becomes even prohibitive when we need to train numerous models on the same dataset, such as hyper …"
Wei Jin,Higher-order Interaction Matters: Dynamic Hypergraph Neural Networks for Epidemic Modeling,2025,https://arxiv.org/abs/2503.20114,"The ongoing need for effective epidemic modeling has driven advancements in capturing the complex dynamics of infectious diseases. Traditional models, such as Susceptible-Infected-Recovered, and graph-based approaches often fail to account for higher-order interactions and the nuanced structure pattern inherent in human contact networks. This study introduces a novel Human Contact-Tracing Hypergraph Neural Network framework tailored for epidemic modeling called EpiDHGNN, leveraging the capabilities of hypergraphs to model intricate, higher-order relationships from both location and individual level. Both real-world and synthetic epidemic data are used to train and evaluate the model. Results demonstrate that EpiDHGNN consistently outperforms baseline models across various epidemic modeling tasks, such as source detection and forecast, by effectively capturing the higher-order interactions and preserving the complex structure of human interactions. This work underscores the potential of representing human contact data as hypergraphs and employing hypergraph-based methods to improve epidemic modeling, providing reliable insights for public health decision-making."
Wei Jin,Scalable Graph Condensation with Evolving Capabilities,2025,https://arxiv.org/abs/2502.17614,"Graph data has become a pivotal modality due to its unique ability to model relational datasets. However, real-world graph data continues to grow exponentially, resulting in a quadratic increase in the complexity of most graph algorithms as graph sizes expand. Although graph condensation (GC) methods have been proposed to address these scalability issues, existing approaches often treat the training set as static, overlooking the evolving nature of real-world graph data. This limitation leads to inefficiencies when condensing growing training sets. In this paper, we introduce GECC (Graph Evolving Clustering Condensation), a scalable graph condensation method designed to handle large-scale and evolving graph data. GECC employs a traceable and efficient approach by performing class-wise clustering on aggregated features. Furthermore, it can inherits previous condensation results as clustering centroids when the condensed graph expands, thereby attaining an evolving capability. This methodology is supported by robust theoretical foundations and demonstrates superior empirical performance. Comprehensive experiments show that GECC achieves better performance than most state-of-the-art graph condensation methods while delivering an around 1,000x speedup on large datasets."
Wei Jin,TimeDistill: Efficient Long-Term Time Series Forecasting with MLP via Cross-Architecture Distillation,2025,https://arxiv.org/abs/2502.15016,"Transformer-based and CNN-based methods demonstrate strong performance in long-term time series forecasting. However, their high computational and storage requirements can hinder large-scale deployment. To address this limitation, we propose integrating lightweight MLP with advanced architectures using knowledge distillation (KD). Our preliminary study reveals different models can capture complementary patterns, particularly multi-scale and multi-period patterns in the temporal and frequency domains. Based on this observation, we introduce TimeDistill, a cross-architecture KD framework that transfers these patterns from teacher models (e.g., Transformers, CNNs) to MLP. Additionally, we provide a theoretical analysis, demonstrating that our KD approach can be interpreted as a specialized form of mixup data augmentation. TimeDistill improves MLP performance by up to 18.6%, surpassing teacher models on eight datasets. It also achieves up to 7X faster inference and requires 130X fewer parameters. Furthermore, we conduct extensive evaluations to highlight the versatility and effectiveness of TimeDistill."
Wei Jin,CAPE: Covariate-Adjusted Pre-Training for Epidemic Time Series Forecasting,2025,https://arxiv.org/abs/2502.03393,"Accurate forecasting of epidemic infection trajectories is crucial for safeguarding public health. However, limited data availability during emerging outbreaks and the complex interaction between environmental factors and disease dynamics present significant challenges for effective forecasting. In response, we introduce CAPE, a novel epidemic pre-training framework designed to harness extensive disease datasets from diverse regions and integrate environmental factors directly into the modeling process for more informed decision-making on downstream diseases. Based on a covariate adjustment framework, CAPE utilizes pre-training combined with hierarchical environment contrasting to identify universal patterns across diseases while estimating latent environmental influences. We have compiled a diverse collection of epidemic time series datasets and validated the effectiveness of CAPE under various evaluation scenarios, including full-shot, few-shot, zero-shot, cross-location, and cross-disease settings, where it outperforms the leading baseline by an average of 9.9% in full-shot and 14.3% in zero-shot settings. The code will be released upon acceptance."
Wei Jin,Threshold Filtering Packing for Supervised Fine-Tuning: Training Related Samples within Packs,2025,https://arxiv.org/abs/2408.09327,"Packing for Supervised Fine-Tuning (SFT) in autoregressive models involves concatenating data points of varying lengths until reaching the designed maximum length to facilitate GPU processing. However, randomly concatenating data points and feeding them into an autoregressive transformer can lead to cross-contamination of sequences due to the significant difference in their subject matter. The mainstream approaches in SFT ensure that each token in the attention calculation phase only focuses on tokens within its own short sequence, without providing additional learning signals for the preceding context. To address these challenges, we introduce Threshold Filtering Packing (TFP), a method that selects samples with related context while maintaining sufficient diversity within the same pack. Our experiments show that TFP offers a simple-to-implement and scalable approach that significantly enhances SFT performance, with observed improvements of up to 7\% on GSM8K, 4\% on HumanEval, and 15\% on the adult-census-income dataset."
Wei Jin,Trustworthy and Responsible AI for Information and Knowledge Management System,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3680111,"The way research and business manage and utilize knowledge is undergoing a significant transformation, driven by Artificial Intelligence (AI). Deep learning and machine learning are emerging as powerful tools for optimizing knowledge management systems, leading to more informed and productive development. AI offers unique solutions for organizations struggling with information overload and inefficient knowledge transfer. These AI models can significantly improve data management and utilization. Imagine an AI-powered system that streamlines onboarding processes, provides precise answers to various queries, and even captures the valuable tacit knowledge (implicit skills and expertise) often residing within individuals. AI bridges the gap between explicit knowledge (easily documented information) and tacit knowledge, fostering a more comprehensive and accessible knowledge base. However, such AI …"
Wei Jin,Sub-graph Based Diffusion Model for Link Prediction,2024,https://arxiv.org/abs/2409.08487,"Denoising Diffusion Probabilistic Models (DDPMs) represent a contemporary class of generative models with exceptional qualities in both synthesis and maximizing the data likelihood. These models work by traversing a forward Markov Chain where data is perturbed, followed by a reverse process where a neural network learns to undo the perturbations and recover the original data. There have been increasing efforts exploring the applications of DDPMs in the graph domain. However, most of them have focused on the generative perspective. In this paper, we aim to build a novel generative model for link prediction. In particular, we treat link prediction between a pair of nodes as a conditional likelihood estimation of its enclosing sub-graph. With a dedicated design to decompose the likelihood estimation process via the Bayesian formula, we are able to separate the estimation of sub-graph structure and its node features. Such designs allow our model to simultaneously enjoy the advantages of inductive learning and the strong generalization capability. Remarkably, comprehensive experiments across various datasets validate that our proposed method presents numerous advantages: (1) transferability across datasets without retraining, (2) promising generalization on limited training data, and (3) robustness against graph adversarial attacks."
Wei Jin,Navigating complexity,2024,https://dl.acm.org/doi/abs/10.5555/3692070.3694569,"Graph condensation aims to reduce the size of a large-scale graph dataset by synthesizing a compact counterpart without sacrificing the performance of Graph Neural Networks (GNNs) trained on it, which has shed light on reducing the computational cost for training GNNs. Nevertheless, existing methods often fall short of accurately replicating the original graph for certain datasets, thereby failing to achieve the objective of lossless condensation. To understand this phenomenon, we investigate the potential reasons and reveal that the previous state-of-the-art trajectory matching method provides biased and restricted supervision signals from the original graph when optimizing the condensed one. This significantly limits both the scale and efficacy of the condensed graph. In this paper, we make the first attempt toward lossless graph condensation by bridging the previously neglected supervision signals. Specifically …"
Wei Jin,Neural networks for endemic measles dynamics: comparative analysis and integration with mechanistic models,2024,https://www.medrxiv.org/content/10.1101/2024.05.28.24307979.abstract,"Measles is an important infectious disease system both for its burden on public health and as an opportunity for studying nonlinear spatio-temporal disease dynamics. Traditional mechanistic models often struggle to fully capture the complex nonlinear spatio-temporal dynamics inherent in measles outbreaks. In this paper, we first develop a high-dimensional feed-forward neural network model with spatial features (SFNN) to forecast endemic measles outbreaks and systematically compare its predictive power with that of a classical mechanistic model (TSIR). We illustrate the utility of our model using England and Wales measles data from 1944-1965. These data present multiple modeling challenges due to the interplay between metapopulations, seasonal trends, and nonlinear dynamics related to demographic changes. Our results show that, while the TSIR model yields more accurate very short-term (1 to 2 biweeks ahead) forecasts for highly populous cities, overall, our neural network model (SFNN) outperforms the TSIR in other forecasting windows. Furthermore, we show that our spatial-feature neural network model, without imposing mechanistic assumptions a priori, can uncover gravity-model-like spatial hierarchy of measles spread in which major cities play an important role in driving regional outbreaks. We then turn our attention to integrative approaches that combine mechanistic and machine learning models. Specifically, we investigate how the TSIR can be utilized to improve a state-of-the-art approach known as Physics-Informed-Neural-Networks (PINN) which explicitly combines compartmental models and neural networks. Our results …"
Wei Jin,Enabling On-Device Learning via Experience Replay with Efficient Dataset Condensation,2024,https://arxiv.org/abs/2405.16113,"Upon deployment to edge devices, it is often desirable for a model to further learn from streaming data to improve accuracy. However, extracting representative features from such data is challenging because it is typically unlabeled, non-independent and identically distributed (non-i.i.d), and is seen only once. To mitigate this issue, a common strategy is to maintain a small data buffer on the edge device to hold the most representative data for further learning. As most data is either never stored or quickly discarded, identifying the most representative data to avoid significant information loss becomes critical. In this paper, we propose an on-device framework that addresses this issue by condensing incoming data into more informative samples. Specifically, to effectively handle unlabeled incoming data, we propose a pseudo-labeling technique designed for unlabeled on-device learning environments. Additionally, we develop a dataset condensation technique that only requires little computation resources. To counteract the effects of noisy labels during the condensation process, we further utilize a contrastive learning objective to improve the purity of class data within the buffer. Our empirical results indicate substantial improvements over existing methods, particularly when buffer capacity is severely restricted. For instance, with a buffer capacity of just one sample per class, our method achieves an accuracy that outperforms the best existing baseline by 58.4% on the CIFAR-10 dataset."
Wei Jin,Deep Learning on Graphs: A Data-Centric Exploration,2024,https://ojs.aaai.org/index.php/AAAI/article/view/30287,"Many learning tasks in Artificial Intelligence (AI) require dealing with graph data, ranging from biology and chemistry to finance and education. As powerful learning tools for graphs,  graph neural networks (GNNs) have demonstrated remarkable performance in various graph-related applications.  Despite the significant accomplishments of GNNs, recent studies have highlighted that their efficiency and effectiveness face significant challenges such as adversarial robustness and scalability, which are fundamentally linked to data. While major attention has been devoted to improving GNNs from the model perspective, the potential of directly enhancing data has often been overlooked.  It underscores a critical gap in GNN research---while model improvements are undoubtedly important, we also need to recognize and address the data-related factors contributing to the challenges. Hence, \textbf{my research is to investigate solutions for these challenges from the data perspective, employing strategies such as data characterization, reduction, augmentation, transformation, and detection."
Wei Jin,Deeprobust: a platform for adversarial attacks and defenses,2021,,
Wei Jin,Adversarial attacks and defenses on graphs,2021,,
Wei Jin,Deeprobust: A pytorch library for adversarial attacks and defenses,2020,,
Joon-Seok Kim,Location-Based Social Network Data Generation Based on Patterns of Life,2020,https://ieeexplore.ieee.org/abstract/document/9162189/,"Location-based social networks (LBSNs) have been studied extensively in recent years. However, utilizing real-world LBSN data sets yields several weaknesses: sparse and small data sets, privacy concerns, and a lack of authoritative ground-truth. To overcome these weaknesses, we leverage a large-scale LBSN simulation to create a framework to simulate human behavior and to create synthetic but realistic LBSN data based on human patterns of life. Such data not only captures the location of users over time but also their interactions via social networks. Patterns of life are simulated by giving agents (i.e., people) an array of “needs” that they aim to satisfy, e.g., agents go home when they are tired, to restaurants when they are hungry, to work to cover their financial needs, and to recreational sites to meet friends and satisfy their social needs. While existing real-world LBSN data sets are trivially small, the proposed …"
Joon-Seok Kim,Change of human mobility during COVID-19: A United States case study,2021,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0259031,"With the onset of COVID-19 and the resulting shelter in place guidelines combined with remote working practices, human mobility in 2020 has been dramatically impacted. Existing studies typically examine whether mobility in specific localities increases or decreases at specific points in time and relate these changes to certain pandemic and policy events. However, a more comprehensive analysis of mobility change over time is needed. In this paper, we study mobility change in the US through a five-step process using mobility footprint data. (Step 1) Propose the Delta Time Spent in Public Places (ΔTSPP) as a measure to quantify daily changes in mobility for each US county from 2019-2020. (Step 2) Conduct Principal Component Analysis (PCA) to reduce the ΔTSPP time series of each county to lower-dimensional latent components of change in mobility. (Step 3) Conduct clustering analysis to find counties that exhibit similar latent components. (Step 4) Investigate local and global spatial autocorrelation for each component. (Step 5) Conduct correlation analysis to investigate how various population characteristics and behavior correlate with mobility patterns. Results show that by describing each county as a linear combination of the three latent components, we can explain 59% of the variation in mobility trends across all US counties. Specifically, change in mobility in 2020 for US counties can be explained as a combination of three latent components: 1) long-term reduction in mobility, 2) no change in mobility, and 3) short-term reduction in mobility. Furthermore, we find that US counties that are geographically close are more likely to exhibit a …"
Joon-Seok Kim,Mobility data science (dagstuhl seminar 22021),2022,https://vbn.aau.dk/en/publications/mobility-data-science-dagstuhl-seminar-22021,"This report documents the program and the outcomes of Dagstuhl Seminar 22021"" Mobility Data Science"". This seminar was held January 9-14, 2022, including 47 participants from industry and academia. The goal of this Dagstuhl Seminar was to create a new research community of mobility data science in which the whole is greater than the sum of its parts by bringing together established leaders as well as promising young researchers from all fields related to mobility data science."
Joon-Seok Kim,Data-driven mobility models for COVID-19 simulation,2020,https://dl.acm.org/doi/abs/10.1145/3423455.3430305,"Agent-based models (ABM) play a prominent role in guiding critical decision-making and supporting the development of effective policies for better urban resilience and response to the COVID-19 pandemic. However, many ABMs lack realistic representations of human mobility, a key process that leads to physical interaction and subsequent spread of disease. Therefore, we propose the application of Latent Dirichlet Allocation (LDA), a topic modeling technique, to foot-traffic data to develop a realistic model of human mobility in an ABM that simulates the spread of COVID-19. In our novel approach, LDA treats POIs as ""words"" and agent home census block groups (CBGs) as ""documents"" to extract ""topics"" of POIs that frequently appear together in CBG visits. These topics allow us to simulate agent mobility based on the LDA topic distribution of their home CBG. We compare the LDA based mobility model with …"
Joon-Seok Kim,Urban life: a model of people and places,2023,https://link.springer.com/article/10.1007/s10588-021-09348-7,"We introduce the Urban Life agent-based simulation used by the Ground Truth program to capture the innate needs of a human-like population and explore how such needs shape social constructs such as friendship and wealth. Urban Life is a spatially explicit model to explore how urban form impacts agents’ daily patterns of life. By meeting up at places agents form social networks, which in turn affect the places the agents visit. In our model, location and co-location affect all levels of decision making as agents prefer to visit nearby places. Co-location is necessary (but not sufficient) to connect agents in the social network. The Urban Life model was used in the Ground Truth program as a virtual world testbed to produce data in a setting in which the underlying ground truth was explicitly known. Data was provided to research teams to test and validate Human Domain research methods to an extent previously …"
Joon-Seok Kim,Location-Based Social Simulation for Prescriptive Analytics of Disease Spread,2020,https://dl.acm.org/doi/abs/10.1145/3404820.3404828,"Human mobility and social networks have received considerable attention from researchers in recent years. What has been sorely missing is a comprehensive data set that not only addresses geometric movement patterns derived from trajectories, but also provides social networks and causal links as to why movement happens in the first place. To some extent, this challenge is addressed by studying location-based social networks (LBSNs). However, the scope of real-world LBSN data sets is constrained by privacy concerns, a lack of authoritative ground-truth, their sparsity, and small size. To overcome these issues we have infused a novel geographically explicit agent-based simulation framework to simulate human behavior and to create synthetic but realistic LBSN data based on human patterns-of-life (i.e., a geo-social simulation). Such data not only captures the location of users over time, but also their …"
Joon-Seok Kim,Mobility Data Science: Perspectives and Challenges,2024,https://dl.acm.org/doi/abs/10.1145/3652158,"Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of Global Positioning System (GPS)–equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated a significant impact in various domains, including traffic management, urban planning, and health sciences. In this article, we present the domain of mobility data science. Towards a unified approach to mobility data science, we present a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state-of-the-art, and describe open challenges for the research community in the coming years."
Joon-Seok Kim,Massive trajectory data based on patterns of life,2023,https://dl.acm.org/doi/abs/10.1145/3589132.3625592,"Individual human location trajectory and check-in data have been the driving force for human mobility research in recent years. However, existing human mobility datasets are very limited in size and representativeness. For example, one of the largest and most commonly used datasets of individual human location trajectories, GeoLife, captures fewer than two hundred individuals. To help fill this gap, this Data and Resources paper leverages an existing data generator based on fine-grained simulation of individual human patterns of life to produce large-scale trajectory, check-in, and social network data. In this simulation, individual human agents commute between their home and work locations, visit restaurants to eat, and visit recreational sites to meet friends. We provide large datasets of months of simulated trajectories for two example regions in the United States: San Francisco and New Orleans. In addition to …"
Joon-Seok Kim,COVID-19 Ensemble Models Using Representative Clustering,2020,https://dl.acm.org/doi/abs/10.1145/3431843.3431848,"In response to the COVID-19 pandemic, there have been various attempts to develop realistic models to both predict the spread of the disease and evaluate policy measures aimed at mitigation. Different models that operate under different parameters and assumptions produce radically different predictions, creating confusion among policy-makers and the general population and limiting the usefulness of the models. This newsletter article proposes a novel ensemble modeling approach that uses representative clustering to identify where existing model predictions of COVID-19 spread agree and unify these predictions into a smaller set of predictions. The proposed ensemble prediction approach is composed of the following stages: (1) the selection of the ensemble components, (2) the imputation of missing predictions for each component, and (3) representative clustering in application to time-series data to …"
Joon-Seok Kim,Semantically Diverse Path Search,2020,https://ieeexplore.ieee.org/abstract/document/9162294/,"Location-Based Services are often used to find proximal Points of Interest PoI - e.g., nearby restaurants and museums, police stations, hospitals, etc. - in a plethora of applications. An important recently addressed variant of the problem not only considers the distance/proximity aspect, but also desires semantically diverse locations in the answer-set. For instance, rather than picking several close-by attractions with similar features - e.g., restaurants with similar menus; museums with similar art exhibitions - a tourist may be more interested in a result set that could potentially provide more diverse types of experiences, for as long as they are within an acceptable distance from a given (current) location. Towards that goal, in this work we propose a novel approach to efficiently retrieve a path that will maximize the semantic diversity of the visited PoIs that are within distance limits along a given road network. We introduce a …"
Joon-Seok Kim,Managing Uncertainty in Evolving Geo-Spatial Data,2020,https://ieeexplore.ieee.org/abstract/document/9162308/,"Our ability to extract knowledge from evolving spatial phenomena and make it actionable is often impaired by unreliable, erroneous, obsolete, imprecise, sparse, and noisy data. Integrating the impact of this uncertainty is a paramount when estimating the reliability/confidence of any time-varying query result from the underlying input data. The goal of this advanced seminar is to survey solutions for managing, querying and mining uncertain spatial and spatio-temporal data. We survey different models and show examples of how to efficiently enrich query results with reliability information. We discuss both analytical solutions as well as approximate solutions based on geosimulation."
Joon-Seok Kim,Towards Mobility Data Science (Vision Paper),2023,https://arxiv.org/abs/2307.05717,"Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of GPS-equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated significant impact in various domains including traffic management, urban planning, and health sciences. In this paper, we present the emerging domain of mobility data science. Towards a unified approach to mobility data science, we envision a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state of the art and describe open challenges for the research community in the coming years."
Joon-Seok Kim,Vehicle relocation for ride-hailing,2020,https://ieeexplore.ieee.org/abstract/document/9259995/,"Ever increasing traffic and consequential congestion wastes fuel and is a significant contributor to Green House Gas (GHG) emissions. Contributors here include ride-sharing services such as Uber, Lyft, and Didi, with their drivers not only transporting passengers, but also spending a considerable time in traffic searching for new ones. To mitigate their impact, this work proposes a novel algorithm to improve the efficiency the drivers' search for passengers. Our algorithm directs unassigned drivers to locations where new passengers are expected to emerge. We use a non-negative matrix factorization approach to model the time and location of passengers given historical training data. A probabilistic search strategy then guides drivers to nearby locations for which we predict new passengers. To ensure that drivers do not over subscribe to such areas, we randomize destinations and provide each driver with a home …"
Joon-Seok Kim,Expert-in-the-Loop Prescriptive Analytics using Mobility Intervention for Epidemics,2020,https://www.researchgate.net/profile/Joon-Seok-Kim-2/publication/343906417_Expert-in-the-Loop_Prescriptive_Analytics_using_Mobility_Intervention_for_Epidemics/links/5f479549299bf13c503dedc9/Expert-in-the-Loop-Prescriptive-Analytics-using-Mobility-Intervention-for-Epidemics.pdf,"Due to complexity of social phenomena, it is a big challenge to predict the curves of epidemics that spread via social contacts and to control such epidemics. Misguided policies to mitigate epidemics may result in catastrophic consequences such as financial crisis, massive unemployment, and the surge of the number of critically ill patients exceeding the capacity of hospitals. In particular, under/overestimation of efficacy of interventions can mislead policymakers about perception of evolving situations. To avoid such pitfalls, we propose Expert-in-the-Loop (EITL) prescriptive analytics using mobility intervention for epidemics. Rather than employing a purely data-driven approach, the key advantage of our approach is to leverage experts’ best knowledge in estimating disease spreading and the efficacy of interventions which allows us to efficiently narrow down factors and the scope of combinatorial possible worlds. We introduce our experience to develop Expert-in-the-Loop simulations during the Challenge on Mobility Intervention for Epidemics. We demonstrate that misconceptions about the causality can be corrected in the iterations of consulting with experts, developing simulations, and experimentation."
Joon-Seok Kim,Co-simulation framework for network attack generation and monitoring,2024,https://ieeexplore.ieee.org/abstract/document/10695812/,"Resilience assessment is crucial for maintaining high availability, security, and quality of service in power grids. However, most current grid research lacks hardware testbed capabilities. Moreover, the integration of distributed energy resources expands the grid’s attack surface, necessitating reliable and realistic modeling techniques to be accessible to the broader research community. Consequently, simulation testbeds have emerged to model real-world power grid topologies and evaluate the impact of various disruptions. Existing co-simulation platforms for power grids focus on limited components, such as focusing only on the dynamics of the physical layer. Additionally, many platforms require specialized hardware that may be too expensive for most researchers. Furthermore, not many platforms support realistic modeling of the communication layer, which demands the use of Supervisory Control and Data …"
Joon-Seok Kim,In Silico Human Mobility Data Science: Leveraging Massive Simulated Mobility Data (Vision Paper),2024,https://dl.acm.org/doi/abs/10.1145/3672557,"Human mobility data science using trajectories or check-ins of individuals has many applications. Recently, we have seen a plethora of research efforts that tackle these applications. However, research progress in this field is limited by a lack of large and representative datasets. The largest and most commonly used dataset of individual human trajectories captures fewer than 200 individuals, while datasets of individual human check-ins capture fewer than 100 check-ins per city per day. Thus, it is not clear if findings from the human mobility data science community would generalize to large populations. Since obtaining massive, representative, and individual-level human mobility data is hard to come by due to privacy considerations, the vision of this work is to embrace the use of data generated by large-scale socially realistic microsimulations. Informed by both real data and leveraging social and behavioral …"
Joon-Seok Kim,Proceedings of the 3rd ACM SIGSPATIAL International Workshop on GeoSpatial Simulation,2020,https://dl.acm.org/doi/abs/10.1145/3423335,"Geosimulations using computer simulation models provide researchers with an effective way of analyzing complex geographic phenomena and their outcomes. This analysis is crucial in our understanding of complex spatial systems such as ecosystems, transportation, weather/climate, cities and landscapes that we interact with and influence on a daily basis. As computing technology continues to advance and become more widely available, we envision techniques for spatial data collection, management and analysis will benefit researchers, practitioners and users alike. Likewise, new global challenges like the ongoing COVID-19 pandemic will require the research community to continue to develop new simulation models and techniques to analyze such phenomena. While simulations in the past have tended to rely on closed-world assumptions, we believe, to address emerging challenges there is a need to …"
Joon-Seok Kim,The Patterns of Life Human Mobility Simulation,2024,https://dl.acm.org/doi/abs/10.1145/3678717.3691319,"We demonstrate the Patterns of Life Simulation to create realistic simulations of human mobility in a city. This simulation has recently been used to generate massive amounts of trajectory and check-in data. Our demonstration focuses on using the simulation twofold: (1) using the graphical user interface (GUI), and (2) running the simulation headless by disabling the GUI for faster data generation. We further demonstrate how the Patterns of Life simulation can be used to simulate any region on Earth by using publicly available data from OpenStreetMap. Finally, we also demonstrate recent improvements to the scalability of the simulation allows simulating up to 100,000 individual agents for years of simulation time. During our demonstration, as well as offline using our guides on GitHub, participants will learn: (1) The theories of human behavior driving the Patters of Life simulation, (2) how to simulate to generate …"
Joon-Seok Kim,Humonet: A framework for realistic modeling and simulation of human mobility network,2024,https://ieeexplore.ieee.org/abstract/document/10591691/,"Understanding, analyzing, and predicting human mobility and dynamics are valuable to solving pressing problems, developing effective plans, and prescribing timely remedies. As a computational approach, realistic human mobility simulations allow us to understand, analyze, and predict complex systems, including human societies. Accurate simulations rely on (1) the model that captures interactions and behaviors of myriad entities in our society and (2) the mapping of model instances to real-world entities. Taking this into account, this paper introduces the Human Mobility Network simulation framework (HumoNet), an integrated patterns of life (POL) simulation framework that leverages real-world data layers including transportation networks, points of interest, populations, popularity, and human trajectories. HumoNet is a data informed model in which agents are equipped with activities, locomotion, and planning …"
Joon-Seok Kim,GeoSim 2019 Workshop Report The 2nd ACM SIGSPATIAL International Workshop on Geospatial Simulation,2020,https://dl.acm.org/doi/abs/10.1145/3383653.3383661,"Space has long been acknowledged by researchers as a fundamental constraint which shapes our world. As technological changes have transformed the very concept of distance, the relative location and connectivity of geospatial phenomena have remained stubbornly significant in how systems function. At the same time, however, technology has allowed us to begin to bring tools like simulation to bear on our understanding of how such systems work. While previous generations of scientists and practitioners were unable to gather spatial data or to incorporate it into models at any meaningful scale, new methodologies and data sources are becoming increasingly available to researchers, developers, users, and practitioners. This flowering of different approaches is occurring simultaneously across many fields, and at every point in the research process."
Joon-Seok Kim,Dicer: Data intensive computing environment and runtime for evaluating unprecedented scale of geospatial-temporal human mobility data,2024,https://ieeexplore.ieee.org/abstract/document/10591690/,"With the significant increase in sources and volume of human mobility data through commercial data vendors as well as microsimulation of cities, the scale of geospatial-temporal data to analyze and assess for mobility characterization has grown to the level of Big Data. There are mobility related commercial organizations deploying scalable computing, but often the system architecture, workflow, and intermediate processing components are not fully disclosed in relevant scope. Current research literature has a notable lack of studies demonstrating architectures and workflows for human mobility analytics that are implemented on a TeraByte scale of geospatial-temporal data. In this context, this paper presents a hyperscale-level system solution named DICER (Data Intensive Computing Environment and Runtime) for processing and analytics of geospatial-temporal data at big data scale. Although the cluster …"
Joon-Seok Kim,A design of activity-based mobility intervention,2023,https://dl.acm.org/doi/abs/10.1145/3609956.3609970,"Human mobility influences our society and vice versa. During the COVID-19 pandemic, non-pharmaceutical intervention that alters activity-based mobility such as work-from-home greatly impacted human mobility patterns. Many studies on developing mitigation strategies have employed or implemented their own mobility intervention within their model assumption. For fair evaluation between intervention strategies across models, it is significant to set up compatible experimental environments. However, it is difficult to apply the identical intervention to different kinds of models and compare their effectiveness because each model might have different assumptions, capabilities, and implementations. Even if one can apply intervention to heterogeneous models, it may produce undesirable artifacts due to difference of models and integration with intervention. Therefore, minimizing undesirable artifacts and facilitating …"
Joon-Seok Kim,GeoAI for Public Health,2023,https://www.taylorfrancis.com/chapters/edit/10.1201/9781003308423-15/geoai-public-health-andreas-z%C3%BCfle-taylor-anderson-hamdi-kavak-dieter-pfoser-joon-seok-kim-amira-roess,"Infectious disease spread within the human population can be conceptualized as a complex system composed of individuals who interact and transmit viruses through spatio-temporal processes that manifest across and between scales. The complexity of this system ultimately means that the spread of infectious diseases is difficult to understand, predict, and respond to effectively. Research interest in GeoAI for public health has been fueled by the increased availability of rich data sources such as human mobility data, OpenStreetMap data, contact tracing data, symptomatic online surveys, retail and commerce data, genomics data, and more. This data availability has resulted in a wide variety of data-driven solutions for infectious disease spread prediction which show potential in enhancing our forecasting capabilities. This chapter (1) motivates the need for AI-based solutions in public health by showing the …"
Joon-Seok Kim,Towards Large-Scale Agent-Based Geospatial Simulation,2021,https://scholar.google.com/scholar?cluster=16099309276903693248&hl=en&oi=scholarr,
Joon-Seok Kim,SpatialEpi'22: Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology,2022,,
Joon-Seok Kim,Simplification of indoor space footprints,2022,https://dl.acm.org/doi/pdf/10.1145/3548732.3548739,"location of vertices of P, the problem can be categorized into (1) vertex-restricted,(2) curve-restricted, and (3) nonrestricted simplification, see van de Kerkhof et al.[2019]. The Ramer–Douglas–Peucker (RDP) algorithm [Ramer 1972, Douglas and Peucker 1973] is widely used in practice and provides a vertex-restricted approxi mation to simplify 2D polylines and polygons. However, it does not provide any quality guarantees and it may not preserve the essential shape of the entire foot print because it does not reflect a specific form (see Figure 6.1 (b)). Although Fig ure 6.1 (b) and (c) are similar in terms of the number of segments, the figure demon strates that the RDP cannot preserve spatial features such as intrusion, extrusion, offset, and corners. In geographic information science, simplification is consid ered a type of generalization process [Weibel and Dutton 1999]. These processes or operations consider not only …"
Joon-Seok Kim,Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology,2021,https://dl.acm.org/doi/abs/10.1145/3486633,"The spatial behavior of humans, plants, and animals as well as changing geographical and ecological environments play a role in the spread of diseases. In light of the COVID-19 pandemic, recent scientific efforts focus on the development of real time monitoring and response systems, modeling and simulation to predict disease outcomes under existing or hypothetical scenarios, and the analysis of spatiotemporal data to describe or explain behaviors that affect disease trajectories. In general, these efforts seek to generate or leverage spatiotemporal data to improve our understanding, prediction, and response to infectious disease outbreaks."
Joon-Seok Kim,The 3rd ACM sigspatial international workshop on geospatial simulation: geosim 2020 workshop report,2021,https://dl.acm.org/doi/abs/10.1145/3447994.3448000,"Space has long been acknowledged by researchers as a fundamental constraint which shapes our world. As technological changes have transformed the very concept of distance, the relative location and connectivity of geospatial phenomena have remained stubbornly significant in how systems function. At the same time, however, technology has advanced the science of geospatial simulation to bear on our understanding of how such systems work. While previous generations of scientists and practitioners were unable to gather spatial data or to incorporate it into models at any meaningful scale, new methodologies and data sources are becoming increasingly available to researchers, developers, users, and practitioners. These developments present new research opportunities for geospatial simulation."
Joon-Seok Kim,Vulnerable Neighborhood Explorer (Vne): An Open-Source Visual Analytics Tool for Exploring Social Vulnerability to Disasters Across Different Neighborhoods,2025,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5110503,"We developed the Vulnerable Neighborhood Explorer (VNE), a geovisual analytics tool that helps decision-makers and researchers identify disaster-prone neighborhoods using socioeconomic and demographic data. By creating neighborhood boundaries from user-provided data, VNE enables analysis of disparities in disaster impacts (eg, casualties, injuries, infections) and their socioeconomic drivers. It employs clustering algorithms and a dynamic interface with Coordinated and Multiple Views (CMV), linking maps and charts interactively. Features like cross-filtering and brushing instantly update visualizations, allowing seamless exploration of vulnerable neighborhoods and their population characteristics in specific disaster contexts."
Joon-Seok Kim,Human Mobility Challenge: Are Transformers Effective for Human Mobility Prediction?,2024,https://dl.acm.org/doi/abs/10.1145/3681771.3700130,"Transformer-based models are popular for time series forecasting and spatiotemporal prediction due to their ability to infer semantic correlations in long sequences. However, for human mobility prediction, temporal correlations, such as location patterns at the same time on previous days or weeks, are essential. While positional encodings help retain order, the self-attention mechanism causes a loss of temporal detail. To validate this claim, we used a simple approach in the 2nd ACM SIGSPATIAL Human Mobility Prediction Challenge, predicting locations based on past patterns weighted by reliability scores for missing data. Our simple approach was among the top 10 competitors and significantly outperformed the Transformer-based model that won the 2023 challenge."
Joon-Seok Kim,CyberGIS-Vis for Democratizing Access to Scalable Spatiotemporal Geovisual Analytics: A Case Study of COVID-19,2024,https://dl.acm.org/doi/abs/10.1145/3681777.3698474,"The COVID-19 pandemic underscored the critical need for effective disease mapping tools, essential for tracking infectious diseases. Following the WHO's pandemic declaration in March 2020, numerous technological solutions emerged to map cases, assess risk factors, and monitor mobility. However, there remains a shortage of reusable, open-source geovisual analytics tool for rapid response to future pandemics. To address this gap, we developed an innovative open-source JavaScript-based geovisual analytics tool as part of the CyberGIS-Vis project. This paper introduces two visualization modules of CyberGIS-Vis, showcasing their use in visualizing spatiotemporal COVID-19 data by integrating advanced cyberGIS and online visualization with robust analytics for geospatial knowledge discovery."
Joon-Seok Kim,A Visual Analytic Platform for Interactive Validation of Human Mobility Simulations,2024,https://dl.acm.org/doi/abs/10.1145/3681770.3698570,"Human mobility insights guide domain experts in an array of decisions, including critical infrastructure design, disaster response, epidemic modeling, national security, and policy making. Due to the inherent noise and privacy concerns in real-world individual-level mobility data, it is often preferred to leverage simulators that generate synthetic mobility data instead. However, it is critical to inspect and validate the output of such simulators to ensure the synthetic data is aligned with the characteristics of the population and the area of interest known to domain experts. While there exist many quantitative approaches for validating synthetic data, we argue it is also important to also validate such data qualitatively to capture aspects that are known to domain experts but difficult to quantify. In this work, we demonstrate a visual analytic platform that empowers domain experts to interact with their simulation outputs along …"
Joon-Seok Kim,Comparative Analysis of Human Mobility Patterns: Utilizing Taxi and Mobile (SafeGraph) Data to Investigate Neighborhood-Scale Mobility in New York City,2024,https://arxiv.org/abs/2410.16462,"Numerous researchers have utilized GPS-enabled vehicle data and SafeGraph mobility data to analyze human movements. However, the comparison of their ability to capture human mobility remains unexplored. This study investigates differences in human mobility using taxi trip records and the SafeGraph dataset in New York City neighborhoods. The analysis includes neighborhood clustering to identify population characteristics and a comparative analysis of mobility patterns. Our findings show that taxi data tends to capture human mobility to and from locations such as Lower Manhattan, where taxi demand is consistently high, while often underestimating the volume of trips originating from areas with lower taxi demand, particularly in the suburbs of NYC. In contrast, SafeGraph data excels in capturing trips to and from areas where commuting by driving one's own car is common, but underestimates trips in pedestrian-heavy areas. The comparative analysis also sheds new light on transportation mode choices for trips across various neighborhoods. The results of this study underscore the importance of understanding the representativeness of human mobility big data and highlight the necessity for careful consideration when selecting the most suitable dataset for human mobility research."
Joon-Seok Kim,15 GeoAI for Public Health,2023,https://books.google.com/books?hl=en&lr=&id=liXpEAAAQBAJ&oi=fnd&pg=PA305&dq=info:j2_0afPNA1IJ:scholar.google.com&ots=CO88PfUO-9&sig=Dy0vezjMa890OMtubgurRbwcWBo,"Artificial intelligence (AI) models of infectious disease spread are critical decisionsupport systems to help explain the mechanisms of infectious disease spread, predict the number of cases and deaths, and prescribe effective policy guidelines. Ideally, by observing the spatiotemporal behavior of individuals, we can comprehend the uptake of preventative behaviors that help reduce transmission by wearing masks, reducing"
Joon-Seok Kim,SpatialEpi'2022 Workshop Report: The 3rd ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology,2023,https://dl.acm.org/doi/abs/10.1145/3632268.3632277,"Since the onset of the COVID-19 pandemic, researchers in the SIGSPATIAL community have utilized computational solutions to better explain, predict, and respond to infectious disease outbreaks. Using spatial computing for pandemic preparedness has also been highlighted as a major application of mobility data science [16]. At the beginning of the COVID-19 pandemic, the SIGSPATIAL community rapidly published ideas to improve our understanding of the spread of the virus in two SIGSPATIAL Special Newsletter Issues in March and July 2020 [28, 29]. These efforts led to the 1st and 2nd ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology [5, 4] (formerly called Workshop on Modeling and Understanding the Spread of COVID-19 in 2020) which has provided authors of these newsletter articles a forum to present and discuss their solutions. Including both work published at the …"
Joon-Seok Kim,GeoSim 2022 Workshop Report: The 5th ACM SIGSPATIAL International Workshop on Geospatial Simulation,2023,https://dl.acm.org/doi/abs/10.1145/3632268.3632280,"Geospatial simulation is an effective tool to experience physical and/or cyber space (e.g., metaverse). New experiences gained from geospatial simulations can bring significant benefits including situation awareness, insight into environments, and entertainment. To take advantage of such simulations, it is crucial to advance methodology of modeling and simulation, develop plausible models and apply them to domains, leveraging big data and evolving technologies."
Joon-Seok Kim,GeoSim 2021 Workshop Report: The 4th ACM SIGSPATIAL International Workshop on Geospatial Simulation,2022,https://dl.acm.org/doi/abs/10.1145/3578484.3578487,"Geospatial simulation is an effective tool to experience physical and/or cyber space (e.g., metaverse). New experiences gained from geospatial simulations can bring significant benefits including situation awareness, insight into environments, and entertainment. To take advantage of such simulations, it is crucial to advance methodology of modeling and simulation, develop plausible models and apply them to domains, leveraging big data and evolving technologies."
Joon-Seok Kim,GeoSim'22: Proceedings of the 5th ACM SIGSPATIAL International Workshop on GeoSpatial Simulation,2022,,
Joon-Seok Kim,GeoSim'21: Proceedings of the 4th ACM SIGSPATIAL International Workshop on GeoSpatial Simulation,2021,,
Fei Liu,Self-Attention Network for Skeleton-based Human Action Recognition,2020,http://openaccess.thecvf.com/content_WACV_2020/html/Cho_Self-Attention_Network_for_Skeleton-based_Human_Action_Recognition_WACV_2020_paper.html,"Skeleton-based action recognition has recently attracted a lot of attention. Researchers are coming up with new approaches for extracting spatio-temporal relations and making considerable progress on large-scale skeleton based datasets. Most of the architectures being proposed are based upon recurrent neural networks (RNNs), convolutional neural networks (CNNs) and graph-based CNNs. When it comes to skeleton-based action recognition, the importance of long term contextual information is central which is not captured by the current architectures. In order to come up with a better representation and capturing of long term spatio-temporal relationships, we propose three variants of Self-Attention Network (SAN), namely, SAN-V1, SAN-V2 and SAN-V3. Our SAN variants has the impressive capability of extracting high-level semantics by capturing long-range correlations. We have also integrated the Temporal Segment Network (TSN) with our SAN variants which resulted in improved overall performance. Different configurations of Self-Attention Network (SAN) variants and Temporal Segment Network (TSN) are explored with extensive experiments. Our chosen configuration outperforms state-of-the-art Top-1 and Top-5 by 4.4% and 2.9% respectively on Kinetics and shows consistently better performance than state-of-the-art methods on NTU RGB+ D."
Fei Liu,InFoBench: Evaluating Instruction Following Ability in Large Language Models,2024,https://arxiv.org/abs/2401.03601,"This paper introduces the Decomposed Requirements Following Ratio (DRFR), a new metric for evaluating Large Language Models' (LLMs) ability to follow instructions. Addressing a gap in current methodologies, DRFR breaks down complex instructions into simpler criteria, facilitating a detailed analysis of LLMs' compliance with various aspects of tasks. Alongside this metric, we present InFoBench, a benchmark comprising 500 diverse instructions and 2,250 decomposed questions across multiple constraint categories. Our experiments compare DRFR with traditional scoring methods and explore annotation sources, including human experts, crowd-sourced workers, and GPT-4. The findings demonstrate DRFR's higher reliability and the effectiveness of using GPT-4 as a cost-efficient annotator. The evaluation of several advanced LLMs using this framework reveals their strengths and areas needing improvement, particularly in complex instruction-following. This study contributes a novel metric and benchmark, offering insights for future LLM development and evaluation."
Fei Liu,Controlling the Amount of Verbatim Copying in Abstractive Summarization,2020,https://ojs.aaai.org/index.php/AAAI/article/view/6420,"An abstract must not change the meaning of the original text. A single most effective way to achieve that is to increase the amount of copying while still allowing for text abstraction. Human editors can usually exercise control over copying, resulting in summaries that are more extractive than abstractive, or vice versa. However, it remains poorly understood whether modern neural abstractive summarizers can provide the same flexibility, ie, learning from single reference summaries to generate multiple summary hypotheses with varying degrees of copying. In this paper, we present a neural summarization model that, by learning from single human abstracts, can produce a broad spectrum of summaries ranging from purely extractive to highly generative ones. We frame the task of summarization as language modeling and exploit alternative mechanisms to generate summary hypotheses. Our method allows for control over copying during both training and decoding stages of a neural summarization model. Through extensive experiments we illustrate the significance of our proposed method on controlling the amount of verbatim copying and achieve competitive results over strong baselines. Our analysis further reveals interesting and unobvious facts."
Fei Liu,MeetingBank: A Benchmark Dataset for Meeting Summarization,2023,https://arxiv.org/abs/2305.17529,"As the number of recorded meetings increases, it becomes increasingly important to utilize summarization technology to create useful summaries of these recordings. However, there is a crucial lack of annotated meeting corpora for developing this technology, as it can be hard to collect meetings, especially when the topics discussed are confidential. Furthermore, meeting summaries written by experienced writers are scarce, making it hard for abstractive summarizers to produce sensible output without a reliable reference. This lack of annotated corpora has hindered the development of meeting summarization technology. In this paper, we present MeetingBank, a new benchmark dataset of city council meetings over the past decade. MeetingBank is unique among other meeting corpora due to its divide-and-conquer approach, which involves dividing professionally written meeting minutes into shorter passages and aligning them with specific segments of the meeting. This breaks down the process of summarizing a lengthy meeting into smaller, more manageable tasks. The dataset provides a new testbed of various meeting summarization systems and also allows the public to gain insight into how council decisions are made. We make the collection, including meeting video links, transcripts, reference summaries, agenda, and other metadata, publicly available to facilitate the development of better meeting summarization techniques. Our dataset can be accessed at: https://meetingbank.github.io"
Fei Liu,How Domain Terminology Affects Meeting Summarization Performance,2020,https://arxiv.org/abs/2011.00692,"Meetings are essential to modern organizations. Numerous meetings are held and recorded daily, more than can ever be comprehended. A meeting summarization system that identifies salient utterances from the transcripts to automatically generate meeting minutes can help. It empowers users to rapidly search and sift through large meeting collections. To date, the impact of domain terminology on the performance of meeting summarization remains understudied, despite that meetings are rich with domain knowledge. In this paper, we create gold-standard annotations for domain terminology on a sizable meeting corpus; they are known as jargon terms. We then analyze the performance of a meeting summarization system with and without jargon terms. Our findings reveal that domain terminology can have a substantial impact on summarization performance. We publicly release all domain terminology to advance research in meeting summarization."
Fei Liu,Toward Unifying Text Segmentation and Long Document Summarization,2022,https://arxiv.org/abs/2210.16422,"Text segmentation is important for signaling a document's structure. Without segmenting a long document into topically coherent sections, it is difficult for readers to comprehend the text, let alone find important information. The problem is only exacerbated by a lack of segmentation in transcripts of audio/video recordings. In this paper, we explore the role that section segmentation plays in extractive summarization of written and spoken documents. Our approach learns robust sentence representations by performing summarization and segmentation simultaneously, which is further enhanced by an optimization-based regularizer to promote selection of diverse summary sentences. We conduct experiments on multiple datasets ranging from scientific articles to spoken transcripts to evaluate the model's performance. Our findings suggest that the model can not only achieve state-of-the-art performance on publicly available benchmarks, but demonstrate better cross-genre transferability when equipped with text segmentation. We perform a series of analyses to quantify the impact of section segmentation on summarizing written and spoken documents of substantial length and complexity."
Fei Liu,BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models,2024,https://arxiv.org/abs/2406.00083,"Large Language Models (LLMs) are constrained by outdated information and a tendency to generate incorrect data, commonly referred to as ""hallucinations."" Retrieval-Augmented Generation (RAG) addresses these limitations by combining the strengths of retrieval-based methods and generative models. This approach involves retrieving relevant information from a large, up-to-date dataset and using it to enhance the generation process, leading to more accurate and contextually appropriate responses. Despite its benefits, RAG introduces a new attack surface for LLMs, particularly because RAG databases are often sourced from public data, such as the web. In this paper, we propose \TrojRAG{} to identify the vulnerabilities and attacks on retrieval parts (RAG database) and their indirect attacks on generative parts (LLMs). Specifically, we identify that poisoning several customized content passages could achieve a retrieval backdoor, where the retrieval works well for clean queries but always returns customized poisoned adversarial queries. Triggers and poisoned passages can be highly customized to implement various attacks. For example, a trigger could be a semantic group like ""The Republican Party, Donald Trump, etc."" Adversarial passages can be tailored to different contents, not only linked to the triggers but also used to indirectly attack generative LLMs without modifying them. These attacks can include denial-of-service attacks on RAG and semantic steering attacks on LLM generations conditioned by the triggers. Our experiments demonstrate that by just poisoning 10 adversarial passages can induce 98.2\% success rate to retrieve …"
Fei Liu,StreamHover: Livestream Transcript Summarization and Annotation,2021,https://arxiv.org/abs/2109.05160,"With the explosive growth of livestream broadcasting, there is an urgent need for new summarization technology that enables us to create a preview of streamed content and tap into this wealth of knowledge. However, the problem is nontrivial due to the informal nature of spoken language. Further, there has been a shortage of annotated datasets that are necessary for transcript summarization. In this paper, we present StreamHover, a framework for annotating and summarizing livestream transcripts. With a total of over 500 hours of videos annotated with both extractive and abstractive summaries, our benchmark dataset is significantly larger than currently existing annotated corpora. We explore a neural extractive summarization model that leverages vector-quantized variational autoencoder to learn latent vector representations of spoken utterances and identify salient utterances from the transcripts to form summaries. We show that our model generalizes better and improves performance over strong baselines. The results of this study provide an avenue for future research to improve summarization solutions for efficient browsing of livestreams."
Fei Liu,CATE: Computation-aware Neural Architecture Encoding with Transformers,2021,http://proceedings.mlr.press/v139/yan21c.html,"Recent works (White et al., 2020a; Yan et al., 2020) demonstrate the importance of architecture encodings in Neural Architecture Search (NAS). These encodings encode either structure or computation information of the neural architectures. Compared to structure-aware encodings, computation-aware encodings map architectures with similar accuracies to the same region, which improves the downstream architecture search performance (Zhang et al., 2019; White et al., 2020a). In this work, we introduce a Computation-Aware Transformer-based Encoding method called CATE. Different from existing computation-aware encodings based on fixed transformation (eg path encoding), CATE employs a pairwise pre-training scheme to learn computation-aware encodings using Transformers with cross-attention. Such learned encodings contain dense and contextualized computation information of neural architectures. We compare CATE with eleven encodings under three major encoding-dependent NAS subroutines in both small and large search spaces. Our experiments show that CATE is beneficial to the downstream search, especially in the large search space. Moreover, the outside search space experiment demonstrates its superior generalization ability beyond the search space on which it was trained. Our code is available at: https://github. com/MSU-MLSys-Lab/CATE."
Fei Liu,A Sliding-Window Approach to Automatic Creation of Meeting Minutes,2021,https://arxiv.org/abs/2104.12324,"Meeting minutes record any subject matters discussed, decisions reached and actions taken at meetings. The importance of minuting cannot be overemphasized in a time when a significant number of meetings take place in the virtual space. In this paper, we present a sliding window approach to automatic generation of meeting minutes. It aims to tackle issues associated with the nature of spoken text, including lengthy transcripts and lack of document structure, which make it difficult to identify salient content to be included in the meeting minutes. Our approach combines a sliding window and a neural abstractive summarizer to navigate through the transcripts to find salient content. The approach is evaluated on transcripts of natural meeting conversations, where we compare results obtained for human transcripts and two versions of automatic transcripts and discuss how and to what extent the summarizer succeeds at capturing salient content."
Fei Liu,Understanding Points of Correspondence between Sentences for Abstractive Summarization,2020,https://arxiv.org/abs/2006.05621,"Fusing sentences containing disparate content is a remarkable human ability that helps create informative and succinct summaries. Such a simple task for humans has remained challenging for modern abstractive summarizers, substantially restricting their applicability in real-world scenarios. In this paper, we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text. The types of points of correspondence are delineated by text cohesion theory, covering pronominal and nominal referencing, repetition and beyond. We create a dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences. Our dataset bridges the gap between coreference resolution and summarization. It is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems. (https://github.com/ucfnlp/points-of-correspondence)"
Fei Liu,Joint Parsing and Generation for Abstractive Summarization,2020,https://ojs.aaai.org/index.php/AAAI/article/view/6419,"Sentences produced by abstractive summarization systems can be ungrammatical and fail to preserve the original meanings, despite being locally fluent. In this paper we propose to remedy this problem by jointly generating a sentence and its syntactic dependency parse while performing abstraction. If generating a word can introduce an erroneous relation to the summary, the behavior must be discouraged. The proposed method thus holds promise for producing grammatical sentences and encouraging the summary to stay true-to-original. Our contributions of this work are twofold. First, we present a novel neural architecture for abstractive summarization that combines a sequential decoder with a tree-based decoder in a synchronized manner to generate a summary sentence and its syntactic parse. Secondly, we describe a novel human evaluation protocol to assess if, and to what extent, a summary remains true to its original meanings. We evaluate our method on a number of summarization datasets and demonstrate competitive results against strong baselines."
Fei Liu,LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing,2024,https://arxiv.org/abs/2406.16253,"This work is motivated by two key trends. On one hand, large language models (LLMs) have shown remarkable versatility in various generative tasks such as writing, drawing, and question answering, significantly reducing the time required for many routine tasks. On the other hand, researchers, whose work is not only time-consuming but also highly expertise-demanding, face increasing challenges as they have to spend more time reading, writing, and reviewing papers. This raises the question: how can LLMs potentially assist researchers in alleviating their heavy workload? This study focuses on the topic of LLMs assist NLP Researchers, particularly examining the effectiveness of LLM in assisting paper (meta-)reviewing and its recognizability. To address this, we constructed the ReviewCritique dataset, which includes two types of information: (i) NLP papers (initial submissions rather than camera-ready) with both human-written and LLM-generated reviews, and (ii) each review comes with ""deficiency"" labels and corresponding explanations for individual segments, annotated by experts. Using ReviewCritique, this study explores two threads of research questions: (i) ""LLMs as Reviewers"", how do reviews generated by LLMs compare with those written by humans in terms of quality and distinguishability? (ii) ""LLMs as Metareviewers"", how effectively can LLMs identify potential issues, such as Deficient or unprofessional review segments, within individual paper reviews? To our knowledge, this is the first work to provide such a comprehensive analysis."
Fei Liu,Learning to Fuse Sentences with Transformers for Summarization,2020,https://arxiv.org/abs/2010.03726,"The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning. In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer's performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion."
Fei Liu,Generation of Patient After-Visit Summaries to Support Physicians,2022,https://par.nsf.gov/servlets/purl/10357249,"An after-visit summary (AVS) is a summary note given to patients after their clinical visit. It recaps what happened during their clinical visit and guides patients’ disease self-management. Studies have shown that a majority of patients found after-visit summaries useful. However, many physicians face excessive workloads and do not have time to write clear and informative summaries. In this paper, we study the problem of automatic generation of after-visit summaries and examine whether those summaries can convey the gist of clinical visits. We report our findings on a new clinical dataset that contains a large number of electronic health record (EHR) notes and their associated summaries. Our results suggest that generation of lay language after-visit summaries remains a challenging task. Crucially, we introduce a feedback mechanism that alerts physicians when an automatic summary fails to capture the important details of the clinical notes or when it contains hallucinated facts that are potentially detrimental to the summary quality. Automatic and human evaluation demonstrates the effectiveness of our approach in providing writing feedback and supporting physicians. 1"
Fei Liu,PaniniQA: Enhancing Patient Education Through Interactive Question Answering,2023,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00616/118717,"A patient portal allows discharged patients to access their personalized discharge instructions in electronic health records (EHRs). However, many patients have difficulty understanding or memorizing their discharge instructions (Zhao et al., ). In this paper, we present PaniniQA, a patient-centric interactive question answering system designed to help patients understand their discharge instructions. PaniniQA first identifies important clinical content from patients’ discharge instructions and then formulates patient-specific educational questions. In addition, PaniniQA is also equipped with answer verification functionality to provide timely feedback to correct patients’ misunderstandings. Our comprehensive automatic & human evaluation results demonstrate our PaniniQA is capable of improving patients’ mastery of their medical instructions through effective interactions."
Fei Liu,A New Approach to Overgenerating and Scoring Abstractive Summaries,2021,https://arxiv.org/abs/2104.01726,"We propose a new approach to generate multiple variants of the target summary with diverse content and varying lengths, then score and select admissible ones according to users' needs. Abstractive summarizers trained on single reference summaries may struggle to produce outputs that achieve multiple desirable properties, i.e., capturing the most important information, being faithful to the original, grammatical and fluent. In this paper, we propose a two-staged strategy to generate a diverse set of candidate summaries from the source text in stage one, then score and select admissible ones in stage two. Importantly, our generator gives a precise control over the length of the summary, which is especially well-suited when space is limited. Our selectors are designed to predict the optimal summary length and put special emphasis on faithfulness to the original text. Both stages can be effectively trained, optimized and evaluated. Our experiments on benchmark summarization datasets suggest that this paradigm can achieve state-of-the-art performance."
Fei Liu,A Cascade Approach to Neural Abstractive Summarization with Content Selection and Fusion,2020,https://arxiv.org/abs/2010.03722,"We present an empirical study in favor of a cascade architecture to neural text summarization. Summarization practices vary widely but few other than news summarization can provide a sufficient amount of training data enough to meet the requirement of end-to-end neural abstractive systems which perform content selection and surface realization jointly to generate abstracts. Such systems also pose a challenge to summarization evaluation, as they force content selection to be evaluated along with text generation, yet evaluation of the latter remains an unsolved problem. In this paper, we present empirical results showing that the performance of a cascaded pipeline that separately identifies important content pieces and stitches them together into a coherent text is comparable to or outranks that of end-to-end systems, whereas a pipeline architecture allows for flexible content selection. We finally discuss how we can take advantage of a cascaded pipeline in neural text summarization and shed light on important directions for future research."
Fei Liu,Generating User-Engaging News Headlines,2023,https://aclanthology.org/2023.acl-long.183/,"The potential choices for news article headlines are enormous, and finding the right balance between conveying the essential message and capturing the reader’s attention is key to effective headlining. However, presenting the same news headline to all readers is a suboptimal strategy, because it does not take into account the different preferences and interests of diverse readers, who may be confused about why a particular article has been recommended to them and do not see a clear connection between their interests and the recommended article. In this paper, we present a novel framework that addresses these challenges by incorporating user profiling to generate personalized headlines, and a combination of automated and human evaluation methods to determine user preference for personalized headlines. Our framework utilizes a learnable relevance function to assign personalized signature phrases to users based on their reading histories, which are then used to personalize headline generation. Through extensive evaluation, we demonstrate the effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience. Our framework has the potential to improve the efficacy of news recommendations and facilitate creation of personalized content."
Fei Liu,Automatic Summarization of Open-Domain Podcast Episodes,2020,https://arxiv.org/abs/2011.04132,"We present implementation details of our abstractive summarizers that achieve competitive results on the Podcast Summarization task of TREC 2020. A concise textual summary that captures important information is crucial for users to decide whether to listen to the podcast. Prior work focuses primarily on learning contextualized representations. Instead, we investigate several less-studied aspects of neural abstractive summarization, including (i) the importance of selecting important segments from transcripts to serve as input to the summarizer; (ii) striking a balance between the amount and quality of training instances; (iii) the appropriate summary length and start/end points. We highlight the design considerations behind our system and offer key insights into the strengths and weaknesses of neural abstractive systems. Our results suggest that identifying important segments from transcripts to use as input to an abstractive summarizer is advantageous for summarizing long documents. Our best system achieves a quality rating of 1.559 judged by NIST evaluators---an absolute increase of 0.268 (+21%) over the creator descriptions."
Fei Liu,DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4,2023,https://arxiv.org/abs/2305.14702,"Human preference judgments are pivotal in guiding large language models (LLMs) to produce outputs that align with human values. Human evaluations are also used in summarization tasks to compare outputs from various systems, complementing existing automatic metrics. Despite their significance, however, there has been limited research probing these pairwise or -wise comparisons. The collective impact and relative importance of factors such as output length, informativeness, fluency, and factual consistency are still not well understood. It is also unclear if there are other hidden factors influencing human judgments. In this paper, we conduct an in-depth examination of a collection of pairwise human judgments released by OpenAI. Utilizing the Bradley-Terry-Luce (BTL) model, we reveal the inherent preferences embedded in these human judgments. We find that the most favored factors vary across tasks and genres, whereas the least favored factors tend to be consistent, e.g., outputs are too brief, contain excessive off-focus content or hallucinated facts. Our findings have implications on the construction of balanced datasets in human preference evaluations, which is a crucial step in shaping the behaviors of future LLMs."
Fei Liu,Better Highlighting: Creating Sub-Sentence Summary Highlights,2020,https://arxiv.org/abs/2010.10566,"Amongst the best means to summarize is highlighting. In this paper, we aim to generate summary highlights to be overlaid on the original documents to make it easier for readers to sift through a large amount of text. The method allows summaries to be understood in context to prevent a summarizer from distorting the original meaning, of which abstractive summarizers usually fall short. In particular, we present a new method to produce self-contained highlights that are understandable on their own to avoid confusion. Our method combines determinantal point processes and deep contextualized representations to identify an optimal set of sub-sentence segments that are both important and non-redundant to form summary highlights. To demonstrate the flexibility and modeling power of our method, we conduct extensive experiments on summarization datasets. Our analysis provides evidence that highlighting is a promising avenue of research towards future summarization."
Fei Liu,Towards Abstractive Grounded Summarization of Podcast Transcripts,2022,https://arxiv.org/abs/2203.11425,"Podcasts have recently shown a rapid rise in popularity. Summarization of podcast transcripts is of practical benefit to both content providers and consumers. It helps consumers to quickly decide whether they will listen to the podcasts and reduces the cognitive load of content providers to write summaries. Nevertheless, podcast summarization faces significant challenges including factual inconsistencies with respect to the inputs. The problem is exacerbated by speech disfluencies and recognition errors in transcripts of spoken language. In this paper, we explore a novel abstractive summarization method to alleviate these challenges. Specifically, our approach learns to produce an abstractive summary while grounding summary segments in specific portions of the transcript to allow for full inspection of summary details. We conduct a series of analyses of the proposed approach on a large podcast dataset and show that the approach can achieve promising results. Grounded summaries bring clear benefits in locating the summary and transcript segments that contain inconsistent information, and hence significantly improve summarization quality in both automatic and human evaluation metrics."
Fei Liu,Learning as Conversation: Dialogue Systems Reinforced for Information Acquisition,2022,https://arxiv.org/abs/2205.14748,"We propose novel AI-empowered chat bots for learning as conversation where a user does not read a passage but gains information and knowledge through conversation with a teacher bot. Our information-acquisition-oriented dialogue system employs a novel adaptation of reinforced self-play so that the system can be transferred to various domains without in-domain dialogue data, and can carry out conversations both informative and attentive to users. Our extensive subjective and objective evaluations on three large public data corpora demonstrate the effectiveness of our system to deliver knowledge-intensive and attentive conversations and help end users substantially gain knowledge without reading passages. Our code and datasets are publicly available for follow-up research."
Fei Liu,SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs,2024,https://arxiv.org/abs/2402.10979,"Large language models hold significant potential for integrating various data types, such as text documents and database records, for advanced analytics. However, blending text and numerical data presents substantial challenges. LLMs need to process and cross-reference entities and numbers, handle data inconsistencies and redundancies, and develop planning capabilities such as building a working memory for managing complex data queries. In this paper, we introduce four novel tasks centered around sports data analytics to evaluate the numerical reasoning and information fusion capabilities of LLMs. These tasks involve providing LLMs with detailed, play-by-play sports game descriptions, then challenging them with adversarial scenarios such as new game rules, longer durations, scrambled narratives, and analyzing key statistics in game summaries. We conduct extensive experiments on NBA and NFL games to assess the performance of LLMs on these tasks. Our benchmark, SportsMetrics, introduces a new mechanism for assessing LLMs' numerical reasoning and fusion skills."
Fei Liu,Modeling Endorsement for Multi-Document Abstractive Summarization,2021,https://arxiv.org/abs/2110.07844,"A crucial difference between single- and multi-document summarization is how salient content manifests itself in the document(s). While such content may appear at the beginning of a single document, essential information is frequently reiterated in a set of documents related to a particular topic, resulting in an endorsement effect that increases information salience. In this paper, we model the cross-document endorsement effect and its utilization in multiple document summarization. Our method generates a synopsis from each document, which serves as an endorser to identify salient content from other documents. Strongly endorsed text segments are used to enrich a neural encoder-decoder model to consolidate them into an abstractive summary. The method has a great potential to learn from fewer examples to identify salient content, which alleviates the need for costly retraining when the set of documents is dynamically adjusted. Through extensive experiments on benchmark multi-document summarization datasets, we demonstrate the effectiveness of our proposed method over strong published baselines. Finally, we shed light on future research directions and discuss broader challenges of this task using a case study."
Fei Liu,Identifying Factual Inconsistency in Summaries: Towards Effective Utilization of Large Language Model,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240212821X/abstract,"Factual inconsistency poses a significant hurdle for the commercial deployment of abstractive summarizers. Under this Large Language Model (LLM) era, this work focuses around two important questions: what is the best way to leverage LLM for factual inconsistency detection, and how could we distill a smaller LLM with both high efficiency and efficacy? Three zero-shot paradigms are firstly proposed and evaluated across five diverse datasets: direct inference on the entire summary or each summary window; entity verification through question generation and answering. Experiments suggest that LLM itself is capable to resolve this task train-free under the proper paradigm design, surpassing strong trained baselines by 2.8% on average. To further promote practical utility, we then propose training strategies aimed at distilling smaller open-source LLM that learns to score the entire summary at once with high …"
Fei Liu,Define: Enhancing llm decision-making with factor profiles and analogical reasoning,2024,https://arxiv.org/abs/2410.01772,"LLMs are ideal for decision-making due to their ability to reason over long contexts and identify critical factors. However, challenges arise when processing transcripts of spoken speech describing complex scenarios. These transcripts often contain ungrammatical or incomplete sentences, repetitions, hedging, and vagueness. For example, during a company's earnings call, an executive might project a positive revenue outlook to reassure investors, despite significant uncertainty regarding future earnings. It is crucial for LLMs to incorporate this uncertainty systematically when making decisions. In this paper, we introduce DeFine, a new framework that constructs probabilistic factor profiles from complex scenarios. DeFine then integrates these profiles with analogical reasoning, leveraging insights from similar past experiences to guide LLMs in making critical decisions in novel situations. Our framework separates the tasks of quantifying uncertainty in complex scenarios and incorporating it into LLM decision-making. This approach is particularly useful in fields such as medical consultations, negotiations, and political debates, where making decisions under uncertainty is vital."
Fei Liu,RRescue: Ranking LLM Responses with Partial Ordering to Improve Response Generation,2024,https://arxiv.org/abs/2311.09136,"Customizing LLMs for a specific task involves separating high-quality responses from lower-quality ones. This skill can be developed using supervised fine-tuning with extensive human preference data. However, obtaining a large volume of expert-annotated data is costly for most tasks. In this paper, we explore a novel method to optimize LLMs using ranking metrics. This method trains the model to prioritize the best responses from a pool of candidates created for a particular task. Rather than a traditional full ordering, we advocate for a partial ordering, as achieving consensus on the perfect order of candidate responses can be challenging. Our partial ordering is more robust, less sensitive to noise, and can be achieved with limited human annotations or through heuristic methods. We test our system's improved response generation ability using benchmark datasets, including textual entailment and multi-document question answering. We conduct ablation studies to understand crucial factors, such as how to gather candidate responses for a specific task, determine their most suitable order, and balance supervised fine-tuning with ranking metrics. Our approach, named Rescue, offers a promising avenue for enhancing the response generation and task accuracy of LLMs."
Fei Liu,When Reasoning Meets Information Aggregation: A Case Study with Sports Narratives,2024,https://arxiv.org/abs/2406.12084,"Reasoning is most powerful when an LLM accurately aggregates relevant information. We examine the critical role of information aggregation in reasoning by requiring the LLM to analyze sports narratives. To succeed at this task, an LLM must infer points from actions, identify related entities, attribute points accurately to players and teams, and compile key statistics to draw conclusions. We conduct comprehensive experiments with real NBA basketball data and present SportsGen, a new method to synthesize game narratives. By synthesizing data, we can rigorously evaluate LLMs' reasoning capabilities under complex scenarios with varying narrative lengths and density of information. Our findings show that most models, including GPT-4o, often fail to accurately aggregate basketball scores due to frequent scoring patterns. Open-source models like Llama-3 further suffer from significant score hallucinations. Finally, the effectiveness of reasoning is influenced by narrative complexity, information density, and domain-specific terms, highlighting the challenges in analytical reasoning tasks."
Fei Liu,STRUX: An LLM for Decision-Making with Structured Explanations,2024,https://arxiv.org/abs/2410.12583,"Countless decisions shape our daily lives, and it is paramount to understand the how and why behind these choices. In this paper, we introduce a new LLM decision-making framework called STRUX, which enhances LLM decision-making by providing structured explanations. These include favorable and adverse facts related to the decision, along with their respective strengths. STRUX begins by distilling lengthy information into a concise table of key facts. It then employs a series of self-reflection steps to determine which of these facts are pivotal, categorizing them as either favorable or adverse in relation to a specific decision. Lastly, we fine-tune an LLM to identify and prioritize these key facts to optimize decision-making. STRUX has been evaluated on the challenging task of forecasting stock investment decisions based on earnings call transcripts and demonstrated superior performance against strong baselines. It enhances decision transparency by allowing users to understand the impact of different factors, representing a meaningful step towards practical decision-making with LLMs."
Fei Liu,Generating Coherent Narratives with Subtopic Planning to Answer How-to Questions,2022,https://aclanthology.org/2022.gem-1.3/,"Answering how-to questions remains a major challenge in question answering research. A vast number of narrow, long-tail questions cannot be readily answered using a search engine. Moreover, there is little to no annotated data available to develop such systems. This paper makes a first attempt at generating coherent, long-form answers for how-to questions. We propose new architectures, consisting of passage retrieval, subtopic planning and narrative generation, to consolidate multiple relevant passages into a coherent, explanatory answer. Our subtopic planning module aims to produce a set of relevant, diverse subtopics that serve as the backbone for answer generation to improve topic coherence. We present extensive experiments on a WikiHow dataset repurposed for long-form question answering. Empirical results demonstrate that generating narratives to answer how-to questions is a challenging task. Nevertheless, our architecture incorporated with subtopic planning can produce high-quality, diverse narratives evaluated using automatic metrics and human assessment."
Fei Liu,PlanGenLLMs: A Modern Survey of LLM Planning Capabilities,2025,https://arxiv.org/abs/2502.11221,"LLMs have immense potential for generating plans, transforming an initial world state into a desired goal state. A large body of research has explored the use of LLMs for various planning tasks, from web navigation to travel planning and database querying. However, many of these systems are tailored to specific problems, making it challenging to compare them or determine the best approach for new tasks. There is also a lack of clear and consistent evaluation criteria. Our survey aims to offer a comprehensive overview of current LLM planners to fill this gap. It builds on foundational work by Kartam and Wilkins (1990) and examines six key performance criteria: completeness, executability, optimality, representation, generalization, and efficiency. For each, we provide a thorough analysis of representative works and highlight their strengths and weaknesses. Our paper also identifies crucial future directions, making it a valuable resource for both practitioners and newcomers interested in leveraging LLM planning to support agentic workflows."
Fei Liu,Semantic Parsing of Brief and Multi-Intent Natural Language Utterances,2021,https://aclanthology.org/2021.adaptnlp-1.25/,"Many military communication domains involve rapidly conveying situation awareness with few words. Converting natural language utterances to logical forms in these domains is challenging, as these utterances are brief and contain multiple intents. In this paper, we present a first effort toward building a weakly-supervised semantic parser to transform brief, multi-intent natural utterances into logical forms. Our findings suggest a new “projection and reduction” method that iteratively performs projection from natural to canonical utterances followed by reduction of natural utterances is the most effective. We conduct extensive experiments on two military and a general-domain dataset and provide a new baseline for future research toward accurate parsing of multi-intent utterances."
Fei Liu,HARBOR: Exploring Persona Dynamics in Multi-Agent Competition,2025,https://arxiv.org/abs/2502.12149,"We investigate factors contributing to LLM agents' success in competitive multi-agent environments, using auctions as a testbed where agents bid to maximize profit. The agents are equipped with bidding domain knowledge, distinct personas that reflect item preferences, and a memory of auction history. Our work extends the classic auction scenario by creating a realistic environment where multiple agents bid on houses, weighing aspects such as size, location, and budget to secure the most desirable homes at the lowest prices. Particularly, we investigate three key questions: (a) How does a persona influence an agent's behavior in a competitive setting? (b) Can an agent effectively profile its competitors' behavior during auctions? (c) How can persona profiling be leveraged to create an advantage using strategies such as theory of mind? Through a series of experiments, we analyze the behaviors of LLM agents and shed light on new findings. Our testbed, called HARBOR, offers a valuable platform for deepening our understanding of multi-agent workflows in competitive environments."
Fei Liu,Proceedings of the 4th New Frontiers in Summarization Workshop (EMNLP 2023),2023,https://par.nsf.gov/servlets/purl/10510733,"The development of intelligent systems capable of producing concise, fluent, and accurate summaries is a longstanding objective in natural language processing. This workshop serves as a forum for the exchange of ideas towards achieving this aim. It brings together experts from various disciplines, including summarization, language generation, and cognitive and psycholinguistics, to discuss key issues in automatic summarization. The agenda covers a wide array of topics, such as innovative paradigms and frameworks, multilingual and cross-lingual setups, shared tasks, information integration, novel evaluation methods, applied research, and future research directions. The workshop is aimed at fostering a cohesive research community, expediting the transfer of knowledge, and developing new tools, datasets, and resources to meet the needs of academia, industry, and government.This fourth edition of the workshop, following our previous workshops at EMNLP 2017, EMNLP 2019, and EMNLP 2021, received 31 paper submissions, with acceptance rates of 42%. We are honored to host five distinguished speakers: Kathleen McKeown (Columbia University), Jackie Cheung (McGill University), Rui Zhang (Penn State University), Iz Beltagy (AI2), Chenguang Zhu (Zoom), who collectively represent a wide spectrum of expertise in summarization and text generation fields. We extend our gratitude to these speakers, as well as to our program committee members and workshop attendees."
Fei Liu,Proceedings of the Third Workshop on New Frontiers in Summarization,2021,https://aclanthology.org/2021.newsum-1.0.pdf,"Developing intelligent systems which can produce concise, fluent, and accurate summaries has been a long-standing goal in natural language processing. The aim of this workshop is to provide a research forum for cross-fertilization of ideas towards this goal. We seek to bring together researchers from a diverse range of fields (eg, summarization, language generation, cognitive and psycholinguistics) for discussions on key issues related to automatic summarization. This includes discussion on novel paradigms/frameworks, multilingual and cross-lingual setups, shared tasks of interest, information integration and presentation, new evaluation protocols, applied research and applications, and possible future research foci. The workshop aims to pave the way towards building a cohesive research community, accelerating knowledge diffusion, developing new tools, datasets, and resources that are in line with the needs of academia, industry, and government. This is the third edition of the workshop, following our previous workshops at EMNLP 2017 and EMNLP 2019. The workshop received 18 long paper submissions, of which 9 were accepted, and 14 short paper submissions, of which 7 were accepted. This resulted in an overall acceptance rate of 50%. We are pleased to have three invited speakers at this year’s workshop: Asli Celikyilmaz (Facebook AI Research), Sebastian Gehrmann (Google Research), and Shashi Narayan (Google Research). Together, they cover a broad spectrum of work in summarization and adjacent areas. We would like to thank our invited speakers, as well as our programme committee members and workshop …"
Yolanda Rankin,The intersectional experiences of Black women in computing,2020,https://dl.acm.org/doi/abs/10.1145/3328778.3366873,"Efforts to broaden participation in computing have led to gender-focused interventions intended to increase the number of women in the field of computing. However, such efforts have failed to significantly increase the percentage of Black women in computing. For example, only 1% of the 28,884 bachelor\textquotesingle s degrees in computing were awarded to Black women in 2018. Moreover, too few empirical studies have intentionally explored the lived experiences of Black women, an often overlooked and understudied population in the computing ecosystem. In this paper, we introduce intersectionality - the complex overlap of socially constructed identities such as race, gender, class, sexuality, etc. - as a theoretical framework and springboard for exploring the lived experiences of Black women in computing. We interview 14 Black women in various stages of the computing ecosystem (undergraduate students …"
Yolanda Rankin,I can't breathe: Reflections from Black women in CSCW and HCI,2021,https://dl.acm.org/doi/abs/10.1145/3432933,"In this paper, three Black women in HCI and CSCW share their experiences of being Black women academics enduring a global pandemic that is disportionately impacting the Black community while simultaneously experiencing the civil unrest due to racial injustice and police brutality. Using Black feminist epistemologies as a theoretical framework and auto-ethnography and testimonial authority as both methodology and epistemic resistance, the authors exercise epistemic agency to testify to their lived intersectional experiences and the various fronts on which they fight to be seen, to be heard, and to live. Additionally, they advocate for more inclusionary policies of Black women and other marginalized populations within the CSCW and HCI communities. We conclude with a call to action for both communities to: 1) stand in solidarity with Blacks in computing; and 2) acknowledge, disavow, and dismantle Whiteness …"
Yolanda Rankin,"Black women speak: Examining power, privilege, and identity in CS education",2021,https://dl.acm.org/doi/abs/10.1145/3451344,"Despite the increasing number of women receiving bachelor’s degrees in computing (i.e., Computer Science, Computer Engineering, Information Technology, etc.), a closer look reveals that the percentage of Black women in computing has significantly dropped in recent years, highlighting the underrepresentation of Black women and its negative impact on broadening participation in the field of computing. The literature reveals that several K-16 interventions have been designed to increase the representation of Black women and girls in computing. Despite these best efforts, the needle seems to have barely moved in increasing the representation or the retention of Black women in computing. Instead, the primary goals have been to recruit and retain women in the CS pipeline using gender-focused efforts intended to increase the number of women who also identify as members of racialized groups. However, these …"
Yolanda Rankin,Real talk: Saturated sites of violence in CS education,2021,https://dl.acm.org/doi/abs/10.1145/3408877.3432432,"Despite numerous CS education pedagogical interventions, the pipeline of Black women in Computing has not increased, which illustrates the need to address structural issues (such as racism, sexism, power, and privilege) that impact Black women's intersectional identities. Without honest conversations about power relations within the field of Computing, one cannot expect to engender social change that equates to equity for all CS students. Leveraging intersectionality as a critical framework, we interview 18 Black women about their experiences navigating the computing education ecosystem. Intersectional analysis of Black women's experiences reveals that CS education consists of saturated sites of violence in which interconnected systems of power converge to enact oppression. Findings reveal three saturated sites of violence within CS education: 1. traditional K-12 classrooms; 2. predominantly White …"
Yolanda Rankin,"“all that you touch, you change”: Expanding the canon of speculative design towards black futuring",2022,https://dl.acm.org/doi/abs/10.1145/3491102.3502118," Traditional approaches to technology design have historically ignored Blackness in both who engages and conceptualizes future technologies. Design contributions of groups marginalized along race and class are often othered, and rarely considered the design standard. While frameworks have emerged to encourage attention to gender and social justice in design, little work has acknowledged evidence of the Black imaginary in this process. The current canon of design defines futuring and speculation as stemming from a narrow view of science fiction, one which does not include Black futurist perspectives. In this essay, we expand the canon of design by arguing that frameworks such as Afrofuturism, Afrofuturist feminism, and Black feminism be considered instrumental in design’s imagining of our future technological landscape. We contribute to the larger conversation of who gets to future in design, suggesting a …"
Yolanda Rankin,A method to the madness: Applying an intersectional analysis of structural oppression and power in HCI and design,2023,https://dl.acm.org/doi/abs/10.1145/3507695,"With increased focus on historically excluded populations, there have been recent calls for HCI research methods to more adequately acknowledge and address the historical context of racism, sexism, gendered racism, epistemic violence, classism, and so on. In this article, we utilize Black feminist epistemologies to serve as critical frameworks for understanding the historical context that reveals the interconnected systems of power that mutually influence one another to create unequal outcomes or social inequalities for different populations. Leveraging Black feminist thought (BFT) and intersectionality as critical social theories of design praxis, we introduce intersectional analysis of power—a method that enables HCI researchers, designers, and practitioners to identify and situate saturated sites of violence in a historical context and to transform the ways in which they engage with populations that have been …"
Yolanda Rankin,Intersectionality in HCI: Lost in translation,2020,https://dl.acm.org/doi/fullHtml/10.1145/3416498,"In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors"
Yolanda Rankin,A seat at the table: Black feminist thought as a critical framework for inclusive game design,2020,https://dl.acm.org/doi/abs/10.1145/3415188,"Game-based second language (L2) learning represents an ideal alternative to foreign language classroom instruction. However, despite a diverse player demographic, the design of L2 games is often not informed by players representative of marginalized populations, especially women of color (i.e., Black women). Such oversight in the design process contributes to games that perpetuate gendered and racist stereotypes, and therefore, are less appealing to women of color. In response this dilemma, we utilize Black Feminist Thought (BFT) as a critical framework to engage Black women, a marginalized and understudied population within the gaming subculture, and more broadly, the Computer Supported Cooperative Work (CSCW) community in game design. Twenty-five Black women take on multiple roles as game designers, foreign language instructor, and informants who represent both producers and …"
Yolanda Rankin,Resisting racism in tech design: centering the experiences of black youth,2021,https://dl.acm.org/doi/abs/10.1145/3449291,"Speech-based interfaces that feature conversational agents have a diverse population of users, including children. While recent HCI research has investigated child-agent interactions in the context of speech-based interfaces with rare mention of sample populations' racial makeup, scant research has examined how racially minoritized groups, in particular Black youth, interact with such technologies. Subsequently, issues of race and racism continue to be largely neglected within the HCI community, contributing to technology that marginalizes Black people. Leveraging Black feminist epistemology as a critical framework, we engage Black students in the ideation process of conversational agents as speech-based interfaces, drawing attention to how race, gender, and class influence their design choices. Our findings reveal that Black students prefer custom-designed conversational agents that are modeled after …"
Yolanda Rankin,What's race got to do with it? Engaging in race in HCI,2020,https://dl.acm.org/doi/abs/10.1145/3334480.3375156,"There is an urgent and ongoing need to engage critically with race in human-computer interaction. In this workshop, we consider two intertwining aspects: first, how HCI research and practice should engage with race; second, how the HCI community itself can become more racially inclusive and equitable. The workshop offers a safe space for HCI scholars and practitioners to discuss how their experiences with race and racism impact their research and work life. Insights from critical race theory will inform the discussion. Workshop participants will draft a set of guidelines for research and a set of recommendations for SIGCHI leadership and the CHI community."
Yolanda Rankin,A call to action for the ACM,2020,https://scholar.google.com/scholar?cluster=3061077023055144417&hl=en&oi=scholarr,
Yolanda Rankin,The role of familial influences in African American women's persistence in computing,2020,https://ieeexplore.ieee.org/abstract/document/9272503/,"Because African American women represent a vastly underrepresented population in the field of computing (i.e., 1% of bachelor's degrees awarded to African American women in 2018), multiple approaches have been utilized to increase the representation of African American women in the computing pipeline. However, strategies to recruit and retain African American women in computing emphasize mentorship in educational settings, ignoring the significance of familial influences in African American women's decision to pursue a degree in computing or how this impacts their ability to successfully navigate the computing pipeline. Furthermore, familial influences represent one form of social capital that can be leveraged to gain access to opportunities in computing. In this exploratory study, we investigate the role of family members and the family values that influence African American women's decision to pursue …"
Yolanda Rankin,Unpacking the complexities of community-led violence prevention work,2022,https://dl.acm.org/doi/abs/10.1145/3491102.3502122," With increased public scrutiny of policing and growing calls for community-based violence prevention, street outreach programs that hire residents to mediate conflicts in their neighborhoods are gaining support. To understand how street outreach workers (SOWs) use information and communication technologies (ICTs) and how they envision future ICTs that better support their work, we interviewed 25 SOWs across three organizations. Results suggest that SOWs leverage ICTs to: 1) identify and mediate conflict; 2) support collaboration and teamwork; and 3) invoke community connections and trust. SOWs posit that new ICTs could provide a seamless infrastructure for communication among SOWs and between community members, assist with training to sharpen conflict negotiation skills, and provide insight on effective conflict mediation strategies."
Yolanda Rankin,Reflecting on being black in computing,2021,https://dl.acm.org/doi/fullHtml/10.1145/3480237,"→ Sitting on the sidelines because one is not directly affected by discrimination is not sufficient, nor is diversity a transaction to be undertaken only when it is convenient or serves one’s interest.→ There is a role for each of us to build stronger, more creative, inclusive communities."
Yolanda Rankin,The choice is yours: Intersectional studies versus studies of intersectional populations in computing education research,2024,https://dl.acm.org/doi/abs/10.1145/3626252.3630942,"Despite the emergence of intersectional computing and increased scholarship that utilizes the concept of intersectionality, there is a lack of consensus about the appropriation of intersectionality as a critical framework within the computing education community. Intersectionality provides a critical lens for understanding and analyzing the complexity in human experiences that are shaped by multiple social constructs (race, gender, class, etc.) in mutually influencing ways. What lies at the heart of the matter is acknowledging the humanity of intersectional populations to create safe spaces and a sense of belonging in the computing community. However, using Eurocentric research methods when working with intersectional populations tends to further marginalize them. Calling into question the validity of Eurocentric methods, we argue for alternative ways of knowing in CS education research that affirm intersectional …"
Yolanda Rankin,Anti-racism in action: A speculative design approach to reimagining SIGCHI,2022,https://dl.acm.org/doi/abs/10.1145/3491101.3516504," In this interactive panel, a brief introduction by the panelists regarding their stances on race and HCI will be followed by breakout group discussion in which participants will be prompted to ask themselves what anti-racist actions they can take in their workplaces and in HCI work."
Yolanda Rankin,"In-game social interactions to facilitate ESL students' morphological awareness, language and literacy skills",2021,https://dl.acm.org/doi/abs/10.1145/3474706,"Video games that require players to utilize a target or second language to complete tasks have emerged as alternative pedagogical tools for Second Language Acquisition (SLA). With the exception of vocabulary acquisition, much of the prior research in game-based SLA fails to gauge students' literacy skills, specifically their morphological awareness or understanding of the smallest meaningful linguistic units (e.g., prefixes, suffixes, and roots). Given this shortcoming, we utilize a two-player online game to facilitate social interactions between Native English Speakers (NES) and English as a Second Language (ESL) students as a mechanism to generate ESL students' written output in the targeted language and draw attention to their morphological awareness. Analysis of chat logs demonstrates the game's potential to enhance ESL students' morphological awareness and other important L2 literacy skills such as …"
Yolanda Rankin,Discovering intersectionality: part 2: reclaiming our time,2021,https://dl.acm.org/doi/abs/10.1145/3468783,"In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors"
Yolanda Rankin,Building space for feminist solidarity,2022,https://dl.acm.org/doi/fullHtml/10.1145/3554759,"In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors"
Yolanda Rankin,Piecing together the next 15 years of computing education research workshop report,2022,https://dl.acm.org/doi/abs/10.1145/3478432.3499037,"The session will present an overview of findings of a recently funded NSF workshop that set out to examine the pressing issues for computing education research for the next 15 years. Based on dialogs for scholars working in this area, the workshop participants developed a series of themes and topics that they felt should become the focus of computing education research efforts for the next 15 years. Main themes that emerged and will be discussed in this session include: diversity, equity, inclusion, ethics, broadening participation, teaching, learning, K-12, research to practice, computing's connection to other fields, and computing education research disciplinary issues. The session will focus on interesting research questions from each of these areas that are ripe to be explored as well as enablers and blockers to the progress of this work."
Yolanda Rankin,Keepin'it real about race in HCI,2021,https://dl.acm.org/doi/fullHtml/10.1145/3477097,"@ INTERACTIONSMAG 28 INTERACTIONS SEPTEMBER–OCTOBER 2021 the consumption and production of cultural content. Much like critical race theory [1], the creation of zines allowed us to use counternarratives that are missing from the mainstream and that challenge the dominant assumptions. In this article, we, the Race in HCI Collective, present and analyze our zines and provide further insight to illustrate the best practices for engaging with minoritized populations. Through these efforts, we hope to facilitate the broader HCI community’s engagement with race."
Yolanda Rankin,Discovering intersectionality part I: researcher interrupted,2021,https://dl.acm.org/doi/abs/10.1145/3457869,"In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors"
Yolanda Rankin,Defining Damage-Centered Research in HCI: A Black Feminist Perspective,2024,https://dl.acm.org/doi/fullHtml/10.1145/3655007,"Yolanda Rankin, Emory University Jakita O. Thomas, Auburn University only for ourselves but also for the larger HCI community. As scholars who are members of historically excluded populations in computing, we question whether the work we do within our communities is justifiably labeled damage-centered research. To address this question, here we engage in dialogic reflection, a tenet of Black feminist thought [2], as we discuss Eve Tuck’s “Suspending Damage: A Letter to Communities”[3]. Sheena Erete: Thank you for joining me in this conversation. The three of us have engaged in community-based research with marginalized communities collectively for decades. However, a new"
Yolanda Rankin,INTech: Designing intersectional learning experiences for black girls,2023,https://dl.acm.org/doi/abs/10.1145/3575868,"In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors"
Yolanda Rankin,SIGCHI at 40: Celebrations and Aspirations,2022,https://dl.acm.org/doi/fullHtml/10.1145/3564036,"To celebrate 40 years of SIGCHI, we came together for a panel at the CHI 2022 conference. Conceived by Susan Dray and moderated by Andrew Kun, the panel sought to inspire the SIGCHI community. The panelists—Elizabeth Churchill, Tamara L. Clegg, Jonathan Grudin, Kristina Höök, Daria Loi, Yolanda Rankin, Elizabeth Rosenzweig, and Kentaro Toyama—represented a diverse set of backgrounds and career stages. Andrew prompted them to reflect on the successes and challenges of the past 40 years and to provide provocations: What are the anticipated problems, approaches, and visions for the future of SIGCHI? Our conversation addressed the following questions:• Why do we do what we do?• What goals should we set for ourselves?• How do we reach those goals? As you read the panelists’ perspectives, we hope that you will be inspired to continue to build a strong, inclusive, and productive SIGCHI."
Yolanda Rankin,Moving from Theory to Application: Black Feminist Thought as an Intersectional Framework for Design,2024,https://dl.acm.org/doi/fullHtml/10.1145/3686258,"In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors"
Yolanda Rankin,An Ethical Imperative: Increasing the Participation of Black Women in Computer Science Education Research,2024,https://dl.acm.org/doi/abs/10.1145/3626253.3631660,"Enhanced participation of Black women in CS education research is of ethical imperative, and empowering individuals who would otherwise not be able to fully engage in this community improves the quality of research and increases our national potential to solve real-world problems. We posit that the lack of participation of Black women in CS education research is not due to a lack of interest or expertise, but instead is another example of the continued marginalization of Black women that exists throughout our society. This panel of Black women scholars will share (1) their unique experiences and perspectives as Black women in the field of CS education, (2) the barriers Black women encounter in CS education research, and (3) existing and potential support mechanisms that enable Black women to more fully engage in the CS education research community."
Yolanda Rankin,SIGCSE Board DEIA Update,2023,https://dl.acm.org/doi/abs/10.1145/3607479.3607480,"The SIGCSE board is committed to creating a welcoming, safe, and inclusive environment for all members of the SIGCSE community. As stated in our email on October 7th 2022: ""The SIGCSE Board is taking these matters very seriously and is working on specific next steps and a timeline for addressing them. We are committed to developing ways forward to ensure the safety and respect of all members of the SIGCSE community."""
Yolanda Rankin,Implementing community-based participatory design and mixed methods to capture and analyze mental models of no/low literate users,2021,https://ieeexplore.ieee.org/abstract/document/9565805/,"One of 21 Nigerian women still die from avoidable maternal death. Yet, one of the most critical intervention for safe motherhood is ensuring that women (even in the most remote areas) have access to and are well informed of antenatal and postnatal care information and services. Previous research reveals that Ilorin women depended more on each other for antenatal and postnatal care information than on skilled birth attendants. However, when designing for historically underserved populations, the adoption and scaling of the interventions can be truncated if the target population is not adequately considered and integrated into the design process. This paper describes including no/low literate users as co-designers through community based participatory design in the development process and mixed methods to analyze collected data. Our results inform best practices for developing information architecture for …"
Yolanda Rankin,Theorizing & Researching Class for Broadening Participation in Computing Efforts,2025,https://dl.acm.org/doi/abs/10.1145/3641555.3704718,"Race and gender are crucial concepts in the computer science (CS) education research community's broadening participation efforts and scholarship. They help to critique the ways that white supremacy, anti-Blackness, and patriarchy structure and discipline CS classrooms and workplaces. In addition, attention to race and gender has helped to reimagine and redesign CS education to be more culturally responsive and sustaining for marginalized students. This panel builds on these foundational efforts by starting a conversation about what a more intentional focus on the concept of class and its connections to political economy can offer researchers and educators who are committed to more race and gender inclusivity, diversity, and equity in CS education across primary, secondary, and post-secondary levels. What might the concept introduce into intersectional analyses of the exclusionary structures of the …"
Yolanda Rankin,Sister Circles: An Intersectional Method in Computing Education,2025,https://dl.acm.org/doi/abs/10.1145/3641554.3701944,"Recent scholarship reveals that Black women who live at the intersection of race and gender are having a very different experience in computing education. For example, Black women testify to incidents of gendered racism in K-16 education, and in some cases, choose to leave the field of computing altogether. Additionally, the use of Eurocentric methodologies and tools that position intersectional populations as objects of study rather than agents of knowledge reinforces power differentials that continue to marginalize intersectional populations in the field of computing. In contrast, we advocate for developing appropriate intersectional methods that center intersectional populations in computing education research. As proof of concept, we apply Black feminist epistemologies or Black women's ways of knowing to center the experiences of Black women, an intersectional and underrepresented population in computing …"
Yolanda Rankin,Faith to Move Mountains: Black Women in Computing Education,2025,https://dl.acm.org/doi/abs/10.1145/3641554.3701954,"One of the challenges of broadening participation in computing lies in acknowledging that white supremacy and racism have created racial disparities in the K-12 education system in the United States. For example, Black rural communities in the southeastern region of the United States often lack access to CS education compared to privileged white rural communities in the same area. However, Emmanuel, a faith-based organization situated in a rural Black community, serves as a beacon of hope, seeking to address the racial and class disparities that contribute to social inequalities that continue to marginalize K-12 Black students. Emmanuel, the manifestation of Black leadership, Black culture, and Black spirituality, provides a variety of supplemental programs to address the spiritual, social, and educational needs of its constituents. In this experience report, we leverage Black feminist thought to demonstrate how …"
Yolanda Rankin,A Powerful Sisterhood: Black Women Scholars in Feminist HCI,2025,https://dl.acm.org/doi/fullHtml/10.1145/3705739,"In this forum we explore different perspectives for how to apply intersectionality as a critical framework for design across multiple contexts. --- Yolanda A. Rankin and Jakita O. Thomas, Editors"
Yolanda Rankin,"Navigating Tensions, Managing Conflict, and Reaching Academic Harmony in HCI",2024,https://dl.acm.org/doi/abs/10.1145/3678884.3689130,"With the growth of the fields of HCI and CSCW, researchers are increasingly applying new and existing methodologies, epistemologies, and theories. These varying approaches have led to diverse perspectives that sometimes lead to tensions between researchers. In this panel, we will discuss our experiences engaging with these tensions, including how we have communicated our critiques about existing research, the field, and institutions (e.g., ACM), as well as how we have received critiques from other researchers. We will discuss the role of power (e.g., pressure from academia to publish, power differentials based on career status), methods to engage in critical yet constructive dialogue, and ways in which thoughtful approaches to resolving these conflicts can improve CSCW and HCI."
Yolanda Rankin,""" Their religion is yoga"": Understanding the Role of Spirituality for Black Women in Computing",2024,https://dl.acm.org/doi/abs/10.1145/3626253.3635594,"Research suggests that despite the growing number of Black women who intend to major in computer science, adverse experiences in hostile computing degree programs contribute to their leaving the field as an act of resistance. The Black women who choose to persist utilize various mechanisms to help them navigate hostile environments within computing. One such mechanism is social capital where Black women leverage their social connections with others in the field of computing. As a part of a larger study that explores the role that social capital plays for Black women in computing, we used the Social Capital Community Benchmark Survey (SCCBS) to ask 14 Black women in three virtual focus groups about the social influences that impact their ability to persist in computing. Results reveal that spirituality is a large part of persistence in computing. However, SCCBS privileges certain religious denominations …"
Yolanda Rankin,The Role of Black Feminist Thought in Informal CS Education,2023,https://ieeexplore.ieee.org/abstract/document/10675943/,"Faith-based organizations provide a variety of supplemental programs to address social, economic, and political issues that negatively impact marginalized communities. In this experience report, we engage Black women employed at a faith-based organization, as experts and collaborators, in creating an equitable learning environment to accommodate the computing education needs of Black students who live in an under-resourced rural community. Leveraging Black feminist thought, we afford these Black women, who are new to computing education, an opportunity to develop their block style programming skills using Scratch. Combining our areas of expertise, we develop learning materials that affirm the racial identity of Black elementary students, contributing to the development of the faith-based organization’s informal computing education program."
Yolanda Rankin,"SIGCSE Bulletin Vol. 55, No. 2",2023,https://sigcse.org/about/bulletin/bulletin.55.2.pdf,"Welcome to the April issue of the SIGCSE Bulletin for 2023. This issue comes hot on the heels of the SIGCSE Technical Symposium, held March 15-18 in Toronto (and in cyberspace). The conference organizers have an extensive rundown of the many highlights. I had"
Kai Shu,"Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media",2020,https://www.liebertpub.com/doi/abs/10.1089/big.2020.0062,"Social media has become a popular means for people to consume and share the news. At the same time, however, it has also enabled the wide dissemination of fake news, that is, news with intentionally false information, causing significant negative effects on society. To mitigate this problem, the research of fake news detection has recently received a lot of attention. Despite several existing computational solutions on the detection of fake news, the lack of comprehensive and community-driven fake news data sets has become one of major roadblocks. Not only existing data sets are scarce, they do not contain a myriad of features often required in the study such as news content, social context, and spatiotemporal information. Therefore, in this article, to facilitate fake news-related research, we present a fake news data repository FakeNewsNet, which contains two comprehensive data sets with diverse features in …"
Kai Shu,Mining Dual Emotion for Fake News Detection,2021,https://dl.acm.org/doi/abs/10.1145/3442381.3450004,"Emotion plays an important role in detecting fake news online. When leveraging emotional signals, the existing methods focus on exploiting the emotions of news contents that conveyed by the publishers (i.e., publisher emotion). However, fake news often evokes high-arousal or activating emotions of people, so the emotions of news comments aroused in the crowd (i.e., social emotion) should not be ignored. Furthermore, it remains to be explored whether there exists a relationship between publisher emotion and social emotion (i.e., dual emotion), and how the dual emotion appears in fake news. In this paper, we verify that dual emotion is distinctive between fake and real news and propose Dual Emotion Features to represent dual emotion and the relationship between them for fake news detection. Further, we exhibit that our proposed features can be easily plugged into existing fake news detectors as an …"
Kai Shu,Position: TrustLLM: Trustworthiness in large language models,2024,http://proceedings.mlr.press/v235/huang24x.html,"Large language models (LLMs) have gained considerable attention for their excellent natural language processing capabilities. Nonetheless, these LLMs present many challenges, particularly in the realm of trustworthiness. This paper introduces TrustLLM, a comprehensive study of trustworthiness in LLMs, including principles for different dimensions of trustworthiness, established benchmark, evaluation, and analysis of trustworthiness for mainstream LLMs, and discussion of open challenges and future directions. Specifically, we first propose a set of principles for trustworthy LLMs that span eight different dimensions. Based on these principles, we further establish a benchmark across six dimensions including truthfulness, safety, fairness, robustness, privacy, and machine ethics. We then present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of over 30 datasets. Our findings firstly show that in general trustworthiness and capability (ie, functional effectiveness) are positively related. Secondly, our observations reveal that proprietary LLMs generally outperform most open-source counterparts in terms of trustworthiness, raising concerns about the potential risks of widely accessible open-source LLMs. However, a few open-source LLMs come very close to proprietary ones, suggesting that open-source models can achieve high levels of trustworthiness without additional mechanisms like moderator, offering valuable insights for developers in this field. Thirdly, it is important to note that some LLMs may be overly calibrated towards exhibiting trustworthiness, to the extent that they compromise their utility by mistakenly treating benign …"
Kai Shu,User Preference-aware Fake News Detection,2021,https://dl.acm.org/doi/abs/10.1145/3404835.3462990,"Disinformation and fake news have posed detrimental effects on individuals and society in recent years, attracting broad attention to fake news detection. The majority of existing fake news detection algorithms focus on mining news content and/or the surrounding exogenous context for discovering deceptive signals; while the endogenous preference of a user when he/she decides to spread a piece of fake news or not is ignored. The confirmation bias theory has indicated that a user is more likely to spread a piece of fake news when it confirms his/her existing beliefs/preferences. Users' historical, social engagements such as posts provide rich information about users' preferences toward news and have great potentials to advance fake news detection. However, the work on exploring user preference for fake news detection is somewhat limited. Therefore, in this paper, we study the novel problem of exploiting user …"
Kai Shu,Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation.,2020,https://aaai.org/ojs/index.php/ICWSM/article/view/7329,"Consuming news from social media is becoming increasingly popular. However, social media also enables the wide dissemination of fake news. Because of the detrimental effects of fake news, fake news detection has attracted increasing attention. However, the performance of detecting fake news only from news content is generally limited as fake news pieces are written to mimic true news. In the real world, news pieces spread through propagation networks on social media. The news propagation networks usually involve multi-levels. In this paper, we study the challenging problem of investigating and exploiting news hierarchical propagation network on social media for fake news detection."
Kai Shu,Combating Disinformation in A Social Media Age,2020,https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1385,"The creation, dissemination, and consumption of disinformation and fabricated content on social media is a growing concern, especially with the ease of access to such sources, and the lack of awareness of the existence of such false information. In this article, we present an overview of the techniques explored to date for the combating of disinformation with various forms. We introduce different forms of disinformation, discuss factors related to the spread of disinformation, elaborate on the inherent challenges in detecting disinformation, and show some approaches to mitigating disinformation via education, research, and collaboration. Looking ahead, we present some promising future research directions on disinformation.This article is categorized under: Algorithmic Development > Multimedia Commercial, Legal, and Ethical Issues > Social Considerations Application Areas > Education and Learning "
Kai Shu,Authorship Attribution for Neural Text Generation,2020,https://aclanthology.org/2020.emnlp-main.673/,"In recent years, the task of generating realistic short and long texts have made tremendous advancements. In particular, several recently proposed neural network-based language models have demonstrated their astonishing capabilities to generate texts that are challenging to distinguish from human-written texts with the naked eye. Despite many benefits and utilities of such neural methods, in some applications, being able to tell the “author” of a text in question becomes critically important. In this work, in the context of this Turing Test, we investigate the so-called authorship attribution problem in three versions:(1) given two texts T1 and T2, are both generated by the same method or not?(2) is the given text T written by a human or machine?(3) given a text T and k candidate neural methods, can we single out the method (among k alternatives) that generated T? Against one humanwritten and eight machine-generated texts (ie, CTRL, GPT, GPT2, GROVER, XLM, XLNET, PPLM, FAIR), we empirically experiment with the performance of various models in three problems. By and large, we find that most generators still generate texts significantly different from human-written ones, thereby making three problems easier to solve. However, the qualities of texts generated by GPT2, GROVER, and FAIR are better, often confusing machine classifiers in solving three problems. All codes and datasets of our experiments are available at: https://bit. ly/302zWdz"
Kai Shu,"Mining Disinformation and Fake News: Concepts, Methods, and Recent Advancements",2020,https://link.springer.com/chapter/10.1007/978-3-030-42699-6_1,"In recent years, disinformation including fake news, has became a global phenomenon due to its explosive growth, particularly on social media. The wide spread of disinformation and fake news can cause detrimental societal effects. Despite the recent progress in detecting disinformation and fake news, it is still non-trivial due to its complexity, diversity, multi-modality, and costs of fact-checking or annotation. The goal of this chapter is to pave the way for appreciating the challenges and advancements via: (1) introducing the types of information disorder on social media and examine their differences and connections; (2) describing important and emerging tasks to combat disinformation for characterization, detection and attribution; and (3) discussing a weak supervision approach to detect disinformation with limited labeled data. We then provide an overview of the chapters in this book that represent the recent …"
Kai Shu,Can llm-generated misinformation be detected?,2024,https://arxiv.org/abs/2309.13788,"The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery on combating misinformation in the age of LLMs and the countermeasures."
Kai Shu,Temporally evolving graph neural network for fake news detection,2021,https://www.sciencedirect.com/science/article/pii/S0306457321001965,"The proliferation of fake news on social media has the probability to bring an unfavorable impact on public opinion and social development. Many efforts have been paid to develop effective detection and intervention algorithms in recent years. Most of the existing propagation-based fake news detection methods focus on static networks and assume the whole information propagation network structure is accessible before performing learning algorithms. However, in real-world information diffusion networks, new nodes and edges constantly emerge. Therefore, in this paper, we introduce a novel temporal propagation-based fake news detection framework, which could fuse structure, content semantics, and temporal information. In particular, our model can model temporal evolution patterns of real-world news as the graph evolving under the setting of continuous-time dynamic diffusion networks. We conduct extensive …"
Kai Shu,Graph prototypical networks for few-shot learning on attributed networks,2020,https://dl.acm.org/doi/abs/10.1145/3340531.3411922,"Attributed networks nowadays are ubiquitous in a myriad of high-impact applications, such as social network analysis, financial fraud detection, and drug discovery. As a central analytical task on attributed networks, node classification has received much attention in the research community. In real-world attributed networks, a large portion of node classes only contains limited labeled instances, rendering a long-tail node class distribution. Existing node classification algorithms are unequipped to handle the few-shot node classes. As a remedy, few-shot learning has attracted a surge of attention in the research community. Yet, few-shot node classification remains a challenging problem as we need to address the following questions: (i) How to extract meta-knowledge from an attributed network for few-shot node classification? (ii) How to identify the informativeness of each labeled instance for building a robust and …"
Kai Shu,Combating Misinformation in the Age of LLMs: Opportunities and Challenges,2023,https://onlinelibrary.wiley.com/doi/abs/10.1002/aaai.12188,"Misinformation such as fake news and rumors is a serious threat for information ecosystems and public trust. The emergence of large language models (LLMs) has great potential to reshape the landscape of combating misinformation. Generally, LLMs can be a double‐edged sword in the fight. On the one hand, LLMs bring promising opportunities for combating misinformation due to their profound world knowledge and strong reasoning abilities. Thus, one emerging question is: can we utilize LLMs to combat misinformation? On the other hand, the critical challenge is that LLMs can be easily leveraged to generate deceptive misinformation at scale. Then, another important question is: how to combat LLM‐generated misinformation? In this paper, we first systematically review the history of combating misinformation before the advent of LLMs. Then we illustrate the current efforts and present an outlook for these two …"
Kai Shu,Mm-covid: A multilingual and multimodal data repository for combating covid-19 disinformation,2020,https://arxiv.org/abs/2011.04088,"The COVID-19 epidemic is considered as the global health crisis of the whole society and the greatest challenge mankind faced since World War Two. Unfortunately, the fake news about COVID-19 is spreading as fast as the virus itself. The incorrect health measurements, anxiety, and hate speeches will have bad consequences on people's physical health, as well as their mental health in the whole world. To help better combat the COVID-19 fake news, we propose a new fake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19 Fake News Data Repository). This dataset provides the multilingual fake news and the relevant social context. We collect 3981 pieces of fake news content and 7192 trustworthy information from English, Spanish, Portuguese, Hindi, French and Italian, 6 different languages. We present a detailed and exploratory analysis of MM-COVID from different perspectives and demonstrate the utility of MM-COVID in several potential applications of COVID-19 fake news study on multilingual and social media."
Kai Shu,A public health research agenda for managing infodemics: methods and results of the first WHO infodemiology conference,2021,https://infodemiology.jmir.org/2021/1/e30979,"An infodemic is an overflow of information of varying quality that surges across digital and physical environments during an acute public health event. It leads to confusion, risk-taking, and behaviors that can harm health and lead to erosion of trust in health authorities and public health responses. Owing to the global scale and high stakes of the health emergency, responding to the infodemic related to the pandemic is particularly urgent. Building on diverse research disciplines and expanding the discipline of infodemiology, more evidence-based interventions are needed to design infodemic management interventions and tools and implement them by health emergency responders.The World Health Organization organized the first global infodemiology conference, entirely online, during June and July 2020, with a follow-up process from August to October 2020, to review current multidisciplinary evidence, interventions, and practices that can be applied to the COVID-19 infodemic response. This resulted in the creation of a public health research agenda for managing infodemics.As part of the conference, a structured expert judgment synthesis method was used to formulate a public health research agenda. A total of 110 participants represented diverse scientific disciplines from over 35 countries and global public health implementing partners. The conference used a laddered discussion sprint methodology by rotating participant teams, and a managed follow-up process was used to assemble a research agenda based on the discussion and structured expert …"
Kai Shu,Bond: Benchmarking unsupervised outlier node detection on static attributed graphs,2022,https://proceedings.neurips.cc/paper_files/paper/2022/hash/acc1ec4a9c780006c9aafd595104816b-Abstract-Datasets_and_Benchmarks.html,"Detecting which nodes in graphs are outliers is a relatively new machine learning task with numerous applications. Despite the proliferation of algorithms developed in recent years for this task, there has been no standard comprehensive setting for performance evaluation. Consequently, it has been difficult to understand which methods work well and when under a broad range of settings. To bridge this gap, we present—to the best of our knowledge—the first comprehensive benchmark for unsupervised outlier node detection on static attributed graphs called BOND, with the following highlights.(1) We benchmark the outlier detection performance of 14 methods ranging from classical matrix factorization to the latest graph neural networks.(2) Using nine real datasets, our benchmark assesses how the different detection methods respond to two major types of synthetic outliers and separately to “organic”(real non-synthetic) outliers.(3) Using an existing random graph generation technique, we produce a family of synthetically generated datasets of different graph sizes that enable us to compare the running time and memory usage of the different outlier detection algorithms. Based on our experimental results, we discuss the pros and cons of existing graph outlier detection algorithms, and we highlight opportunities for future research. Importantly, our code is freely available and meant to be easily extendable: https://github. com/pygod-team/pygod/tree/main/benchmark"
Kai Shu,"Disinformation, Misinformation, and Fake News in Social Media",2020,,
Kai Shu,Memory-Guided Multi-View Multi-Domain Fake News Detection,2022,https://ieeexplore.ieee.org/abstract/document/9802916/,"The wide spread of fake news is increasingly threatening both individuals and society. Great efforts have been made for automatic fake news detection on a single domain (e.g., politics). However, correlations exist commonly across multiple news domains, and thus it is promising to simultaneously detect fake news of multiple domains. Based on our analysis, we pose two challenges in multi-domain fake news detection: 1) domain shift, caused by the discrepancy among domains in terms of words, emotions, styles, etc. 2) domain labeling incompleteness, stemming from the real-world categorization that only outputs one single domain label, regardless of topic diversity of a news piece. In this paper, we propose a Memory-guided Multi-view Multi-domain Fake News Detection Framework (M FEND) to address these two challenges. We model news pieces from a multi-view perspective, including semantics, emotion, and …"
Kai Shu,Leveraging Multi-Source Weak Social Supervision for Early Detection of Fake News,2020,https://arxiv.org/abs/2004.01732,"Social media has greatly enabled people to participate in online activities at an unprecedented rate. However, this unrestricted access also exacerbates the spread of misinformation and fake news online which might cause confusion and chaos unless being detected early for its mitigation. Given the rapidly evolving nature of news events and the limited amount of annotated data, state-of-the-art systems on fake news detection face challenges due to the lack of large numbers of annotated training instances that are hard to come by for early detection. In this work, we exploit multiple weak signals from different sources given by user and content engagements (referred to as weak social supervision), and their complementary utilities to detect fake news. We jointly leverage the limited amount of clean data along with weak signals from social engagements to train deep neural networks in a meta-learning framework to estimate the quality of different weak instances. Experiments on realworld datasets demonstrate that the proposed framework outperforms state-of-the-art baselines for early detection of fake news without using any user engagements at prediction time."
Kai Shu,Towards Fair Classifiers Without Sensitive Attributes: Exploring Biases in Related Features,2022,https://dl.acm.org/doi/abs/10.1145/3488560.3498493,"Despite the rapid development and great success of machine learning models, extensive studies have exposed their disadvantage of inheriting latent discrimination and societal bias from the training data. This phenomenon hinders their adoption on high-stake applications. Thus, many efforts have been taken for developing fair machine learning models. Most of them require that sensitive attributes are available during training to learn fair models. However, in many real-world applications, it is usually infeasible to obtain the sensitive attributes due to privacy or legal issues, which challenges existing fair-ensuring strategies. Though the sensitive attribute of each data sample is unknown, we observe that there are usually some non-sensitive features in the training data that are highly correlated with sensitive attributes, which can be used to alleviate the bias. Therefore, in this paper, we study a novel problem of …"
Kai Shu,Domain Adaptive Fake News Detection via Reinforcement Learning,2022,https://dl.acm.org/doi/abs/10.1145/3485447.3512258,"With social media being a major force in information consumption, accelerated propagation of fake news has presented new challenges for platforms to distinguish between legitimate and fake news. Effective fake news detection is a non-trivial task due to the diverse nature of news domains and expensive annotation costs. In this work, we address the limitations of existing automated fake news detection models by incorporating auxiliary information (e.g., user comments and user-news interactions) into a novel reinforcement learning-based model called REinforced Adaptive Learning Fake News Detection (REAL-FND). REAL-FND exploits cross-domain and within-domain knowledge that makes it robust in a target domain, despite being trained in a different source domain. Extensive experiments on real-world datasets illustrate the effectiveness of the proposed model, especially when limited labeled data is …"
Kai Shu,Causal Understanding of Fake News Dissemination on Social Media,2021,https://dl.acm.org/doi/abs/10.1145/3447548.3467321,"Recent years have witnessed remarkable progress towards computational fake news detection. To mitigate its negative impact, we argue that it is critical to understand what user attributes potentially cause users to share fake news. The key to this causal-inference problem is to identify confounders -- variables that cause spurious associations between treatments (e.g., user attributes) and outcome (e.g., user susceptibility). In fake news dissemination, confounders can be characterized by fake news sharing behavior that inherently relates to user attributes and online activities. Learning such user behavior is typically subject to selection bias in users who are susceptible to share news on social media. Drawing on causal inference theories, we first propose a principled approach to alleviating selection bias in fake news dissemination. We then consider the learned unbiased fake news sharing behavior as the …"
Kai Shu,Can Large Language Model Agents Simulate Human Trust Behaviors?,2024,https://proceedings.neurips.cc/paper_files/paper/2024/file/1cb57fcf7ff3f6d37eebae5becc9ea6d-Paper-Conference.pdf,"Large Language Model (LLM) agents have been increasingly adopted as simulation tools to model humans in social science and role-playing applications. However, one fundamental question remains: can LLM agents really simulate human behavior? In this paper, we focus on one critical and elemental behavior in human interactions, trust, and investigate whether LLM agents can simulate human trust behavior. We first find that LLM agents generally exhibit trust behavior, referred to as agent trust, under the framework of Trust Games, which are widely recognized in behavioral economics. Then, we discover that GPT-4 agents manifest high behavioral alignment with humans in terms of trust behavior, indicating the feasibility of simulating human trust behavior with LLM agents. In addition, we probe the biases of agent trust and differences in agent trust towards other LLM agents and humans. We also explore the intrinsic properties of agent trust under conditions including external manipulations and advanced reasoning strategies. Our study provides new insights into the behaviors of LLM agents and the fundamental analogy between LLMs and humans beyond value alignment. We further illustrate broader implications of our discoveries for applications where trust is paramount."
Kai Shu,Pygod: A python library for graph outlier detection,2024,http://www.jmlr.org/papers/v25/23-0963.html,"PyGOD is an open-source Python library for detecting outliers in graph data. As the first comprehensive library of its kind, PyGOD supports a wide array of leading graph-based methods for outlier detection under an easy-to-use, well-documented API designed for use by both researchers and practitioners. PyGOD provides modularized components of the different detectors implemented so that users can easily customize each detector for their purposes. To ease the construction of detection workflows, PyGOD offers numerous commonly used utility functions. To scale computation to large graphs, PyGOD supports functionalities for deep models such as sampling and mini-batch processing. PyGOD uses best practices in fostering code reliability and maintainability, including unit testing, continuous integration, and code coverage. To facilitate accessibility, PyGOD is released under a BSD 2-Clause license at https://pygod.org and at the Python Package Index (PyPI)."
Kai Shu,Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models,2023,https://arxiv.org/abs/2310.05253,"Claim verification plays a crucial role in combating misinformation. While existing works on claim verification have shown promising results, a crucial piece of the puzzle that remains unsolved is to understand how to verify claims without relying on human-annotated data, which is expensive to create at a large scale. Additionally, it is important for models to provide comprehensive explanations that can justify their decisions and assist human fact-checkers. This paper presents First-Order-Logic-Guided Knowledge-Grounded (FOLK) Reasoning that can verify complex claims and generate explanations without the need for annotated evidence using Large Language Models (LLMs). FOLK leverages the in-context learning ability of LLMs to translate the claim into a First-Order-Logic (FOL) clause consisting of predicates, each corresponding to a sub-claim that needs to be verified. Then, FOLK performs FOL-Guided reasoning over a set of knowledge-grounded question-and-answer pairs to make veracity predictions and generate explanations to justify its decision-making process. This process makes our model highly explanatory, providing clear explanations of its reasoning process in human-readable form. Our experiment results indicate that FOLK outperforms strong baselines on three datasets encompassing various claim verification challenges. Our code and data are available."
Kai Shu,Cross-domain Graph Anomaly Detection,2021,https://ieeexplore.ieee.org/abstract/document/9556511/,"Anomaly detection on attributed graphs has received increasing research attention lately due to the broad applications in various high-impact domains, such as cybersecurity, finance, and healthcare. Heretofore, most of the existing efforts are predominately performed in an unsupervised manner due to the expensive cost of acquiring anomaly labels, especially for newly formed domains. How to leverage the invaluable auxiliary information from a labeled attributed graph to facilitate the anomaly detection in the unlabeled attributed graph is seldom investigated. In this study, we aim to tackle the problem of cross-domain graph anomaly detection with domain adaptation. However, this task remains nontrivial mainly due to: 1) the data heterogeneity including both the topological structure and nodal attributes in an attributed graph and 2) the complexity of capturing both invariant and specific anomalies on the target …"
Kai Shu,Unsupervised cyberbullying detection via time-informed Gaussian mixture model,2020,https://arxiv.org/abs/2008.02642,"Social media is a vital means for information-sharing due to its easy access, low cost, and fast dissemination characteristics. However, increases in social media usage have corresponded with a rise in the prevalence of cyberbullying. Most existing cyberbullying detection methods are supervised and, thus, have two key drawbacks: (1) The data labeling process is often time-consuming and labor-intensive; (2) Current labeling guidelines may not be generalized to future instances because of different language usage and evolving social networks. To address these limitations, this work introduces a principled approach for unsupervised cyberbullying detection. The proposed model consists of two main components: (1) A representation learning network that encodes the social media session by exploiting multi-modal features, e.g., text, network, and time. (2) A multi-task learning network that simultaneously fits the comment inter-arrival times and estimates the bullying likelihood based on a Gaussian Mixture Model. The proposed model jointly optimizes the parameters of both components to overcome the shortcomings of decoupled training. Our core contribution is an unsupervised cyberbullying detection model that not only experimentally outperforms the state-of-the-art unsupervised models, but also achieves competitive performance compared to supervised models."
Kai Shu,"""This is Fake! Shared it by Mistake"": Assessing the Intent of Fake News Spreaders.",2022,https://dl.acm.org/doi/abs/10.1145/3485447.3512264," Individuals can be misled by fake news and spread it unintentionally without knowing it is false. This phenomenon has been frequently observed but has not been investigated. Our aim in this work is to assess the intent of fake news spreaders. To distinguish between intentional versus unintentional spreading, we study the psychological explanations of unintentional spreading. With this foundation, we then propose an influence graph, using which we assess the intent of fake news spreaders. Our extensive experiments show that the assessed intent can help significantly differentiate between intentional and unintentional fake news spreaders. Furthermore, the estimated intent can significantly improve the current techniques that detect fake news. To our best knowledge, this is the first work to model individuals’ intent in fake news spreading."
Kai Shu,From generation to judgment: Opportunities and challenges of llm-as-a-judge,2024,https://arxiv.org/abs/2411.16594,"Assessment and evaluation have long been critical challenges in artificial intelligence (AI) and natural language processing (NLP). However, traditional methods, whether matching-based or embedding-based, often fall short of judging subtle attributes and delivering satisfactory results. Recent advancements in Large Language Models (LLMs) inspire the ""LLM-as-a-judge"" paradigm, where LLMs are leveraged to perform scoring, ranking, or selection across various tasks and applications. This paper provides a comprehensive survey of LLM-based judgment and assessment, offering an in-depth overview to advance this emerging field. We begin by giving detailed definitions from both input and output perspectives. Then we introduce a comprehensive taxonomy to explore LLM-as-a-judge from three dimensions: what to judge, how to judge and where to judge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and highlight key challenges and promising directions, aiming to provide valuable insights and inspire future research in this promising research area. Paper list and more resources about LLM-as-a-judge can be found at \url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and \url{https://llm-as-a-judge.github.io}."
Kai Shu,Fact-Enhanced Synthetic News Generation,2021,https://ojs.aaai.org/index.php/AAAI/article/view/17629,"The advanced text generation methods have witnessed great success in text summarization, language translation, and synthetic news generation. However, these techniques can be abused to generate disinformation and fake news. To better understand the potential threats of synthetic news, we develop a novel generation method FACTGEN to generate high-quality news content. The majority of existing text generation methods either afford limited supplementary information or lose consistency between the input and output which makes the synthetic news less trustworthy. To address these issues, FACTGEN retrieves external facts to enrich the output and reconstructs the input claim from the generated content to improve the consistency among the input and the output. Experiment results on real-world datasets demonstrate that the generated news contents of FACTGEN are consistent and contain rich facts. We also discuss an effective defending technique to identify these synthetic news pieces if FACTGEN was used to generate fake news."
Kai Shu,Detecting Fake News with Weak Social Supervision,2020,https://ieeexplore.ieee.org/abstract/document/9103278/,"Limited labeled data are becoming one of the largest bottlenecks for supervised learning systems. This is especially the case for many real-world tasks, where large-scale labeled examples are either too expensive to acquire or unavailable due to privacy or data access constraints. Weak supervision has shown to be effective in mitigating the scarcity of labeled data by leveraging weak labels or injecting constraints from heuristic rules and/or extrinsic knowledge sources. Social media has little labeled data but possesses unique characteristics that make it suitable for generating weak supervision, resulting in a new type of weak supervision, i.e., weak social supervision. In this article, we illustrate how various aspects of social media can be used as weak social supervision. Specifically, we use the recent research on fake news detection as the use case, where social engagements are abundant but annotated …"
Kai Shu,Backdoor activation attack: Attack large language models using activation steering for safety-alignment,2024,,
Kai Shu,"Combating health misinformation in social media: Characterization, detection, intervention, and open issues",2022,https://arxiv.org/abs/2211.05289,"Social media has been one of the main information consumption sources for the public, allowing people to seek and spread information more quickly and easily. However, the rise of various social media platforms also enables the proliferation of online misinformation. In particular, misinformation in the health domain has significant impacts on our society such as the COVID-19 infodemic. Therefore, health misinformation in social media has become an emerging research direction that attracts increasing attention from researchers of different disciplines. Compared to misinformation in other domains, the key differences of health misinformation include the potential of causing actual harm to humans' bodies and even lives, the hardness to identify for normal people, and the deep connection with medical science. In addition, health misinformation on social media has distinct characteristics from conventional channels such as television on multiple dimensions including the generation, dissemination, and consumption paradigms. Because of the uniqueness and importance of combating health misinformation in social media, we conduct this survey to further facilitate interdisciplinary research on this problem. In this survey, we present a comprehensive review of existing research about online health misinformation in different disciplines. Furthermore, we also systematically organize the related literature from three perspectives: characterization, detection, and intervention. Lastly, we conduct a deep discussion on the pressing open issues of combating health misinformation in social media and provide future directions for multidisciplinary researchers."
Kai Shu,Multi-Source Domain Adaptation with Weak Supervision for Early Fake News Detection,2021,https://ieeexplore.ieee.org/abstract/document/9671592/,"Recently, the massive and diverse fake news from politics to entertainment and health has amplified the social distrust problem and has become a big challenge for the society and research community. The existing fake news detection methods are mostly designed for either a specific domain or require huge labeled data from various domains. If there is not enough labeled data in a certain domain, existing models may not work well for detecting fake news from that domain. To overcome these limitations we propose a novel framework based on multisource domain adaptation and weak supervision for early fake news detection. The framework transfers sufficient labeled source domains’ knowledge into a target/new domain with limited or even no labeled data by the multi-source domain adaptation, and applies researchers’ prior knowledge about fake news to the target domain by the weak supervision. The weak …"
Kai Shu,Learning with Weak Supervision for Email Intent Detection,2020,https://dl.acm.org/doi/abs/10.1145/3397271.3401121,"Email remains one of the most frequently used means of online communication. People spend significant amount of time every day on emails to exchange information, manage tasks and schedule events. Previous work has studied different ways for improving email productivity by prioritizing emails, suggesting automatic replies or identifying intents to recommend appropriate actions. The problem has been mostly posed as a supervised learning problem where models of different complexities were proposed to classify an email message into a predefined taxonomy of intents or classes. The need for labeled data has always been one of the largest bottlenecks in training supervised models. This is especially the case for many real-world tasks, such as email intent classification, where large scale annotated examples are either hard to acquire or unavailable due to privacy or data access constraints. Email users often …"
Kai Shu,Attacking Fake News Detectors via Manipulating News Social Engagement,2023,https://dl.acm.org/doi/abs/10.1145/3543507.3583868," Social media is one of the main sources for news consumption, especially among the younger generation. With the increasing popularity of news consumption on various social media platforms, there has been a surge of misinformation which includes false information or unfounded claims. As various text- and social context-based fake news detectors are proposed to detect misinformation on social media, recent works start to focus on the vulnerabilities of fake news detectors. In this paper, we present the first adversarial attack framework against Graph Neural Network (GNN)-based fake news detectors to probe their robustness. Specifically, we leverage a multi-agent reinforcement learning (MARL) framework to simulate the adversarial behavior of fraudsters on social media. Research has shown that in real-world settings, fraudsters coordinate with each other to share different news in order to evade the detection …"
Kai Shu,Nothing Stands Alone: Leveraging News Relations through a Hypergraph for Fake News Detection,2022,,
Kai Shu,Applications of machine learning for COVID-19 misinformation: a systematic review,2022,https://link.springer.com/article/10.1007/s13278-022-00921-9,"The inflammable growth of misinformation on social media and other platforms during pandemic situations like COVID-19 can cause significant damage to the physical and mental stability of the people. To detect such misinformation, researchers have been applying various machine learning (ML) and deep learning (DL) techniques. The objective of this study is to systematically review, assess, and synthesize state-of-the-art research articles that have used different ML and DL techniques to detect COVID-19 misinformation. A structured literature search was conducted in the relevant bibliographic databases to ensure that the survey was solely centered on reproducible and high-quality research. We reviewed 43 papers that fulfilled our inclusion criteria out of 260 articles found from our keyword search. We have surveyed a complete pipeline of COVID-19 misinformation detection. In particular, we have identified …"
Kai Shu,Muser: A multi-step evidence retrieval enhancement framework for fake news detection,2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599873,"The ease of spreading false information online enables individuals with malicious intent to manipulate public opinion and destabilize social stability. Recently, fake news detection based on evidence retrieval has gained popularity in an effort to identify fake news reliably and reduce its impact. Evidence retrieval-based methods can improve the reliability of fake news detection by computing the textual consistency between the evidence and the claim in the news. In this paper, we propose a framework for fake news detection based on MUlti- Step Evidence Retrieval enhancement (MUSER), which simulates the steps of human beings in the process of reading news, summarizing, consulting materials, and inferring whether the news is true or fake. Our model can explicitly model dependencies among multiple pieces of evidence, and perform multi-step associations for the evidence required for news verification through …"
Kai Shu,Joint spatial and temporal modeling for hydrological prediction,2020,https://ieeexplore.ieee.org/abstract/document/9078096/,"The accurate and timely estimation of river discharge plays an important role in hydrological modeling, especially for avoiding the consequences of flood events. The majority of existing work on hydrologic prediction focuses on modeling the inherent physical process for specific river basins, while the geographic-connections between rivers are largely ignored. Geographically connected rivers provide rich spatial information that can be used to predict discharge amounts. In this paper, we study a novel problem of exploiting both temporal patterns and spatial connections for hydrological prediction. We construct three relationship graphs for hydrological gauges in the study area: the hydraulic distance graph, the Euclidean distance graph and the correlation graph. We fuse these graphs into one hydrological network graph, and propose a novel framework ST-Hydro which exploits Graph Convolutional Networks (GCN …"
Kai Shu,Characterizing Multi-domain False News and Underlying User Effects on Chinese Weibo,2022,https://www.sciencedirect.com/science/article/pii/S0306457322000784,"False news that spreads on social media has proliferated over the past years and has led to multi-aspect threats in the real world. While there are studies of false news on specific domains (like politics or health care), little work is found comparing false news across domains. In this article, we investigate false news across nine domains on Weibo, the largest Twitter-like social media platform in China, from 2009 to 2019. The newly collected data comprise 44,728 posts in the nine domains, published by 40,215 users, and reposted over 3.4 million times. Based on the distributions and spreads of the multi-domain dataset, we observe that false news in domains that are close to daily life like health and medicine generated more posts but diffused less effectively than those in other domains like politics, and that political false news had the most effective capacity for diffusion. The widely diffused false news posts on Weibo …"
Kai Shu,Combating online hostile posts in regional languages during emergency situation,2021,https://scholar.google.com/scholar?cluster=10922030424879595749&hl=en&oi=scholarr,
Kai Shu,Can Large Language Models Identify Authorship?,2024,https://arxiv.org/abs/2403.08213,"The ability to accurately identify authorship is crucial for verifying content authenticity and mitigating misinformation. Large Language Models (LLMs) have demonstrated an exceptional capacity for reasoning and problem-solving. However, their potential in authorship analysis remains under-explored. Traditional studies have depended on hand-crafted stylistic features, whereas state-of-the-art approaches leverage text embeddings from pre-trained language models. These methods, which typically require fine-tuning on labeled data, often suffer from performance degradation in cross-domain applications and provide limited explainability. This work seeks to address three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship verification effectively? (2) Are LLMs capable of accurately attributing authorship among multiple candidates authors (e.g., 10 and 20)? (3) Can LLMs provide explainability in authorship analysis, particularly through the role of linguistic features? Moreover, we investigate the integration of explicit linguistic features to guide LLMs in their reasoning processes. Our assessment demonstrates LLMs' proficiency in both tasks without the need for domain-specific fine-tuning, providing explanations into their decision making via a detailed analysis of linguistic features. This establishes a new benchmark for future research on LLM-based authorship analysis."
Kai Shu,Can Editing LLMs Inject Harm?,2024,https://arxiv.org/abs/2407.20224,"Knowledge editing has been increasingly adopted to correct the false or outdated knowledge in Large Language Models (LLMs). Meanwhile, one critical but under-explored question is: can knowledge editing be used to inject harm into LLMs? In this paper, we propose to reformulate knowledge editing as a new type of safety threat for LLMs, namely Editing Attack, and conduct a systematic investigation with a newly constructed dataset EditAttack. Specifically, we focus on two typical safety risks of Editing Attack including Misinformation Injection and Bias Injection. For the risk of misinformation injection, we first categorize it into commonsense misinformation injection and long-tail misinformation injection. Then, we find that editing attacks can inject both types of misinformation into LLMs, and the effectiveness is particularly high for commonsense misinformation injection. For the risk of bias injection, we discover that not only can biased sentences be injected into LLMs with high effectiveness, but also one single biased sentence injection can cause a bias increase in general outputs of LLMs, which are even highly irrelevant to the injected sentence, indicating a catastrophic impact on the overall fairness of LLMs. Then, we further illustrate the high stealthiness of editing attacks, measured by their impact on the general knowledge and reasoning capacities of LLMs, and show the hardness of defending editing attacks with empirical evidence. Our discoveries demonstrate the emerging misuse risks of knowledge editing techniques on compromising the safety alignment of LLMs and the feasibility of disseminating misinformation or bias with LLMs as new …"
Kai Shu,Integrating mamba and transformer for long-short range time series forecasting,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240414757X/abstract,"Time series forecasting is an important problem and plays a key role in a variety of applications including weather forecasting, stock market, and scientific simulations. Although transformers have proven to be effective in capturing dependency, its quadratic complexity of attention mechanism prevents its further adoption in long-range time series forecasting, thus limiting them attend to short-range range. Recent progress on state space models (SSMs) have shown impressive performance on modeling long range dependency due to their subquadratic complexity. Mamba, as a representative SSM, enjoys linear time complexity and has achieved strong scalability on tasks that requires scaling to long sequences, such as language, audio, and genomics. In this paper, we propose to leverage a hybrid framework Mambaformer that internally combines Mamba for long-range dependency, and Transformer for short range …"
Kai Shu,Meta-prompt based learning for low-resource false information detection,2023,https://www.sciencedirect.com/science/article/pii/S030645732300016X,"The wide spread of false information has detrimental effects on society, and false information detection has received wide attention. When new domains appear, the relevant labeled data is scarce, which brings severe challenges to the detection. Previous work mainly leverages additional data or domain adaptation technology to assist detection. The former would lead to a severe data burden; the latter underutilizes the pre-trained language model because there is a gap between the downstream task and the pre-training task, which is also inefficient for model storage because it needs to store a set of parameters for each domain. To this end, we propose a meta-prompt based learning (MAP) framework for low-resource false information detection. We excavate the potential of pre-trained language models by transforming the detection tasks into pre-training tasks by constructing template. To solve the problem of the …"
Kai Shu,Artificial intelligence algorithms for treatment of diabetes,2022,https://www.mdpi.com/1999-4893/15/9/299,"Artificial intelligence (AI) algorithms can provide actionable insights for clinical decision-making and managing chronic diseases. The treatment and management of complex chronic diseases, such as diabetes, stands to benefit from novel AI algorithms analyzing the frequent real-time streaming data and the occasional medical diagnostics and laboratory test results reported in electronic health records (EHR). Novel algorithms are needed to develop trustworthy, responsible, reliable, and robust AI techniques that can handle the imperfect and imbalanced data of EHRs and inconsistencies or discrepancies with free-living self-reported information. The challenges and applications of AI for two problems in the healthcare domain were explored in this work. First, we introduced novel AI algorithms for EHRs designed to be fair and unbiased while accommodating privacy concerns in predicting treatments and outcomes. Then, we studied the innovative approach of using machine learning to improve automated insulin delivery systems through analyzing real-time information from wearable devices and historical data to identify informative trends and patterns in free-living data. Application examples in the treatment of diabetes demonstrate the benefits of AI tools for medical and health informatics."
Kai Shu,Enhancing Model Robustness and Fairness with Causality: A Regularization Approach,2021,https://arxiv.org/abs/2110.00911,"Recent work has raised concerns on the risk of spurious correlations and unintended biases in statistical machine learning models that threaten model robustness and fairness. In this paper, we propose a simple and intuitive regularization approach to integrate causal knowledge during model training and build a robust and fair model by emphasizing causal features and de-emphasizing spurious features. Specifically, we first manually identify causal and spurious features with principles inspired from the counterfactual framework of causal inference. Then, we propose a regularization approach to penalize causal and spurious features separately. By adjusting the strength of the penalty for each type of feature, we build a predictive model that relies more on causal features and less on non-causal features. We conduct experiments to evaluate model robustness and fairness on three datasets with multiple metrics. Empirical results show that the new models built with causal awareness significantly improve model robustness with respect to counterfactual texts and model fairness with respect to sensitive attributes."
Kai Shu,Topic-preserving synthetic news generation: An adversarial deep reinforcement learning approach,2020,https://arxiv.org/abs/2010.16324,"Nowadays, there exist powerful language models such as OpenAI's GPT-2 that can generate readable text and can be fine-tuned to generate text for a specific domain. Considering GPT-2, it cannot directly generate synthetic news with respect to a given topic and the output of the language model cannot be explicitly controlled. In this paper, we study the novel problem of topic-preserving synthetic news generation. We propose a novel deep reinforcement learning-based method to control the output of GPT-2 with respect to a given news topic. When generating text using GPT-2, by default, the most probable word is selected from the vocabulary. Instead of selecting the best word each time from GPT-2's output, an RL agent tries to select words that optimize the matching of a given topic. In addition, using a fake news detector as an adversary, we investigate generating realistic news using our proposed method. In this paper, we consider realistic news as news that cannot be easily detected by a fake news classifier. Experimental results demonstrate the effectiveness of the proposed framework on generating topic-preserving news content than state-of-the-art baselines."
Kai Shu,"Challenges in Combating COVID-19 Infodemic - Data, Tools, and Ethics",2020,https://arxiv.org/abs/2005.13691,"While the COVID-19 pandemic continues its global devastation, numerous accompanying challenges emerge. One important challenge we face is to efficiently and effectively use recently gathered data and find computational tools to combat the COVID-19 infodemic, a typical information overloading problem. Novel coronavirus presents many questions without ready answers; its uncertainty and our eagerness in search of solutions offer a fertile environment for infodemic. It is thus necessary to combat the infodemic and make a concerted effort to confront COVID-19 and mitigate its negative impact in all walks of life when saving lives and maintaining normal orders during trying times. In this position paper of combating the COVID-19 infodemic, we illustrate its need by providing real-world examples of rampant conspiracy theories, misinformation, and various types of scams that take advantage of human kindness, fear, and ignorance. We present three key challenges in this fight against the COVID-19 infodemic where researchers and practitioners instinctively want to contribute and help. We demonstrate that these three challenges can and will be effectively addressed by collective wisdom, crowdsourcing, and collaborative research."
Kai Shu,Cross-domain fake news detection on social media: A context-aware adversarial approach,2022,https://link.springer.com/chapter/10.1007/978-981-19-1524-6_9,"People nowadays increasingly consume information from social media due to its convenience and fast dissemination. However, social media also accelerate the propagation of disinformation and fake news, causing detrimental effects. Thus, detecting fake news is a critical task for benefiting individuals and society. However, it is a non-trivial task due to the expensive annotation cost and the diverse nature of news domains. Thus, it is important to exploit auxiliary information to help improve prediction performance. We develop a deep architecture to exploit both cross-domain knowledge transfer and within-domain joint modeling of news content, user comments, and user-news interactions for fake news detection. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed method, even with limited labeled data in the target domain."
Kai Shu,Advances in Social Network Analysis and Mining in the Big Data Era: Overview of the IEEE/ACM ASONAM 2021 International Conference,2021,https://www.cs.emory.edu/~kshu5/files/ASONAM2021_chair.pdf,"This paper contains a summary of the research program of the 2021 IEEE/ACM International Conference on Advances in Social Network Analysis and Mining (ASONAM 2021), held as virtual event during November 8-11, 2021. In addition to this, following the research contributions presented in ASONAM 2021, we provide a brief overview on future research directions in social network analysis and mining."
Kai Shu,Benchmarking node outlier detection on graphs,2022,https://scholar.google.com/scholar?cluster=256759143775045271&hl=en&oi=scholarr,
Kai Shu,Dafd: Domain adaptation framework for fake news detection,2021,https://link.springer.com/chapter/10.1007/978-3-030-92185-9_25,"Nowadays, social media has become the leading platform for news dissemination and consumption. Due to the convenience of social media platforms, fake news spread at an unprecedented speed, which has brought severe adverse effects to society. In recent years, the method based on deep learning has shown superior performance in fake news detection. However, the training of this kind of model needs a large amount of labeled data. When a new domain of fake news appears, it usually contains only a small amount of labeled data. We proposed a novel Domain Adaptation framework for Fake news Detection named DAFD. It adopts a dual strategy based on domain adaptation and adversarial training, aligns the data distribution of the source domain and target domain during the pre-training process, and generates adversarial examples in the embedding space during the fine-tuning process to …"
Kai Shu,Combating Disinformation on Social Media: A Computational Perspective  ,2022,https://www.sciencedirect.com/science/article/pii/S2772485922000229,"The use of social media has accelerated information sharing and instantaneous communications. The low barrier to enter social media enables more users to participate and makes them stay engaged longer, while incentivizing individuals with a hidden agenda to use disinformation to manipulate information and influence opinions. Disinformation, such as fake news, hoaxes, and conspiracy theories, has increasingly been weaponized to divide people and create detrimental societal effects. Therefore, it is imperative to understand disinformation and systematically investigate how we can improve resistance against it, taking into account the tension between the need for information and the need for security and protection against disinformation. In this survey, we look into the concepts, methods, and recent advancements of detecting disinformation from a computational perspective. We will also discuss open issues …"
Kai Shu,Incorporating user-comment graph for fake news detection,2020,https://qiniu.pattern.swarma.org/pdf/arxiv/2011.01579.pdf,"Fake news refers to false and often inflammatory information disseminated under the guise of news reports. In this era of rapid development of social networks, fake news is common on social networks. Many bloggers choose to publish completely fake news because a large percentage of readers tend to share content without reading carefully, arXiv: 2011.01579 v1 [cs. SI] 3 Nov 2020"
Kai Shu,Fin-fact: A benchmark dataset for multimodal financial fact checking and explanation generation,2025,https://arxiv.org/abs/2309.08793,"Fact-checking in financial domain is under explored, and there is a shortage of quality dataset in this domain. In this paper, we propose Fin-Fact, a benchmark dataset for multimodal fact-checking within the financial domain. Notably, it includes professional fact-checker annotations and justifications, providing expertise and credibility. With its multimodal nature encompassing both textual and visual content, Fin-Fact provides complementary information sources to enhance factuality analysis. Its primary objective is combating misinformation in finance, fostering transparency, and building trust in financial reporting and news dissemination. By offering insightful explanations, Fin-Fact empowers users, including domain experts and end-users, to understand the reasoning behind fact-checking decisions, validating claim credibility, and fostering trust in the fact-checking process. The Fin-Fact dataset, along with our experimental codes is available at https://github.com/IIT-DM/Fin-Fact/."
Kai Shu,Fair classification via domain adaptation: A dual adversarial learning approach,2023,https://www.frontiersin.org/articles/10.3389/fdata.2022.1049565/full,"Modern machine learning (ML) models are becoming increasingly popular and are widely used in decision-making systems. However, studies have shown critical issues of ML discrimination and unfairness, which hinder their adoption on high-stake applications. Recent research on fair classifiers has drawn significant attention to developing effective algorithms to achieve fairness and good classification performance. Despite the great success of these fairness-aware machine learning models, most of the existing models require sensitive attributes to pre-process the data, regularize the model learning or post-process the prediction to have fair predictions. However, sensitive attributes are often incomplete or even unavailable due to privacy, legal or regulation restrictions. Though we lack the sensitive attribute for training a fair model in the target domain, there might exist a similar domain that has sensitive attributes. Thus, it is important to exploit auxiliary information from a similar domain to help improve fair classification in the target domain. Therefore, in this paper, we study a novel problem of exploring domain adaptation for fair classification. We propose a new framework that can learn to adapt the sensitive attributes from a source domain for fair classification in the target domain. Extensive experiments on real-world datasets illustrate the effectiveness of the proposed model for fair classification, even when no sensitive attributes are available in the target domain."
Kai Shu,"Authorship Attribution in the Era of LLMs: Problems, Methodologies, and Challenges",2024,https://dl.acm.org/doi/abs/10.1145/3715073.3715076,"Accurate attribution of authorship is crucial for maintaining the integrity of digital content, improving forensic investigations, and mitigating the risks of misinformation and plagiarism. Addressing the imperative need for proper authorship attribution is essential to uphold the credibility and accountability of authentic authorship. The rapid advancements of Large Language Models (LLMs) have blurred the lines between human and machine authorship, posing significant challenges for traditional methods. We present a comprehensive literature review that examines the latest research on authorship attribution in the era of LLMs. This survey systematically explores the landscape of this field by categorizing four representative problems: (1) Human-written Text Attribution; (2) LLM-generated Text Detection; (3) LLM-generated Text Attribution; and (4) Human-LLM Co-authored Text Attribution. We also discuss the challenges …"
Kai Shu,Re-search for the truth: Multi-round retrieval-augmented large language models are strong fake news detectors,2024,https://arxiv.org/abs/2403.09747,"The proliferation of fake news has had far-reaching implications on politics, the economy, and society at large. While Fake news detection methods have been employed to mitigate this issue, they primarily depend on two essential elements: the quality and relevance of the evidence, and the effectiveness of the verdict prediction mechanism. Traditional methods, which often source information from static repositories like Wikipedia, are limited by outdated or incomplete data, particularly for emerging or rare claims. Large Language Models (LLMs), known for their remarkable reasoning and generative capabilities, introduce a new frontier for fake news detection. However, like traditional methods, LLM-based solutions also grapple with the limitations of stale and long-tail knowledge. Additionally, retrieval-enhanced LLMs frequently struggle with issues such as low-quality evidence retrieval and context length constraints. To address these challenges, we introduce a novel, retrieval-augmented LLMs framework--the first of its kind to automatically and strategically extract key evidence from web sources for claim verification. Employing a multi-round retrieval strategy, our framework ensures the acquisition of sufficient, relevant evidence, thereby enhancing performance. Comprehensive experiments across three real-world datasets validate the framework's superiority over existing methods. Importantly, our model not only delivers accurate verdicts but also offers human-readable explanations to improve result interpretability."
Kai Shu,Investigating online financial misinformation and its consequences: A computational perspective,2023,https://arxiv.org/abs/2309.12363,"The rapid dissemination of information through digital platforms has revolutionized the way we access and consume news and information, particularly in the realm of finance. However, this digital age has also given rise to an alarming proliferation of financial misinformation, which can have detrimental effects on individuals, markets, and the overall economy. This research paper aims to provide a comprehensive survey of online financial misinformation, including its types, sources, and impacts. We first discuss the characteristics and manifestations of financial misinformation, encompassing false claims and misleading content. We explore various case studies that illustrate the detrimental consequences of financial misinformation on the economy. Finally, we highlight the potential impact and implications of detecting financial misinformation. Early detection and mitigation strategies can help protect investors, enhance market transparency, and preserve financial stability. We emphasize the importance of greater awareness, education, and regulation to address the issue of online financial misinformation and safeguard individuals and businesses from its harmful effects. In conclusion, this research paper sheds light on the pervasive issue of online financial misinformation and its wide-ranging consequences. By understanding the types, sources, and impacts of misinformation, stakeholders can work towards implementing effective detection and prevention measures to foster a more informed and resilient financial ecosystem."
Kai Shu,"Method and apparatus for collecting, detecting and visualizing fake news",2022,https://patents.google.com/patent/US11494446B2/en,"Detecting fake news involves analyzing a distribution of publishers who publish many news articles, analyzing a distribution of various topics relating to the published news articles, analyzing a social media context relating to the published news articles, and detecting fake news articles among the news articles based on the analysis of the distribution of publishers, the analysis of the distribution of the various topics, and the analysis of the social media context. Detecting fake news alternatively involves receiv ing online news articles including both fake online news articles and real online news articles, creating a hierarchical macro-level propagation network of the fake online news and real online news articles, the hierarchical macro-level propagation network comprising news nodes, social media post nodes, and social media repost nodes, creating a hier archical micro-level propagation network of the fake online …"
Kai Shu,Spatial community-informed evolving graphs for demand prediction,2020,https://link.springer.com/chapter/10.1007/978-3-030-67670-4_27,"The rapidly increasing number of sharing bikes has facilitated people’s daily commuting significantly. However, the number of available bikes in different stations may be imbalanced due to the free check-in and check-out of users. Therefore, predicting the bike demand in each station is an important task in a city to satisfy requests in different stations. Recent works mainly focus on demand prediction in settled stations, which ignore the realistic scenarios that bike stations may be deployed or removed. To predict station-level demands with evolving new stations, we face two main challenges: (1) How to effectively capture new interactions in time-evolving station networks; (2) How to learn spatial patterns for new stations due to the limited historical data. To tackle these challenges, we propose a novel Spatial Community-informed Evolving Graphs (SCEG) framework to predict station-level demands, which …"
Kai Shu,From Creation to Clarification: ChatGPT's Journey Through the Fake News Quagmire,2024,https://dl.acm.org/doi/abs/10.1145/3589335.3651509,"The rampant spread of fake news has adversely affected society, resulting in extensive research on curbing its spread. As a notable milestone in large language models (LLMs), ChatGPT has gained significant attention due to its exceptional capabilities. In this study, we present an exploration of ChatGPT's proficiency in generating, explaining, and detecting fake news as follows.Generation -- We employ different prompt methods to generate fake news and prove the high quality of these instances through both self-assessment and human evaluation.Explanation -- We obtain nine features to characterize fake news based on ChatGPT's explanations and analyze the distribution of these factors across multiple public datasets.Detection -- We examine ChatGPT's capacity to identify fake news. We propose a reason-aware prompt method to improve its performance. We further probe into the potential extra information …"
Kai Shu,TAP: A Comprehensive Data Repository for Traffic Accident Prediction in Road Networks,2023,https://dl.acm.org/doi/abs/10.1145/3589132.3625655,"Road safety is a major global public health concern, and effective prediction of traffic accidents at a fine-grained spatial scale plays a critical role in reducing roadway deaths and serious injuries. However, previous studies have either overlooked implicit spatial correlations or inadequately simulated road structures due to the lack of graph-structured datasets. To bridge this gap, we introduce a graph-based Traffic Accident Prediction (TAP) data repository, along with two representative tasks: accident occurrence and severity prediction. With its real-world graph structures, comprehensive geographical coverage, and rich geospatial features, this repository has considerable potential to facilitate various traffic-related tasks. We extensively evaluate eleven Graph Neural Network (GNN) baselines using the constructed datasets. We also develop a novel GNN-based model, which can capture additional angular and …"
Kai Shu,FinD: Fine-Grained Discrepancy-based Fake News Detection,2022,,
Kai Shu,Model Attribution in Machine-Generated Disinformation: A Domain Generalization Approach with Supervised Contrastive Learning,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240721264B/abstract,"Model attribution for machine-generated disinformation poses a significant challenge in understanding its origins and mitigating its spread. This task is especially challenging because modern large language models (LLMs) produce disinformation with human-like quality. Additionally, the diversity in prompting methods used to generate disinformation complicates accurate source attribution. These methods introduce domain-specific features that can mask the fundamental characteristics of the models. In this paper, we introduce the concept of model attribution as a domain generalization problem, where each prompting method represents a unique domain. We argue that an effective attribution model must be invariant to these domain-specific features. It should also be proficient in identifying the originating models across all scenarios, reflecting real-world detection challenges. To address this, we introduce a novel …"
Kai Shu,PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot Learners,2023,https://arxiv.org/abs/2205.09229,"Recent advances in large pre-trained language models (PLMs) lead to impressive gains in natural language understanding (NLU) tasks with task-specific fine-tuning. However, directly fine-tuning PLMs heavily relies on sufficient labeled training instances, which are usually hard to obtain. Prompt-based tuning on PLMs has shown to be powerful for various downstream few-shot tasks. Existing works studying prompt-based tuning for few-shot NLU tasks mainly focus on deriving proper label words with a verbalizer or generating prompt templates to elicit semantics from PLMs. In addition, conventional data augmentation strategies such as synonym substitution, though widely adopted in low-resource scenarios, only bring marginal improvements for prompt-based few-shot learning. Thus, an important research question arises: how to design effective data augmentation methods for prompt-based few-shot tuning? To this end, considering the label semantics are essential in prompt-based tuning, we propose a novel label-guided data augmentation framework PromptDA, which exploits the enriched label semantic information for data augmentation. Extensive experiment results on few-shot text classification tasks demonstrate the superior performance of the proposed framework by effectively leveraging label semantics and data augmentation for natural language understanding. Our code is available at https://github.com/canyuchen/PromptDA."
Kai Shu,A Model-Agnostic Approach to Differentially Private Topic Mining,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539417,"Topic mining extracts patterns and insights from text data (e.g., documents, emails and product reviews), which can be used in various applications such as intent detection. However, topic mining can result in severe privacy threats to the users who have contributed to the text corpus since they can be re-identified from the text data with certain background knowledge. To our best knowledge, we propose the first differentially private topic mining technique (namely TopicDP) which injects well-calibrated Gaussian noise into the matrix output of any topic mining algorithm to ensure differential privacy and good utility. Specifically, we smoothen the sensitivity for the Gaussian mechanism via sensitivity sampling, which addresses the major challenges resulted from the high sensitivity in topic mining for differential privacy. Furthermore, we theoretically prove the differential privacy guarantee under the Rényi differential …"
Kai Shu,When fairness meets privacy: Fair classification with semi-private sensitive attributes,2022,https://arxiv.org/abs/2207.08336,"Machine learning models have demonstrated promising performance in many areas. However, the concerns that they can be biased against specific demographic groups hinder their adoption in high-stake applications. Thus, it is essential to ensure fairness in machine learning models. Most previous efforts require direct access to sensitive attributes for mitigating bias. Nonetheless, it is often infeasible to obtain large-scale users' sensitive attributes considering users' concerns about privacy in the data collection process. Privacy mechanisms such as local differential privacy (LDP) are widely enforced on sensitive information in the data collection stage due to legal compliance and people's increasing awareness of privacy. Therefore, a critical problem is how to make fair predictions under privacy. We study a novel and practical problem of fair classification in a semi-private setting, where most of the sensitive attributes are private and only a small amount of clean ones are available. To this end, we propose a novel framework FairSP that can achieve Fair prediction under the Semi-Private setting. First, FairSP learns to correct the noise-protected sensitive attributes by exploiting the limited clean sensitive attributes. Then, it jointly models the corrected and clean data in an adversarial way for debiasing and prediction. Theoretical analysis shows that the proposed model can ensure fairness under mild assumptions in the semi-private setting. Extensive experimental results on real-world datasets demonstrate the effectiveness of our method for making fair predictions under privacy and maintaining high accuracy."
Kai Shu,On fair classification with mostly private sensitive attributes,2022,https://scholar.google.com/scholar?cluster=14034038192776003142&hl=en&oi=scholarr,
Kai Shu,"Racial Attacks during the COVID‐19 Pandemic: Politicizing an Epidemic Crisis on Longstanding Racism and Misinformation, Disinformation, and Misconception",2021,https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.501,"The COVID‐19 pandemic crisis has affected everyone's life on a daily basis for more than a year. However, some racial groups have experienced a double pandemic, that of COVID‐19 and racist attacks incorrectly tied to the pandemic. Harassment and physical intimidation were the source of many anti‐Asian attacks. The number of unarmed black people assaulted and killed by police almost tripled during 2020 when compared 2019. In this panel, we will attempt to analyze recent racial attacks in terms of malinformation, such as misinformation, disinformation, or shallow, historical stereotypes of ethnic minorities as another layer of the pandemic originating with racism or inflamed grievances. The panelists will discuss the proposed topic drawing from each panelist's expertise and an interactive discussion with the audience will follow after each panelist's presentation. Members and attendees at ASIS&T who have …"
Kai Shu,"Disinformation in the online information ecosystem: detection, mitigation and challenges",2020,https://arxiv.org/abs/2010.09113,"With the rapid increase in access to internet and the subsequent growth in the population of online social media users, the quality of information posted, disseminated and consumed via these platforms is an issue of growing concern. A large fraction of the common public turn to social media platforms and in general the internet for news and even information regarding highly concerning issues such as COVID-19 symptoms. Given that the online information ecosystem is extremely noisy, fraught with misinformation and disinformation, and often contaminated by malicious agents spreading propaganda, identifying genuine and good quality information from disinformation is a challenging task for humans. In this regard, there is a significant amount of ongoing research in the directions of disinformation detection and mitigation. In this survey, we discuss the online disinformation problem, focusing on the recent 'infodemic' in the wake of the coronavirus pandemic. We then proceed to discuss the inherent challenges in disinformation research, and then elaborate on the computational and interdisciplinary approaches towards mitigation of disinformation, after a short overview of the various directions explored in detection efforts."
Kai Shu,Can Knowledge Editing Really Correct Hallucinations?,2025,https://arxiv.org/abs/2410.16251,"Large Language Models (LLMs) suffer from hallucinations, referring to the non-factual information in generated content, despite their superior capacities across tasks. Meanwhile, knowledge editing has been developed as a new popular paradigm to correct the erroneous factual knowledge encoded in LLMs with the advantage of avoiding retraining from scratch. However, one common issue of existing evaluation datasets for knowledge editing is that they do not ensure LLMs actually generate hallucinated answers to the evaluation questions before editing. When LLMs are evaluated on such datasets after being edited by different techniques, it is hard to directly adopt the performance to assess the effectiveness of different knowledge editing methods in correcting hallucinations. Thus, the fundamental question remains insufficiently validated: Can knowledge editing really correct hallucinations in LLMs? We proposed HalluEditBench to holistically benchmark knowledge editing methods in correcting real-world hallucinations. First, we rigorously construct a massive hallucination dataset with 9 domains, 26 topics and more than 6,000 hallucinations. Then, we assess the performance of knowledge editing methods in a holistic way on five dimensions including Efficacy, Generalization, Portability, Locality, and Robustness. Through HalluEditBench, we have provided new insights into the potentials and limitations of different knowledge editing methods in correcting hallucinations, which could inspire future improvements and facilitate the progress in the field of knowledge editing."
Kai Shu,"Method and apparatus for collecting, detecting and visualizing fake news",2021,,
Kai Shu,Systems and methods for a privacy preserving text representation learning framework,2023,https://patents.google.com/patent/US11763093B2/en,Various embodiments of a computer-implemented system which learns textual representations while filtering out potentially personally identifying data and retaining semantic meaning within the textual representations are disclosed herein.
Kai Shu,Hybrid PDES Simulation of HPC Networks using Zombie Packets,2023,https://dl.acm.org/doi/abs/10.1145/3573900.3591122,"High-fidelity network simulations provide insights into new realms for high-performance computing (HPC) architectures, although at a high cost. Surrogate models offer a significant reduction in runtime, yet they cannot serve as complete replacements and should be only used when appropriate. Thus the need for hybrid modeling, where high-fidelity simulation and surrogates run side-by-side. We present a surrogate model for HPC networks in which packets bypass the network, and the network state itself is suspended when switching to the surrogate. To bypass the network, every packet is scheduled to arrive at a predicted time in the future estimated from historical data; to suspend the network, all in-flight packets are delivered to their destinations, but they are kept in the system to awaken as zombies when switching back to high-fidelity. Speedup for a hybrid model is relative to the proportion of surrogate to high …"
Kai Shu,Taxonomy-Guided Zero-Shot Recommendations with LLMs,2025,https://arxiv.org/abs/2406.14043,"With the emergence of large language models (LLMs) and their ability to perform a variety of tasks, their application in recommender systems (RecSys) has shown promise. However, we are facing significant challenges when deploying LLMs into RecSys, such as limited prompt length, unstructured item information, and un-constrained generation of recommendations, leading to sub-optimal performance. To address these issues, we propose a novel method using a taxonomy dictionary. This method provides a systematic framework for categorizing and organizing items, improving the clarity and structure of item information. By incorporating the taxonomy dictionary into LLM prompts, we achieve efficient token utilization and controlled feature generation, leading to more accurate and contextually relevant recommendations. Our Taxonomy-guided Recommendation (TaxRec) approach features a two-step process: one-time taxonomy categorization and LLM-based recommendation, enabling zero-shot recommendations without the need for domain-specific fine-tuning. Experimental results demonstrate TaxRec significantly enhances recommendation quality compared to traditional zero-shot approaches, showcasing its efficacy as personal recommender with LLMs. Code is available at https://github.com/yueqingliang1/TaxRec."
Kai Shu,MetaGAD: Learning to Meta Transfer for Few-shot Graph Anomaly Detection,2024,https://www.researchgate.net/profile/Canyu-Chen-3/publication/370869574_MetaGAD_Learning_to_Meta_Transfer_for_Few-shot_Graph_Anomaly_Detection/links/646fb9956a3c4c6efbdfae3b/MetaGAD-Learning-to-Meta-Transfer-for-Few-shot-Graph-Anomaly-Detection.pdf,"Graph anomaly detection has long been an important problem in various domains pertaining to information security such as financial fraud, social spam, network intrusion, etc. The majority of existing methods are performed in an unsupervised manner, as labeled anomalies in a large scale are often too expensive to acquire. However, the identified anomalies may turn out to be data noises or uninteresting data instances due to the lack of prior knowledge on the anomalies. In realistic scenarios, it is often feasible to obtain limited labeled anomalies, which have great potential to advance graph anomaly detection. However, the work exploring limited labeled anomalies and a large amount of unlabeled nodes in graphs to detect anomalies is rather limited. Therefore, in this paper, we study a novel problem of few-shot graph anomaly detection. We propose a new framework MetaGAD to learn to meta-transfer the knowledge between unlabeled and labeled nodes for graph anomaly detection. Experimental results on six real-world datasets with synthetic anomalies and"" organic"" anomalies (available in the dataset) demonstrate the effectiveness of the proposed approach in detecting anomalies with limited labeled anomalies."
Kai Shu,Integrating multimodal and longitudinal neuroimaging data with multi-source network representation learning,2022,https://link.springer.com/article/10.1007/s12021-021-09523-w,"Uncovering the complex network of the brain is of great interest to the field of neuroimaging. Mining from these rich datasets, scientists try to unveil the fundamental biological mechanisms in the human brain. However, neuroimaging data collected for constructing brain networks is generally costly, and thus extracting useful information from a limited sample size of brain networks is demanding. Currently, there are two common trends in neuroimaging data collection that could be exploited to gain more information: 1) multimodal data, and 2) longitudinal data. It has been shown that these two types of data provide complementary information. Nonetheless, it is challenging to learn brain network representations that can simultaneously capture network properties from multimodal as well as longitudinal datasets. Here we propose a general fusion framework for multi-source learning of brain networks – multimodal brain …"
Kai Shu,Labeled Data Generation with Inexact Supervision,2021,https://dl.acm.org/doi/abs/10.1145/3447548.3467306,"The recent advanced deep learning techniques have shown the promising results in various domains such as computer vision and natural language processing. The success of deep neural networks in supervised learning heavily relies on a large amount of labeled data. However, obtaining labeled data with target labels is often challenging due to various reasons such as cost of labeling and privacy issues, which challenges existing deep models. In spite of that, it is relatively easy to obtain data with inexact supervision, i.e., having labels/tags related to the target task. For example, social media platforms are overwhelmed with billions of posts and images with self-customized tags, which are not the exact labels for target classification tasks but are usually related to the target labels. It is promising to leverage these tags (inexact supervision) and their relations with target classes to generate labeled data to facilitate …"
Kai Shu,"On the trustworthiness of generative foundation models: Guideline, assessment, and perspective",2025,https://arxiv.org/abs/2502.14296,"Generative Foundation Models (GenFMs) have emerged as transformative tools. However, their widespread adoption raises critical concerns regarding trustworthiness across dimensions. This paper presents a comprehensive framework to address these challenges through three key contributions. First, we systematically review global AI governance laws and policies from governments and regulatory bodies, as well as industry practices and standards. Based on this analysis, we propose a set of guiding principles for GenFMs, developed through extensive multidisciplinary collaboration that integrates technical, ethical, legal, and societal perspectives. Second, we introduce TrustGen, the first dynamic benchmarking platform designed to evaluate trustworthiness across multiple dimensions and model types, including text-to-image, large language, and vision-language models. TrustGen leverages modular components--metadata curation, test case generation, and contextual variation--to enable adaptive and iterative assessments, overcoming the limitations of static evaluation methods. Using TrustGen, we reveal significant progress in trustworthiness while identifying persistent challenges. Finally, we provide an in-depth discussion of the challenges and future directions for trustworthy GenFMs, which reveals the complex, evolving nature of trustworthiness, highlighting the nuanced trade-offs between utility and trustworthiness, and consideration for various downstream applications, identifying persistent challenges and providing a strategic roadmap for future research. This work establishes a holistic framework for advancing trustworthiness in …"
Kai Shu,Understanding the concerns and choices of public when using large language models for healthcare,2024,https://arxiv.org/abs/2401.09090,"Large language models (LLMs) have shown their potential in biomedical fields. However, how the public uses them for healthcare purposes such as medical Q\&A, self-diagnosis, and daily healthcare information seeking is under-investigated. This paper adopts a mixed-methods approach, including surveys (N=214) and interviews (N=17) to investigate how and why the public uses LLMs for healthcare. We found that participants generally believed LLMs as a healthcare tool have gained popularity, and are often used in combination with other information channels such as search engines and online health communities to optimize information quality. Based on the findings, we reflect on the ethical and effective use of LLMs for healthcare and propose future research directions."
Kai Shu,Beyond detection: Unveiling fairness vulnerabilities in abusive language models,2023,https://arxiv.org/abs/2311.09428,"This work investigates the potential of undermining both fairness and detection performance in abusive language detection. In a dynamic and complex digital world, it is crucial to investigate the vulnerabilities of these detection models to adversarial fairness attacks to improve their fairness robustness. We propose a simple yet effective framework FABLE that leverages backdoor attacks as they allow targeted control over the fairness and detection performance. FABLE explores three types of trigger designs (i.e., rare, artificial, and natural triggers) and novel sampling strategies. Specifically, the adversary can inject triggers into samples in the minority group with the favored outcome (i.e., ""non-abusive"") and flip their labels to the unfavored outcome, i.e., ""abusive"". Experiments on benchmark datasets demonstrate the effectiveness of FABLE attacking fairness and utility in abusive language detection."
Kai Shu,Combating disinformation on social media and its challenges: A computational perspective,2023,https://ojs.aaai.org/index.php/AAAI/article/view/26821,"The use of social media has accelerated information sharing and instantaneous communications. The low barrier to entering social media enables more users to participate and keeps them engaged longer, incentivizing individuals with a hidden agenda to spread disinformation online to manipulate information and sway opinion. Disinformation, such as fake news, hoaxes, and conspiracy theories, has increasingly become a hindrance to the functioning of online social media as an effective channel for trustworthy information. Therefore, it is imperative to understand disinformation and systematically investigate how to improve resistance against it. This article highlights relevant theories and recent advancements of detecting disinformation from a computational perspective, and urges the need for future interdisciplinary research."
Kai Shu,Machine Learning for Interconnect Network Traffic Forecasting: Investigation and Exploitation,2023,https://dl.acm.org/doi/abs/10.1145/3573900.3591123," Interconnect networks play a key role in high-performance computing (HPC) systems. Parallel discrete event simulation (PDES) has been a long-standing pillar for studying large-scale networking systems by replicating the real-world behaviors of HPC facilities. However, the simulation requirements and computational complexity of PDES are growing at an intractable rate. An active research topic is to build a surrogate-ready PDES framework where an accurate surrogate model built on machine learning can be used to forecast network traffic for improving PDES. In this paper, we make the first attempt to introduce two representative time series methods, the Autoregressive Integrated Moving Average (ARIMA) and the Adaptive Long Short-Term Memory (ADP-LSTM), to forecast the traffic in interconnect networks, using the Dragonfly system as a representative example. The proposed ADP-LSTM can efficiently adapt …"
Kai Shu,WALNUT: A Benchmark on Semi-weakly Supervised Learning for Natural Language Understanding.,2022,https://arxiv.org/abs/2108.12603,"Building machine learning models for natural language understanding (NLU) tasks relies heavily on labeled data. Weak supervision has been proven valuable when large amount of labeled data is unavailable or expensive to obtain. Existing works studying weak supervision for NLU either mostly focus on a specific task or simulate weak supervision signals from ground-truth labels. It is thus hard to compare different approaches and evaluate the benefit of weak supervision without access to a unified and systematic benchmark with diverse tasks and real-world weak labeling rules. In this paper, we propose such a benchmark, named WALNUT (semi-WeAkly supervised Learning for Natural language Understanding Testbed), to advocate and facilitate research on weak supervision for NLU. WALNUT consists of NLU tasks with different types, including document-level and token-level prediction tasks. WALNUT is the first semi-weakly supervised learning benchmark for NLU, where each task contains weak labels generated by multiple real-world weak sources, together with a small set of clean labels. We conduct baseline evaluations on WALNUT to systematically evaluate the effectiveness of various weak supervision methods and model architectures. Our results demonstrate the benefit of weak supervision for low-resource NLU tasks and highlight interesting patterns across tasks. We expect WALNUT to stimulate further research on methodologies to leverage weak supervision more effectively. The benchmark and code for baselines are available at \url{aka.ms/walnut_benchmark}."
Kai Shu,Emulating Reader Behaviors for Fake News Detection,2025,https://ieeexplore.ieee.org/abstract/document/10834537/,"The wide dissemination of fake news has affected our lives in many aspects, making fake news detection important and attracting increasing attention. Existing approaches make substantial contributions in this field by modeling news from a single-modal or multi-modal perspective. However, these modal-based methods can result in sub-optimal outcomes as they ignore reader behaviors in news consumption and authenticity verification. For instance, they haven't taken into consideration the component-by-component reading process: from the headline, images, comments, to the body, which is essential for modeling news with more granularity. To this end, we propose an approach of  Em ulating the  be haviors of  r eaders (Ember) for fake news detection on social media, incorporating readers' reading and verificating process to model news from the component perspective thoroughly. Specifically, we first construct …"
Kai Shu,SST: Multi-Scale Hybrid Mamba-Transformer Experts for Long-Short Range Time Series Forecasting,2024,https://arxiv.org/abs/2404.14757,"Despite significant progress in time series forecasting, existing forecasters often overlook the heterogeneity between long-range and short-range time series, leading to performance degradation in practical applications. In this work, we highlight the need of distinct objectives tailored to different ranges. We point out that time series can be decomposed into global patterns and local variations, which should be addressed separately in long- and short-range time series. To meet the objectives, we propose a multi-scale hybrid Mamba-Transformer experts model State Space Transformer (SST). SST leverages Mamba as an expert to extract global patterns in coarse-grained long-range time series, and Local Window Transformer (LWT), the other expert to focus on capturing local variations in fine-grained short-range time series. With an input-dependent mechanism, State Space Model (SSM)-based Mamba is able to selectively retain long-term patterns and filter out fluctuations, while LWT employs a local window to enhance locality-awareness capability, thus effectively capturing local variations. To adaptively integrate the global patterns and local variations, a long-short router dynamically adjusts contributions of the two experts. SST achieves superior performance with scaling linearly  on time series length . The comprehensive experiments demonstrate the SST can achieve SOTA results in long-short range time series forecasting while maintaining low memory footprint and computational cost. The code of SST is available at https://github.com/XiongxiaoXu/SST."
Kai Shu,ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges,2025,https://arxiv.org/abs/2412.05206,"Computational argumentation, which involves generating answers or summaries for controversial topics like abortion bans and vaccination, has become increasingly important in today's polarized environment. Sophisticated LLM capabilities offer the potential to provide nuanced, evidence-based answers to such questions through Retrieval-Augmented Argumentation (RAArg), leveraging real-world evidence for high-quality, grounded arguments. However, evaluating RAArg remains challenging, as human evaluation is costly and difficult for complex, lengthy answers on complicated topics. At the same time, re-using existing argumentation datasets is no longer sufficient, as they lack long, complex arguments and realistic evidence from potentially misleading sources, limiting holistic evaluation of retrieval effectiveness and argument quality. To address these gaps, we investigate automated evaluation methods using multiple fine-grained LLM judges, providing better and more interpretable assessments than traditional single-score metrics and even previously reported human crowdsourcing. To validate the proposed techniques, we introduce ConQRet, a new benchmark featuring long and complex human-authored arguments on debated topics, grounded in real-world websites, allowing an exhaustive evaluation across retrieval effectiveness, argument quality, and groundedness. We validate our LLM Judges on a prior dataset and the new ConQRet benchmark. Our proposed LLM Judges and the ConQRet benchmark can enable rapid progress in computational argumentation and can be naturally extended to other complex retrieval-augmented …"
Kai Shu,Piecing It All Together: Verifying Multi-Hop Multimodal Claims,2025,https://arxiv.org/abs/2411.09547,"Existing claim verification datasets often do not require systems to perform complex reasoning or effectively interpret multimodal evidence. To address this, we introduce a new task: multi-hop multimodal claim verification. This task challenges models to reason over multiple pieces of evidence from diverse sources, including text, images, and tables, and determine whether the combined multimodal evidence supports or refutes a given claim. To study this task, we construct MMCV, a large-scale dataset comprising 16k multi-hop claims paired with multimodal evidence, generated and refined using large language models, with additional input from human feedback. We show that MMCV is challenging even for the latest state-of-the-art multimodal large language models, especially as the number of reasoning hops increases. Additionally, we establish a human performance benchmark on a subset of MMCV. We hope this dataset and its evaluation task will encourage future research in multimodal multi-hop claim verification."
Kai Shu,ClinicalBench: Can LLMs Beat Traditional ML Models in Clinical Prediction?,2024,https://arxiv.org/abs/2411.06469,"Large Language Models (LLMs) hold great promise to revolutionize current clinical systems for their superior capacities on medical text processing tasks and medical licensing exams. Meanwhile, traditional ML models such as SVM and XGBoost have still been mainly adopted in clinical prediction tasks. An emerging question is Can LLMs beat traditional ML models in clinical prediction? Thus, we build a new benchmark ClinicalBench to comprehensively study the clinical predictive modeling capacities of both general-purpose and medical LLMs, and compare them with traditional ML models. ClinicalBench embraces three common clinical prediction tasks, two databases, 14 general-purpose LLMs, 8 medical LLMs, and 11 traditional ML models. Through extensive empirical investigation, we discover that both general-purpose and medical LLMs, even with different model scales, diverse prompting or fine-tuning strategies, still cannot beat traditional ML models in clinical prediction yet, shedding light on their potential deficiency in clinical reasoning and decision-making. We call for caution when practitioners adopt LLMs in clinical applications. ClinicalBench can be utilized to bridge the gap between LLMs' development for healthcare and real-world clinical practice."
Kai Shu,Investigating Gender Euphoria and Dysphoria on TikTok: Characterization and Comparison,2024,https://link.springer.com/chapter/10.1007/978-3-031-78548-1_24,"With the emergence of short video-sharing platforms, engagement with social media sites devoted to opinion and knowledge dissemination has rapidly increased. Among these platforms, TikTok is one of the most popular globally and has become the platform of choice for transgender and nonbinary individuals, who have formed a large community to mobilize personal experience and exchange information. The knowledge produced in online spaces can influence the ways in which people understand and experience their own gender and transitions, as they hear about others and weigh experiential and medical knowledge against their own. This paper extends current research and past interview methods on gender euphoria and gender dysphoria to analyze what and how online communities on TikTok discuss these two types of gender experiences. Our findings indicate that gender euphoria and gender …"
Kai Shu,Special issue on “Learning to combat online hostile posts in regional languages during emergency situations”,2022,https://www.sciencedirect.com/science/article/pii/S0925231222005999,"The current special issue of Neurocomputing was designed to encourage researchers from interdisciplinary domains working on multilingual social media analytics to think beyond the conventional way of combating online hostile posts. The special issue was primarily based on the theme of the First Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situation (CONSTRAINT) (https://lcs2.iiitd.edu.in/CONSTRAINT-2021/), held with AAAI'2021. We invited a few good quality papers accepted in CONSTRAINT to submit an extended version. We also made the call open for the general audience. The special issue broadly focused on three major points: (i) Regional language: the offensive posts under inspection may be written in low-resource regional languages (e.g., Tamil, Urdu, Bangali, Polish, Czech, Lithuanian, etc.). (ii) Emergency situation: The proposed solutions should be …"
Kai Shu,WHO public health research agenda for managing infodemics,2021,https://openaccess.city.ac.uk/id/eprint/30055/,"BackgroundAn “infodemic” is an overabundance of information–some accurate and some not–that occurs during an epidemic. Early use of the term was in 2003, blending the words information and epidemic1, following previous information epidemic discussions2. An infodemic spreads between humans in a similar manner to an epidemic, via digital and physical information systems. It makes it hard for people to find trustworthy sources and reliable guidance when they need it."
Kai Shu,The 5th international workshop on mining actionable insights from social networks (Maison 2020),2020,https://www.cs.emory.edu/~kshu5/files/cikm_workshop.pdf,"For the fifth edition of the workshop on Mining Actionable Insights from Social Networks (MAISoN), we organized a special edition with focus on dis/misinformation mining from social media, colocated with CIKM 2020. This topic has attracted a lot of interest from the community since the Coronavirus (COVID-19) epidemic has given rise to an increase of misinformation on social media. The aim of this edition was to bring together researchers from different disciplines interested in mining dis/misinformation on social media. In particular, the distinguishing focus of this special edition was its emphasis on techniques that use social media data for building diagnostic, predictive and prescriptive analysis models related to misinformation. This means that there is rigorous attention for techniques that can be used to understand how and why dis/misinformation is created and spread, to uncover hidden and unexpected aspects of dis/misinformation content, and to recommend insightful countermeasures to restrict the circulation of dis/misinformation and alleviate their negative effects."
Kai Shu,Can Multimodal LLMs Perform Time Series Anomaly Detection?,2025,https://arxiv.org/abs/2502.17812,"Large language models (LLMs) have been increasingly used in time series analysis. However, the potential of multimodal LLMs (MLLMs), particularly vision-language models, for time series remains largely under-explored. One natural way for humans to detect time series anomalies is through visualization and textual description. Motivated by this, we raise a critical and practical research question: Can multimodal LLMs perform time series anomaly detection? To answer this, we propose VisualTimeAnomaly benchmark to evaluate MLLMs in time series anomaly detection (TSAD). Our approach transforms time series numerical data into the image format and feed these images into various MLLMs, including proprietary models (GPT-4o and Gemini-1.5) and open-source models (LLaVA-NeXT and Qwen2-VL), each with one larger and one smaller variant. In total, VisualTimeAnomaly contains 12.4k time series images spanning 3 scenarios and 3 anomaly granularities with 9 anomaly types across 8 MLLMs. Starting with the univariate case (point- and range-wise anomalies), we extend our evaluation to more practical scenarios, including multivariate and irregular time series scenarios, and variate-wise anomalies. Our study reveals several key insights: 1) MLLMs detect range- and variate-wise anomalies more effectively than point-wise anomalies. 2) MLLMs are highly robust to irregular time series, even with 25% of the data missing. 3) Open-source MLLMs perform comparably to proprietary models in TSAD. While open-source MLLMs excel on univariate time series, proprietary MLLMs demonstrate superior effectiveness on multivariate time series …"
Kai Shu,Systems and methods for unsupervised cyberbullying detection via time-informed Gaussian mixture model,2024,https://patents.google.com/patent/US11916866B2/en,"A computer-implemented framework and/or system for cyberbullying detection is disclosed. The system includes two main components:(1) A representation learning network that encodes the social media session by exploiting multi-modal features, eg, text, network, and time; and (2) a multi-task learning network that simultaneously fits the comment inter-arrival times and estimates the bullying likelihood based on a Gaussian Mixture Model. The system jointly optimizes the parameters of both components to overcome the shortcomings of decoupled training. The system includes an unsupervised cyberbullying detection model that not only experimentally outperforms the state-of-the-art unsupervised models, but also achieves competitive performance compared to supervised models."
Kai Shu,CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection,2023,https://arxiv.org/abs/2311.11473,"Graph Neural Networks (GNNs) have emerged as a powerful tool for representation learning on graphs, but they often suffer from overfitting and label noise issues, especially when the data is scarce or imbalanced. Different from the paradigm of previous methods that rely on single-node confidence, in this paper, we introduce a novel Class-wise Selection for Graph Neural Networks, dubbed CSGNN, which employs a neighbor-aggregated latent space to adaptively select reliable nodes across different classes. Specifically, 1) to tackle the class imbalance issue, we introduce a dynamic class-wise selection mechanism, leveraging the clustering technique to identify clean nodes based on the neighbor-aggregated confidences. In this way, our approach can avoid the pitfalls of biased sampling which is common with global threshold techniques. 2) To alleviate the problem of noisy labels, built on the concept of the memorization effect, CSGNN prioritizes learning from clean nodes before noisy ones, thereby iteratively enhancing model performance while mitigating label noise. Through extensive experiments, we demonstrate that CSGNN outperforms state-of-the-art methods in terms of both effectiveness and robustness."
Kai Shu,Unleashing the Power of Twitter: A Data Analysis of the US Senate's Social Media Strategy using Unsupervised Machine Learning,2023,https://openreview.net/forum?id=nGmeqyvK10,"Social media, such as Twitter, plays a crucial role in political discourse and communication. It is the window of voters to their candidates, and what senators publish may determine their success in the elections. A deep analysis is needed to comprehend the current situation and generate strategies to reach the audience. This paper joins the creation of a self-made dataset, using machine learning topic models, analyzing how geography influences the political landscape, and employing a proposed popularity metric to explain the current political landscape and provide insights about the most influential senators and their discourse."
Kai Shu,Delving into Data Science Methods in Response to the COVID‐19 Infodemic,2022,https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/pra2.625,"The circulation of myriad of information from diverse digital platforms during the COVID‐19 pandemic caused the unprecedented infodemic. Along with the increased case numbers, the shared information accelerated exponentially, especially via social media, and a large proportion of the daily distributed information was blended with myth, rumors, pseudoscience, or modified facts. Uncovering viral mis‐ and disinformation narratives and information voids is essential to a swift and effective response on delivering public health information and policy by the governments during a public health emergency. Although many studies have examined how information was circulated and shared during the COVID‐19 pandemic era, large gaps in literature exist as to how effectively to track, describe, and answer it. In this panel, the panelists propose and discuss data science methods to analyze the COVID‐19 infodemic. We …"
Kai Shu,Foreword to the special issue on dis/misinformation mining from social media,2022,https://www.sciencedirect.com/science/article/pii/S0306457321003228,"The enormity and high variance of the information that propagates through large user communities on social media influences the public discourse in society and sets trends and agendas in topics that range from marketing, education, business and medicine to politics, technology, and the entertainment industry. This influence can however act as a double-edged sword, since it can also introduce threats to the community, if it is rooted in dissemination of disinformation, ie, purposefully manipulated news and information, or misinformation, ie, false and incorrect information, on social networks.In recent years, the potential threats of dis/misinformation have been the subject of huge controversy in different domains like public healthcare systems, socio-economics, business and politics. For instance, the circulation of scientifically invalid information and news can negatively affect the way the public responds to the …"
Kai Shu,Joint Local and Global Sequence Modeling in Temporal Correlation Networks for Trending Topic Detection,2020,https://dl.acm.org/doi/abs/10.1145/3394231.3397924,"Trending topics represent the topics that are becoming increasingly popular and attract a sudden spike in human attention. Trending topics are critical and useful in modern search engines, which can not only enhance user engagements but also improve user search experiences. Large volumes of user search queries over time are indicative aggregated user interests and thus provide rich information for detecting trending topics. The topics derived from query logs can be naturally treated as a temporal correlation network, suggesting both local and global trending signals. The local signals represent the trending/non-trending information within each frequency sequence, and the global correlation signals denote the relationships across frequency sequences. We hypothesize that integrating local and global signals can benefit trending topic detection. In an attempt to jointly exploit the complementary information of …"
Kai Shu,Understanding Disinformation: Learning with Weak Social Supervision,2020,https://search.proquest.com/openview/b5f984a3b348cbd6408e05914d6e23d0/1?pq-origsite=gscholar&cbl=44156,"Social media has become an important means of user-centered information sharing and communications in a gamut of domains, including news consumption, entertainment, marketing, public relations, and many more. The low cost, easy access, and rapid dissemination of information on social media draws a large audience but also exacerbate the wide propagation of disinformation including fake news, ie, news with intentionally false information. Disinformation on social media is growing fast in volume and can have detrimental societal effects. Despite the importance of this problem, our understanding of disinformation in social media is still limited. Recent advancements of computational approaches on detecting disinformation and fake news have shown some early promising results. Novel challenges are still abundant due to its complexity, diversity, dynamics, multi-modality, and costs of fact-checking or …"
Kai Shu,Graph with Sequence: Broad-Range Semantic Modeling for Fake News Detection,2025,https://arxiv.org/abs/2412.05672,"The rapid proliferation of fake news on social media threatens social stability, creating an urgent demand for more effective detection methods. While many promising approaches have emerged, most rely on content analysis with limited semantic depth, leading to suboptimal comprehension of news content.To address this limitation, capturing broader-range semantics is essential yet challenging, as it introduces two primary types of noise: fully connecting sentences in news graphs often adds unnecessary structural noise, while highly similar but authenticity-irrelevant sentences introduce feature noise, complicating the detection process. To tackle these issues, we propose BREAK, a broad-range semantics model for fake news detection that leverages a fully connected graph to capture comprehensive semantics while employing dual denoising modules to minimize both structural and feature noise. The semantic structure denoising module balances the graph's connectivity by iteratively refining it between two bounds: a sequence-based structure as a lower bound and a fully connected graph as the upper bound. This refinement uncovers label-relevant semantic interrelations structures. Meanwhile, the semantic feature denoising module reduces noise from similar semantics by diversifying representations, aligning distinct outputs from the denoised graph and sequence encoders using KL-divergence to achieve feature diversification in high-dimensional space. The two modules are jointly optimized in a bi-level framework, enhancing the integration of denoised semantics into a comprehensive representation for detection. Extensive experiments …"
Kai Shu,Strigolactone signaling: Insights into rice tillering and nitrogen deficiency responses,2025,https://www.the-innovation.org/article/doi/10.59717/j.xinn-life.2025.100137,"Strigolactone signaling: Insights into rice tillering and nitrogen deficiency responses 2.{{subColumn.name}} 
2.{{journal.title}} {{journal.title}} 2.{{subColumn.name}} Article search All Journals {{newsColumn.name}} 
3.{{subColumn.name}} The Innovation Life > Accepted COMMENTARY Open Access Cite 
PDF Strigolactone signaling: Insights into rice tillering and nitrogen deficiency responses 
Wenguan Zhou 1 , Weiqiang Li 2, , , Lam-Son Phan Tran 3 , Kai Shu 1,4, , 1. Shaanxi Key 
Laboratory of Qinling Ecological Intelligent Monitoring and Protection, School of Ecology 
and Environment, Northwestern Polytechnical University, Xi’an 710129, China 2. Jilin Da'an 
Agro-ecosystem National Observation and Research Station, Northeast Institute of 
Geography and Agroecology, Chinese Academy of Sciences, Changchun 130102, China 3. 
Institute of Genomics for Crop Abiotic Stress Tolerance, Department of Plant and Soil …"
Kai Shu,Benchmarking LLMs for Political Science: A United Nations Perspective,2025,https://arxiv.org/abs/2502.14122,"Large Language Models (LLMs) have achieved significant advances in natural language processing, yet their potential for high-stake political decision-making remains largely unexplored. This paper addresses the gap by focusing on the application of LLMs to the United Nations (UN) decision-making process, where the stakes are particularly high and political decisions can have far-reaching consequences. We introduce a novel dataset comprising publicly available UN Security Council (UNSC) records from 1994 to 2024, including draft resolutions, voting records, and diplomatic speeches. Using this dataset, we propose the United Nations Benchmark (UNBench), the first comprehensive benchmark designed to evaluate LLMs across four interconnected political science tasks: co-penholder judgment, representative voting simulation, draft adoption prediction, and representative statement generation. These tasks span the three stages of the UN decision-making process--drafting, voting, and discussing--and aim to assess LLMs' ability to understand and simulate political dynamics. Our experimental analysis demonstrates the potential and challenges of applying LLMs in this domain, providing insights into their strengths and limitations in political science. This work contributes to the growing intersection of AI and political science, opening new avenues for research and practical applications in global governance. The UNBench Repository can be accessed at: https://github.com/yueqingliang1/UNBench."
Kai Shu,Understanding and Tackling Label Errors in Individual-Level Nature Language Understanding,2025,https://arxiv.org/abs/2502.13297,"Natural language understanding (NLU) is a task that enables machines to understand human language. Some tasks, such as stance detection and sentiment analysis, are closely related to individual subjective perspectives, thus termed individual-level NLU. Previously, these tasks are often simplified to text-level NLU tasks, ignoring individual factors. This not only makes inference difficult and unexplainable but often results in a large number of label errors when creating datasets. To address the above limitations, we propose a new NLU annotation guideline based on individual-level factors. Specifically, we incorporate other posts by the same individual and then annotate individual subjective perspectives after considering all individual posts. We use this guideline to expand and re-annotate the stance detection and topic-based sentiment analysis datasets. We find that error rates in the samples were as high as 31.7\% and 23.3\%. We further use large language models to conduct experiments on the re-annotation datasets and find that the large language models perform well on both datasets after adding individual factors. Both GPT-4o and Llama3-70B can achieve an accuracy greater than 87\% on the re-annotation datasets. We also verify the effectiveness of individual factors through ablation studies. We call on future researchers to add individual factors when creating such datasets. Our re-annotation dataset can be found at https://github.com/24yearsoldstudent/Individual-NLU"
Kai Shu,Multi-modal Robustness Fake News Detection with Cross-Modal and Propagation Network Contrastive Learning,2025,https://www.sciencedirect.com/science/article/pii/S0950705124014345,"Social media has transformed the landscape of news dissemination, characterized by its rapid, extensive, and diverse content, coupled with the challenge of verifying authenticity. The proliferation of multimodal news on these platforms has presented novel obstacles in detecting fake news. Existing approaches typically focus on single modalities, such as text or images, or combine text and image content or with propagation network data. However, the potential for more robust fake news detection lies in considering three modalities simultaneously. In addition, the heavy reliance on labeled data in current detection methods proves time-consuming and costly. To address these challenges, we propose a novel approach, Multi-modal Robustness Fake News Detection with Cross-Modal and Propagation Network Contrastive Learning (MFCL). This method integrates intrinsic features from text, images, and propagation …"
Kai Shu,Online Energy Optimization in GPUs: A Multi-Armed Bandit Approach,2024,https://arxiv.org/abs/2410.11855,"Energy consumption has become a critical design metric and a limiting factor in the development of future computing architectures, from small wearable devices to large-scale leadership computing facilities. The predominant methods in energy management optimization are focused on CPUs. However, GPUs are increasingly significant and account for the majority of energy consumption in heterogeneous high performance computing (HPC) systems. Moreover, they typically rely on either purely offline training or a hybrid of offline and online training, which are impractical and lead to energy loss during data collection. Therefore, this paper studies a novel and practical online energy optimization problem for GPUs in HPC scenarios. The problem is challenging due to the inherent performance-energy trade-offs of GPUs, the exploration & exploitation dilemma across frequencies, and the lack of explicit performance counters in GPUs. To address these challenges, we formulate the online energy consumption optimization problem as a multi-armed bandit framework and develop a novel bandit based framework EnergyUCB. EnergyUCB is designed to dynamically adjust GPU core frequencies in real-time, reducing energy consumption with minimal impact on performance. Specifically, the proposed framework EnergyUCB (1) balances the performance-energy trade-off in the reward function, (2) effectively navigates the exploration & exploitation dilemma when adjusting GPU core frequencies online, and (3) leverages the ratio of GPU core utilization to uncore utilization as a real-time GPU performance metric. Experiments on a wide range of real-world …"
Kai Shu,Joint learning from explicit and inferred labels,2024,https://patents.google.com/patent/US12073326B2/en,"This document relates to training of machine learning models. One example method involves providing a machine learning model having a first classification layer, a second classification layer, and an encoder that feeds into the first classification layer and the second classification layer. The example method also involves obtaining first training examples having explicit labels and second training examples having inferred labels. The inferred labels are based at least on actions associated with the second training examples. The example method also involves training the machine learning model using the first training examples and the second training examples using a training objective that considers first training loss of the first classification layer for the explicit labels and second training loss of the second classification layer for the inferred labels. The method also involves outputting a trained machine learning …"
Kai Shu,EML: Emotion-Aware Meta Learning for Cross-Event False Information Detection,2024,https://dl.acm.org/doi/abs/10.1145/3661485,"Modern social media’s development has dramatically changed how people obtain information. However, the wide dissemination of various false information has severe detrimental effects. Accordingly, many deep learning-based methods have been proposed to detect false information and achieve promising results. However, these methods are unsuitable for new events due to the extremely limited labeled data and their discrepant data distribution to existing events. Domain adaptation methods have been proposed to mitigate these problems. However, their performance is suboptimal because they are not sensitive to new events due to they aim to align the domain information between existing events, and they hardly capture the fine-grained difference between real and fake claims by only using semantic information. Therefore, we propose a novel Emotion-aware Meta Learning (EML) approach for cross-event …"
Kai Shu,Surrogate Modeling for HPC Application Iteration Times Forecasting with Network Features,2024,https://dl.acm.org/doi/abs/10.1145/3615979.3656055," Interconnect networks are the foundation for modern high performance computing (HPC) systems. Parallel discrete event simulation (PDES), serving as a cornerstone in the study of large-scale networking systems by modeling and simulating the real-world behaviors of HPC facilities, faces escalating computational complexities at an unsustainable scale. The research community is interested in building a surrogate-ready PDES framework where an accurate surrogate model can be used to forecast HPC behaviors and replace computationally expensive PDES phases. In this paper, we focus on forecasting application iteration times, the key indicator of large-scale networking performance, with network features, such as bandwidth-consumed and busy time on routers. We introduce five representative methods, including LAST, Average, ARIMA, LSTM, and the proposed framework LSTM-Feat, to forecast the iteration …"
Kai Shu,LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models,2024,https://arxiv.org/abs/2405.18776,"Differentially Private Stochastic Gradient Descent (DP-SGD) and its variants have been proposed to ensure rigorous privacy for fine-tuning large-scale pre-trained language models. However, they rely heavily on the Gaussian mechanism, which may overly perturb the gradients and degrade the accuracy, especially in stronger privacy regimes (e.g., the privacy budget ). To address such limitations, we propose a novel Language Model-based Optimal Differential Privacy (LMO-DP) mechanism, which takes the first step to enable the tight composition of accurately fine-tuning (large) language models with a sub-optimal DP mechanism, even in strong privacy regimes (e.g., ). Furthermore, we propose a novel offline optimal noise search method to efficiently derive the sub-optimal DP that significantly reduces the noise magnitude. For instance, fine-tuning RoBERTa-large (with 300M parameters) on the SST-2 dataset can achieve an accuracy of 92.20% (given , ) by drastically outperforming the Gaussian mechanism (e.g.,  for small  and ). We also draw similar findings on the text generation tasks on GPT-2. Finally, to our best knowledge, LMO-DP is also the first solution to accurately fine-tune Llama-2 with strong differential privacy guarantees. The code will be released soon and available upon request."
Kai Shu,Fine-Grained Discrepancy Contrastive Learning for Robust Fake News Detection,2024,https://ieeexplore.ieee.org/abstract/document/10448066/,"In recent years, fake news on social media has become a significant threat to societal security, elevating fake news detection to a research priority. Among various strategies, fact-checking detection methods stand out for their accuracy, leveraging evidence from dedicated fact databases. However, these methods often retrieve raw truth, including vast amounts of irrelevant data, based on semantic similarity. This approach results in information redundancy and risks missing the nuanced differences between fake news and the truth. As a result, subtle changes in fake news can greatly increase the risk of misclassification, compromising the methods’ robustness. To this end, we propose a robust fake news detection framework with Fine-grained Discrepancy Contrastive Learning (FinDCL). By simulating subtle discrepancies between fake news and event-related truth, our method enhances the capture and identification …"
Kai Shu,EML: Emotion-Aware Meta Learning for Cross-Event False Information Detection,2024,,
Kai Shu,Systems and methods for a cross media joint friend and item recommendation framework,2024,https://patents.google.com/patent/US20240020735A1/en,"G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR"
Kai Shu,"Benchmarking, Measuring, and Optimizing",2024,https://link.springer.com/content/pdf/10.1007/978-981-97-0316-6.pdf,"The Bench symposium invites papers addressing pressing problems in benchmarking, measuring, and optimizing systems. The call for papers for the Bench 2023 conference attracted a number of high-quality submissions. These underwent a thorough review by at least four international experts. Ultimately, the program committee selected 11 papers for presentation at Bench 2023. The papers in this volume have been revised as per the program committee’s recommendations. At the conference, the International Open Benchmark Council (BenchCouncil) presented the BenchCouncil Achievement Award, recognizing a senior member for their enduring contributions to the field. Lieven Eeckhout from the Ghent University, Belgium, was named the 2023 recipient of the BenchCouncil Achievement Award. In the award’s keynote address, Eeckhout emphasized the importance of rigorous performance evaluation …"
Kai Shu,Joint learning from explicit and inferred labels,2023,https://patents.google.com/patent/US11816566B2/en,Appl. No.: 16/876.931 This document relates to training of machine learning mod-
Kai Shu,Hybrid PDES Simulation of HPC Networks using Zombie Packets,2023,https://indigo.uic.edu/articles/conference_contribution/Hybrid_PDES_Simulation_of_HPC_Networks_using_Zombie_Packets/26072548/1/files/47164987.pdf,"High-fidelity network simulations provide insights into new realms for high-performance computing (HPC) architectures, although at a high cost. Surrogate models offer a significant reduction in runtime, yet they cannot serve as complete replacements and should be only used when appropriate. Thus the need for hybrid modeling, where high-fidelity simulation and surrogates run side-by-side. We present a surrogate model for HPC networks in which packets bypass the network, and the network state itself is suspended when switching to the surrogate. To bypass the network, every packet is scheduled to arrive at a predicted time in the future estimated from historical data; to suspend the network, all in-flight packets are delivered to their destinations, but they are kept in the system to awaken as zombies when switching back to high-fidelity. Speedup for a hybrid model is relative to the proportion of surrogate to high-fidelity. We obtained a 3× speedup for a simulation where 70% of virtual time was spent in surrogate mode. When considering the surrogate portion only, the speedup jumps to nearly 20× on a uniform random network traffic example. The accuracy of the overall simulation increased when the network state was suspended instead of ignored, which demonstrates the need for modeling the network state when transitioning from surrogate back to high-fidelity mode."
Kai Shu,Adversarial Approach,2022,https://books.google.com/books?hl=en&lr=&id=lOlxEAAAQBAJ&oi=fnd&pg=PA215&dq=info:XIe-DhpGoKcJ:scholar.google.com&ots=lXIvjIOOEy&sig=FCN-09FGLT_yGGqPosdZzolyrYQ,"People nowadays increasingly consume information from social media due to its convenience and fast dissemination. However, social media also accelerate the propagation of disinformation and fake news, causing detrimental effects. Thus, detecting fake news is a critical task for benefiting individuals and society. However, it is a non-trivial task due to the expensive annotation cost and the diverse nature of news domains. Thus, it is important to exploit auxiliary information to help improve prediction performance. We develop a deep architecture to exploit both cross-domain knowledge transfer and within-domain joint modeling of news content, user comments, and user-news interactions for fake news detection. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed method, even with limited labeled data in the target domain."
Kai Shu,Proceedings of the Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situations,2022,https://aclanthology.org/2022.constraint-1.0.pdf,"The advent of Web 2.0 induced the evolution of what has traditionally been described as a “participatory Web”. From pop-culture music to Black Friday becoming a global phenomenon, and movements like BlackLivesMatter turning into a powerful instrument of global resistance, the Internet and social media have played a pivotal role. As much as we relish the connectedness facilitated by social media, the sentient being in all of us cannot remain obscured by the perils of the unabated misuse of the very free speech that these platforms aim to empower. Within the shadows of a transparent yet anonymous social media, lurk those disguising themselves as pseudo-flag-bearers of free speech, and pounce on every opportunity they get to spread vile content, detrimental to society. Such miscreants are desperate to misuse those 280 character sound bites to further their anti-openness agendas in the form of hate speech, disinformation, and ill-intended propaganda. Such menace experiences flare-ups during emergency situations such as the COVID-19 outbreak and geopolitically conflicting global order. There have been numerous efforts toward addressing some of these problems computationally, but with evolving complexities of online harmful content, more robust solutions are needed. Some of these challenges stem from linguistic diversity, abstract semiotics, multimodality, anonymity of the real instigators, etc. Thus, there is a pressing need to start a discussion around such aspects, which are more inclusive than conventional efforts. With this in mind, and motivated by the success of the first edition of the CONSTRAINT Workshop on Combating …"
Kai Shu,Systems and methods for a cross media joint friend and item recommendation framework,2021,,
Kai Shu,The Second International MIS2 Workshop: Misinformation and Misbehavior Mining on the Web,2021,https://dl.acm.org/doi/abs/10.1145/3447548.3469443,"Misinformation and misbehavior mining on the web (MIS2) workshop is held virtually on August 14, 2021 and is co-located with the ACM SIGKDD 2021 conference. The web has become a breeding ground for misbehavior and misinformation. It is timely and crucial to understand, detect, forecast, and mitigate their harm. MIS2 workshop as an interdisciplinary venue for researchers and practitioners who study the dark side of the web. The workshop program includes a peer-reviewed set of paper presentations and keynote talks, giving the attendees an immersive experience of this research field."
Kai Shu,The 5th International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2020) Special Edition on Dis/Misinformation Mining from Social media,2020,https://dl.acm.org/doi/abs/10.1145/3340531.3414078,"For the fifth edition of the workshop on Mining Actionable Insights from Social Networks (MAISoN), we organized a special edition with focus on dis/misinformation mining from social media, co-located with CIKM 2020. This topic has attracted a lot of interest from the community since the Coronavirus (COVID-19) epidemic has given rise to an increase of misinformation on social media. The aim of this edition was to bring together researchers from different disciplines interested in mining dis/misinformation on social media. In particular, the distinguishing focus of this special edition was its emphasis on techniques that use social media data for building diagnostic, predictive and prescriptive analysis models related to misinformation. This means that there is rigorous attention for techniques that can be used to understand how and why dis/misinformation is created and spread, to uncover hidden and unexpected aspects …"
Shengpu Tang,Evaluating a widely implemented proprietary deterioration index model among hospitalized patients with COVID-19,2021,https://www.atsjournals.org/doi/abs/10.1513/AnnalsATS.202006-698OC,"Rationale: The Epic Deterioration Index (EDI) is a proprietary prediction model implemented in over 100 U.S. hospitals that was widely used to support medical decision-making during the coronavirus disease (COVID-19) pandemic. The EDI has not been independently evaluated, and other proprietary models have been shown to be biased against vulnerable populations.Objectives: To independently evaluate the EDI in hospitalized patients with COVID-19 overall and in disproportionately affected subgroups.Methods: We studied adult patients admitted with COVID-19 to units other than the intensive care unit at a large academic medical center from March 9 through May 20, 2020. We used the EDI, calculated at 15-minute intervals, to predict a composite outcome of intensive care unit–level care, mechanical ventilation, or in-hospital death. In a subset of patients hospitalized for at least 48 hours, we also evaluated …"
Shengpu Tang,Democratizing EHR analyses with FIDDLE: a flexible data-driven preprocessing pipeline for structured clinical data,2020,https://academic.oup.com/jamia/article-abstract/27/12/1921/5920826,"In applying machine learning (ML) to electronic health record (EHR) data, many decisions must be made before any ML is applied; such preprocessing requires substantial effort and can be labor-intensive. As the role of ML in health care grows, there is an increasing need for systematic and reproducible preprocessing techniques for EHR data. Thus, we developed FIDDLE (Flexible Data-Driven Pipeline), an open-source framework that streamlines the preprocessing of data extracted from the EHR.Largely data-driven, FIDDLE systematically transforms structured EHR data into feature vectors, limiting the number of decisions a user must make while incorporating good practices from the literature. To demonstrate its utility and flexibility, we conducted a proof-of-concept experiment in which we applied FIDDLE to 2 publicly available EHR data …"
Shengpu Tang,Model selection for offline reinforcement learning: Practical considerations for healthcare settings,2021,https://proceedings.mlr.press/v149/tang21a.html,"Reinforcement learning (RL) can be used to learn treatment policies and aid decision making in healthcare. However, given the need for generalization over complex state/action spaces, the incorporation of function approximators (eg, deep neural networks) requires model selection to reduce overfitting and improve policy performance at deployment. Yet a standard validation pipeline for model selection requires running a learned policy in the actual environment, which is often infeasible in a healthcare setting. In this work, we investigate a model selection pipeline for offline RL that relies on off-policy evaluation (OPE) as a proxy for validation performance. We present an in-depth analysis of popular OPE methods, highlighting the additional hyperparameters and computational requirements (fitting/inference of auxiliary models) when used to rank a set of candidate policies. We compare the utility of different OPE methods as part of the model selection pipeline in the context of learning to treat patients with sepsis. Among all the OPE methods we considered, fitted Q evaluation (FQE) consistently leads to the best validation ranking, but at a high computational cost. To balance this trade-off between accuracy of ranking and computational efficiency, we propose a simple two-stage approach to accelerate model selection by avoiding potentially unnecessary computation. Our work serves as a practical guide for offline RL model selection and can help RL practitioners select policies using real-world datasets. To facilitate reproducibility and future extensions, the code accompanying this paper is available online"
Shengpu Tang,Early identification of patients admitted to hospital for covid-19 at risk of clinical deterioration: model development and multisite external validation study,2022,https://www.bmj.com/content/376/bmj-2021-068576.short,"To create and validate a simple and transferable machine learning model from electronic health record data to accurately predict clinical deterioration in patients with covid-19 across institutions, through use of a novel paradigm for model development and code sharing.Retrospective cohort study.One US hospital during 2015-21 was used for model training and internal validation. External validation was conducted on patients admitted to hospital with covid-19 at 12 other US medical centers during 2020-21.33 119 adults (≥18 years) admitted to hospital with respiratory distress or covid-19.An ensemble of linear models was trained on the development cohort to predict a composite outcome of clinical deterioration within the first five days of hospital admission, defined as in-hospital mortality or any of three treatments indicating severe illness …"
Shengpu Tang,Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare,2022,https://proceedings.neurips.cc/paper_files/paper/2022/hash/dda7f9378a210c25e470e19304cce85d-Abstract-Conference.html,"Many reinforcement learning (RL) applications have combinatorial action spaces, where each action is a composition of sub-actions. A standard RL approach ignores this inherent factorization structure, resulting in a potential failure to make meaningful inferences about rarely observed sub-action combinations; this is particularly problematic for offline settings, where data may be limited. In this work, we propose a form of linear Q-function decomposition induced by factored action spaces. We study the theoretical properties of our approach, identifying scenarios where it is guaranteed to lead to zero bias when used to approximate the Q-function. Outside the regimes with theoretical guarantees, we show that our approach can still be useful because it leads to better sample efficiency without necessarily sacrificing policy optimality, allowing us to achieve a better bias-variance trade-off. Across several offline RL problems using simulators and real-world datasets motivated by healthcare, we demonstrate that incorporating factored action spaces into value-based RL can result in better-performing policies. Our approach can help an agent make more accurate inferences within underexplored regions of the state-action space when applying RL to observational datasets."
Shengpu Tang,Predicting acute graft-versus-host disease using machine learning and longitudinal vital sign data from electronic health records,2020,https://ascopubs.org/doi/abs/10.1200/CCI.19.00105,"Acute graft-versus-host disease (aGVHD) remains a significant complication of allogeneic hematopoietic cell transplantation (HCT) and limits its broader application. The ability to predict grade II to IV aGVHD could potentially mitigate morbidity and mortality. To date, researchers have focused on using snapshots of a patient (eg, biomarkers at a single time point) to predict aGVHD onset. We hypothesized that longitudinal data collected and stored in electronic health records (EHRs) could distinguish patients at high risk of developing aGVHD from those at low risk.The study included a cohort of 324 patients undergoing allogeneic HCT at the University of Michigan C.S. Mott Children’s Hospital during 2014 to 2017. Using EHR data, specifically vital sign measurements collected within the first 10 days of transplantation, we built a predictive model using penalized logistic …"
Shengpu Tang,Clinician-in-the-loop decision making: Reinforcement learning with near-optimal set-valued policies,2020,http://proceedings.mlr.press/v119/tang20c.html?ref=https://giter.site,"Standard reinforcement learning (RL) aims to find an optimal policy that identifies the best action for each state. However, in healthcare settings, many actions may be near-equivalent with respect to the reward (eg, survival). We consider an alternative objective–learning set-valued policies to capture near-equivalent actions that lead to similar cumulative rewards. We propose a model-free algorithm based on temporal difference learning and a near-greedy heuristic for action selection. We analyze the theoretical properties of the proposed algorithm, providing optimality guarantees and demonstrate our approach on simulated environments and a real clinical task. Empirically, the proposed algorithm exhibits good convergence properties and discovers meaningful near-equivalent actions. Our work provides theoretical, as well as practical, foundations for clinician/human-in-the-loop decision making, in which humans (eg, clinicians, patients) can incorporate additional knowledge (eg, side effects, patient preference) when selecting among near-equivalent actions."
Shengpu Tang,Respecting Autonomy And Enabling Diversity: The Effect Of Eligibility And Enrollment On Research Data Demographics,2021,https://www.healthaffairs.org/doi/abs/10.1377/hlthaff.2021.01197,"Many promising advances in precision health and other Big Data research rely on large data sets to analyze correlations among genetic variants, behavior, environment, and outcomes to improve population health. But these data sets are generally populated with demographically homogeneous cohorts. We conducted a retrospective cohort study of patients at a major academic medical center during 2012–19 to explore how recruitment and enrollment approaches affected the demographic diversity of participants in its research biospecimen and data bank. We found that compared with the overall clinical population, patients who consented to enroll in the research data bank were significantly less diverse in terms of age, sex, race, ethnicity, and socioeconomic status. Compared with patients who were recruited for the data bank, patients who enrolled were younger and less likely to be Black or African American …"
Shengpu Tang,Predicting postoperative opioid use with machine learning and insurance claims in opioid-naïve patients,2021,https://www.sciencedirect.com/science/article/pii/S0002961021002154,"BackgroundThe clinical impact of postoperative opioid use requires accurate prediction strategies to identify at-risk patients. We utilize preoperative claims data to predict postoperative opioid refill and new persistent use in opioid-naïve patients.MethodsA retrospective study was conducted on 112,898 opioid-naïve adult postoperative patients from Optum’s de-identified Clinformatics® Data Mart database. Potential predictors included sociodemographic data, comorbidities, and prescriptions within one year prior to surgery.ResultsCompared to linear models, non-linear models led to modest improvements in predicting refills – area under the receiver operating characteristics curve (AUROC) 0.68 vs. 0.67 (p < 0.05) – and performed identically in predicting new persistent use – AUROC = 0.66. Undergoing major surgery, opioid prescriptions within 30 days prior to surgery, and abdominal pain were useful in predicting …"
Shengpu Tang,Counterfactual-Augmented Importance Sampling for Semi-Offline Policy Evaluation,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/25b15618c98ff0c4655df0c5a277e1c6-Abstract-Conference.html,"In applying reinforcement learning (RL) to high-stakes domains, quantitative and qualitative evaluation using observational data can help practitioners understand the generalization performance of new policies. However, this type of off-policy evaluation (OPE) is inherently limited since offline data may not reflect the distribution shifts resulting from the application of new policies. On the other hand, online evaluation by collecting rollouts according to the new policy is often infeasible, as deploying new policies in these domains can be unsafe. In this work, we propose a semi-offline evaluation framework as an intermediate step between offline and online evaluation, where human users provide annotations of unobserved counterfactual trajectories. While tempting to simply augment existing data with such annotations, we show that this naive approach can lead to biased results. Instead, we design a new family of OPE estimators based on importance sampling (IS) and a novel weighting scheme that incorporate counterfactual annotations without introducing additional bias. We analyze the theoretical properties of our approach, showing its potential to reduce both bias and variance compared to standard IS estimators. Our analyses reveal important practical considerations for handling biased, noisy, or missing annotations. In a series of proof-of-concept experiments involving bandits and a healthcare-inspired simulator, we demonstrate that our approach outperforms purely offline IS estimators and is robust to imperfect annotations. Our framework, combined with principled human-centered design of annotation solicitation, can enable the application …"
Shengpu Tang,MIMIC-III and eICU-CRD: Feature Representation by FIDDLE Preprocessing,2021,https://www.physionet.org/content/mimic-eicu-fiddle-feature/1.0.0/,"This is a preprocessed dataset derived from patient records in MIMIC-III and eICU, two large-scale electronic health record (EHR) databases. It contains features and labels for 5 prediction tasks involving 3 adverse outcomes (prediction times listed in parentheses): in-hospital mortality (48h), acute respiratory failure (4h and 12h), and shock (4h and 12h). We extracted comprehensive, high-dimensional feature representations (up to~ 8,000 features) using FIDDLE (FlexIble Data-Driven pipeLinE), an open-source preprocessing pipeline for structured clinical data. These 5 prediction tasks were designed in consultation with a critical care physician for their clinical importance, and were used as part of the proof-of-concept experiments in the original paper to demonstrate FIDDLE's utility in aiding the feature engineering step of machine learning model development. The intent of this release is to share preprocessed MIMIC-III and eICU datasets used in the experiments to support and enable reproducible machine learning research on EHR data."
Shengpu Tang,Leveraging factored action spaces for off-policy evaluation,2023,https://arxiv.org/abs/2307.07014,"Off-policy evaluation (OPE) aims to estimate the benefit of following a counterfactual sequence of actions, given data collected from executed sequences. However, existing OPE estimators often exhibit high bias and high variance in problems involving large, combinatorial action spaces. We investigate how to mitigate this issue using factored action spaces i.e. expressing each action as a combination of independent sub-actions from smaller action spaces. This approach facilitates a finer-grained analysis of how actions differ in their effects. In this work, we propose a new family of ""decomposed"" importance sampling (IS) estimators based on factored action spaces. Given certain assumptions on the underlying problem structure, we prove that the decomposed IS estimators have less variance than their original non-decomposed versions, while preserving the property of zero bias. Through simulations, we empirically verify our theoretical results, probing the validity of various assumptions. Provided with a technique that can derive the action space factorisation for a given problem, our work shows that OPE can be improved ""for free"" by utilising this inherent problem structure."
Shengpu Tang,Machine learning for health (ML4H) 2022,2022,https://proceedings.mlr.press/v193/parziale22a.html,"The second Machine Learning for Health (ML4H) symposium was held both virtually and in-person on November 28, 2022, in New Orleans, Louisiana, USA. Similar to the previous year’s symposium (Roy et al., 2021), ML4H was organized as a stand-alone event co-located with the Neural Information Processing Systems (NeurIPS) conference. This year, ML4H accepted a total of 80 submissions including 52 extended abstracts and 28 full-length proceedings papers. The symposium invited submissions comprising machine learning research on relevant problems in health and biomedicine. ML4H 2022 featured two submission tracks: a proceedings track, which encompassed full-length submissions of technically mature and rigorous work, and an extended abstract track, which would accept less mature, but innovative"
Shengpu Tang,Machine Learning for Health (ML4H) 2023,2023,https://proceedings.mlr.press/v225/hegselmann23a,"The third Machine Learning for Health (ML4H) symposium was held on December 10, 2023, in New Orleans, Louisiana, USA. Following the last two years (Roy et al., 2021; Parziale et al., 2022), the symposium was again a stand-alone event co-located with the Neural Information Processing Systems (NeurIPS) conference.ML4H 2023 invited high-quality submissions on relevant problems in a variety of health-related disciplines including healthcare, biomedicine, and public health. Two submission tracks were offered: the archival Proceedings track, and the non-archival Findings track. Proceedings were targeted at mature work with strong technical sophistication and a high impact to health. The Findings track looked for new ideas that could spark insightful discussion, serve as"
Shengpu Tang,Machine Learning for Health symposium 2022 -- Extended Abstract track,2022,https://arxiv.org/abs/2211.15564,"A collection of the extended abstracts that were presented at the 2nd Machine Learning for Health symposium (ML4H 2022), which was held both virtually and in person on November 28, 2022, in New Orleans, Louisiana, USA. Machine Learning for Health (ML4H) is a longstanding venue for research into machine learning for health, including both theoretical works and applied works. ML4H 2022 featured two submission tracks: a proceedings track, which encompassed full-length submissions of technically mature and rigorous work, and an extended abstract track, which would accept less mature, but innovative research for discussion. All the manuscripts submitted to ML4H Symposium underwent a double-blind peer-review process. Extended abstracts included in this collection describe innovative machine learning research focused on relevant problems in health and biomedicine."
Shengpu Tang,Towards Data-Driven Offline Simulations for Online Reinforcement Learning,2022,https://arxiv.org/abs/2211.07614,"Modern decision-making systems, from robots to web recommendation engines, are expected to adapt: to user preferences, changing circumstances or even new tasks. Yet, it is still uncommon to deploy a dynamically learning agent (rather than a fixed policy) to a production system, as it's perceived as unsafe. Using historical data to reason about learning algorithms, similar to offline policy evaluation (OPE) applied to fixed policies, could help practitioners evaluate and ultimately deploy such adaptive agents to production. In this work, we formalize offline learner simulation (OLS) for reinforcement learning (RL) and propose a novel evaluation protocol that measures both fidelity and efficiency of the simulation. For environments with complex high-dimensional observations, we propose a semi-parametric approach that leverages recent advances in latent state discovery in order to achieve accurate and efficient offline simulations. In preliminary experiments, we show the advantage of our approach compared to fully non-parametric baselines. The code to reproduce these experiments will be made available at https://github.com/microsoft/rl-offline-simulation."
Shengpu Tang,CANDOR: Counterfactual ANnotated DOubly Robust Off-Policy Evaluation,2024,https://arxiv.org/abs/2412.08052,"Off-policy evaluation (OPE) provides safety guarantees by estimating the performance of a policy before deployment. Recent work introduced IS+, an importance sampling (IS) estimator that uses expert-annotated counterfactual samples to improve behavior dataset coverage. However, IS estimators are known to have high variance; furthermore, the performance of IS+ deteriorates when annotations are imperfect. In this work, we propose a family of OPE estimators inspired by the doubly robust (DR) principle. A DR estimator combines IS with a reward model estimate, known as the direct method (DM), and offers favorable statistical guarantees. We propose three strategies for incorporating counterfactual annotations into a DR-inspired estimator and analyze their properties under various realistic settings. We prove that using imperfect annotations in the DM part of the estimator best leverages the annotations, as opposed to using them in the IS part. To support our theoretical findings, we evaluate the proposed estimators in three contextual bandit environments. Our empirical results show that when the reward model is misspecified and the annotations are imperfect, it is most beneficial to use the annotations only in the DM portion of a DR estimator. Based on these theoretical and empirical insights, we provide a practical guide for using counterfactual annotations in different realistic settings."
Shengpu Tang,Analysis of Complete Blood Count Data and Use in Classification Machine Learning Models to Predict Icans Incidence Following CAR-T Cell Therapy,2024,https://www.astctjournal.org/article/S2666-6367(24)00029-0/fulltext,"CD19 directed CAR-T cell therapies are increasingly used for treatment of hematological malignancies, however immune cell-associated neurotoxicity syndrome (ICANS), remains a challenge to predict and treat. We retrieved demographic and complete blood count (CBC) data from electronic health records (EHR) to evaluate whether this simple, accessible, and routinely collected data could be used to train classification machine learning (ML) models for prediction of ICANS.Demographic and CBC measures from n=96 patients treated for B-cell malignancies at the University of Michigan (UM) were analyzed for univariate significance at baseline (prior to lymphodepletion) and through day (D) 3 post CAR-T infusion. Complete datasets were available for n=76 patients. These were then used for feature selection and ML model training. Features found significant were used as inputs in binary …"
Shengpu Tang,Towards Clinically Applicable Reinforcement Learning,2024,https://deepblue.lib.umich.edu/handle/2027.42/194733,"In healthcare, clinicians constantly make decisions about when and how to treat each patient. These decisions are based on medical training and clinical experience, but they may not always be optimal. Reinforcement learning (RL) offers an appealing framework to create decision support tools that could assist clinicians in selecting appropriate treatments. Despite recent successes of RL in domains such as games and chat-bots, existing approaches are often incompatible with clinical decision-making problems in healthcare. In this thesis, we develop several methods to improve the applicability of RL, in particular, offline RL, for clinical settings.   First, to enable clinician-in-the-loop decision-making, we propose to learn set-valued policies to capture near-equivalent actions that achieve similar outcomes (e.g., survival). By providing multiple choices instead of a single best action, we allow clinicians to incorporate additional contextual knowledge (e.g., cost, availability, patient preferences) when making final treatment decisions. Second, when different types of treatments need to be selected simultaneously, a standard approach for policy learning is inefficient as it considers a combinatorially large number of actions. To better leverage the structure of factored action spaces, we propose to use a linear decomposition of the Q-function. We show both theoretically and empirically that our approach makes more efficient use of limited data, leading to better policies. Third, we present a practical pipeline of model selection for offline RL - an issue often skirted by past work. Based on an in-depth analysis of various methods for offline policy evaluation (OPE …"
Shengpu Tang,Machine Learning for Health symposium 2023--Findings track,2023,https://arxiv.org/abs/2312.00655,"A collection of the accepted Findings papers that were presented at the 3rd Machine Learning for Health symposium (ML4H 2023), which was held on December 10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality submissions on relevant problems in a variety of health-related disciplines including healthcare, biomedicine, and public health. Two submission tracks were offered: the archival Proceedings track, and the non-archival Findings track. Proceedings were targeted at mature work with strong technical sophistication and a high impact to health. The Findings track looked for new ideas that could spark insightful discussion, serve as valuable resources for the community, or could enable new collaborations. Submissions to the Proceedings track, if not accepted, were automatically considered for the Findings track. All the manuscripts submitted to ML4H Symposium underwent a double-blind peer-review process."
Shengpu Tang,Proceedings of the 3rd Machine Learning for Health Symposium,2023,https://www.iris.unisa.it/handle/11386/4858746,"Proceedings of the 3rd Machine Learning for Health Symposium IRIS IRIS Home Sfoglia 
Macrotipologie & tipologie Autore Titolo Riviste Serie IT Italiano Italiano English English LOGIN 
1.IRIS 2.Catalogo Prodotti Ricerca 3.5 Curatela 4.5.3 Curatela con ISSN Proceedings of the 3rd 
Machine Learning for Health Symposium Parziale, Antonio; 2023-01-01 Scheda breve Scheda 
completa Scheda completa (DC) Anno 2023 Appare nelle tipologie: 5.3 Curatela con ISSN File 
in questo prodotto: Non ci sono file associati a questo prodotto. I documenti in IRIS sono protetti 
da copyright e tutti i diritti sono riservati, salvo diversa indicazione. Utilizza questo identificativo 
per citare o creare un link a questo documento: https://hdl.handle.net/11386/4858746 
Attenzione Attenzione! I dati visualizzati non sono stati sottoposti a validazione da parte 
dell'ateneo Citazioni ???jsp.display-item.citation.pmc??? ND Scopus ND ???jsp.display-…"
Emily Wall,"Left, right, and gender: Exploring interaction traces to mitigate human biases",2021,https://ieeexplore.ieee.org/abstract/document/9555923/,"Human biases impact the way people analyze data and make decisions. Recent work has shown that some visualization designs can better support cognitive processes and mitigate cognitive biases (i.e., errors that occur due to the use of mental “shortcuts”). In this work, we explore how visualizing a user's interaction history (i.e., which data points and attributes a user has interacted with) can be used to mitigate potential biases that drive decision making by promoting conscious reflection of one's analysis process. Given an interactive scatterplot-based visualization tool, we showed interaction history in real-time while exploring data (by coloring points in the scatterplot that the user has interacted with), and in a summative format after a decision has been made (by comparing the distribution of user interactions to the underlying distribution of the data). We conducted a series of in-lab experiments and a crowd-sourced …"
Emily Wall,VITALITY: Promoting serendipitous discovery of academic literature with transformers & visual analytics,2021,https://ieeexplore.ieee.org/abstract/document/9552447/,"There are a few prominent practices for conducting reviews of academic literature, including searching for specific keywords on Google Scholar or checking citations from some initial seed paper(s). These approaches serve a critical purpose for academic literature reviews, yet there remain challenges in identifying relevant literature when similar work may utilize different terminology (e.g., mixed-initiative visual analytics papers may not use the same terminology as papers on model-steering, yet the two topics are relevant to one another). In this paper, we introduce a system, VITALITY, intended to complement existing practices. In particular, VITALITY promotes serendipitous discovery of relevant literature using transformer language models, allowing users to find semantically similar papers in a word embedding space given (1) a list of input paper(s) or (2) a working abstract. VITALITY visualizes this document-level …"
Emily Wall,Lumos: Increasing awareness of analytic behavior during visual data analysis,2021,https://ieeexplore.ieee.org/abstract/document/9552196/,"Visual data analysis tools provide people with the agency and flexibility to explore data using a variety of interactive functionalities. However, this flexibility may introduce potential consequences in situations where users unknowingly overemphasize or underemphasize specific subsets of the data or attribute space they are analyzing. For example, users may overemphasize specific attributes and/or their values (e.g., Gender is always encoded on the X axis), underemphasize others (e.g., Religion is never encoded), ignore a subset of the data (e.g., older people are filtered out), etc. In response, we present Lumos, a visual data analysis tool that captures and shows the interaction history with data to increase awareness of such analytic behaviors. Using in-situ (at the place of interaction) and ex-situ (in an external view) visualization techniques, Lumos provides real-time feedback to users for them to reflect on their …"
Emily Wall,Vibe: A design space for visual belief elicitation in data journalism,2022,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14556,"The process of forming, expressing, and updating beliefs from data plays a critical role in data‐driven decision making. Effectively eliciting those beliefs has potential for high impact across a broad set of applications, including increased engagement with data and visualizations, personalizing visualizations, and understanding users' visual reasoning processes, which can inform improved data analysis and decision making strategies (e.g., via bias mitigation). Recently, belief‐driven visualizations have been used to elicit and visualize readers' beliefs in a visualization alongside data in narrative media and data journalism platforms such as the New York Times and FiveThirtyEight. However, there is little research on different aspects that constitute designing an effective belief‐driven visualization. In this paper, we synthesize a design space for belief‐driven visualizations based on formative and summative interviews …"
Emily Wall,A qualitative interview study of distributed tracing visualisation: A characterisation of challenges and opportunities,2023,https://ieeexplore.ieee.org/abstract/document/10034850/,"Distributed tracing tools have emerged in recent years to enable operators of modern internet applications to troubleshoot cross-component problems in deployed applications. Due to the rich, detailed diagnostic data captured by distributed tracing tools, effectively presenting this data is important. However, use of visualisation to enable sensemaking of this complex data in distributed tracing tools has received relatively little attention. Consequently, operators struggle to make effective use of existing tools. In this article we present the first characterisation of distributed tracing visualisation through a qualitative interview study with six practitioners from two large internet companies. Across two rounds of 1-on-1 interviews we use grounded theory coding to establish users, extract concrete use cases and identify shortcomings of existing distributed tracing tools. We derive guidelines for development of future distributed …"
Emily Wall,Exploring the capability of llms in performing low-level visual analytic tasks on svg data visualizations,2024,https://ieeexplore.ieee.org/abstract/document/10771094/,"Data visualizations help extract insights from datasets, but reaching these insights requires decomposing high level goals into low-level analytic tasks that can be complex due to varying degrees of data literacy and visualization experience. Recent advancements in large language models (LLMs) have shown promise for lowering barriers for users to achieve tasks such as writing code and may likewise facilitate visualization insight. Scalable Vector Graphics (SVG), a text-based image format common in data visualizations, matches well with the text sequence processing of transformer-based LLMs. In this paper, we explore the capability of LLMs to perform 10 low-level visual analytic tasks defined by Amar, Eagan, and Stasko directly on SVG-based visualizations [2]. Using zero-shot prompts, we instruct the models to provide responses or modify the SVG code based on given visualizations. Our findings demonstrate …"
Emily Wall,Vishikers’ guide to evaluation: Competing considerations in study design,2022,https://ieeexplore.ieee.org/abstract/document/9790020/,"In this Viewpoint article, we describe the persistent tensions between various camps on the “right” way to conduct evaluations in visualization. Visualization as a field is the amalgamation of cognitive and perceptual sciences and computer graphics, among others. As a result, the relatively disjointed lineages in visualization understandably approach the topic of evaluation very differently. It is both a blessing and a curse to our field. It is a blessing, because the collaboration of diverse perspectives is the breeding ground of innovation. Yet it is a curse, because as a community, we have yet to resolve an appreciation for differing perspectives on the topic of evaluation. We explicate these differing expectations and conventions to appreciate the spectrum of evaluation design decisions. We describe some guiding questions that researchers may consider when designing evaluations to navigate differing readers’ evaluation …"
Emily Wall,Belief Decay or Persistence? A Mixed‐method Study on Belief Movement Over Time,2023,https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14816,"When individuals encounter new information (data), that information is incorporated with their existing beliefs (prior) to form a new belief (posterior) in a process referred to as belief updating. While most studies on rational belief updating in visual data analysis elicit beliefs immediately after data is shown, we posit that there may be critical movement in an individual's beliefs when elicited immediately after data is shown v. after a temporal delay (e.g., due to forgetfulness or weak incorporation of the data). Our paper investigates the hypothesis that posterior beliefs elicited after a time interval will “decay” back towards the prior beliefs compared to the posterior beliefs elicited immediately after new data is presented. In this study, we recruit 101 participants to complete three tasks where beliefs are elicited immediately after seeing new data and again after a brief distractor task. We conduct (1) a quantitative analysis of …"
Emily Wall,Detecting and mitigating human bias in visual analytics,2020,https://scholar.google.com/scholar?cluster=62468100167144373&hl=en&oi=scholarr,"People are susceptible to a multitude of biases, including perceptual biases and illusions; cognitive biases like confirmation bias or anchoring bias; and social biases like racial or gender bias that are borne of cultural experiences and stereotypes. As humans are an integral part of data analysis and decision making in many domains, their biases can be injected into and even amplified by models and algorithms. This dissertation focuses on developing a better understanding of the role of human biases in visual data analysis. It is comprised of three high-level goals: 1. Define bias: We present four common perspectives on the term “bias” and describe how they are relevant in the context of visual data analysis. 2. Detect bias: We introduce a set of computational bias metrics that, applied to user interaction sequences in real-time, can be used to approximate bias in the user’s analysis process. 3. Mitigate bias: We describe a design space of ways in which visualizations might be modified to increase awareness of bias. We implement a system which integrates and visualizes the bias metrics and show how it can increase awareness of bias."
Emily Wall,Unmasking Dunning-Kruger Effect in Visual Reasoning & Judgment,2024,https://ieeexplore.ieee.org/abstract/document/10682498/,"The Dunning-Kruger Effect (DKE) is a metacognitive phenomenon where low-skilled individuals tend to overestimate their competence while high-skilled individuals tend to underestimate their competence. This effect has been observed in a number of domains including humor, grammar, and logic. In this paper, we explore if and how DKE manifests in visual reasoning and judgment tasks. Across two online user studies involving (1) a sliding puzzle game and (2) a scatterplot-based categorization task, we demonstrate that individuals are susceptible to DKE in visual reasoning and judgment tasks: those who performed best underestimated their performance, while bottom performers overestimated their performance. In addition, we contribute novel analyses that correlate susceptibility of DKE with personality traits and user interactions. Our findings pave the way for novel modes of bias detection via interaction …"
Emily Wall,VITALITY 2: Reviewing Academic Literature Using Large Language Models,2024,https://arxiv.org/abs/2408.13450,"Academic literature reviews have traditionally relied on techniques such as keyword searches and accumulation of relevant back-references, using databases like Google Scholar or IEEEXplore. However, both the precision and accuracy of these search techniques is limited by the presence or absence of specific keywords, making literature review akin to searching for needles in a haystack. We present vitaLITy 2, a solution that uses a Large Language Model or LLM-based approach to identify semantically relevant literature in a textual embedding space. We include a corpus of 66,692 papers from 1970-2023 which are searchable through text embeddings created by three language models. vitaLITy 2 contributes a novel Retrieval Augmented Generation (RAG) architecture and can be interacted with through an LLM with augmented prompts, including summarization of a collection of papers. vitaLITy 2 also provides a chat interface that allow users to perform complex queries without learning any new programming language. This also enables users to take advantage of the knowledge captured in the LLM from its enormous training corpus. Finally, we demonstrate the applicability of vitaLITy 2 through two usage scenarios. vitaLITy 2 is available as open-source software at https://vitality-vis.github.io."
Emily Wall,Behavior Matters: An Alternative Perspective on Promoting Responsible Data Science,2024,https://arxiv.org/abs/2410.17273,"Data science pipelines inform and influence many daily decisions, from what we buy to who we work for and even where we live. When designed incorrectly, these pipelines can easily propagate social inequity and harm. Traditional solutions are technical in nature; e.g., mitigating biased algorithms. In this vision paper, we introduce a novel lens for promoting responsible data science using theories of behavior change that emphasize not only technical solutions but also the behavioral responsibility of practitioners. By integrating behavior change theories from cognitive psychology with data science workflow knowledge and ethics guidelines, we present a new perspective on responsible data science. We present example data science interventions in machine learning and visual data analysis, contextualized in behavior change theories that could be implemented to interrupt and redirect potentially suboptimal or negligent practices while reinforcing ethically conscious behaviors. We conclude with a call to action to our community to explore this new research area of behavior change interventions for responsible data science."
Emily Wall,Let’s Get Vysical: Perceptual Accuracy in Visual & Tactile Encodings,2023,https://ieeexplore.ieee.org/abstract/document/10360913/,"In this paper, we explore the effectiveness of tactile data encodings using swell paper in comparison to visual encodings displayed with SVGs for data perception tasks. By replicating and adapting Cleveland and McGill’s graphical perception study for the tactile modality, we establish a novel tactile encoding hierarchy. In a study with 12 university students, we found that participants perceived visual encodings more accurately when comparing values, judging their ratios with lower cognitive load, and better self-evaluated performance than tactile encodings. However, tactile encodings differed from their visual counterparts in terms of how accurately values could be decoded from them. This suggests that data physicalizations will require different design guidance than that developed for visual encodings. By providing empirical evidence for the perceptual accuracy of tactile encodings, our work contributes to …"
Emily Wall,"Perception of Skill in Visual Problem Solving: An Analysis of Interactive Behaviors, Personality Traits, and the Dunning-Kruger Effect",2022,https://trexvis.github.io/Workshop2022/papers/Chen.pdf,"Domain expertise plays a significant role in visual data analysis. In the best case, domain expertise allows people to effectively guide analyses based on prior experiences. However, a lack of self-evaluation of domain expertise can sometimes lead people to fail to recognize their actual performance when making decisions. This reflects a well known psychological phenomenon Dunning-Kruger (DK) effect, wherein unskilled people in certain areas will overestimate their competence while the skilled tend to underestimate their performance accordingly. This paper reports on a within-subject study to (1) replicate the DK effect in a visual problem-solving task,(2) understand participants’ interaction behavior while performing the task, and (3) examine the relationship between personality traits and the possibility of being subjected to DK effect. Results show that participants who ranked in the top group and bottom group did misjudge their competence. In addition, we observe that participants in the two extreme groups employed different strategies to perform the task. This difference can also be found in people with different personalities."
Emily Wall,COVID-19 Health Equity Dashboard-Addressing Vulnerable Populations,2020,https://osf.io/preprints/2frha/,"We present a case study of the COVID-19 Health Equity Dashboard, an open-source web-based interactive data visualization, that provides timely, localized, and actionable data of the ongoing COVID-19 pandemic. The dashboard features interactive maps and charts alongside population vulnerability characteristics, allowing for benchmarking county-level outcomes and disparities against the state and nation. While the dashboard faces several public health communication challenges, we continue to investigate and support data dissemination for public health officials' decision making."
Emily Wall,A Design Space of Behavior Change Interventions for Responsible Data Science,2025,https://dl.acm.org/doi/abs/10.1145/3708359.3712140,"Behavior change theories, rooted in psychology and sociology, offer valuable insights into why and how individuals and groups modify their actions and decisions. By leveraging these theories in the context of responsible data science, we can better understand and influence the behaviors of data scientists, who play a central role in ensuring ethical outcomes by collecting data, developing, and deploying models. In this paper, we present a comprehensive design space for behavior change interventions aimed at promoting responsible behaviors in data science, structured around the 5W1H interrogative framework (Why, Who, What, When, Where, and How). This framework provides a practical guide for developing effective interventions designed to promote responsible behaviors in data science. We showcase the usability of this design space by using it to characterize existing responsible data science intervention …"
Emily Wall,A Novel Lens on Metacognition in Visualization,2025,https://emilywall.github.io/media/papers/MetacognitionCHI25.pdf,"Metacognition, or the awareness and regulation of one’s own cognitive processes, allows individuals to take command of their learning and decision making in various contexts. In tasks that require problem-solving and adaptive learning, individuals with heightened metacognitive awareness tend to outperform others, as they are better equipped to regulate cognition, leading to more effective processes. On the other hand, visualization research facilitates exploration and decision making with data. We posit that metacognitive frameworks that examine how individuals think about their own thinking processes can likewise enhance visualization processes. In this paper, we review metacognition literature from the cognitive and learning science to identify opportunities in visualization to improve people’s ability to reason with data. We propose the use of a metacognitive framework, serving as a starting point to inspire future research to improve visualization practices and outcomes."
Emily Wall,Confirmation Bias: The Double-Edged Sword of Data Facts in Visual Data Communication,2025,https://cyxiong.com/wp-content/uploads/2025/02/chi25-744.pdf,"Incorporating data facts, which are natural language descriptions of data patterns, alongside visualizations can guide readers and enhance the visibility of data patterns. However, data facts might also induce confirmation bias in visual analysis. We conducted a series of crowdsourced experiments to explore the biasing effects of data facts. Our findings show that the presentation style, strength, and alignment of data facts with pre-existing beliefs significantly impact confirmation bias. Data facts that support prior beliefs can exacerbate confirmation bias, whereas those that refute an individual’s beliefs can mitigate it. This effect is amplified when data facts are used in combination with visual annotations. Data facts describing variable correlations are perceived to be more compelling than ones describing average values and are associated with higher levels of confirmation bias. We underscore the persuasive influence of data facts in visualizations and caution against their indiscriminate use in efforts to mitigate bias."
Emily Wall,Visualization and Automation in Data Science: Exploring the Paradox of Humans-in-the-Loop,2024,https://ieeexplore.ieee.org/abstract/document/10747692/,"We explore the interplay between automation and human involvement in data science. Emerging from in-depth discussions at a Dagstuhl seminar, we synthesize perspectives from Automated Data Science (AutoDS) and Interactive Data Visualization (VIS) – two fields that traditionally represent opposing ends of the human-machine spectrum. While AutoDS seeks to enhance efficiency through increasing automation, VIS underscores the critical value of human involvement in providing nuanced understanding, creativity, innovation, and contextual relevance. We explore these dichotomies through an online survey and advocate for a balanced approach that harmonizes the speed and consistency of effective automation with the indispensable insights of human expertise and thought. Ultimately, we confront the essential question: what aspects of data science should we automate?"
Emily Wall,Trust Junk and Evil Knobs: Calibrating Trust in AI Visualization,2024,https://ieeexplore.ieee.org/abstract/document/10541601/,"Many papers make claims about specific visualization techniques that are said to enhance or calibrate trust in AI systems. But a design choice that enhances trust in some cases appears to damage it in others. In this paper, we explore this inherent duality through an analogy with ""knobs"". Turning a knob too far in one direction may result in under-trust, too far in the other, over-trust or, turned up further still, in a confusing distortion. While the designs or so-called ""knobs"" are not inherently evil, they can be misused or used in an adversarial context and thereby manipulated to mislead users or promote unwarranted levels of trust in AI systems. When a visualization that has no meaningful connection with the underlying model or data is employed to enhance trust, we refer to the result as ""trust junk."" From a review of 65 papers, we identify nine commonly made claims about trust calibration. We synthesize them into a …"
Emily Wall,Trust Junk and Evil Knobs: Calibrating Trust in AI Visualization,2024,https://kclpure.kcl.ac.uk/portal/en/publications/trust-junk-and-evil-knobs-calibrating-trust-in-ai-visualization,"Trust Junk and Evil Knobs: Calibrating Trust in AI Visualization — King's College London 
Skip to main navigation Skip to search Skip to main content King's College London Home 
King's College London Logo Home Profiles Research units Research output Projects 
Student theses Activities Datasets Impacts Prizes Search by expertise, name or affiliation 
Trust Junk and Evil Knobs: Calibrating Trust in AI Visualization Rita Borgo, Peta Masters, 
Emily Wall, Laura Matzen, Mennatallah El-Assady, Helia Hosseinpour, Alex Endert, Polo 
Chau, Adam Perer, Harald Schupp, Hendrik Strobelt, Lace Padilla Human Centred 
Computing Informatics Emory University Sandia National Laboratories University of 
Konstanz ETH Zurich University of California, Merced Georgia Institute of Technology 
Carnegie Mellon University IBM Research AI Northeastern University Research output: 
Chapter in Book/Report/Conference proceeding › …"
Emily Wall,Visual Salience to Mitigate Gender Bias in Recommendation Letters,2023,,
Emily Wall,vitaLITy: Promoting Serendipitous Discovery of Academic Literature,2022,https://scholar.google.com/scholar?cluster=17187010792239132794&hl=en&oi=scholarr,"There are a few prominent practices for conducting academic literature reviews, including searching for specific keywords on Google Scholar or checking citations from initial seed paper (s). While these approaches serve a critical purpose for academic literature reviews, there remain challenges in identifying relevant literature when (1) different work may utilize the same terminology (eg,“transformer” in electronics refers to a device that transfers energy between circuits; whereas in computing, it refers to a type of deep learning model, commonly applied to unstructured text data) or (2) similar work may utilize different terminology (eg, work on “bias” in visualization seldom mentions “uncertainty” even though bias sometimes emerges when people make decisions under uncertainty). We developed a visual analytics system, VitaLITy, to promote serendipitous discovery of academic papers wherein users may “stumble upon” relevant literature, when other search approaches may fail. VitaLITy (1) utilizes transformer language models to help users find semantically similar papers given a list of seed paper (s) or a working abstract,(2) visualizes the embedding space in an interactive 2-D scatterplot, and (3) summarizes meta information about the paper corpus (eg, keywords, co-authors, citation counts, and publication year). We also curated a comprehensive dataset comprising papers from 38 popular visualization publication venues (eg, ACM CHI, IEEE VIS) using custom web-scrapers. We have open-sourced the VitaLITy system, dataset, and web-scrapers at https://vitality-vis. github. io/for the research community to grow the list of supported venues …"
Emily Wall,Lumos: Increasing Awareness of Biases during Visual Data Analysis,2021,https://scholar.google.com/scholar?cluster=15409392941844699804&hl=en&oi=scholarr,"Human biases impact the way people analyze data and make decisions. Dark-skinned people denied parole (racial bias), women denied C-suite promotions (gender bias), ailing but younger people denied optimal treatment (age bias), etc. are examples of biases rampant in the world. Visual data analysis tools such as Tableau and Excel help users see and understand their data but do not report potential biases exhibited by users (eg, an overemphasis on the Age attribute). Lumos is an analysis tool that helps users visualize traces of their interactions with data to increase awareness of potential biases. Using in-situ and ex-situ visualization techniques, Lumos provides real-time feedback to users to reflect upon their activities and potentially change future course. For example, Lumos remembers and highlights datapoints that have been previously examined in the same visualizations (in-situ) and overlays the interacted datapoints on the underlying data distribution in a separate visualization (ex-situ). Now sometimes, custom policies rather than biases drive decision-making. For example, a university admissions committee selecting more female than male student applicants can be a conscious choice in abidance to the university's gender-equality policy, rather than an unconscious bias. To address these situations, Lumos allows users to configure custom target distributions and accordingly updates the interaction traces. We believe Lumos can improve data exploration and decision-making scenarios to not only help mitigate the dangers of human biases affecting judgements, but also foster more transparent analysis processes."
Emily Wall,Foley Scholars,2020,https://scholar.google.com/scholar?cluster=6919886953572527746&hl=en&oi=scholarr,"Matthew K. Hong:"" Personalizing Health Management Through Human-Centered Data Augmentation"" During complex chronic treatment, adolescent patients (ages 10-19) must communicate all illness needs to the care team so they can access relevant health resources when most needed. This communication is challenging because patients, family caregivers and clinicians have unmatched experiences, conceptions and linguistic representations of indicators of health. Most importantly, patients lack the means to capture and represent their felt illness experience. My colleagues and I addressed these challenges by advancing personalized computing technology and human-centric methods that inform collaborative approaches for managing personal health data. In this talk, I will describe how technology can be designed to effectively scaffold patients’ gradual participation in managing their illness. I draw from Health Informatics, Participatory Design, and Human-Computer Interaction to show how we can augment clinically-generated, and patient-generated data in ways that cater to personal health needs. I will discuss how human-centered data-augmentation can help designers create intelligent systems to improve chronic care for pediatric patients."
Kristin Williams,An open repository of real-time COVID-19 indicators,2021,https://www.pnas.org/doi/abs/10.1073/pnas.2111452118,"The COVID-19 pandemic presented enormous data challenges in the United States. Policy makers, epidemiological modelers, and health researchers all require up-to-date data on the pandemic and relevant public behavior, ideally at fine spatial and temporal resolution. The COVIDcast API is our attempt to fill this need: Operational since April 2020, it provides open access to both traditional public health surveillance signals (cases, deaths, and hospitalizations) and many auxiliary indicators of COVID-19 activity, such as signals extracted from deidentified medical claims data, massive online surveys, cell phone mobility data, and internet search trends. These are available at a fine geographic resolution (mostly at the county level) and are updated daily. The COVIDcast API also tracks all revisions to historical data, allowing modelers to account for the frequent revisions and backfill that are common for many public …"
Kristin Williams,The Upcycled Home: Removing Barriers to Lightweight Modification of the Home’s Everyday Objects,2020,https://dl.acm.org/doi/abs/10.1145/3313831.3376314,"The Internet-of-things (IoT) embeds computing in everyday objects, but has largely focused on new devices while ignoring the home's many existing possessions. We present a field study with 10 American families to understand how these possessions could be included in the smart home through upcycling. We describe three patterns for how families collaborate around home responsibilities; we explore families' mental models of home that may be in tension with existing IoT systems; and we identify ways that families can more easily imagine a smart home that includes their existing possessions. These insights can help us design an upcycled approach to IoT that supports users in reconfiguring objects (and social roles as mediated by objects) in a way that is sensitive to what will be displaced, discarded, or made obsolete. Our findings inform the design of future lightweight systems for the upcycled home."
Kristin Williams,Celebrating Everyday Success: Improving Engagement and Motivation using a System for Recording Daily Highlights,2020,https://dl.acm.org/doi/abs/10.1145/3313831.3376369,"The demands of daily work offer few opportunities for workers to take stock of their own progress, big or small, which can lead to lower motivation, engagement, and higher risk of burnout. We present Highlight Matome, a personal online tool that encourages workers to quickly record and rank a single work highlight each day, helping them gain awareness of their own successes. We describe results from a field experiment investigating our tool's effectiveness for improving workers' engagement, perceptions, and affect. Thirty-three knowledge workers in Japan and the U.S. used Highlight Matome for six weeks. Our results show that using our tool for less than one minute each day significantly increased measures of work engagement, dedication, and positivity. A qualitative analysis of the highlights offers a window into participants' emotions and perceptions. We discuss implications for theories of inner work life and …"
Kristin Williams,Citational practices: interrogating hegemonic knowledge structures in computing research in Latin America,2021,https://dl.acm.org/doi/abs/10.1145/3488392.3488411," Citations are nodes in the networks of knowledge we create. Portals to conversations with the past and bonding material with the scholarship of the present. Choosing who we cite is a practice signaling who we recognize and respect as a knowledge source. Therefore, we recognize citations as a relational practice. As this relational characteristic of citing is mediated by wealth we distribute across those who we cite, it is imperative to interrogate how just these practices are. Thus, we ought to engage with Citational Justice. Building on recent work discussing citational practices within HCI, we use the opportunity of this workshop to expand this conversation into deeper reflection on how we cite and the practices and infrastructures surrounding citations. Our goal with this workshop is two-fold. First, to create a common language to collectively reflect, interrogate our own citational practices and reverberations, while …"
Kristin Williams,Why do we need to learn about citational practices? Recognizing knowledge production from the Global Souths and beyond,2023,https://dl.acm.org/doi/abs/10.1145/3589256,"How do you decide which papers to cite, how many, and from which particular sources? We reflect and discuss the implications of these critical questions based on our experiences in the panel and workshops on the topic of citational justice that took place at CSCW, CLIHC, and India HCI in 2021."
Kristin Williams,The environmental impact of research communities: insights from conference sustainability chairs,2021,https://dl.acm.org/doi/abs/10.1145/3468216,"As sustainability chairs for key computing conferences, we explore the environmental impact of research conferences, reflect on the complexities of making physical and virtual conferences sustainable, and discuss the environmental consequences of computing research itself."
Kristin Williams,An Upcycled IoT: Building tomorrow’s IoT out of today’s household possessions,2021,https://dl.acm.org/doi/abs/10.1145/3466872,"An upcycled approach uses everyday objects as design material for IoT systems by enabling users to make their “dumb” objects “smart.” Adopting this approach, IoT Codex realizes a new socially informed, context-aware computing and end-user programming."
Kristin Williams,The IoT Codex: A Book of Paper Engineering Techniques for Authoring and Composing Embedded Computing Applications,2020,http://reports-archive.adm.cs.cmu.edu/anon/anon/usr/ftp/usr0/ftp/isr2020/CMU-ISR-20-115C.pdf,"End user programming (EUP) for the smart home has become widely available in commercial systems through services like If This, Then That (IFTTT). This approach uses graphical user interfaces (GUIs) to encapsulate control flow constructs like if-then conditionals in easier-to-use abstractions like form filling. Yet, non-experts largely do not use them to author their own recipes, and instead, naively rely on experts to compose those they do use (often risking their own domestic privacy and security). To support non-experts with authoring and composing embedded computing applications for their home, this work adapts paper engineering techniques to create alternative abstractions and interaction techniques in the form of a book: the IoT Codex. This book contributes a suite of paper mechanisms to convey the affordances of an EUP language for domestic IoT. These mechanisms constrain what expressions can be composed in the language by using both shape and kinematics. At the same time, they encourage non-experts to tinker and experiment with physical artifacts to develop programming expertise using material properties such as adhesives, wax, gold leaf, and others common to scrapbooks. In doing so, the resulting IoT Codex contributes physical computing techniques to aid non-experts in selecting appropriate EUP elements and remixing them to realize their own IoT ideas."
Kristin Williams,Let’s Get Vysical: Perceptual Accuracy in Visual & Tactile Encodings,2023,https://ieeexplore.ieee.org/abstract/document/10360913/,"In this paper, we explore the effectiveness of tactile data encodings using swell paper in comparison to visual encodings displayed with SVGs for data perception tasks. By replicating and adapting Cleveland and McGill’s graphical perception study for the tactile modality, we establish a novel tactile encoding hierarchy. In a study with 12 university students, we found that participants perceived visual encodings more accurately when comparing values, judging their ratios with lower cognitive load, and better self-evaluated performance than tactile encodings. However, tactile encodings differed from their visual counterparts in terms of how accurately values could be decoded from them. This suggests that data physicalizations will require different design guidance than that developed for visual encodings. By providing empirical evidence for the perceptual accuracy of tactile encodings, our work contributes to …"
Kristin Williams,IoT stickers: enabling lightweight modification of everyday objects,2020,https://dl.acm.org/doi/abs/10.1145/3379350.3415807,"Internet-of-Things (IoT) devices promise to enhance even the most mundane of objects with computational properties by seamlessly coupling the virtual world to the physical. However, IoT's associated costs and cumbersome setup limits its extension to many everyday tasks and objects, such as those in the home. To address these issues, my dissertation work will enable IoT Stickers'a book of inexpensive, battery-free sensors and composition patterns'to support customizing everyday objects with software and web services using stickers. Using RFID-based paper mechanisms, IoT Stickers integrates common sensors and web services with interactive stickers through a trigger-action architecture. This integration enables computational services to be tailored to everyday activities by setting parameters to be passed to the sticker's actions and composing the stickers together. Thus, IoT Stickers demonstrates a way to …"
Kristin Williams,The IoT Codex: A Book of Programmable Stickers for Authoring and Composing Embedded Computing Applications,2023,https://ieeexplore.ieee.org/abstract/document/10305681/,"The Internet-of-Things (IoT) promises to enhance everyday objects with computing, but rarely enables directly authoring or composing that behavior. Lightweight IoT approaches attach identifiers (e.g., RFID tags) to objects to enable networked services. Typically these tags are passive, and so, depend on activity recognition and predefined context. This limits interaction to invoking predetermined behavior. Instead, this work presents The IoT Codex: a lightweight approach to customizing everyday objects with IoT by enabling interactive attachable IDs (aIDs) to compose software-supported behavior in situ. This work contributes 1) paper engineering techniques to construct aIDs that embody state, and 2) a tangible, end user programming (EUP) language for customizing IoT within symbolic and idiosyncratic contexts. Here, we provide preliminary validation of our approach with an empirically informed design space …"
Kristin Williams,An Upcycled IoT: Creating Tomorrow's Internet of Things Out of Today's Household Possessions,2022,https://search.proquest.com/openview/55a6712e09494fb99215da34a0b58e6c/1?pq-origsite=gscholar&cbl=18750&diss=y,"The Internet-of-Things (IoT) promises to enhance even the most mundane of objects with computational properties. Yet, IoT has largely focused on new devices while ignoring the home's many existing possessions. Requiring households to replace their possessions to adopt IoT creates substantial waste. This includes increasing artifacts diverted to the waste stream, as well as eroding agency, individual identities, values, and ways of life. To enable an alternative approach, this dissertation shows how IoT could augment existing household possessions rather than replace them. To do so, it worked with 10 American families to design an upcycled approach to IoT that makes use of existing household possessions and then built a system responsive to these findings. The results 1) describe patterns of families' socio-material practices, 2) developed techniques to enable existing possessions to be transformed with IoT …"
Kristin Williams,System using end-user micro-journaling for monitoring organizational health and for improving end-user outcomes,2021,https://patents.google.com/patent/US20210192457A1/en,"Example implementations described herein are directed to a platform facilitating a micro-journaling solu tion which is directed to balancing benefits for the workers (eg, helping increase measures of motivation, engagement, etc. and helping them compose progress reports) and ben efits for the organization. Example implementations facili tate a lightweight interaction (eg, taking less than 1-minute over repeated periods) and can help workers reflect on positive aspects of their work, which leads to the worker experiencing more positive emotions and an immediate reward for such short interactions."
Li Xiong,Advances and open problems in federated learning,2021,https://www.nowpublishers.com/article/Details/MAL-083,"Federated learning (FL) is a machine learning setting where many clients (eg, mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (eg, service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this monograph discusses recent advances and presents an extensive collection of open problems and challenges."
Li Xiong,Federated graph classification over non-iid graphs,2021,https://proceedings.neurips.cc/paper/2021/hash/9c6947bd95ae487c81d4e19d3ed8cd6f-Abstract.html,"Federated learning has emerged as an important paradigm for training machine learning models in different domains. For graph-level tasks such as graph classification, graphs can also be regarded as a special type of data samples, which can be collected and stored in separate local systems. Similar to other domains, multiple local systems, each holding a small set of graphs, may benefit from collaboratively training a powerful graph mining model, such as the popular graph neural networks (GNNs). To provide more motivation towards such endeavors, we analyze real-world graphs from different domains to confirm that they indeed share certain graph properties that are statistically significant compared with random graphs. However, we also find that different sets of graphs, even from the same domain or same dataset, are non-IID regarding both graph structures and node features. To handle this, we propose a graph clustered federated learning (GCFL) framework that dynamically finds clusters of local systems based on the gradients of GNNs, and theoretically justify that such clusters can reduce the structure and feature heterogeneity among graphs owned by the local systems. Moreover, we observe the gradients of GNNs to be rather fluctuating in GCFL which impedes high-quality clustering, and design a gradient sequence-based clustering mechanism based on dynamic time warping (GCFL+). Extensive experimental results and in-depth analysis demonstrate the effectiveness of our proposed frameworks."
Li Xiong,PCKV: Locally differentially private correlated Key-Value data collection with optimized utility,2020,https://www.usenix.org/conference/usenixsecurity20/presentation/gu,"Data collection under local differential privacy (LDP) has been mostly studied for homogeneous data. Real-world applications often involve a mixture of different data types such as key-value pairs, where the frequency of keys and mean of values under each key must be estimated simultaneously. For key-value data collection with LDP, it is challenging to achieve a good utility-privacy tradeoff since the data contains two dimensions and a user may possess multiple key-value pairs. There is also an inherent correlation between key and values which if not harnessed, will lead to poor utility. In this paper, we propose a locally differentially private key-value data collection framework that utilizes correlated perturbations to enhance utility. We instantiate our framework by two protocols PCKV-UE (based on Unary Encoding) and PCKV-GRR (based on Generalized Randomized Response), where we design an advanced Padding-and-Sampling mechanism and an improved mean estimator which is non-interactive. Due to our correlated key and value perturbation mechanisms, the composed privacy budget is shown to be less than that of independent perturbation of key and value, which enables us to further optimize the perturbation parameters via budget allocation. Experimental results on both synthetic and real-world datasets show that our proposed protocols achieve better utility for both frequency and mean estimations under the same LDP guarantees than state-of-the-art mechanisms."
Li Xiong,Dealer: An end-to-end model marketplace with differential privacy,2021,https://par.nsf.gov/biblio/10225109,"Data-driven machine learning has become ubiquitous. A marketplace for machine learning models connects data owners and model buyers, and can dramatically facilitate data-driven machine learning applications. In this paper, we take a formal data marketplace perspective and propose the first en D -to-end mod e l m a rketp l ace with diff e rential p r ivacy ( Dealer ) towards answering the following questions: How to formulate data owners' compensation functions and model buyers' price functions? How can the broker determine prices for a set of models to maximize the revenue with arbitrage-free guarantee, and train a set of models with maximum Shapley coverage given a manufacturing budget to remain competitive ? For the former, we propose compensation function for each data owner based on Shapley value and privacy sensitivity, and price function for each model buyer based on Shapley coverage sensitivity and noise sensitivity. Both privacy sensitivity and noise sensitivity are measured by the level of differential privacy. For the latter, we formulate two optimization problems for model pricing and model training, and propose efficient dynamic programming algorithms. Experiment results on the real chess dataset and synthetic datasets justify the design of Dealer and verify the efficiency and effectiveness of the proposed algorithms."
Li Xiong,Providing input-discriminative protection for local differential privacy,2020,https://ieeexplore.ieee.org/abstract/document/9101808/,"Local Differential Privacy (LDP) provides provable privacy protection for data collection without the assumption of the trusted data server. In the real-world scenario, different data have different privacy requirements due to the distinct sensitivity levels. However, LDP provides the same protection for all data. In this paper, we tackle the challenge of providing input-discriminative protection to reflect the distinct privacy requirements of different inputs. We first present the Input- Discriminative LDP (ID-LDP) privacy notion and focus on a specific version termed MinID-LDP, which is shown to be a fine-grained version of LDP. Then, we focus on the application of frequency estimation and develop the IDUE mechanism based on Unary Encoding for single-item input and the extended mechanism IDUE-PS (with Padding-and-Sampling protocol) for item-set input. The results on both synthetic and real-world datasets validate the …"
Li Xiong,Generating sequential electronic health records using dual adversarial autoencoder,2020,https://academic.oup.com/jamia/article-abstract/27/9/1411/5912632,"Recent studies on electronic health records (EHRs) started to learn deep generative models and synthesize a huge amount of realistic records, in order to address significant privacy issues surrounding the EHR. However, most of them only focus on structured records about patients’ independent visits, rather than on chronological clinical records. In this article, we aim to learn and synthesize realistic sequences of EHRs based on the generative autoencoder.We propose a dual adversarial autoencoder (DAAE), which learns set-valued sequences of medical entities, by combining a recurrent autoencoder with 2 generative adversarial networks (GANs). DAAE improves the mode coverage and quality of generated sequences by adversarially learning both the continuous latent distribution and the discrete data distribution. Using the MIMIC-III …"
Li Xiong,Advancing differential privacy: Where we are now and future directions for real-world deployment,2024,https://arxiv.org/abs/2304.06929,"In this article, we present a detailed review of current practices and state-of-the-art methodologies in the field of differential privacy (DP), with a focus of advancing DP's deployment in real-world applications. Key points and high-level contents of the article were originated from the discussions from ""Differential Privacy (DP): Challenges Towards the Next Frontier,"" a workshop held in July 2022 with experts from industry, academia, and the public sector seeking answers to broad questions pertaining to privacy and its implications in the design of industry-grade systems. This article aims to provide a reference point for the algorithmic and design decisions within the realm of privacy, highlighting important challenges and potential research directions. Covering a wide spectrum of topics, this article delves into the infrastructure needs for designing private systems, methods for achieving better privacy/utility trade-offs, performing privacy attacks and auditing, as well as communicating privacy with broader audiences and stakeholders."
Li Xiong,Semifed: Semi-supervised federated learning with consistency and pseudo-labeling,2021,https://arxiv.org/abs/2108.09412,"Federated learning enables multiple clients, such as mobile phones and organizations, to collaboratively learn a shared model for prediction while protecting local data privacy. However, most recent research and applications of federated learning assume that all clients have fully labeled data, which is impractical in real-world settings. In this work, we focus on a new scenario for cross-silo federated learning, where data samples of each client are partially labeled. We borrow ideas from semi-supervised learning methods where a large amount of unlabeled data is utilized to improve the model's accuracy despite limited access to labeled examples. We propose a new framework dubbed SemiFed that unifies two dominant approaches for semi-supervised learning: consistency regularization and pseudo-labeling. SemiFed first applies advanced data augmentation techniques to enforce consistency regularization and then generates pseudo-labels using the model's predictions during training. SemiFed takes advantage of the federation so that for a given image, the pseudo-label holds only if multiple models from different clients produce a high-confidence prediction and agree on the same label. Extensive experiments on two image benchmarks demonstrate the effectiveness of our approach under both homogeneous and heterogeneous data distribution settings"
Li Xiong,Projected federated averaging with heterogeneous differential privacy,2021,https://dl.acm.org/doi/abs/10.14778/3503585.3503592,"Federated Learning (FL) is a promising framework for multiple clients to learn a joint model without directly sharing the data. In addition to high utility of the joint model, rigorous privacy protection of the data and communication efficiency are important design goals. Many existing efforts achieve rigorous privacy by ensuring differential privacy for intermediate model parameters, however, they assume a uniform privacy parameter for all the clients. In practice, different clients may have different privacy requirements due to varying policies or preferences.In this paper, we focus on explicitly modeling and leveraging the heterogeneous privacy requirements of different clients and study how to optimize utility for the joint model while minimizing communication cost. As differentially private perturbations affect the model utility, a natural idea is to make better use of information submitted by the clients with higher privacy …"
Li Xiong,Transparent contribution evaluation for secure federated learning on blockchain,2021,https://ieeexplore.ieee.org/abstract/document/9438754/,"Federated Learning is a promising machine learning paradigm when multiple parties collaborate to build a high-quality machine learning model. Nonetheless, these parties are only willing to participate when given enough incentives, such as a fair reward based on their contributions. Many studies explored Shapley value based methods to evaluate each party’s contribution to the learned model. However, they commonly assume a semi-trusted server to train the model and evaluate the data owners’ model contributions, which lacks transparency and may hinder the success of federated learning in practice. In this work, we propose a blockchain-based federated learning framework and a protocol to transparently evaluate each participant’s contribution. Our framework protects all parties’ privacy in the model building phase and transparently evaluates contributions based on the model updates. The experiment with …"
Li Xiong,Crowdsourcing under data poisoning attacks: A comparative study,2020,https://link.springer.com/chapter/10.1007/978-3-030-49669-2_18,"Crowdsourcing is a paradigm that provides a cost-effective solution for obtaining services or data from a large group of users. It is increasingly being used in modern society for data collection in domains such as image annotation or real-time traffic reports. A key component of these crowdsourcing applications is truth inference which aims to derive the true answer for a given task from the user-contributed data, e.g. the existence of objects in an image, or true traffic condition of a road. In addition to the variable quality of the contributed data, a potential challenge presented to crowdsourcing applications is data poisoning attacks where malicious users may intentionally and strategically report incorrect information in order to mislead the system to infer the wrong truth for all or a targeted set of tasks. In this paper, we propose a comprehensive data poisoning attack taxonomy for truth inference in crowdsourcing …"
Li Xiong,Certified robustness to word substitution attack with differential privacy,2021,https://aclanthology.org/2021.naacl-main.87/,"The robustness and security of natural language processing (NLP) models are significantly important in real-world applications. In the context of text classification tasks, adversarial examples can be designed by substituting words with synonyms under certain semantic and syntactic constraints, such that a well-trained model will give a wrong prediction. Therefore, it is crucial to develop techniques to provide a rigorous and provable robustness guarantee against such attacks. In this paper, we propose WordDP to achieve certified robustness against word substitution at-tacks in text classification via differential privacy (DP). We establish the connection between DP and adversarial robustness for the first time in the text domain and propose a conceptual exponential mechanism-based algorithm to formally achieve the robustness. We further present a practical simulated exponential mechanism that has efficient inference with certified robustness. We not only provide a rigorous analytic derivation of the certified condition but also experimentally compare the utility of WordDP with existing defense algorithms. The results show that WordDP achieves higher accuracy and more than 30X efficiency improvement over the state-of-the-art certified robustness mechanism in typical text classification tasks."
Li Xiong,L-SRR: Local differential privacy for location-based services with staircase randomized response,2022,https://dl.acm.org/doi/abs/10.1145/3548606.3560636,"Location-based services (LBS) have been significantly developed and widely deployed in mobile devices. It is also well-known that LBS applications may result in severe privacy concerns by collecting sensitive locations. A strong privacy model ''local differential privacy'' (LDP) has been recently deployed in many different applications (e.g., Google RAPPOR, iOS, and Microsoft Telemetry) but not effective for LBS applications due to the low utility of existing LDP mechanisms. To address such deficiency, we propose the first LDP framework for a variety of location-based services (namely ''L-SRR''), which privately collects and analyzes user locations with high utility. Specifically, we design a novel randomization mechanism ''Staircase Randomized Response'' (SRR) and extend the empirical estimation to significantly boost the utility for SRR in different LBS applications (e.g., traffic density estimation, and k-nearest …"
Li Xiong,PAM: understanding product images in cross product category attribute extraction,2021,https://dl.acm.org/doi/abs/10.1145/3447548.3467164,"Understanding product attributes plays an important role in improving online shopping experience for customers and serves asan integral part for constructing a product knowledge graph. Most existing methods focus on attribute extraction from text description or utilize visual information from product images such as shape and color. Compared to the inputs considered in prior works, a product image in fact contains more information, represented by a rich mixture of words and visual clues with a layout carefully designed to impress customers. This work proposes a more inclusive framework that fully utilizes these different modalities for attribute extraction.Inspired by recent works in visual question answering, we use a transformer based sequence to sequence model to fuse representations of product text, Optical Character Recognition (OCR) tokens and visual objects detected in the product image. The framework is …"
Li Xiong,Regularizing neural networks via minimizing hyperspherical energy,2020,http://openaccess.thecvf.com/content_CVPR_2020/html/Lin_Regularizing_Neural_Networks_via_Minimizing_Hyperspherical_Energy_CVPR_2020_paper.html,"Inspired by the Thomson problem in physics where the distribution of multiple propelling electrons on a unit sphere can be modeled via minimizing some potential energy, hyperspherical energy minimization has demonstrated its potential in regularizing neural networks and improving their generalization power. In this paper, we first study the important role that hyperspherical energy plays in neural network training by analyzing its training dynamics. Then we show that naively minimizing hyperspherical energy suffers from some difficulties due to highly non-linear and non-convex optimization as the space dimensionality becomes higher, therefore limiting the potential to further improve the generalization. To address these problems, we propose the compressive minimum hyperspherical energy (CoMHE) as a more effective regularization for neural networks. Specifically, CoMHE utilizes projection mappings to reduce the dimensionality of neurons and minimizes their hyperspherical energy. According to different designs for the projection mapping, we propose several distinct yet well-performing variants and provide some theoretical guarantees to justify their effectiveness. Our experiments show that CoMHE consistently outperforms existing regularization methods, and can be easily applied to different neural networks."
Li Xiong,Efficient sampling approaches to shapley value approximation,2023,https://dl.acm.org/doi/abs/10.1145/3588728,"Shapley value provides a unique way to fairly assess each player's contribution in a coalition and has enjoyed many applications. However, the exact computation of Shapley value is #P-hard due to the combinatoric nature of Shapley value. Many existing applications of Shapley value are based on Monte-Carlo approximation, which requires a large number of samples and the assessment of utility on many coalitions to reach high quality approximation, and thus is still far from being efficient. Can we achieve an efficient approximation of Shapley value by smartly obtaining samples? In this paper, we treat the sampling approach to Shapley value approximation as a stratified sampling problem. Our main technical contributions are a novel stratification design and two sample allocation methods based on Neyman allocation and empirical Bernstein bound, respectively. Experimental results on several real data sets and …"
Li Xiong,Orthogonal over-parameterized training,2021,http://openaccess.thecvf.com/content/CVPR2021/html/Liu_Orthogonal_Over-Parameterized_Training_CVPR_2021_paper.html,"The inductive bias of a neural network is largely determined by the architecture and the training algorithm. To achieve good generalization, how to effectively train a neural network is of great importance. We propose a novel orthogonal over-parameterized training (OPT) framework that can provably minimize the hyperspherical energy which characterizes the diversity of neurons on a hypersphere. By maintaining the minimum hyperspherical energy during training, OPT can greatly improve the empirical generalization. Specifically, OPT fixes the randomly initialized weights of the neurons and learns an orthogonal transformation that applies to these neurons. We consider multiple ways to learn such an orthogonal transformation, including unrolling orthogonalization algorithms, applying orthogonal parameterization, and designing orthogonality-preserving gradient descent. For better scalability, we propose the stochastic OPT which performs orthogonal transformation stochastically for partial dimensions of neurons. Interestingly, OPT reveals that learning a proper coordinate system for neurons is crucial to generalization. We provide some insights on why OPT yields better generalization. Extensive experiments validate the superiority of OPT over the standard training."
Li Xiong,Mobility Data Science: Dagstuhl Seminar 22021,2022,https://vbn.aau.dk/en/publications/mobility-data-science-dagstuhl-seminar-22021,"This report documents the program and the outcomes of Dagstuhl Seminar 22021"" Mobility Data Science"". This seminar was held January 9-14, 2022, including 47 participants from industry and academia. The goal of this Dagstuhl Seminar was to create a new research community of mobility data science in which the whole is greater than the sum of its parts by bringing together established leaders as well as promising young researchers from all fields related to mobility data science."
Li Xiong,Benchmarking blockchain-based gene-drug interaction data sharing methods: a case study from the iDASH 2019 secure genome analysis competition blockchain track,2021,https://www.sciencedirect.com/science/article/pii/S1386505621001854,"Blockchain distributed ledger technology is just starting to be adopted in genomics and healthcare applications. Despite its increased prevalence in biomedical research applications, skepticism regarding the practicality of blockchain technology for real-world problems is still strong and there are few implementations beyond proof-of-concept. We focus on benchmarking blockchain strategies applied to distributed methods for sharing records of gene-drug interactions. We expect this type of sharing will expedite personalized medicine.We generated gene-drug interaction test datasets using the Clinical Pharmacogenetics Implementation Consortium (CPIC) resource. We developed three blockchain-based methods to share patient records on gene-drug interactions: Query Index, Index Everything, and Dual-Scenario Indexing.We achieved a runtime of about 60 seconds for …"
Li Xiong,Shapleyfl: Robust federated learning based on shapley value,2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599500,"Federated Learning (FL) allows clients to form a consortium to train a global model under the orchestration of a central server while keeping data on the local client without sharing it, thus mitigating data privacy issues. However, training a robust global model is challenging since the local data is invisible to the server. The local data of clients are naturally heterogeneous, while some clients can use corrupted data or send malicious updates to interfere with the training process artificially. Meanwhile, communication and computation costs are inevitable challenges in designing a practical FL algorithm. In this paper, to improve the robustness of FL, we propose a Shapley value-inspired adaptive weighting mechanism, which regards the FL training as sequential cooperative games and adjusts clients' weights according to their contributions. We also develop a client sampling strategy based on importance sampling …"
Li Xiong,Communication efficient federated generalized tensor factorization for collaborative health data analytics,2021,https://dl.acm.org/doi/abs/10.1145/3442381.3449832," Modern healthcare systems knitted by a web of entities (e.g., hospitals, clinics, pharmacy companies) are collecting a huge volume of healthcare data from a large number of individuals with various medical procedures, medications, diagnosis, and lab tests. To extract meaningful medical concepts (i.e., phenotypes) from such higher-arity relational healthcare data, tensor factorization has been proven to be an effective approach and received increasing research attention, due to their intrinsic capability to represent the high-dimensional data. Recently, federated learning offers a privacy-preserving paradigm for collaborative learning among different entities, which seemingly provides an ideal potential to further enhance the tensor factorization-based collaborative phenotyping to handle sensitive personal health data. However, existing attempts to federated tensor factorization come with various limitations, including …"
Li Xiong,REACT: Real-time contact tracing and risk monitoring using privacy-enhanced mobile tracking,2020,https://dl.acm.org/doi/abs/10.1145/3431843.3431845,"Contact tracing is an essential public health tool for controlling epidemic disease outbreaks such as the COVID-19 pandemic. Digital contact tracing using real-time locations or proximity of individuals can be used to significantly speed up and scale up contact tracing. In this article, we present our project, REACT, for REAal-time Contact Tracing and risk monitoring via privacy-enhanced tracking of users' locations and symptoms. With privacy enhancement that allows users to control and refine the precision with which their information will be collected and used, REACT will enable: 1) contact tracing of individuals who are exposed to infected cases and identification of hot-spot locations, 2) individual risk monitoring based on the locations they visit and their contact with others; and 3) community risk monitoring and detection of early signals of community spread. We will briefly describe our ongoing work and the …"
Li Xiong,Federated node classification over graphs with latent link-type heterogeneity,2023,https://dl.acm.org/doi/abs/10.1145/3543507.3583471," Federated learning (FL) aims to train powerful and generalized global models without putting distributed data together, which has been shown effective in various domains of machine learning. The non-IIDness of data across local clients has been a major challenge for FL. In graphs, one specifically important perspective of non-IIDness is manifested in the link-type heterogeneity underlying homogeneous graphs– the seemingly uniform links captured in most real-world networks can carry different levels of homophily or semantics of relations, while the exact sets and distributions of such latent link-types can further differ across local clients. Through our preliminary data analysis, we are motivated to design a new graph FL framework that can simultaneously discover latent link-types and model message-passing w.r.t. the discovered link-types through the collaboration of distributed local clients. Specifically, we …"
Li Xiong,Efficient logging and querying for blockchain-based cross-site genomic dataset access audit,2020,https://link.springer.com/article/10.1186/s12920-020-0725-y,"Genomic data have been collected by different institutions and companies and need to be shared for broader use. In a cross-site genomic data sharing system, a secure and transparent access control audit module plays an essential role in ensuring the accountability. A centralized access log audit system is vulnerable to the single point of attack and also lack transparency since the log could be tampered by a malicious system administrator or internal adversaries. Several studies have proposed blockchain-based access audit to solve this problem but without considering the efficiency of the audit queries. The 2018 iDASH competition first track provides us with an opportunity to design efficient logging and querying system for cross-site genomic dataset access audit. We designed a blockchain-based log system which can provide a light-weight and widely compatible module for existing blockchain …"
Li Xiong,Muter: Machine unlearning on adversarially trained models,2023,http://openaccess.thecvf.com/content/ICCV2023/html/Liu_MUter_Machine_Unlearning_on_Adversarially_Trained_Models_ICCV_2023_paper.html,"Machine unlearning is an emerging task of removing the influence of selected training datapoints from a trained model upon data deletion requests, which echoes the widely enforced data regulations mandating the Right to be Forgotten. Many unlearning methods have been proposed recently, achieving significant efficiency gains over the naive baseline of retraining from scratch. However, existing methods focus exclusively on unlearning from standard training models and do not apply to adversarial training models (ATMs) despite their popularity as effective defenses against adversarial examples. During adversarial training, the training data are involved in not only an outer loop for minimizing the training loss, but also an inner loop for generating the adversarial perturbation. Such bi-level optimization greatly complicates the influence measure for the data to be deleted and renders the unlearning more challenging than standard model training with single-level optimization. This paper proposes a new approach called MUter for unlearning from ATMs. We derive a closed-form unlearning step underpinned by a total Hessian-related data influence measure, while existing methods can mis-capture the data influence associated with the indirect Hessian part. We further alleviate the computational cost by introducing a series of approximations and conversions to avoid the most computationally demanding parts of Hessian inversions. The efficiency and effectiveness of MUter have been validated through experiments on four datasets using both linear and neural network models."
Li Xiong,Mobility data science: Perspectives and challenges,2024,https://dl.acm.org/doi/abs/10.1145/3652158,"Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of Global Positioning System (GPS)–equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated a significant impact in various domains, including traffic management, urban planning, and health sciences. In this article, we present the domain of mobility data science. Towards a unified approach to mobility data science, we present a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state-of-the-art, and describe open challenges for the research community in the coming years."
Li Xiong,Visually aware recommendation with aesthetic features,2021,https://link.springer.com/article/10.1007/s00778-021-00651-y,"Visual information plays a critical role in human decision-making process. Recent developments on visually aware recommender systems have taken the product image into account. We argue that the aesthetic factor is very important in modeling and predicting users’ preferences, especially for some fashion-related domains like clothing and jewelry. This work is an extension of our previous paper (Yu et al., in: WWW, pp 649–658, 2018), where we addressed the need of modeling aesthetic information in visually aware recommender systems. Technically speaking, we make three key contributions in leveraging deep aesthetic features. In Yu et al. (in: WWW, pp 649–658, 2018), (1) we introduced the aesthetic features extracted from product images by a deep aesthetic network to describe the aesthetics of products. We incorporated these features into recommender system to model users’ preferences in the …"
Li Xiong,Broadening differential privacy for deep learning against model inversion attacks,2020,https://ieeexplore.ieee.org/abstract/document/9378274/,"Deep learning models have achieved great success in many real-world tasks such as image recognition, machine translation, and self-driving cars. A large amount of data are needed to train a model, and in many cases, the training data are private. Publishing or sharing a deep learning model trained on private datasets could pose privacy concerns. We study the model inversion attacks against deep learning models, which attempt to reconstruct the features of training data corresponding to a given class given access to the model. While deep learning with differential privacy is state-of-the-art for training privacy-preserving models, whether they can provide meaningful protection against model inversion attacks remains an open question. In this paper, we first improve the existing model inversion attacks (MIA) to successfully reconstruct training images from neural network based image recognition models. Then, we …"
Li Xiong,Robustfed: a truth inference approach for robust federated learning,2022,https://dl.acm.org/doi/abs/10.1145/3511808.3557439,"Federated learning is a prominent framework that enables clients (e.g., mobile devices or organizations) to collaboratively train a global model under a central server's orchestration while keeping local data private. However, the aggregation step in federated learning is vulnerable to adversarial attacks as the central server cannot enforce clients' behavior. As a result, the performance of the global model and convergence of the training process can be affected under such attacks. To mitigate this vulnerability, existing works have proposed robust aggregation methods such as median based aggregation instead of averaging. While they ensure some robustness against Byzantine attacks, they are still vulnerable to label flipping and Gaussian noise attacks. In this paper, we propose a novel robust aggregation algorithm inspired by the truth inference methods in crowdsourcing by incorporating the clients' reliability into …"
Li Xiong,Robust irregular tensor factorization and completion for temporal health data analysis,2020,https://dl.acm.org/doi/abs/10.1145/3340531.3411982,"Electronic health records (EHR) are often generated and collected across a large number of patients featuring distinctive medical conditions and clinical progress over a long period of time, which results in unaligned records along the time dimension. EHR is also prone to missing and erroneous data due to various practical reasons. Recently, PARAFAC2 has been re-popularized for successfully extracting meaningful medical concepts (phenotypes) from such temporal EHR by irregular tensor factorization. Despite recent advances, existing PARAFAC2 methods are unable to robustly handle erroneousness and missing data which are prevalent in clinical practice. We propose REPAIR, a Robust tEmporal PARAFAC2 method for IRregular tensor factorization and completion method, to complete an irregular tensor and extract phenotypes in the presence of missing and erroneous values. To achieve this, REPAIR …"
Li Xiong,MultiFusionNet: atrial fibrillation detection with deep neural networks,2020,https://pmc.ncbi.nlm.nih.gov/articles/PMC7233068/,"Atrial fibrillation (AF) is the most common cardiac arrhythmia as well as a significant risk factor in heart failure and coronary artery disease. AF can be detected by using a short ECG recording. However, discriminating atrial fibrillation from normal sinus rhythm, other arrhythmia and strong noise, given a short ECG recording, is challenging. Towards this end, we propose MultiFusionNet, a deep learning network that uses a multiplicative fusion method to combine two deep neural networks trained on different sources of knowledge, i.e., extracted features and raw data. Thus, MultiFusionNet can exploit the relevant extracted features to improve upon the utilization of the deep learning model on the raw data. Our experiments show that this approach offers the most accurate AF classification and outperforms recently published algorithms that either use extracted features or raw data separately. Finally, we show that our …"
Li Xiong,DPAR: Decoupled Graph Neural Networks with Node-Level Differential Privacy,2024,https://dl.acm.org/doi/abs/10.1145/3589334.3645531,"Graph Neural Networks (GNNs) have achieved great success in learning with graph-structured data. Privacy concerns have also been raised for the trained models which could expose the sensitive information of graphs including both node features and the structure information. In this paper, we aim to achieve node-level differential privacy (DP) for training GNNs so that a node and its edges are protected. Node DP is inherently difficult for GNNs because all direct and multi-hop neighbors participate in the calculation of gradients for each node via layer-wise message passing and there is no bound on how many direct and multi-hop neighbors a node can have, so existing DP methods will result in high privacy cost or poor utility due to high node sensitivity. We propose a D ecoupled GNN with Differentially P rivate A pproximate Personalized PageR ank (DPAR) for training GNNs with an enhanced privacy-utility …"
Li Xiong,Demonstration of dealer: An end-to-end model marketplace with differential privacy,2021,https://dl.acm.org/doi/abs/10.14778/3476311.3476335,"Data-driven machine learning (ML) has witnessed great success across a variety of application domains. Since ML model training relies on a large amount of data, there is a growing demand for high-quality data to be collected for ML model training. Data markets can be employed to significantly facilitate data collection. In this work, we demonstrate Dealer, an enD-to-end model marketplace with differential privacy. Dealer consists of three entities, data owners, the broker, and model buyers. Data owners receive compensation for their data usages allocated by the broker; The broker collects data from data owners, builds and sells models to model buyers; Model buyers buy their target models from the broker. We demonstrate the functionalities of the three participating entities and the abbreviated interactions between them. The demonstration allows the audience to understand and experience interactively the …"
Li Xiong,Integer-arithmetic-only certified robustness for quantized neural networks,2021,http://openaccess.thecvf.com/content/ICCV2021/html/Lin_Integer-Arithmetic-Only_Certified_Robustness_for_Quantized_Neural_Networks_ICCV_2021_paper.html,"Adversarial data examples have drawn significant attention from the machine learning and security communities. A line of work on tackling adversarial examples is certified robustness via randomized smoothing that can provide a theoretical robustness guarantee. However, such a mechanism usually uses floating-point arithmetic for calculations in inference and requires large memory footprints and daunting computational costs. These defensive models cannot run efficiently on edge devices nor be deployed on integer-only logical units such as Turing Tensor Cores or integer-only ARM processors. To overcome these challenges, we propose an integer randomized smoothing approach with quantization to convert any classifier into a new smoothed classifier, which uses integer-only arithmetic for certified robustness against adversarial perturbations. We prove a tight robustness guarantee under L2-norm for the proposed approach. We show our approach can obtain a comparable accuracy and 4x 5x speedup over floating-point arithmetic certified robust methods on general-purpose CPUs and mobile devices on two distinct datasets (CIFAR-10 and Caltech-101)."
Li Xiong,Dynamic shapley value computation,2023,https://ieeexplore.ieee.org/abstract/document/10184580/,"With the prevalence of data-driven research, data valuation has attracted attention from the computer science field. How to appraise a single datum becomes an imperative problem, especially in the context of machine learning. Shapley value is widely used to fairly measure the contribution of data points in machine learning since it is the unique definition that satisfies all four desired properties: balance, symmetry, additivity, and zero element. However, computing Shapley value is known to be a #P-hard problem. As data is subject to changes, dynamic data exists pervasively in real-world scenarios. Pricing such dynamic data is more challenging due to the prohibitively expensive cost of recalculation from scratch. In this paper, we study the problem of Dynamic Shapley Value Computation, which updates Shapley value when dynamically adding/deleting data points. For adding data points, to prune unnecessary …"
Li Xiong,Equitable data valuation meets the right to be forgotten in model markets,2023,https://par.nsf.gov/biblio/10448789,"The increasing demand for data-driven machine learning (ML) models has led to the emergence of model markets, where a broker collects personal data from data owners to produce high-usability ML models. To incentivize data owners to share their data, the broker needs to price data appropriately while protecting their privacy. For equitable data valuation , which is crucial in data pricing, Shapley value has become the most prevalent technique because it satisfies all four desirable properties in fairness: balance, symmetry, zero element, and additivity. For the right to be forgotten , which is stipulated by many data privacy protection laws to allow data owners to unlearn their data from trained models, the sharded structure in ML model training has become a de facto standard to reduce the cost of future unlearning by avoiding retraining the entire model from scratch. In this paper, we explore how the sharded structure for the right to be forgotten affects Shapley value for equitable data valuation in model markets. To adapt Shapley value for the sharded structure, we propose S-Shapley value, a sharded structure-based Shapley value, which satisfies four desirable properties for data valuation. Since we prove that computing S-Shapley value is #P-complete, two sampling-based methods are developed to approximate S-Shapley value. Furthermore, to efficiently update valuation results after data owners unlearn their data, we present two delta-based algorithms that estimate the change of data value instead of the data value itself. Experimental results demonstrate the efficiency and effectiveness of the proposed algorithms."
Li Xiong,Comparison of time series clustering methods for identifying novel subphenotypes of patients with infection,2023,https://academic.oup.com/jamia/article-abstract/30/6/1158/7116302,"Severe infection can lead to organ dysfunction and sepsis. Identifying subphenotypes of infected patients is essential for personalized management. It is unknown how different time series clustering algorithms compare in identifying these subphenotypes.Patients with suspected infection admitted between 2014 and 2019 to 4 hospitals in Emory healthcare were included, split into separate training and validation cohorts. Dynamic time warping (DTW) was applied to vital signs from the first 8 h of hospitalization, and hierarchical clustering (DTW-HC) and partition around medoids (DTW-PAM) were used to cluster patients into subphenotypes. DTW-HC, DTW-PAM, and a previously published group-based trajectory model (GBTM) were evaluated for agreement in subphenotype clusters, trajectory patterns, and subphenotype associations with …"
Li Xiong,Multi-view active learning for short text classification in user-generated data,2022,https://arxiv.org/abs/2112.02611,"Mining user-generated data often suffers from the lack of enough labeled data, short document lengths, and the informal user language. In this paper, we propose a novel active learning model to overcome these obstacles in the tasks tailored for query phrases--e.g., detecting positive reports of natural disasters. Our model has three novelties: 1) It is the first approach to employ multi-view active learning in this domain. 2) It uses the Parzen-Rosenblatt window method to integrate the representativeness measure into multi-view active learning. 3) It employs a query-by-committee strategy, based on the agreement between predictors, to address the usually noisy language of the documents in this domain. We evaluate our model in four publicly available Twitter datasets with distinctly different applications. We also compare our model with a wide range of baselines including those with multiple classifiers. The experiments testify that our model is highly consistent and outperforms existing models."
Li Xiong,Precad: Privacy-preserving and robust federated learning via crypto-aided differential privacy,2021,https://arxiv.org/abs/2110.11578,"Federated Learning (FL) allows multiple participating clients to train machine learning models collaboratively by keeping their datasets local and only exchanging model updates. Existing FL protocol designs have been shown to be vulnerable to attacks that aim to compromise data privacy and/or model robustness. Recently proposed defenses focused on ensuring either privacy or robustness, but not both. In this paper, we develop a framework called PRECAD, which simultaneously achieves differential privacy (DP) and enhances robustness against model poisoning attacks with the help of cryptography. Using secure multi-party computation (MPC) techniques (e.g., secret sharing), noise is added to the model updates by the honest-but-curious server(s) (instead of each client) without revealing clients' inputs, which achieves the benefit of centralized DP in terms of providing a better privacy-utility tradeoff than local DP based solutions. Meanwhile, a crypto-aided secure validation protocol is designed to verify that the contribution of model update from each client is bounded without leaking privacy. We show analytically that the noise added to ensure DP also provides enhanced robustness against malicious model submissions. We experimentally demonstrate that our PRECAD framework achieves higher privacy-utility tradeoff and enhances robustness for the trained models."
Li Xiong,PGLP: Customizable and rigorous location privacy through policy graph,2020,https://link.springer.com/chapter/10.1007/978-3-030-58951-6_32,"Location privacy has been extensively studied in the literature. However, existing location privacy models are either not rigorous or not customizable, which limits the trade-off between privacy and utility in many real-world applications. To address this issue, we propose a new location privacy notion called PGLP, i.e., Policy Graph based Location Privacy, providing a rich interface to release private locations with customizable and rigorous privacy guarantee. First, we design a rigorous privacy for PGLP by extending differential privacy. Specifically, we formalize location privacy requirements using a location policy graph, which is expressive and customizable. Second, we investigate how to satisfy an arbitrarily given location policy graph under realistic adversarial knowledge, which can be seen as constraints or public knowledge about user’s mobility pattern. We find that a policy graph may not always be …"
Li Xiong,PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps,2024,https://dl.acm.org/doi/abs/10.1145/3658644.3690279,"The pre-training and fine-tuning paradigm has demonstrated its effectiveness and has become the standard approach for tailoring language models to various tasks. Currently, community-based platforms offer easy access to various pre-trained models, as anyone can publish without strict validation processes. However, a released pre-trained model can be a privacy trap for fine-tuning datasets if it is carefully designed. In this work, we propose PreCurious framework to reveal the new attack surface where the attacker releases the pre-trained model and gets a black-box access to the final fine-tuned model. PreCurious aims to escalate the general privacy risk of both membership inference and data extraction on the fine-tuning dataset. The key intuition behind PreCurious is to manipulate the memorization stage of the pre-trained model and guide fine-tuning with a seemingly legitimate configuration. While empirical …"
Li Xiong,Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model,2023,https://ojs.aaai.org/index.php/AAAI/article/view/26400,"Federated Learning, as a popular paradigm for collaborative training, is vulnerable against privacy attacks. Different privacy levels regarding users' attitudes need to be satisfied locally, while a strict privacy guarantee for the global model is also required centrally. Personalized Local Differential Privacy (PLDP) is suitable for preserving users' varying local privacy, yet only provides a central privacy guarantee equivalent to the worst-case local privacy level. Thus, achieving strong central privacy as well as personalized local privacy with a utility-promising model is a challenging problem. In this work, a general framework (APES) is built up to strengthen model privacy under personalized local privacy by leveraging the privacy amplification effect of the shuffle model. To tighten the privacy bound, we quantify the heterogeneous contributions to the central privacy user by user. The contributions are characterized by the ability of generating “echos” from the perturbation of each user, which is carefully measured by proposed methods Neighbor Divergence and Clip-Laplace Mechanism. Furthermore, we propose a refined framework (S-APES) with the post-sparsification technique to reduce privacy loss in high-dimension scenarios. To the best of our knowledge, the impact of shuffling on personalized local privacy is considered for the first time. We provide a strong privacy amplification effect, and the bound is tighter than the baseline result based on existing methods for uniform local privacy. Experiments demonstrate that our frameworks ensure comparable or higher accuracy for the global model."
Li Xiong,Private stochastic non-convex optimization with improved utility rates,2021,https://par.nsf.gov/servlets/purl/10353745,"We study the differentially private (DP) stochastic nonconvex optimization with a focus on its understudied utility measures in terms of the expected excess empirical and population risks. While the excess risks are extensively studied for convex optimization, they are rarely studied for nonconvex optimization, especially the expected population risk. For the convex case, recent studies show that it is possible for private optimization to achieve the same order of excess population risk as to the nonprivate optimization under certain conditions. It still remains an open question for the nonconvex case whether such ideal excess population risk is achievable.In this paper, we progress towards an affirmative answer to this open problem: DP nonconvex optimization is indeed capable of achieving the same excess population risk as to the nonprivate algorithm in most common parameter regimes, under certain conditions (ie, well-conditioned nonconvexity). We achieve such improved utility rates compared to existing results by designing and analyzing the stagewise DP-SGD with early momentum algorithm. We obtain both excess empirical risk and excess population risk to achieve differential privacy. Our algorithm also features the first known results of excess and population risks for DP-SGD with momentum. Experiment results on both shallow and deep neural networks when respectively applied to simple and complex real datasets corroborate the theoretical results."
Li Xiong,React: real-time contact tracing and risk monitoring via privacy-enhanced mobile tracking,2021,https://ieeexplore.ieee.org/abstract/document/9458685/,"Contact tracing is an essential public health tool for controlling epidemic disease outbreaks such as the COVID-19 pandemic. Digital contact tracing using real-time locations or proximity of individuals can be used to significantly speed up and scale up contact tracing. In this demonstration, we present our system, REACT, for REAl-time Contact Tracing and risk monitoring via privacy-enhanced tracking of users’ locations. With privacy enhancement that allows users to control and refine the precision with which their information will be collected and used, REACT will enable: 1) contact tracing of individuals who are exposed to infected cases and identification of hot-spot locations, 2) individual risk monitoring based on the locations they visit and their contact with others. In this paper, we demonstrate the procedure of contact tracing using our application and the utility of contact tracing given the protected locations."
Li Xiong,Federated pruning: Improving neural network efficiency with federated learning,2022,https://arxiv.org/abs/2209.06359,"Automatic Speech Recognition models require large amount of speech data for training, and the collection of such data often leads to privacy concerns. Federated learning has been widely used and is considered to be an effective decentralized technique by collaboratively learning a shared prediction model while keeping the data local on different clients devices. However, the limited computation and communication resources on clients devices present practical difficulties for large models. To overcome such challenges, we propose Federated Pruning to train a reduced model under the federated setting, while maintaining similar performance compared to the full model. Moreover, the vast amount of clients data can also be leveraged to improve the pruning results compared to centralized training. We explore different pruning schemes and provide empirical evidence of the effectiveness of our methods."
Li Xiong,Generating adversarial examples with distance constrained adversarial imitation networks,2021,https://ieeexplore.ieee.org/abstract/document/9591317/,"Recent studies have shown that neural networks are vulnerable to adversarial examples that are designed by adding small perturbations to clean examples in order to trick the classifier to misclassify. Various approaches based on optimization have been proposed for generating adversarial examples with minimal perturbation. Model training based methods such as Adversarial Transformation Network (ATN) provide a fundamentally new way to directly transform an input into an adversarial example, which promises fast generation of adversarial examples. However, the adversarial examples may have suboptimal quality with significantly large perturbations or low attack success rate at small perturbations. In this article, we propose a distance constrained Adversarial Imitation Network (AIN), which enhances ATN and is capable of generating both targeted and untargeted examples with an explicit distance constraint …"
Li Xiong,Towards training robust private aggregation of teacher ensembles under noisy labels,2020,https://ieeexplore.ieee.org/abstract/document/9378234/,"Deep learning models trained on large-scale data have achieved encouraging performance in many real-world tasks. Meanwhile, publishing those models trained on sensitive datasets, such as medical records, could pose serious privacy concerns. To counter these issues, one of the current state-of-the-art approaches is Private Aggregation of Teacher Ensembles, or PATE, which achieved promising results in preserving the utility of the model while providing a strong privacy guarantee. PATE combines an ensemble of ""teacher models"" trained on sensitive data and transfers the knowledge to a ""student"" model through the noisy aggregation of teachers' votes for labeling unlabeled public data which the student model will be trained on. However, the knowledge or voted labels learned by the student are noisy due to private aggregation. Learning directly from noisy labels can significantly impact the accuracy of the …"
Li Xiong,Classification auto-encoder based detector against diverse data poisoning attacks,2023,https://link.springer.com/chapter/10.1007/978-3-031-37586-6_16,"Poisoning attacks are a category of adversarial machine learning threats in which an adversary attempts to subvert the outcome of the machine learning systems by injecting crafted data into training data set, thus increasing the resulting model’s test error. The adversary can tamper with the data feature space, data labels, or both, each leading to a different attack strategy with different strengths. Various detection approaches have recently emerged, each focusing on one attack strategy. The Achilles heel of many of these detection approaches is their dependence on having access to a clean, untampered data set. In this paper, we propose CAE, a Classification Auto-Encoder based detector against diverse poisoned data. CAE can detect all forms of poisoning attacks using a combination of reconstruction and classification errors without having any prior knowledge of the attack strategy. We show that an enhanced …"
Li Xiong,Privacy-preserving sequential pattern mining in distributed EHRs for predicting cardiovascular disease,2021,https://pmc.ncbi.nlm.nih.gov/articles/PMC8378625/,"From electronic health records (EHRs), the relationship between patients' conditions, treatments, and outcomes can be discovered and used in various healthcare research tasks such as risk prediction. In practice, EHRs can be stored in one or more data warehouses, and mining from distributed data sources becomes challenging. Another challenge arises from privacy laws because patient data cannot be used without some patient privacy guarantees. Thus, in this paper, we propose a privacy-preserving framework using sequential pattern mining in distributed data sources. Our framework extracts patterns from each source and shares patterns with other sources to discover discriminative and representative patterns that can be used for risk prediction while preserving privacy. We demonstrate our framework using a case study of predicting Cardiovascular Disease in patients with type 2 diabetes and show the …"
Li Xiong,Temporal network embedding via tensor factorization,2021,https://dl.acm.org/doi/abs/10.1145/3459637.3482200,"Representation learning on static graph-structured data has shown a significant impact on many real-world applications. However, less attention has been paid to the evolving nature of temporal networks, in which the edges are often changing over time. The embeddings of such temporal networks should encode both graph-structured information and the temporally evolving pattern. Existing approaches in learning temporally evolving network representations fail to capture the temporal interdependence. In this paper, we propose Toffee, a novel approach for temporal network representation learning based on tensor decomposition. Our method exploits the tensor-tensor product operator to encode the cross-time information, so that the periodic changes in the evolving networks can be captured. Experimental results demonstrate that Toffee outperforms existing methods on multiple real-world temporal networks in …"
Li Xiong,Introduction to the Special Issue on Contact Tracing,2022,,
Li Xiong,PANDA: policy-aware location privacy for epidemic surveillance,2020,https://arxiv.org/abs/2005.00186,"In this demonstration, we present a privacy-preserving epidemic surveillance system. Recently, many countries that suffer from coronavirus crises attempt to access citizen's location data to eliminate the outbreak. However, it raises privacy concerns and may open the doors to more invasive forms of surveillance in the name of public health. It also brings a challenge for privacy protection techniques: how can we leverage people's mobile data to help combat the pandemic without scarifying our location privacy. We demonstrate that we can have the best of the two worlds by implementing policy-based location privacy for epidemic surveillance. Specifically, we formalize the privacy policy using graphs in light of differential privacy, called policy graph. Our system has three primary functions for epidemic surveillance: location monitoring, epidemic analysis, and contact tracing. We provide an interactive tool allowing the attendees to explore and examine the usability of our system: (1) the utility of location monitor and disease transmission model estimation, (2) the procedure of contact tracing in our systems, and (3) the privacy-utility trade-offs w.r.t. different policy graphs. The attendees can find that it is possible to have the full functionality of epidemic surveillance while preserving location privacy."
Li Xiong,Csgan: Modality-aware trajectory generation via clustering-based sequence gan,2023,https://ieeexplore.ieee.org/abstract/document/10214943/,"Human mobility data is useful for various applications in urban planning, transportation, and public health, but collecting and sharing real-world trajectories can be challenging due to privacy and data quality issues. To address these problems, recent research focuses on generating synthetic trajectories, mainly using generative adversarial networks (GANs) trained by real-world trajectories. In this paper, we hypothesize that by explicitly capturing the modality of transportation (e.g., walking, biking, driving), we can generate not only more diverse and representative trajectories for different modalities but also more realistic trajectories that preserve the geographical density, trajectory, and transition level properties by capturing both cross-modality and modality-specific patterns. Towards this end, we propose a Clustering-based Sequence Generative Adversarial Network (CSGAN)1 that simultaneously clusters the …"
Li Xiong,DP-BREM: differentially-private and byzantine-robust federated learning with client momentum,2023,https://arxiv.org/abs/2306.12608,"Federated Learning (FL) allows multiple participating clients to train machine learning models collaboratively while keeping their datasets local and only exchanging the gradient or model updates with a coordinating server. Existing FL protocols are vulnerable to attacks that aim to compromise data privacy and/or model robustness. Recently proposed defenses focused on ensuring either privacy or robustness, but not both. In this paper, we focus on simultaneously achieving differential privacy (DP) and Byzantine robustness for cross-silo FL, based on the idea of learning from history. The robustness is achieved via client momentum, which averages the updates of each client over time, thus reducing the variance of the honest clients and exposing the small malicious perturbations of Byzantine clients that are undetectable in a single round but accumulate over time. In our initial solution DP-BREM, DP is achieved by adding noise to the aggregated momentum, and we account for the privacy cost from the momentum, which is different from the conventional DP-SGD that accounts for the privacy cost from the gradient. Since DP-BREM assumes a trusted server (who can obtain clients' local models or updates), we further develop the final solution called DP-BREM+, which achieves the same DP and robustness properties as DP-BREM without a trusted server by utilizing secure aggregation techniques, where DP noise is securely and jointly generated by the clients. Both theoretical analysis and experimental results demonstrate that our proposed protocols achieve better privacy-utility tradeoff and stronger Byzantine robustness than several baseline …"
Li Xiong,Spatio-temporal tensor sketching via adaptive sampling,2021,https://link.springer.com/chapter/10.1007/978-3-030-67658-2_28,"Mining massive spatio-temporal data can help a variety of real-world applications such as city capacity planning, event management, and social network analysis. The tensor representation can be used to capture the correlation between space and time and simultaneously exploit the latent structure of the spatial and temporal patterns in an unsupervised fashion. However, the increasing volume of spatio-temporal data has made it prohibitively expensive to store and analyze using tensor factorization.In this paper, we propose SkeTenSmooth, a novel tensor factorization framework that uses adaptive sampling to compress the tensor in a temporally streaming fashion and preserves the underlying global structure. SkeTenSmooth adaptively samples incoming tensor slices according to the detected data dynamics. Thus, the sketches are more representative and informative of the tensor dynamic …"
Li Xiong,Utilizing multimodal feature consistency to detect adversarial examples on clinical summaries,2020,https://aclanthology.org/2020.clinicalnlp-1.29/,"Recent studies have shown that adversarial examples can be generated by applying small perturbations to the inputs such that the well-trained deep learning models will misclassify. With the increasing number of safety and security-sensitive applications of deep learn-ing models, the robustness of deep learning models has become a crucial topic. The robustness of deep learning models for health-care applications is especially critical because the unique characteristics and the high financial interests of the medical domain make it more sensitive to adversarial attacks. Among the modalities of medical data, the clinical summaries have higher risks to be attacked because they are generated by third-party companies. As few works studied adversarial threats on clinical summaries, in this work we first apply adversarial attack to clinical summaries of electronic health records (EHR) to show the text-based deep learning systems are vulnerable to adversarial examples. Secondly, benefiting from the multi-modality of the EHR dataset, we propose a novel defense method, MATCH (Multimodal feATure Consistency cHeck), which leverages the consistency between multiple modalities in the data to defend against adversarial examples on a single modality. Our experiments demonstrate the effectiveness of MATCH on a hospital readmission prediction task comparing with baseline methods."
Li Xiong,Differentially private tabular data synthesis using large language models,2024,https://arxiv.org/abs/2406.01457,"Synthetic tabular data generation with differential privacy is a crucial problem to enable data sharing with formal privacy. Despite a rich history of methodological research and development, developing differentially private tabular data generators that can provide realistic synthetic datasets remains challenging. This paper introduces DP-LLMTGen -- a novel framework for differentially private tabular data synthesis that leverages pretrained large language models (LLMs). DP-LLMTGen models sensitive datasets using a two-stage fine-tuning procedure with a novel loss function specifically designed for tabular data. Subsequently, it generates synthetic data through sampling the fine-tuned LLMs. Our empirical evaluation demonstrates that DP-LLMTGen outperforms a variety of existing mechanisms across multiple datasets and privacy settings. Additionally, we conduct an ablation study and several experimental analyses to deepen our understanding of LLMs in addressing this important problem. Finally, we highlight the controllable generation ability of DP-LLMTGen through a fairness-constrained generation setting."
Li Xiong,Eclipse: Generalizing knn and skyline,2021,https://ieeexplore.ieee.org/abstract/document/9458785/,"k nearest neighbor (kNN) queries and skyline queries are important operators on multi-dimensional data points. Given a query point, kNN returns the k nearest neighbors based on a scoring function such as a weighted sum of the attributes, which requires predefined attribute weights (or preferences). Skyline returns all possible nearest neighbors for any monotonic scoring functions without requiring attribute weights but the number of returned points can be prohibitively large.In this paper, we propose an eclipse operator that generalizes the classic 1NN and skyline queries and provides a more customizable query solution for users. In eclipse, users can specify rough and customizable attribute preferences and control the number of returned points. We show that both 1NN and skyline are instantiations of eclipse. To process eclipse queries, we propose a baseline algorithm with time complexity O(n22d−1), and an …"
Li Xiong,Radar: Recurrent autoencoder based detector for adversarial examples on temporal ehr,2021,https://link.springer.com/chapter/10.1007/978-3-030-67667-4_7,"Leveraging the information-rich and large volume of Electronic Health Records (EHR), deep learning systems have shown great promise in assisting medical diagnosis and regulatory decisions. Although deep learning models have advantages over the traditional machine learning approaches in the medical domain, the discovery of adversarial examples has exposed great threats to the state-of-art deep learning medical systems. While most of the existing studies are focused on the impact of adversarial perturbation on medical images, few works have studied adversarial examples and potential defenses on temporal EHR data. In this work, we propose RADAR, a Recurrent Autoencoder based Detector for Adversarial examples on temporal EHR data, which is the first effort to defend adversarial examples on temporal EHR data. We evaluate RADAR on a mortality classifier using the MIMIC-III dataset …"
Li Xiong,Edgeinfer: robust truth inference under data poisoning attack,2020,https://ieeexplore.ieee.org/abstract/document/9288508/,"As crowdsourcing is becoming more widely used for annotating data from a large group of users, attackers have strong incentives to manipulate the system. Deriving the true answer of tasks in crowdsourcing systems based on user-provided data is susceptible to data poisoning attacks, whereby malicious users may intentionally or strategically report incorrect information to mislead the system into inferring the wrong truth for a set of tasks. Recent work has proposed several attacks on the crowdsourcing systems and showed that existing truth inference methods may be vulnerable to such attacks. In this paper, we propose solutions to enhance the robustness of existing truth inference methods. Our solutions base on 1) detecting and augmenting the answers for the boundary tasks in which users could not reach a strong consensus and hence are subjective to potential manipulation, and 2) enhancing inference …"
Li Xiong,Cross-silo Federated Learning with Record-level Personalized Differential Privacy,2024,https://dl.acm.org/doi/abs/10.1145/3658644.3670351,"Federated learning (FL) enhanced by differential privacy has emerged as a popular approach to better safeguard the privacy of client-side data by protecting clients' contributions during the training process. Existing solutions typically assume a uniform privacy budget for all records and provide one-size-fits-all solutions that may not be adequate to meet each record's privacy requirement. In this paper, we explore the uncharted territory of cross-silo FL with record-level personalized differential privacy. We devise a novel framework namedrPDP-FL, employing a two-stage hybrid sampling scheme with both uniform client-level sampling and non-uniform record-level sampling to accommodate varying privacy requirements.A critical and non-trivial problem is how to determine the ideal per-record sampling probability q given the personalized privacy budget ε. We introduce a versatile solution namedSimulation …"
Li Xiong,Personalized differentially private federated learning without exposing privacy budgets,2023,https://dl.acm.org/doi/abs/10.1145/3583780.3615247,"The meteoric rise of cross-silo Federated Learning (FL) is due to its ability to mitigate data breaches during collaborative training. To further provide rigorous privacy protection with consideration of the varying privacy requirements across different clients, a privacy-enhanced line of work on personalized differentially private federated learning (PDP-FL) has been proposed. However, the existing solution for PDP-FL [20] assumes the raw privacy budgets of all clients should be collected by the server. These values are then directly utilized to improve the model utility via facilitating the privacy preferences partitioning (i.e., partitioning all clients into multiple privacy groups). It is however non-realistic because the raw privacy budgets can be quite informative and sensitive.In this work, our goal is to achieve PDP-FL without exposing clients' raw privacy budgets by indirectly partitioning the privacy preferences solely based …"
Li Xiong,Bit-aware randomized response for local differential privacy in federated learning,2022,https://openreview.net/forum?id=ZUXZKjfptc9,"In this paper, we develop BitRand, a bit-aware randomized response algorithm, to preserve local differential privacy (LDP) in federated learning (FL). We encode embedded features extracted from clients' local data into binary encoding bits, in which different bits have different impacts on the embedded features. Based upon that, we randomize all the bits to preserve LDP with three key advantages: (1) Bit-aware: Bits with a more substantial influence on the model utility have smaller randomization probabilities, and vice-versa, under the same privacy protection; (2) Dimension-elastic: Increasing the dimensions of embedded features, gradients, model outcomes, and training rounds marginally affect the randomization probabilities of binary encoding bits under the same privacy protection; and (3) LDP protection is achieved for both embedded features and labels with tight privacy loss and expected error bounds ensuring high model utility. Extensive theoretical and experimental results show that our BitRand significantly outperforms various baseline approaches in text and image classification."
Li Xiong,Fraud Buster: Tracking IRSF Using Blockchain While Protecting Business Confidentiality.,2021,https://vldb.org/cidrdb/papers/2021/cidr2021_paper05.pdf,"Decentralized delivery of physical or digital items via a sequence of handover actions is common in telecommunication, supply chains, snail mail, email, etc. In decentralized delivery systems, items are passed between carriers, from source to destination, without a central control, and often, by carriers that belong to different organizations. Delivery failures could be due to faults or the result of malicious actions like fraud, eg, in International Revenue Share Fraud (IRSF), international phone calls are dropped by fraudulent telecommunication carriers. Tracking item delivery can help detect faults and fraudulent behavior. But the sequence of carriers used for delivery of a specific item is often business confidential, and should be revealed only in case of fraud. In this paper, we demonstrate a blockchain-based system, Fraud Buster, for confidential tracking of routes in a decentralized delivery system. In particular, we illustrate the ability to track handover of calls while preserving business confidentiality when detecting where calls were dropped. The paper makes the use of a permissioned blockchain for tracking the required information yet revealing only the necessary information, when a fraud occurs."
Li Xiong,TabularMark: Watermarking Tabular Datasets for Machine Learning,2024,https://dl.acm.org/doi/abs/10.1145/3658644.3690373,"Watermarking is broadly utilized to protect ownership of shared data while preserving data utility. However, existing watermarking methods for tabular datasets fall short on the desired properties (detectability, non-intrusiveness, and robustness) and only preserve data utility from the perspective of data statistics, ignoring the performance of downstream ML models trained on the datasets. Can we watermark tabular datasets without significantly compromising their utility for training ML models while preventing attackers from training usable ML models on attacked datasets?In this paper, we propose a hypothesis testing-based watermarking scheme, TabularMark. Data noise partitioning is utilized for data perturbation during embedding, which is adaptable for numerical and categorical attributes while preserving the data utility. For detection, a custom-threshold one proportion z-test is employed, which can reliably …"
Li Xiong,P-Shapley: Shapley Values on Probabilistic Classifiers,2024,https://dl.acm.org/doi/abs/10.14778/3654621.3654638,"The Shapley value provides a unique approach to equitably gauge each player's contribution within a coalition and has extensive applications with various utility functions. In data valuation for machine learning, particularly for classification tasks, using classification accuracy as the utility function has become a de facto standard. However, accuracy can be an imprecise metric, potentially missing finer details crucial for valuation. In this paper, we propose the probability-based Shapley (P-Shapley) value, which leverages predicted probabilities to heighten utility differentiation. Several convex calibration functions are further incorporated for probability calibration. We prove that the P-Shapley value outperforms Shapley values based on accuracy or other coarse metrics in approximation stability and the discrimination of marginal utility change can be further improved by convex calibration functions. Extensive …"
Li Xiong,Unified Modeling and Clustering of Mobility Trajectories with Spatiotemporal Point Processes,2024,https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.72,"In various application domains like transportation, urban planning, and public health, analyzing human mobility, represented as a sequence of consecutive visits (aka trajectories), is crucial for uncovering essential mobility patterns. Current practices often discretize space and time to model trajectory data with sequence-analysis techniques like Transformers and LSTM, but this discretization tends to obscure the intrinsic spatial and temporal characteristics inherent in trajectories. Recent work shows the effectiveness of modeling trajectories directly in continuous space and time using the spatiotempo-ral point process (STPP). However, these approaches often assume that all observed trajectories originate from a single underlying dynamic. In reality, real-world trajectories exhibit varying dynamics or moving patterns. We hypothesize that grouping trajectories governed by similar dynamics into clusters before trajectory …"
Li Xiong,MULTIPAR: Supervised Irregular Tensor Factorization with Multi-task Learning for Computational Phenotyping,2023,https://proceedings.mlr.press/v225/ren23a.html,"Tensor factorization has received increasing interest due to its intrinsic ability to capture latent factors in multi-dimensional data with many applications including Electronic Health Records (EHR) mining. PARAFAC2 and its variants have been proposed to address irregular tensors where one of the tensor modes is not aligned, eg, different patients in EHRs may have different length of records. PARAFAC2 has been successfully applied to EHRs for extracting meaningful medical concepts (phenotypes). Despite recent advancements, current models’ predictability and interpretability are not satisfactory, which limits its utility for downstream analysis. In this paper, we propose MULTIPAR: a supervised irregular tensor factorization with multi-task learning for computational phenotyping. MULTIPAR is flexible to incorporate both static (eg in-hospital mortality prediction) and continuous or dynamic (eg the need for ventilation) tasks. By supervising the tensor factorization with downstream prediction tasks and leveraging information from multiple related predictive tasks, MULTIPAR can yield not only more meaningful phenotypes but also better predictive performance for downstream tasks. We conduct extensive experiments on two real-world temporal EHR datasets to demonstrate that MULTIPAR is scalable and achieves better tensor fit with more meaningful subgroups and stronger predictive performance compared to existing state-of-the-art methods. The implementation of MULTIPAR is available https://github. com/yifeiren13/MULTIPAR."
Li Xiong,Closed-form machine unlearning for matrix factorization,2023,https://dl.acm.org/doi/abs/10.1145/3583780.3614811,"Matrix factorization (MF) is a fundamental model in data mining and machine learning, which finds wide applications in diverse application areas, including recommendation systems with user-item rating matrices, phenotype extraction from electronic health records, and spatial-temporal data analysis for check-in records. The ""right to be forgotten"" has become an indispensable privacy consideration due to the widely enforced data protection regulations, which allow personal users having contributed their data for model training to revoke their data through a data deletion request. Consequently, it gives rise to the emerging task of machine unlearning for the MF model, which removes the influence of the matrix rows/columns from the trained MF factors upon receiving the deletion requests from the data owners of these rows/columns. The central goal is to effectively remove the influence of the rows/columns to be …"
Li Xiong,Interpretation attacks and defenses on predictive models using electronic health records,2023,https://link.springer.com/chapter/10.1007/978-3-031-43418-1_27,"The emergence of complex deep neural networks made it crucial to employ interpretation methods for gaining insight into the rationale behind model predictions. However, recent studies have revealed attacks on these interpretations, which aim to deceive users and subvert the trustworthiness of the models. It is especially critical in medical systems, where interpretations are essential in explaining outcomes. This paper presents the first interpretation attack on predictive models using sequential electronic health records (EHRs). Prior attempts in image interpretation mainly utilized gradient-based methods, yet our research shows that our attack can attain significant success on EHR interpretations that do not rely on model gradients. We introduce metrics compatible with EHR data to evaluate the attack’s success. Moreover, our findings demonstrate that detection methods that have successfully identified …"
Li Xiong,Eulerfd: An efficient double-cycle approximation of functional dependencies,2023,https://ieeexplore.ieee.org/abstract/document/10184804/,"Functional dependencies (FDs) have been extensively employed in discovering inferential relationships in databases, which provide feasible approaches for many data mining tasks, such as data obfuscation, query optimization, and schema normalization. Since the explosive growth of data leads to a rapid increase of FDs on large datasets, existing algorithms that pay more attention to the exact FD discovery cannot extract FDs efficiently. To bridge this gap, we propose an Efficient double-cycle approximation of Functional Dependency (EulerFD) discovery algorithm, which ensures both efficiency and accuracy of FD discovery. EulerFD induces FDs from invalid ones as invalidating an FD only requires comparing and verifying some pairs of tuples (that violate the dependency) while validating an FD requires examining and verifying all tuples. Considering the abundant tuple pairs in large datasets, a novel sampling …"
Li Xiong,Communication efficient tensor factorization for decentralized healthcare networks,2021,https://ieeexplore.ieee.org/abstract/document/9679154/,"Tensor factorization has been proved as an efficient unsupervised learning approach for health data analysis, especially for computational phenotyping, where the high-dimensional Electronic Health Records (EHRs) with patients history of medical procedures, medications, diagnosis, lab tests, etc., are converted to meaningful and interpretable medical concepts. Federated tensor factorization distributes the tensor computation to multiple workers under the coordination of a central server, which enables jointly learning the phenotypes across multiple hospitals while preserving the privacy of the patient information. However, existing federated tensor factorization algorithms encounter the single-point-failure issue with the involvement of the central server, which is not only easily exposed to external attacks, but also limits the number of clients sharing information with the server under restricted uplink bandwidth. In this …"
Li Xiong,Igamt: Privacy-preserving electronic health record synthesization with heterogeneity and irregularity,2024,https://ojs.aaai.org/index.php/AAAI/article/view/29491,"Integrating electronic health records (EHR) into machine learning-driven clinical research and hospital applications is important, as it harnesses extensive and high-quality patient data to enhance outcome predictions and treatment personalization. Nonetheless, due to privacy and security concerns, the secondary purpose of EHR data is consistently governed and regulated, primarily for research intentions, thereby constraining researchers' access to EHR data. Generating synthetic EHR data with deep learning methods is a viable and promising approach to mitigate privacy concerns, offering not only a supplementary resource for downstream applications but also sidestepping the confidentiality risks associated with real patient data. While prior efforts have concentrated on EHR data synthesis, significant challenges persist in the domain of generating synthetic EHR data: balancing the heterogeneity of real EHR including temporal and non-temporal features, addressing the missing values and irregular measures, and ensuring the privacy of the real data used for model training. Existing works in this domain only focused on solving one or two aforementioned challenges. In this work, we propose IGAMT, an innovative framework to generate privacy-preserved synthetic EHR data that not only maintain high quality with heterogeneous features, missing values, and irregular measures but also balances the privacy-utility trade-off. Extensive experiments prove that IGAMT significantly outperforms baseline architectures in terms of visual resemblance and comparable performance in downstream applications. Ablation case studies also prove the …"
Li Xiong,Contrastive Unlearning: A Contrastive Approach to Machine Unlearning,2024,https://arxiv.org/abs/2401.10458,"Machine unlearning aims to eliminate the influence of a subset of training samples (i.e., unlearning samples) from a trained model. Effectively and efficiently removing the unlearning samples without negatively impacting the overall model performance is still challenging. In this paper, we propose a contrastive unlearning framework, leveraging the concept of representation learning for more effective unlearning. It removes the influence of unlearning samples by contrasting their embeddings against the remaining samples so that they are pushed away from their original classes and pulled toward other classes. By directly optimizing the representation space, it effectively removes the influence of unlearning samples while maintaining the representations learned from the remaining samples. Experiments on a variety of datasets and models on both class unlearning and sample unlearning showed that contrastive unlearning achieves the best unlearning effects and efficiency with the lowest performance loss compared with the state-of-the-art algorithms."
Li Xiong,ULDP-FL: Federated Learning with Across Silo User-Level Differential Privacy,2024,https://pmc.ncbi.nlm.nih.gov/articles/PMC11822848/,"Differentially Private Federated Learning (DP-FL) has garnered attention as a collaborative machine learning approach that ensures formal privacy. Most DP-FL approaches ensure DP at the record-level within each silo for cross-silo FL. However, a single user’s data may extend across multiple silos, and the desired user-level DP guarantee for such a setting remains unknown. In this study, we present Uldp-FL, a novel FL framework designed to guarantee user-level DP in cross-silo FL where a single user’s data may belong to multiple silos. Our proposed algorithm directly ensures user-level DP through per-user weighted clipping, departing from group-privacy approaches. We provide a theoretical analysis of the algorithm’s privacy and utility. Additionally, we improve the utility of the proposed algorithm with an enhanced weighting strategy based on user record distribution and design a novel private protocol that …"
Li Xiong,View distillation with unlabeled data for extracting adverse drug effects from user-generated data,2021,https://arxiv.org/abs/2105.11354,"We present an algorithm based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data. Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents. Then a classifier is trained on each view to label a set of unlabeled documents to be used as an initializer for a new classifier in the other view. Finally, the initialized classifier in each view is further trained using the initial training examples. We evaluated our model in the largest publicly available ADR dataset. The experiments testify that our model significantly outperforms the transformer-based models pretrained on domain-specific data."
Li Xiong,A Survey on Data Markets,2024,https://arxiv.org/abs/2411.07267,"Data is the new oil of the 21st century. The growing trend of trading data for greater welfare has led to the emergence of data markets. A data market is any mechanism whereby the exchange of data products including datasets and data derivatives takes place as a result of data buyers and data sellers being in contact with one another, either directly or through mediating agents. It serves as a coordinating mechanism by which several functions, including the pricing and the distribution of data as the most important ones, interact to make the value of data fully exploited and enhanced. In this article, we present a comprehensive survey of this important and emerging direction from the aspects of data search, data productization, data transaction, data pricing, revenue allocation as well as privacy, security, and trust issues. We also investigate the government policies and industry status of data markets across different countries and different domains. Finally, we identify the unresolved challenges and discuss possible future directions for the development of data markets."
Li Xiong,Share: Stackelberg-Nash based Data Markets,2024,https://ieeexplore.ieee.org/abstract/document/10598109/,"With the prevalence of data-driven intelligence, data markets with various data products are gaining considerable interest as a promising paradigm for commoditizing data and facilitating data flow. In this paper, we present Stackelberg-Nash based Data Markets (Share) to first realize a demand-driven incentivized data market with absolute pricing. We propose a three-stage Stackelberg-Nash game to model trading dynamics which not only optimizes the profits of all selfish participants but also adapts to the common buyer-broker-sellers market flow and solves the seller selection problem based on sellers' inner competition. We define Stackelberg-Nash Equilibrium and use backward induction to solve the equilibrium. For inner Nash equilibrium, we apply the conventional direct derivation approach and propose a novel mean-field based method along with provable approximation guarantees for complicated cases …"
Li Xiong,Contrastive unlearning: A contrastive approach to machine unlearning,2024,https://openreview.net/forum?id=lgnAEBE1Xq,"Machine unlearning aims to eliminate the influence of a subset of training samples (i.e., unlearning samples) from a trained model. Effectively and efficiently removing the unlearning samples without negatively impacting the overall model performance is challenging. Existing works mainly exploit input and output space and classification loss, which can result in ineffective unlearning or performance loss. In addition, they utilize on unlearning or remaining samples ineffectively, sacrificing either unlearning efficacy or efficiency. Our main insight is that direct optimization on the representation space utilizing both unlearning and remaining samples can effectively remove influence of unlearning samples while maintaining representations learned from remaining samples. We propose a contrastive unlearning framework, leveraging the concept of representation learning for more effective unlearning. It removes the influence of unlearning samples by contrasting their embeddings against the remaining samples' embeddings so that their embeddings are closer to the embeddings of unseen samples. Experiments on a variety of datasets and models on both class unlearning and sample unlearning showed that contrastive unlearning achieves the best unlearning effects and efficiency with the lowest performance loss compared with the state-of-the-art algorithms."
Li Xiong,An analysis of protected health information leakage in deep-learning based de-identification algorithms,2021,https://arxiv.org/abs/2101.12099,"The increasing complexity of algorithms for analyzing medical data, including de-identification tasks, raises the possibility that complex algorithms are learning not just the general representation of the problem, but specifics of given individuals within the data. Modern legal frameworks specifically prohibit the intentional or accidental distribution of patient data, but have not addressed this potential avenue for leakage of such protected health information. Modern deep learning algorithms have the highest potential of such leakage due to complexity of the models. Recent research in the field has highlighted such issues in non-medical data, but all analysis is likely to be data and algorithm specific. We, therefore, chose to analyze a state-of-the-art free-text de-identification algorithm based on LSTM (Long Short-Term Memory) and its potential in encoding any individual in the training set. Using the i2b2 Challenge Data, we trained, then analyzed the model to assess whether the output of the LSTM, before the compression layer of the classifier, could be used to estimate the membership of the training data. Furthermore, we used different attacks including membership inference attack method to attack the model. Results indicate that the attacks could not identify whether members of the training data were distinguishable from non-members based on the model output. This indicates that the model does not provide any strong evidence into the identification of the individuals in the training data set and there is not yet empirical evidence it is unsafe to distribute the model for general use."
Li Xiong,"The 28th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2020) virtual, online, USA November 3--6, 2020: conference report",2021,https://dl.acm.org/doi/abs/10.1145/3447994.3447997,"This report describes the development and finalization of the 28th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2020), held virtually online, November 3-6, 2020. The attendance for the 2020 conference was 999, the highest in the history of ACM SIGSPATIAL."
Li Xiong,"Two Birds, One Stone: Achieving both Differential Privacy and Certified Robustness for Pre-trained Classifiers via Input Perturbation",2021,https://openreview.net/forum?id=keQjAwuC7j-,"Recent studies have shown that pre-trained classifiers are increasingly powerful to improve the performance on different tasks, e.g, neural language processing, image classification. However, adversarial examples from attackers can trick pre-trained classifiers to misclassify. To solve this challenge, a reconstruction network is built before the public pre-trained classifiers to offer certified robustness and defend against adversarial examples through input perturbation. On the other hand, the reconstruction network requires training on the dataset, which incurs privacy leakage of training data through inference attacks. To prevent this leakage, differential privacy (DP) is applied to offer a provable privacy guarantee on training data through gradient perturbation. Most existing works employ certified robustness and DP independently and fail to exploit the fact that input perturbation designed to achieve certified robustness can achieve (partial) DP. In this paper, we propose perturbation transformation to show how the input perturbation designed for certified robustness can be transformed into gradient perturbation during training. We propose Multivariate Gaussian mechanism to analyze the privacy guarantee of this transformed gradient perturbation and precisely quantify the level of DP achieved by input perturbation. To satisfy the overall DP requirement, we add additional gradient perturbation during training and propose Mixed Multivariate Gaussian Analysis to analyze the privacy guarantee provided by the transformed gradient perturbation and additional gradient perturbation. Moreover, we prove that Mixed Multivariate Gaussian Analysis can work …"
Li Xiong,Federated node classification over distributed ego-networks with secure contrastive embedding sharing,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679834,"Federated learning on graphs (a.k.a., federated graph learning - FGL) has recently received increasing attention due to its capacity to enable collaborative learning over distributed graph datasets without compromising local clients' data privacy. In previous works, clients of FGL typically represent institutes or organizations that possess sets of entire graphs (e.g., molecule graphs in biochemical research) or parts of a larger graph (e.g., sub-user networks of e-commerce platforms). However, another natural paradigm exists where clients act as remote devices retaining the graph structures of local neighborhoods centered around the device owners (i.e., ego-networks), which can be modeled for specific graph applications such as user profiling on social ego-networks and infection prediction on contact ego-networks. FGL in such novel yet realistic ego-network settings faces the unique challenge of incomplete …"
Li Xiong,Shapley Value Approximation Based on Complementary Contribution,2024,https://ieeexplore.ieee.org/abstract/document/10623283/,"Shapley value provides a unique way to fairly assess each player's contribution in a coalition and has enjoyed many applications. However, the exact computation of Shapley value is #P-hard due to the combinatoric nature of Shapley value. Many existing applications of Shapley value are based on Monte-Carlo approximation, which requires a large number of samples and the assessment of utility on many coalitions to reach high-quality approximation, and thus is still far from being efficient. Can we achieve an efficient approximation of Shapley value by smartly obtaining samples? In this paper, we treat the sampling approach to Shapley value approximation as a stratified sampling problem. Our main technical contributions are a novel stratification design and a sampling method based on Neyman allocation. Moreover, computing the Shapley value in a dynamic setting, where new players may join the game and …"
Li Xiong,HRNet: Differentially Private Hierarchical and Multi-Resolution Network for Human Mobility Data Synthesization,2024,https://arxiv.org/abs/2405.08043,"Human mobility data offers valuable insights for many applications such as urban planning and pandemic response, but its use also raises privacy concerns. In this paper, we introduce the Hierarchical and Multi-Resolution Network (HRNet), a novel deep generative model specifically designed to synthesize realistic human mobility data while guaranteeing differential privacy. We first identify the key difficulties inherent in learning human mobility data under differential privacy. In response to these challenges, HRNet integrates three components: a hierarchical location encoding mechanism, multi-task learning across multiple resolutions, and private pre-training. These elements collectively enhance the model's ability under the constraints of differential privacy. Through extensive comparative experiments utilizing a real-world dataset, HRNet demonstrates a marked improvement over existing methods in balancing the utility-privacy trade-off."
Li Xiong,Leveraging Simulation Data to Understand Bias in Predictive Models of Infectious Disease Spread,2024,https://dl.acm.org/doi/abs/10.1145/3660631,"The spread of infectious diseases is a highly complex spatiotemporal process, difficult to understand, predict, and effectively respond to. Machine learning and artificial intelligence (AI) have achieved impressive results in other learning and prediction tasks; however, while many AI solutions are developed for disease prediction, only a few of them are adopted by decision-makers to support policy interventions. Among several issues preventing their uptake, AI methods are known to amplify the bias in the data they are trained on. This is especially problematic for infectious disease models that typically leverage large, open, and inherently biased spatiotemporal data. These biases may propagate through the modeling pipeline to decision-making, resulting in inequitable policy interventions. Therefore, there is a need to gain an understanding of how the AI disease modeling pipeline can mitigate biased input data, in …"
Li Xiong,When Data Pricing Meets Non-Cooperative Game Theory,2024,https://ieeexplore.ieee.org/abstract/document/10597734/,"Driven by the growing field of data intelligence, data market emerges as a promising paradigm for data exchange, enabling the full utilization of data. Data pricing is an essential function in data market that reflects the values or cost of data and is dependent on interactions among multiple market participants including data buyers, data sellers, and data brokers. Game theory presents a promising approach to model the multi-participant interplay in data pricing, yet challenged by the specific nature of data. In this paper, we present a blueprint for applying game theory to data pricing. From a game-theoretic perspective, we highlight the unique characteristics of data (compared to traditional goods) and suggest important desiderata for effective data pricing. We identify four key dimensions (Participant, Object, Action, and Information) to understand the landscape of game theory based data pricing. Within each dimension …"
Li Xiong,Synthetic Information and Digital Twins for Pandemic Science: Challenges and Opportunities,2023,https://ieeexplore.ieee.org/abstract/document/10431612/,"Understanding complex systems requires understanding interactions between different domains and different scales. Pandemic science serves as an exemplar of such complex systems. During the COVID-19 pandemic, a significant amount of health surveillance infrastructure had to be created on the fly. This infrastructure, while useful in many cases, was unable to provide individual-level data across relevant domains due to limitations and privacy barriers. Finding technical solutions to these barriers requires a careful evaluation at scale. Synthetic information (sometimes known as digital twins) coupled with detailed mechanistic models are potent, but underutilized, tools for representing and analyzing complex societal systems. In this paper, we describe how synthetic information can be used to evaluate these technical solutions, and thereby support pandemic preparedness and response. As an illustration, we …"
Li Xiong,Supporting pandemic preparedness with privacy enhancing technology,2023,https://ieeexplore.ieee.org/abstract/document/10431617/,"The COVID-19 pandemic magnified the profound repercussions of modern health crises on a global level. To effectively prepare for subsequent outbreaks, a focus on hyperlocal, real-time tracking of disease trajectories is crucial. At the heart of this strategy lies the fusion of real-time mobility data with epidemiological insights and social determinants. This synergy enables authoritative entities to make timely and informed decisions. However, the intricate process of collecting, analyzing, and sharing data among diverse stakeholders is fraught with privacy dilemmas, thereby impeding optimal data-driven preparedness strategies. To address this, privacy-enhancing technologies (PETs) have risen to prominence as indispensable tools in bolstering pandemic readiness. This paper seeks to elucidate the prevailing challenges and unexplored avenues within this dynamic domain."
Li Xiong,Privacy and security issues in DDDAS systems,2021,https://link.springer.com/chapter/10.1007/978-3-030-74568-4_27,"With the rapidly increasing prevalence of the DDDAS paradigm, privacy and security issues have come to the forefront. In the measurement, feedback, and control phases of dynamic data driven adaptive systems, protecting data integrity (security) and inferred sensitive information (privacy) from inadvertent release or malicious attack is crucial. The PREDICT (Privacy and secuRity Enhancing Dynamic Information Collection and moniToring) project investigates secure dynamic and adaptive techniques for distributed data collection and fusion, sampling and monitoring, and data modeling that preserve privacy and integrity. These approaches deliver provable guarantees of privacy and security while ensuring high fidelity, and complement encryption-based techniques. Application scenarios include health surveillance data release, traffic analysis, situation awareness and monitoring, and fleet tracking."
Li Xiong,Node-level Contrastive Unlearning on Graph Neural Networks,2025,https://arxiv.org/abs/2503.02959,"Graph unlearning aims to remove a subset of graph entities (i.e. nodes and edges) from a graph neural network (GNN) trained on the graph. Unlike machine unlearning for models trained on Euclidean-structured data, effectively unlearning a model trained on non-Euclidean-structured data, such as graphs, is challenging because graph entities exhibit mutual dependencies. Existing works utilize graph partitioning, influence function, or additional layers to achieve graph unlearning. However, none of them can achieve high scalability and effectiveness without additional constraints. In this paper, we achieve more effective graph unlearning by utilizing the embedding space. The primary training objective of a GNN is to generate proper embeddings for each node that encapsulates both structural information and node feature representations. Thus, directly optimizing the embedding space can effectively remove the target nodes' information from the model. Based on this intuition, we propose node-level contrastive unlearning (Node-CUL). It removes the influence of the target nodes (unlearning nodes) by contrasting the embeddings of remaining nodes and neighbors of unlearning nodes. Through iterative updates, the embeddings of unlearning nodes gradually become similar to those of unseen nodes, effectively removing the learned information without directly incorporating unseen data. In addition, we introduce a neighborhood reconstruction method that optimizes the embeddings of the neighbors in order to remove influence of unlearning nodes to maintain the utility of the GNN model. Experiments on various graph data and models show that …"
Li Xiong,Privacy and Accuracy-Aware AI/ML Model Deduplication,2025,https://arxiv.org/abs/2503.02862,"With the growing adoption of privacy-preserving machine learning algorithms, such as Differentially Private Stochastic Gradient Descent (DP-SGD), training or fine-tuning models on private datasets has become increasingly prevalent. This shift has led to the need for models offering varying privacy guarantees and utility levels to satisfy diverse user requirements. However, managing numerous versions of large models introduces significant operational challenges, including increased inference latency, higher resource consumption, and elevated costs. Model deduplication is a technique widely used by many model serving and database systems to support high-performance and low-cost inference queries and model diagnosis queries. However, none of the existing model deduplication works has considered privacy, leading to unbounded aggregation of privacy costs for certain deduplicated models and inefficiencies when applied to deduplicate DP-trained models. We formalize the problems of deduplicating DP-trained models for the first time and propose a novel privacy- and accuracy-aware deduplication mechanism to address the problems. We developed a greedy strategy to select and assign base models to target models to minimize storage and privacy costs. When deduplicating a target model, we dynamically schedule accuracy validations and apply the Sparse Vector Technique to reduce the privacy costs associated with private validation data. Compared to baselines that do not provide privacy guarantees, our approach improved the compression ratio by up to  for individual models (including large language models and vision …"
Li Xiong,"Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training",2025,https://arxiv.org/abs/2502.19726,"Large language models (LLMs) have become the backbone of modern natural language processing but pose privacy concerns about leaking sensitive training data. Membership inference attacks (MIAs), which aim to infer whether a sample is included in a model's training dataset, can serve as a foundation for broader privacy threats. Existing defenses designed for traditional classification models do not account for the sequential nature of text data. As a result, they either require significant computational resources or fail to effectively mitigate privacy risks in LLMs. In this work, we propose a lightweight yet effective empirical privacy defense for protecting training data of language modeling by leveraging the token-specific characteristics. By analyzing token dynamics during training, we propose a token selection strategy that categorizes tokens into hard tokens for learning and memorized tokens for unlearning. Subsequently, our training-phase defense optimizes a novel dual-purpose token-level loss to achieve a Pareto-optimal balance between utility and privacy. Extensive experiments demonstrate that our approach not only provides strong protection against MIAs but also improves language modeling performance by around 10\% across various LLM architectures and datasets compared to the baselines."
Li Xiong,HARBOR: Exploring Persona Dynamics in Multi-Agent Competition,2025,https://arxiv.org/abs/2502.12149,"We investigate factors contributing to LLM agents' success in competitive multi-agent environments, using auctions as a testbed where agents bid to maximize profit. The agents are equipped with bidding domain knowledge, distinct personas that reflect item preferences, and a memory of auction history. Our work extends the classic auction scenario by creating a realistic environment where multiple agents bid on houses, weighing aspects such as size, location, and budget to secure the most desirable homes at the lowest prices. Particularly, we investigate three key questions: (a) How does a persona influence an agent's behavior in a competitive setting? (b) Can an agent effectively profile its competitors' behavior during auctions? (c) How can persona profiling be leveraged to create an advantage using strategies such as theory of mind? Through a series of experiments, we analyze the behaviors of LLM agents and shed light on new findings. Our testbed, called HARBOR, offers a valuable platform for deepening our understanding of multi-agent workflows in competitive environments."
Li Xiong,Auto-Search and Refinement: An Automated Framework for Gender Bias Mitigation in Large Language Models,2025,https://arxiv.org/abs/2502.11559,"Pre-training large language models (LLMs) on vast text corpora enhances natural language processing capabilities but risks encoding social biases, particularly gender bias. While parameter-modification methods like fine-tuning mitigate bias, they are resource-intensive, unsuitable for closed-source models, and lack adaptability to evolving societal norms. Instruction-based approaches offer flexibility but often compromise task performance. To address these limitations, we propose $\textit{FaIRMaker}$, an automated and model-independent framework that employs an $\textbf{auto-search and refinement}$ paradigm to adaptively generate Fairwords, which act as instructions integrated into input queries to reduce gender bias and enhance response quality. Extensive experiments demonstrate that $\textit{FaIRMaker}$ automatically searches for and dynamically refines Fairwords, effectively mitigating gender bias while preserving task integrity and ensuring compatibility with both API-based and open-source LLMs."
Li Xiong,Computing Shapley Values for Dynamic Data,2025,https://ieeexplore.ieee.org/abstract/document/10856827/,"Data valuation is a core function in data markets and cooperative data sharing. Shapley value is a widely used approach to fairly measure the contribution of data points towards a collective utility (e.g., a machine learning model trained from the data). However, computing Shapley values is known to be in general #P-hard due to the exponential utility evaluation. Furthermore, the presence of dynamic data poses additional challenges due to the prohibitively expensive cost of recomputing from scratch. In this paper, we study the problem of Dynamic Shapley Value Computation, which focuses on updating Shapley values when dynamically adding or deleting data points. For adding, to prune redundant computation of overlapping model utilities, we propose the pivot-based algorithm that can reduce half the computation time in expectation. We also propose delta-based algorithms to capture Shapley value changes …"
Li Xiong,ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation,2024,https://arxiv.org/abs/2412.21123,"As large language models (LLMs) increasingly depend on web-scraped datasets, concerns over unauthorized use of copyrighted or personal content for training have intensified. Despite regulations such as the General Data Protection Regulation (GDPR), data owners still have limited control over the use of their content in model training. To address this, we propose ExpShield, a proactive self-guard mechanism that empowers content owners to embed invisible perturbations into their text, limiting data misuse in LLMs training without affecting readability. This preemptive approach enables data owners to protect sensitive content directly, without relying on a third-party to perform defense. Starting from the random perturbation, we demonstrate the rationale for using perturbation to conceal protected content. We further enhance the efficiency by identifying memorization triggers and creating pitfalls to diverge the model memorization in a more focused way. To validate our defense's effectiveness, we propose a novel metric of instance exploitation which captures the individual risk raised by model training. The experimental results validate the effectiveness of our approach as the MIA AUC decreases from 0.95 to 0.55, and instance exploitation approaches zero. This suggests that the individual risk does not increase after training, underscoring the significance of proactive defenses in protecting copyrighted data."
Li Xiong,Controllable Visit Trajectory Generation with Spatiotemporal Constraints,2024,https://ieeexplore.ieee.org/abstract/document/10884246/,"Human mobility data, represented as sequences of visits, are crucial for various application domains, including transportation, urban planning, and public health. However, large-scale human mobility data is typically inaccessible to researchers due to the high cost of data collection and privacy concerns. This limitation has led to several studies proposing learned models to generate synthetic visit sequences. Despite this progress, existing approaches lack mechanisms to control the generation process, which prevents the incorporation of prior knowledge and the spatiotemporal specification of certain visits. To address these limitations, we formally define the Constraint Trajectory Generation problem and introduce Geo-CETRA (Constraint Enforced Trajectory Generation), a novel framework that operates within the continuous spatiotemporal space, enabling direct generation of geographical coordinates and …"
Li Xiong,Patient-Centered and Practical Privacy to Support AI for Healthcare,2024,https://ieeexplore.ieee.org/abstract/document/10835628/,"The increasing integration of artificial intelligence (AI) in healthcare holds great promise for enhancing patient care through predictive modeling and clinical decision support. However, privacy concerns emerge when deploying and sharing AI models, as adversaries can exploit vulnerabilities to infer sensitive patient information. Differential privacy (DP) has been the state-of-the-art approach to mitigate these risks, yet its adoption in healthcare remains limited due to complex privacy needs and the trade-off between privacy guarantees and model utility. This vision paper highlights the challenges and potential research directions of creating patient-centered privacy solutions that are practical, flexible, and transparent. They include improving patient awareness and control, developing privacy-enhanced training mechanisms that respect diverse patient preferences, and enabling post-training unlearning to adapt to …"
Li Xiong,System and method for mitigating international revenue share fraud,2024,https://patents.google.com/patent/US12126712B2/en,"Aspects of the subject disclosure may include, for example, a non-transitory, machine-readable medium, comprising executable instructions that, when executed by a processing system including a processor, facilitate performance of operations including receiving a call; selecting a next carrier to handoff the call; generating a call data record (CDR) for the handoff to the next carrier; encrypting the CDR using a call encryption key, thereby creating an encrypted CDR; encrypting the encrypted CDR using a committee encryption key, thereby creating a double encrypted CDR; recording the double encrypted CDR to a blockchain; and sending the call encryption key to the next carrier. Other embodiments are disclosed."
Li Xiong,Enhanced Privacy Bound for Shuffle Model with Personalized Privacy,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679911,"The shuffle model of Differential Privacy (DP) is an enhanced privacy protocol which significantly amplifies the central DP guarantee by anonymizing and shuffling the local randomized data. Yet, deriving a tight privacy bound is challenging due to its complicated randomization protocol. While most existing works focused on uniform local privacy settings, this work focuses on a more practical personalized privacy setting. To bound the privacy after shuffling, we need to capture the probability of each user generating clones of the neighboring data points and quantify the indistinguishability between two distributions of the number of clones on neighboring datasets. Existing works either inaccurately capture the probability or underestimate the indistinguishability. We develop a more precise analysis, which yields a general and tighter bound for arbitrary DP mechanisms. Firstly, we derive the clone-generating probability …"
Li Xiong,Geo-Llama: Leveraging LLMs for Human Mobility Trajectory Generation with Spatiotemporal Constraints,2024,https://arxiv.org/abs/2408.13918,"Simulating human mobility data is essential for various application domains, including transportation, urban planning, and epidemic control, since real data are often inaccessible to researchers due to expensive costs and privacy issues. Several existing deep generative solutions propose learning from real trajectories to generate synthetic ones. Despite the progress, most of them suffer from training stability issues and scale poorly with growing data size. More importantly, they generally lack control mechanisms to steer the generated trajectories based on spatiotemporal constraints such as fixing specific visits. To address such limitations, we formally define the controlled trajectory generation problem with spatiotemporal constraints and propose Geo-Llama. This novel LLM-inspired framework enforces explicit visit constraints in a contextually coherent way. It fine-tunes pre-trained LLMs on trajectories with a visit-wise permutation strategy where each visit corresponds to a time and location. This enables the model to capture the spatiotemporal patterns regardless of visit orders and allows flexible and in-context constraint integration through prompts during generation. Extensive experiments on real-world and synthetic datasets validate the effectiveness of Geo-Llama, demonstrating its versatility and robustness in handling a broad range of constraints to generate more realistic trajectories compared to existing methods."
Li Xiong,DPDR: Gradient Decomposition and Reconstruction for Differentially Private Deep Learning,2024,https://arxiv.org/abs/2406.02744,"Differentially Private Stochastic Gradients Descent (DP-SGD) is a prominent paradigm for preserving privacy in deep learning. It ensures privacy by perturbing gradients with random noise calibrated to their entire norm at each training step. However, this perturbation suffers from a sub-optimal performance: it repeatedly wastes privacy budget on the general converging direction shared among gradients from different batches, which we refer as common knowledge, yet yields little information gain. Motivated by this, we propose a differentially private training framework with early gradient decomposition and reconstruction (DPDR), which enables more efficient use of the privacy budget. In essence, it boosts model utility by focusing on incremental information protection and recycling the privatized common knowledge learned from previous gradients at early training steps. Concretely, DPDR incorporates three steps. First, it disentangles common knowledge and incremental information in current gradients by decomposing them based on previous noisy gradients. Second, most privacy budget is spent on protecting incremental information for higher information gain. Third, the model is updated with the gradient reconstructed from recycled common knowledge and noisy incremental information. Theoretical analysis and extensive experiments show that DPDR outperforms state-of-the-art baselines on both convergence rate and accuracy."
Li Xiong,Does Differential Privacy Prevent Backdoor Attacks in Practice?,2024,https://link.springer.com/chapter/10.1007/978-3-031-65172-4_20,"Differential Privacy (DP) was originally developed to protect privacy. However, it has recently been utilized to secure machine learning (ML) models from poisoning attacks, with DP-SGD receiving substantial attention. Nevertheless, a thorough investigation is required to assess the effectiveness of different DP techniques in preventing backdoor attacks in practice. In this paper, we investigate the effectiveness of DP-SGD and, for the first time, examine PATE and Label-DP in the context of backdoor attacks. We also explore the role of different components of DP algorithms in defending against backdoor attacks and will show that PATE is effective against these attacks due to the bagging structure of the teacher models it employs. Our experiments reveal that hyper-parameters and the number of backdoors in the training dataset impact the success of DP algorithms. We also conclude that while Label-DP algorithms …"
Li Xiong,System and method for mitigating international revenue share fraud,2023,https://patents.google.com/patent/US11706023B2/en,"2021-05-24 Assigned to AT&T INTELLECTUAL PROPERTY I, LP reassignment AT&T INTELLECTUAL PROPERTY I, LP ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: CHU, TEDDY, DASU, TAMRAPARNI, KANZA, YARON, SRIVASTAVA, DIVESH"
Li Xiong,Wasserstein Adversarial Examples on Univariant Time Series Data,2023,https://arxiv.org/abs/2303.12357,"Adversarial examples are crafted by adding indistinguishable perturbations to normal examples in order to fool a well-trained deep learning model to misclassify. In the context of computer vision, this notion of indistinguishability is typically bounded by  or other norms. However, these norms are not appropriate for measuring indistinguishiability for time series data. In this work, we propose adversarial examples in the Wasserstein space for time series data for the first time and utilize Wasserstein distance to bound the perturbation between normal examples and adversarial examples. We introduce Wasserstein projected gradient descent (WPGD), an adversarial attack method for perturbing univariant time series data. We leverage the closed-form solution of Wasserstein distance in the 1D space to calculate the projection step of WPGD efficiently with the gradient descent method. We further propose a two-step projection so that the search of adversarial examples in the Wasserstein space is guided and constrained by Euclidean norms to yield more effective and imperceptible perturbations. We empirically evaluate the proposed attack on several time series datasets in the healthcare domain. Extensive results demonstrate that the Wasserstein attack is powerful and can successfully attack most of the target classifiers with a high attack success rate. To better study the nature of Wasserstein adversarial example, we evaluate a strong defense mechanism named Wasserstein smoothing for potential certified robustness defense. Although the defense can achieve some accuracy gain, it still has limitations in many cases and leaves space for …"
Li Xiong,Home-based Remote Digital Monitoring to Assess ALS progression (Track-ALS),2023,https://scholar.google.com/scholar?cluster=9281011128554010155&hl=en&oi=scholarr,
Li Xiong,CrowdTeacher: Robust Co-teaching with Noisy Answers and Sample-Specific Perturbations for Tabular Data,2021,https://link.springer.com/chapter/10.1007/978-3-030-75765-6_15,"Samples with ground truth labels may not always be available in numerous domains. While learning from crowdsourcing labels has been explored, existing models can still fail in the presence of sparse, unreliable, or differing annotations. Co-teaching methods have shown promising improvements for computer vision problems with noisy labels by employing two classifiers trained on each others’ confident samples in each batch. Inspired by the idea of separating confident and uncertain samples during the training process, we extend it for the crowdsourcing problem. Our model, CrowdTeacher, uses the idea that perturbation in the input space model can improve the robustness of the classifier for noisy labels. Treating crowdsourcing annotations as a source of noisy labeling, we perturb samples based on the certainty from the aggregated annotations. The perturbed samples are fed to a Co-teaching algorithm tuned …"
Li Xiong,Spatiotemporal Privacy,2021,https://link.springer.com/content/pdf/10.1007/978-3-642-27739-9_1545-1.pdf,"BackgroundLocation privacy has been extensively studied in the literature with focus on specific privacy goals, privacy metrics and location privacy preserving mechanisms (LPPMs). The privacy goal defines what should be protected, which typically are single location and a sequence of locations (ie, a trajectory). The privacy metrics define the quantitative measurement of the protection regarding a specific privacy goal. The prior art of location privacy metrics, such as geo-indistinguishability (Andrés et al., 2013) and δ-location set privacy (Xiao and Xiong, 2015)(Xiao et al., 2017), is extending differential privacy (Dwork, 2008) to location data, which is considered a rigorous approach to define privacy. LPPM achieves specific privacy metrics. One well-known LPPM for geo-indistinguishability is planar Laplace mechanism, which randomly transforms the true location to a perturbed one.Spatiotemporal privacy is …"
Li Xiong,New Methods to Protect Privacy When Using Patient Health Data to Compare Treatments,2021,https://www.ncbi.nlm.nih.gov/books/NBK599332/,"Background:Sharing and reusing clinical data is key to enabling patient-centered outcomes research (PCOR). Data registries established for conducting PCOR must ensure appropriate privacy and confidentiality protections as stated by the PCORI Methodology Committee. There is rising concern that current deidentification or “anonymization” practices insufficiently protect against reidentification and disclosure of private patient data.Objectives:The objective of this project was to develop a framework, which we named patient-centered Statistical Health informAtion RElease (pSHARE), for building patient-centered and privacy-preserving statistical data registries for PCOR using the rigorous differential privacy (DP) framework, which gives a provable guarantee on the privacy of patients who provide data. The main goal was to optimize the trade-off between data utility (ie, minimal noise) and data privacy (ie, DP …"
Carl J. Yang,Adversarial attack and defense on graph data: A survey,2022,https://ieeexplore.ieee.org/abstract/document/9878092/,"Deep neural networks (DNNs) have been widely applied to various applications, including image classification, text generation, audio recognition, and graph data analysis. However, recent studies have shown that DNNs are vulnerable to adversarial attacks. Though there are several works about adversarial attack and defense strategies on domains such as images and natural language processing, it is still difficult to directly transfer the learned knowledge to graph data due to its representation structure. Given the importance of graph analysis, an increasing number of studies over the past few years have attempted to analyze the robustness of machine learning models on graph data. Nevertheless, existing research considering adversarial behaviors on graph data often focuses on specific types of attacks with certain assumptions. In addition, each work proposes its own mathematical formulation, which makes the …"
Carl J. Yang,Heterogeneous network representation learning: A unified framework with survey and benchmark,2020,https://ieeexplore.ieee.org/abstract/document/9300240/,"Since real-world objects and their interactions are often multi-modal and multi-typed, heterogeneous networks have been widely used as a more powerful, realistic, and generic superclass of traditional homogeneous networks (graphs). Meanwhile, representation learning ( a.k.a.  embedding) has recently been intensively studied and shown effective for various network mining and analytical tasks. In this work, we aim to provide a unified framework to deeply summarize and evaluate existing research on heterogeneous network embedding (HNE), which includes but goes beyond a normal survey. Since there has already been a broad body of HNE algorithms, as the first contribution of this article, we provide a generic paradigm for the systematic categorization and analysis over the merits of various existing HNE algorithms. Moreover, existing HNE algorithms, though mostly claimed generic, are often evaluated on …"
Carl J. Yang,Fedgraphnn: A federated learning system and benchmark for graph neural networks,2021,https://arxiv.org/abs/2104.07145,"Graph Neural Network (GNN) research is rapidly growing thanks to the capacity of GNNs in learning distributed representations from graph-structured data. However, centralizing a massive amount of real-world graph data for GNN training is prohibitive due to privacy concerns, regulation restrictions, and commercial competitions. Federated learning (FL), a trending distributed learning paradigm, provides possibilities to solve this challenge while preserving data privacy. Despite recent advances in vision and language domains, there is no suitable platform for the FL of GNNs. To this end, we introduce FedGraphNN, an open FL benchmark system that can facilitate research on federated GNNs. FedGraphNN is built on a unified formulation of graph FL and contains a wide range of datasets from different domains, popular GNN models, and FL algorithms, with secure and efficient system support. Particularly for the datasets, we collect, preprocess, and partition 36 datasets from 7 domains, including both publicly available ones and specifically obtained ones such as hERG and Tencent. Our empirical analysis showcases the utility of our benchmark system, while exposing significant challenges in graph FL: federated GNNs perform worse in most datasets with a non-IID split than centralized GNNs; the GNN model that attains the best result in the centralized setting may not maintain its advantage in the FL setting. These results imply that more research efforts are needed to unravel the mystery behind federated GNNs. Moreover, our system performance analysis demonstrates that the FedGraphNN system is computationally efficient and secure to large …"
Carl J. Yang,Federated graph classification over non-iid graphs,2021,https://proceedings.neurips.cc/paper/2021/hash/9c6947bd95ae487c81d4e19d3ed8cd6f-Abstract.html,"Federated learning has emerged as an important paradigm for training machine learning models in different domains. For graph-level tasks such as graph classification, graphs can also be regarded as a special type of data samples, which can be collected and stored in separate local systems. Similar to other domains, multiple local systems, each holding a small set of graphs, may benefit from collaboratively training a powerful graph mining model, such as the popular graph neural networks (GNNs). To provide more motivation towards such endeavors, we analyze real-world graphs from different domains to confirm that they indeed share certain graph properties that are statistically significant compared with random graphs. However, we also find that different sets of graphs, even from the same domain or same dataset, are non-IID regarding both graph structures and node features. To handle this, we propose a graph clustered federated learning (GCFL) framework that dynamically finds clusters of local systems based on the gradients of GNNs, and theoretically justify that such clusters can reduce the structure and feature heterogeneity among graphs owned by the local systems. Moreover, we observe the gradients of GNNs to be rather fluctuating in GCFL which impedes high-quality clustering, and design a gradient sequence-based clustering mechanism based on dynamic time warping (GCFL+). Extensive experimental results and in-depth analysis demonstrate the effectiveness of our proposed frameworks."
Carl J. Yang,Subgraph federated learning with missing neighbor generation,2021,https://proceedings.neurips.cc/paper/2021/hash/34adeb8e3242824038aa65460a47c29e-Abstract.html,"Graphs have been widely used in data mining and machine learning due to their unique representation of real-world objects and their interactions. As graphs are getting bigger and bigger nowadays, it is common to see their subgraphs separately collected and stored in multiple local systems. Therefore, it is natural to consider the subgraph federated learning setting, where each local system holds a small subgraph that may be biased from the distribution of the whole graph. Hence, the subgraph federated learning aims to collaboratively train a powerful and generalizable graph mining model without directly sharing their graph data. In this work, towards the novel yet realistic setting of subgraph federated learning, we propose two major techniques:(1) FedSage, which trains a GraphSage model based on FedAvg to integrate node features, link structures, and task labels on multiple local subgraphs;(2) FedSage+, which trains a missing neighbor generator along FedSage to deal with missing links across local subgraphs. Empirical results on four real-world graph datasets with synthesized subgraph federated learning settings demonstrate the effectiveness and efficiency of our proposed techniques. At the same time, consistent theoretical implications are made towards their generalization ability on the global graphs."
Carl J. Yang,Brain network transformer,2022,https://proceedings.neurips.cc/paper_files/paper/2022/hash/a408234a9b80604a9cf6ca518e474550-Abstract-Conference.html,"Human brains are commonly modeled as networks of Regions of Interest (ROIs) and their connections for the understanding of brain functions and mental disorders. Recently, Transformer-based models have been studied over different types of data, including graphs, shown to bring performance gains widely. In this work, we study Transformer-based models for brain network analysis. Driven by the unique properties of data, we model brain networks as graphs with nodes of fixed size and order, which allows us to (1) use connection profiles as node features to provide natural and low-cost positional information and (2) learn pair-wise connection strengths among ROIs with efficient attention weights across individuals that are predictive towards downstream analysis tasks. Moreover, we propose an Orthonormal Clustering Readout operation based on self-supervised soft clustering and orthonormal projection. This design accounts for the underlying functional modules that determine similar behaviors among groups of ROIs, leading to distinguishable cluster-aware node embeddings and informative graph embeddings. Finally, we re-standardize the evaluation pipeline on the only one publicly available large-scale brain network dataset of ABIDE, to enable meaningful comparison of different models. Experiment results show clear improvements of our proposed Brain Network Transformer on both the public ABIDE and our restricted ABCD datasets. The implementation is available at https://github. com/Wayfear/BrainNetworkTransformer."
Carl J. Yang,Braingb: a benchmark for brain network analysis with graph neural networks,2022,https://ieeexplore.ieee.org/abstract/document/9933896/,"Mapping the connectome of the human brain using structural or functional connectivity has become one of the most pervasive paradigms for neuroimaging analysis. Recently, Graph Neural Networks (GNNs) motivated from geometric deep learning have attracted broad interest due to their established power for modeling complex networked data. Despite their superior performance in many fields, there has not yet been a systematic study of how to design effective GNNs for brain network analysis. To bridge this gap, we present BrainGB, a benchmark for brain network analysis with GNNs. BrainGB standardizes the process by (1) summarizing brain network construction pipelines for both functional and structural neuroimaging modalities and (2) modularizing the implementation of GNN designs. We conduct extensive experiments on datasets across cohorts and modalities and recommend a set of general recipes for …"
Carl J. Yang,Transfer learning of graph neural networks with ego-graph information maximization,2021,https://proceedings.neurips.cc/paper/2021/hash/0dd6049f5fa537d41753be6d37859430-Abstract.html,"Graph neural networks (GNNs) have achieved superior performance in various applications, but training dedicated GNNs can be costly for large-scale graphs. Some recent work started to study the pre-training of GNNs. However, none of them provide theoretical insights into the design of their frameworks, or clear requirements and guarantees towards their transferability. In this work, we establish a theoretically grounded and practically useful framework for the transfer learning of GNNs. Firstly, we propose a novel view towards the essential graph information and advocate the capturing of it as the goal of transferable GNN training, which motivates the design of EGI (Ego-Graph Information maximization) to analytically achieve this goal. Secondly, when node features are structure-relevant, we conduct an analysis of EGI transferability regarding the difference between the local graph Laplacians of the source and target graphs. We conduct controlled synthetic experiments to directly justify our theoretical conclusions. Comprehensive experiments on two real-world network datasets show consistent results in the analyzed setting of direct-transfering, while those on large-scale knowledge graphs show promising results in the more practical setting of transfering with fine-tuning."
Carl J. Yang,Domain specialization as the key to make large language models disruptive: A comprehensive survey,2023,https://arxiv.org/abs/2305.18703,"Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). Domain specification techniques are key to make large language models disruptive in many applications. Specifically, to solve these hurdles, there has been a notable increase in research and practices conducted in recent years on the domain specialization of LLMs. This emerging field of study, with its substantial potential for impact, necessitates a comprehensive and systematic review to better summarize and guide ongoing work in this area. In this article, we present a comprehensive survey on domain specification techniques for large language models, an emerging direction critical for large language model applications. First, we propose a systematic taxonomy that categorizes the LLM domain-specialization techniques based on the accessibility to LLMs and summarizes the framework for all the subcategories as well as their relations and differences to each other. Second, we present an extensive taxonomy of critical application domains that can benefit dramatically from specialized LLMs, discussing their practical significance and open challenges. Last, we offer our insights …"
Carl J. Yang,Fbnetgen: Task-aware gnn-based fmri analysis via functional brain network generation,2022,https://proceedings.mlr.press/v172/kan22a.html,"Functional magnetic resonance imaging (fMRI) is one of the most common imaging modalities to investigate brain functions. Recent studies in neuroscience stress the great potential of functional brain networks constructed from fMRI data for clinical predictions. Traditional functional brain networks, however, are noisy and unaware of downstream prediction tasks, while also incompatible with the deep graph neural network (GNN) models. In order to fully unleash the power of GNNs in network-based fMRI analysis, we develop FBNETGEN, a task-aware and interpretable fMRI analysis framework via deep brain network generation. In particular, we formulate (1) prominent region of interest (ROI) features extraction,(2) brain networks generation, and (3) clinical predictions with GNNs, in an end-to-end trainable model under the guidance of particular prediction tasks. Along with the process, the key novel component is the graph generator which learns to transform raw time-series features into task-oriented brain networks. Our learnable graphs also provide unique interpretations by highlighting prediction-related brain regions. Comprehensive experiments on two datasets, ie, the recently released and currently largest publicly available fMRI dataset Adolescent Brain Cognitive Development (ABCD), and the widely-used fMRI dataset PNC, prove the superior effectiveness and interpretability of FBNETGEN. The implementation is available at https://github. com/Wayfear/FBNETGEN."
Carl J. Yang,On positional and structural node features for graph neural networks on non-attributed graphs,2022,https://dl.acm.org/doi/abs/10.1145/3511808.3557661,"Graph neural networks (GNNs) have been widely used in various graph-related problems such as node classification and graph classification, where the superior performance is mainly established when natural node features are available. However, it is not well understood how GNNs work without natural node features, especially regarding the various ways to construct artificial ones. In this paper, we point out the two types of artificial node features, i.e., positional and structural node features, and provide insights on why each of them is more appropriate for certain tasks, i.e., positional node classification, structural node classification, and graph classification. Extensive experimental results on 10 benchmark datasets validate our insights, thus leading to a practical guideline on the choices between different artificial node features for GNNs on non-attributed graphs. The code is available at https://github.com/zjzijielu …"
Carl J. Yang,Interpretable graph neural networks for connectome-based brain disorder analysis,2022,https://link.springer.com/chapter/10.1007/978-3-031-16452-1_36,"Human brains lie at the core of complex neurobiological systems, where the neurons, circuits, and subsystems interact in enigmatic ways. Understanding the structural and functional mechanisms of the brain has long been an intriguing pursuit for neuroscience research and clinical disorder therapy. Mapping the connections of the human brain as a network is one of the most pervasive paradigms in neuroscience. Graph Neural Networks (GNNs) have recently emerged as a potential method for modeling complex network data. Deep models, on the other hand, have low interpretability, which prevents their usage in decision-critical contexts like healthcare. To bridge this gap, we propose an interpretable framework to analyze disorder-specific Regions of Interest (ROIs) and prominent connections. The proposed framework consists of two modules: a brain-network-oriented backbone model for disease prediction and a …"
Carl J. Yang,A survey on graph structure learning: Progress and opportunities,2021,https://arxiv.org/abs/2103.03036,"Graphs are widely used to describe real-world objects and their interactions. Graph Neural Networks (GNNs) as a de facto model for analyzing graphstructured data, are highly sensitive to the quality of the given graph structures. Therefore, noisy or incomplete graphs often lead to unsatisfactory representations and prevent us from fully understanding the mechanism underlying the system. In pursuit of an optimal graph structure for downstream tasks, recent studies have sparked an effort around the central theme of Graph Structure Learning (GSL), which aims to jointly learn an optimized graph structure and corresponding graph representations. In the presented survey, we broadly review recent progress in GSL methods. Specifically, we first formulate a general pipeline of GSL and review state-of-the-art methods classified by the way of modeling graph structures, followed by applications of GSL across domains. Finally, we point out some issues in current studies and discuss future directions."
Carl J. Yang,Beyond efficiency: A systematic survey of resource-efficient large language models,2024,https://arxiv.org/abs/2401.00625,"The burgeoning field of Large Language Models (LLMs), exemplified by sophisticated models like OpenAI's ChatGPT, represents a significant advancement in artificial intelligence. These models, however, bring forth substantial challenges in the high consumption of computational, memory, energy, and financial resources, especially in environments with limited resource capabilities. This survey aims to systematically address these challenges by reviewing a broad spectrum of techniques designed to enhance the resource efficiency of LLMs. We categorize methods based on their optimization focus: computational, memory, energy, financial, and network resources and their applicability across various stages of an LLM's lifecycle, including architecture design, pretraining, finetuning, and system design. Additionally, the survey introduces a nuanced categorization of resource efficiency techniques by their specific resource types, which uncovers the intricate relationships and mappings between various resources and corresponding optimization techniques. A standardized set of evaluation metrics and datasets is also presented to facilitate consistent and fair comparisons across different models and techniques. By offering a comprehensive overview of the current sota and identifying open research avenues, this survey serves as a foundational reference for researchers and practitioners, aiding them in developing more sustainable and efficient LLMs in a rapidly evolving landscape."
Carl J. Yang,When do gnns work: Understanding and improving neighborhood aggregation,2020,https://par.nsf.gov/biblio/10208512,"Graph Neural Networks (GNNs) have been shown to be powerful in a wide range of graph-related tasks. While there exists various GNN models, a critical common ingredient is neighborhood aggregation, where the embedding of each node is updated by referring to the embedding of its neighbors. This paper aims to provide a better understanding of this mechanisms by asking the following question: Is neighborhood aggregation always necessary and beneficial? In short, the answer is no. We carve out two conditions under which neighborhood aggregation is not helpful: (1) when a node's neighbors are highly dissimilar and (2) when a node's embedding is already similar with that of its neighbors. We propose novel metrics that quantitatively measure these two circumstances and integrate them into an Adaptive-layer module. Our experiments show that allowing for node-specific aggregation degrees have significant advantage over current GNNs."
Carl J. Yang,Graph auto-encoder via neighborhood wasserstein reconstruction,2022,https://arxiv.org/abs/2202.09025,"Graph neural networks (GNNs) have drawn significant research attention recently, mostly under the setting of semi-supervised learning. When task-agnostic representations are preferred or supervision is simply unavailable, the auto-encoder framework comes in handy with a natural graph reconstruction objective for unsupervised GNN training. However, existing graph auto-encoders are designed to reconstruct the direct links, so GNNs trained in this way are only optimized towards proximity-oriented graph mining tasks, and will fall short when the topological structures matter. In this work, we revisit the graph encoding process of GNNs which essentially learns to encode the neighborhood information of each node into an embedding vector, and propose a novel graph decoder to reconstruct the entire neighborhood information regarding both proximity and structure via Neighborhood Wasserstein Reconstruction (NWR). Specifically, from the GNN embedding of each node, NWR jointly predicts its node degree and neighbor feature distribution, where the distribution prediction adopts an optimal-transport loss based on the Wasserstein distance. Extensive experiments on both synthetic and real-world network datasets show that the unsupervised node representations learned with NWR have much more advantageous in structure-oriented graph mining tasks, while also achieving competitive performance in proximity-oriented ones."
Carl J. Yang,Understanding structural vulnerability in graph convolutional networks,2021,https://arxiv.org/abs/2108.06280,"Recent studies have shown that Graph Convolutional Networks (GCNs) are vulnerable to adversarial attacks on the graph structure. Although multiple works have been proposed to improve their robustness against such structural adversarial attacks, the reasons for the success of the attacks remain unclear. In this work, we theoretically and empirically demonstrate that structural adversarial examples can be attributed to the non-robust aggregation scheme (i.e., the weighted mean) of GCNs. Specifically, our analysis takes advantage of the breakdown point which can quantitatively measure the robustness of aggregation schemes. The key insight is that weighted mean, as the basic design of GCNs, has a low breakdown point and its output can be dramatically changed by injecting a single edge. We show that adopting the aggregation scheme with a high breakdown point (e.g., median or trimmed mean) could significantly enhance the robustness of GCNs against structural attacks. Extensive experiments on four real-world datasets demonstrate that such a simple but effective method achieves the best robustness performance compared to state-of-the-art models."
Carl J. Yang,Multisage: Empowering gcn with contextualized multi-embeddings on web-scale multipartite networks,2020,https://dl.acm.org/doi/abs/10.1145/3394486.3403293,"Graph convolutional networks (GCNs) are a powerful class of graph neural networks. Trained in a semi-supervised end-to-end fashion, GCNs can learn to integrate node features and graph structures to generate high-quality embeddings that can be used for various downstream tasks like search and recommendation. However, existing GCNs mostly work on homogeneous graphs and consider a single embedding for each node, which do not sufficiently model the multi-facet nature and complex interaction of nodes in real-world networks. Here, we present a contextualized GCN engine by modeling the multipartite networks of target nodes and their intermediatecontext nodes that specify the contexts of their interactions. Towards the neighborhood aggregation process, we devise a contextual masking operation at the feature level and a contextual attention mechanism at the node level to achieve interaction …"
Carl J. Yang,SAIS: supervising and augmenting intermediate steps for document-level relation extraction,2021,https://arxiv.org/abs/2109.12093,"Stepping from sentence-level to document-level, the research on relation extraction (RE) confronts increasing text length and more complicated entity interactions. Consequently, it is more challenging to encode the key information sources--relevant contexts and entity types. However, existing methods only implicitly learn to model these critical information sources while being trained for RE. As a result, they suffer the problems of ineffective supervision and uninterpretable model predictions. In contrast, we propose to explicitly teach the model to capture relevant contexts and entity types by supervising and augmenting intermediate steps (SAIS) for RE. Based on a broad spectrum of carefully designed tasks, our proposed SAIS method not only extracts relations of better quality due to more effective supervision, but also retrieves the corresponding supporting evidence more accurately so as to enhance interpretability. By assessing model uncertainty, SAIS further boosts the performance via evidence-based data augmentation and ensemble inference while reducing the computational cost. Eventually, SAIS delivers state-of-the-art RE results on three benchmarks (DocRED, CDR, and GDA) and outperforms the runner-up by 5.04% relatively in F1 score in evidence retrieval on DocRED."
Carl J. Yang,Structure-enhanced heterogeneous graph contrastive learning,2022,https://epubs.siam.org/doi/abs/10.1137/1.9781611977172.10,"Recent years have seen a growing interest in Graph Contrastive Learning (GCL), which trains Graph Neural Network (GNN) model to discriminate similar and dissimilar pairs of nodes without human annotations. Most prior GCL work focuses on homogeneous graphs and little attention has been paid to Heterogeneous Graphs (HGs) that involve different types of nodes and edges. Moreover, earlier studies reveal that the explicit use of structure information of underlying graphs is useful for learning representations. Conventional GCL methods merely measure the likelihood of contrastive pairs according to node representations, which may not align with the true semantic similarities. How to leverage such structure information for GCL is not yet well-understood. To address the aforementioned challenges, this paper presents a novel method dubbed STructure-EnhaNced heterogeneous graph ContrastIve Learning …"
Carl J. Yang,Relation learning on social networks with multi-modal graph edge variational autoencoders,2020,https://dl.acm.org/doi/abs/10.1145/3336191.3371829,"While node semantics have been extensively explored in social networks, little research attention has been paid to pro le edge semantics, i.e., social relations. Ideal edge semantics should not only show that two users are connected, but also why they know each other and what they share in common. However, relations in social networks are often hard to pro le, due to noisy multi-modal signals and limited user-generated ground-truth labels.  In this work, we aim to develop a uni ed and principled frame- work that can pro le user relations as edge semantics in social networks by integrating multi-modal signals in the presence of noisy and incomplete data. Our framework is also exible towards limited or missing supervision. Speci cally, we assume a latent distribution of multiple relations underlying each user link, and learn them with multi-modal graph edge variational autoencoders. We encode the network data …"
Carl J. Yang,Beyond one-model-fits-all: A survey of domain specialization for large language models,2023,https://scholar.google.com/scholar?cluster=13397543884331003453&hl=en&oi=scholarr,
Carl J. Yang,Joint embedding of structural and functional brain networks with graph neural networks for mental illness diagnosis,2022,https://ieeexplore.ieee.org/abstract/document/9871118/,"Multimodal brain networks characterize complex connectivities among different brain regions from both structural and functional aspects and provide a new means for mental disease analysis. Recently, Graph Neural Networks (GNNs) have become a de facto model for analyzing graph-structured data. However, how to employ GNNs to extract effective representations from brain networks in multiple modalities remains rarely explored. Moreover, as brain networks provide no initial node features, how to design informative node attributes and leverage edge weights for GNNs to learn is left unsolved. To this end, we develop a novel multiview GNN for multimodal brain networks. In particular, we treat each modality as a view for brain networks and employ contrastive learning for multimodal fusion. Then, we propose a GNN model which takes advantage of the message passing scheme by propagating messages based …"
Carl J. Yang,Secure deep graph generation with link differential privacy,2020,https://arxiv.org/abs/2005.00455,"Many data mining and analytical tasks rely on the abstraction of networks (graphs) to summarize relational structures among individuals (nodes). Since relational data are often sensitive, we aim to seek effective approaches to generate utility-preserved yet privacy-protected structured data. In this paper, we leverage the differential privacy (DP) framework to formulate and enforce rigorous privacy constraints on deep graph generation models, with a focus on edge-DP to guarantee individual link privacy. In particular, we enforce edge-DP by injecting proper noise to the gradients of a link reconstruction-based graph generation model, while ensuring data utility by improving structure learning with structure-oriented graph discrimination. Extensive experiments on two real-world network datasets show that our proposed DPGGAN model is able to generate graphs with effectively preserved global structure and rigorously protected individual link privacy."
Carl J. Yang,4sdrug: Symptom-based set-to-set small and safe drug recommendation,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539089,"Drug recommendation is an important task of AI for healthcare. To recommend proper drugs, existing methods rely on various clinical records (e.g., diagnosis and procedures), which are commonly found in data such as electronic health records (EHRs). However, detailed records as such are often not available and the inputs might merely include a set of symptoms provided by doctors. Moreover, existing drug recommender systems usually treat drugs as individual items, ignoring the unique requirements that drug recommendation has to be done on a set of items (drugs), which should be as small as possible and safe without harmful drug-drug interactions (DDIs).To deal with the challenges above, in this paper, we propose a novel framework of Symptom-based Set-to-set Small and Safe drug recommendation (4SDrug). To enable set-to-set comparison, we design set-oriented representation and similarity …"
Carl J. Yang,Graph entropy guided node embedding dimension selection for graph neural networks,2021,https://arxiv.org/abs/2105.03178,"Graph representation learning has achieved great success in many areas, including e-commerce, chemistry, biology, etc. However, the fundamental problem of choosing the appropriate dimension of node embedding for a given graph still remains unsolved. The commonly used strategies for Node Embedding Dimension Selection (NEDS) based on grid search or empirical knowledge suffer from heavy computation and poor model performance. In this paper, we revisit NEDS from the perspective of minimum entropy principle. Subsequently, we propose a novel Minimum Graph Entropy (MinGE) algorithm for NEDS with graph data. To be specific, MinGE considers both feature entropy and structure entropy on graphs, which are carefully designed according to the characteristics of the rich information in them. The feature entropy, which assumes the embeddings of adjacent nodes to be more similar, connects node features and link topology on graphs. The structure entropy takes the normalized degree as basic unit to further measure the higher-order structure of graphs. Based on them, we design MinGE to directly calculate the ideal node embedding dimension for any graph. Finally, comprehensive experiments with popular Graph Neural Networks (GNNs) on benchmark datasets demonstrate the effectiveness and generalizability of our proposed MinGE."
Carl J. Yang,Exploiting data sparsity in secure cross-platform social recommendation,2021,https://proceedings.neurips.cc/paper/2021/hash/56db57b4db0a6fcb7f9e0c0b504f6472-Abstract.html,"Social recommendation has shown promising improvements over traditional systems since it leverages social correlation data as an additional input. Most existing work assumes that all data are available to the recommendation platform. However, in practice, user-item interaction data (eg, rating) and user-user social data are usually generated by different platforms, and both of which contain sensitive information. Therefore,"" How to perform secure and efficient social recommendation across different platforms, where the data are highly-sparse in nature"" remains an important challenge. In this work, we bring secure computation techniques into social recommendation, and propose S3Rec, a sparsity-aware secure cross-platform social recommendation framework. As a result, our model can not only improve the recommendation performance of the rating platform by incorporating the sparse social data on the social platform, but also protect data privacy of both platforms. Moreover, to further improve model training efficiency, we propose two secure sparse matrix multiplication protocols based on homomorphic encryption and private information retrieval. Our experiments on two benchmark datasets demonstrate the effectiveness of S3Rec."
Carl J. Yang,Zero-shot scene graph relation prediction through commonsense knowledge integration,2021,https://link.springer.com/chapter/10.1007/978-3-030-86520-7_29,"Relation prediction among entities in images is an important step in scene graph generation (SGG), which further impacts various visual understanding and reasoning tasks. Existing SGG frameworks, however, require heavy training yet are incapable of modeling unseen (i.e., zero-shot) triplets. In this work, we stress that such incapability is due to the lack of commonsense reasoning, i.e., the ability to associate similar entities and infer similar relations based on general understanding of the world. To fill this gap, we propose CommOnsense-integrAted sCene grapH rElation pRediction (COACHER), a framework to integrate commonsense knowledge for SGG, especially for zero-shot relation prediction. Specifically, we develop novel graph mining pipelines to model the neighborhoods and paths around entities in an external commonsense knowledge graph, and integrate them on top of state-of-the-art SGG …"
Carl J. Yang,Gad-nr: Graph anomaly detection via neighborhood reconstruction,2024,https://dl.acm.org/doi/abs/10.1145/3616855.3635767,"Graph Anomaly Detection (GAD) is a technique used to identify abnormal nodes within graphs, finding applications in network security, fraud detection, social media spam detection, and various other domains. A common method for GAD is Graph Auto-Encoders (GAEs), which encode graph data into node representations and identify anomalies by assessing the reconstruction quality of the graphs based on these representations. However, existing GAE models are primarily optimized for direct link reconstruction, resulting in nodes connected in the graph being clustered in the latent space. As a result, they excel at detecting cluster-type structural anomalies but struggle with more complex structural anomalies that do not conform to clusters. To address this limitation, we propose a novel solution called \proj, a new variant of GAE that incorporates neighborhood reconstruction for graph anomaly detection. \proj aims to …"
Carl J. Yang,Efficient federated learning on knowledge graphs via privacy-preserving relation embedding aggregation,2022,https://arxiv.org/abs/2203.09553,"Federated learning (FL) can be essential in knowledge representation, reasoning, and data mining applications over multi-source knowledge graphs (KGs). A recent study FedE first proposes an FL framework that shares entity embeddings of KGs across all clients. However, entity embedding sharing from FedE would incur a severe privacy leakage. Specifically, the known entity embedding can be used to infer whether a specific relation between two entities exists in a private client. In this paper, we introduce a novel attack method that aims to recover the original data based on the embedding information, which is further used to evaluate the vulnerabilities of FedE. Furthermore, we propose a Federated learning paradigm with privacy-preserving Relation embedding aggregation (FedR) to tackle the privacy issue in FedE. Besides, relation embedding sharing can significantly reduce the communication cost due to its smaller size of queries. We conduct extensive experiments to evaluate FedR with five different KG embedding models and three datasets. Compared to FedE, FedR achieves similar utility and significant improvements regarding privacy-preserving effect and communication efficiency on the link prediction task."
Carl J. Yang,BrainNNExplainer: An interpretable graph neural network framework for brain network based disease analysis,2021,https://arxiv.org/abs/2107.05097,"Interpretable brain network models for disease prediction are of great value for the advancement of neuroscience. GNNs are promising to model complicated network data, but they are prone to overfitting and suffer from poor interpretability, which prevents their usage in decision-critical scenarios like healthcare. To bridge this gap, we propose BrainNNExplainer, an interpretable GNN framework for brain network analysis. It is mainly composed of two jointly learned modules: a backbone prediction model that is specifically designed for brain networks and an explanation generator that highlights disease-specific prominent brain network connections. Extensive experimental results with visualizations on two challenging disease prediction datasets demonstrate the unique interpretability and outstanding performance of BrainNNExplainer."
Carl J. Yang,Time-series event prediction with evolutionary state graph,2021,https://dl.acm.org/doi/abs/10.1145/3437963.3441827,"The accurate and interpretable prediction of future events in time-series data often requires the capturing of representative patterns (or referred to as states) underpinning the observed data. To this end, most existing studies focus on the representation and recognition of states, but ignore the changing transitional relations among them. In this paper, we present evolutionary state graph, a dynamic graph structure designed to systematically represent the evolving relations (edges) among states (nodes) along time. We conduct analysis on the dynamic graphs constructed from the time-series data and show that changes on the graph structures (e.g., edges connecting certain state nodes) can inform the occurrences of events (i.e., time-series fluctuation). Inspired by this, we propose a novel graph neural network model, Evolutionary State Graph Network (EvoNet), to encode the evolutionary state graph for accurate and …"
Carl J. Yang,Learning and updating node embedding on dynamic heterogeneous information network,2021,https://dl.acm.org/doi/abs/10.1145/3437963.3441745,"Heterogeneous information networks consist of multiple types of edges and nodes, which have a strong ability to represent the rich semantics underpinning network structures. Recently, the dynamics of networks has been studied in many tasks such as social media analysis and recommender systems. However, existing methods mainly focus on the static networks or dynamic homogeneous networks, which are incapable or inefficient in modeling dynamic heterogeneous information networks. In this paper, we propose a method named Dynamic Heterogeneous Information Network Embedding (DyHINE), which can update embeddings when the network evolves. The method contains two key designs: (1) A dynamic time-series embedding module which employs a hierarchical attention mechanism to aggregate neighbor features and temporal random walks to capture dynamic interactions; (2) An online real-time …"
Carl J. Yang,Walklm: A uniform language model fine-tuning framework for attributed graph embedding,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/2ac879d1865475a7abc8dfc7a9c15c27-Abstract-Conference.html,"Graphs are widely used to model interconnected entities and improve downstream predictions in various real-world applications. However, real-world graphs nowadays are often associated with complex attributes on multiple types of nodes and even links that are hard to model uniformly, while the widely used graph neural networks (GNNs) often require sufficient training toward specific downstream predictions to achieve strong performance. In this work, we take a fundamentally different approach than GNNs, to simultaneously achieve deep joint modeling of complex attributes and flexible structures of real-world graphs and obtain unsupervised generic graph representations that are not limited to specific downstream predictions. Our framework, built on a natural integration of language models (LMs) and random walks (RWs), is straightforward, powerful and data-efficient. Specifically, we first perform attributed RWs on the graph and design an automated program to compose roughly meaningful textual sequences directly from the attributed RWs; then we fine-tune an LM using the RW-based textual sequences and extract embedding vectors from the LM, which encapsulates both attribute semantics and graph structures. In our experiments, we evaluate the learned node embeddings towards different downstream prediction tasks on multiple real-world attributed graph datasets and observe significant improvements over a comprehensive set of state-of-the-art unsupervised node embedding methods. We believe this work opens a door for more sophisticated technical designs and empirical evaluations toward the leverage of LMs for the modeling …"
Carl J. Yang,Graph-aware language model pre-training on a large graph corpus can help multiple graph applications,2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599833,"Model pre-training on large text corpora has been demonstrated effective for various downstream applications in the NLP domain. In the graph mining domain, a similar analogy can be drawn for pre-training graph models on large graphs in the hope of benefiting downstream graph applications, which has also been explored by several recent studies. However, no existing study has ever investigated the pre-training of text plus graph models on large heterogeneous graphs with abundant textual information (a.k.a. large graph corpora) and then fine-tuning the model on different related downstream applications with different graph schemas. To address this problem, we propose a framework of graph-aware language model pre-training (GaLM) on a large graph corpus, which incorporates large language models and graph neural networks, and a variety of fine-tuning methods on downstream applications. We conduct …"
Carl J. Yang,Data-efficient brain connectome analysis via multi-task meta-learning,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3542680,"Brain networks characterize complex connectivities among brain regions as graph structures, which provide a powerful means to study brain connectomes. In recent years, graph neural networks have emerged as a prevalent paradigm of learning with structured data. However, most brain network datasets are limited in sample sizes due to the relatively high cost of data collection, which hinders the deep learning models from sufficient training. Inspired by meta-learning that learns new concepts fast with limited training examples, this paper studies data-efficient training strategies for analyzing brain connectomes in a cross-dataset setting. Specifically, we propose to meta-train the model on datasets of large sample sizes and transfer the knowledge to small datasets. In addition, we also explore brain-network-oriented designs, including atlas transformation and adaptive task reweighing. Compared to other pre-training …"
Carl J. Yang,Co-embedding network nodes and hierarchical labels with taxonomy based generative adversarial networks,2020,https://ieeexplore.ieee.org/abstract/document/9338301/,"Network embedding aims at transferring node proximity in networks into distributed vectors, which can be leveraged in various downstream applications. Recent research has shown that nodes in a network can often be organized in latent hierarchical structures, but without a particular underlying taxonomy, the learned node embedding is less useful nor interpretable. In this work, we aim to improve network embedding by modeling the conditional node proximity in networks indicated by node labels residing in real taxonomies. In the meantime, we also aim to model the hierarchical label proximity in the given taxonomies, which is too coarse by solely looking at the hierarchical topologies. To this end, we propose TAXOGAN to co-embed network nodes and hierarchical labels, through a hierarchical network generation process. Particularly, TAXOGAN models the child labels and network nodes of each parent label in …"
Carl J. Yang,Brainnet: Epileptic wave detection from seeg with hierarchical graph diffusion learning,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539178,"Epilepsy is one of the most serious neurological diseases, affecting 1-2% of the world's population. The diagnosis of epilepsy depends heavily on the recognition of epileptic waves, i.e., disordered electrical brainwave activity in the patient's brain. Existing works have begun to employ machine learning models to detect epileptic waves via cortical electroencephalogram (EEG), which refers to brain data obtained from a noninvasive examination performed on the patient's scalp surface to record electrical activity in the brain. However, the recently developed stereoelectrocorticography (SEEG) method provides information in stereo that is more precise than conventional EEG, and has been broadly applied in clinical practice. Therefore, in this paper, we propose the first data-driven study to detect epileptic waves in a real-world SEEG dataset. While offering new opportunities, SEEG also poses several challenges. In …"
Carl J. Yang,Unsupervised differentiable multi-aspect network embedding,2020,https://dl.acm.org/doi/abs/10.1145/3394486.3403196,"Network embedding is an influential graph mining technique for representing nodes in a graph as distributed vectors. However, the majority of network embedding methods focus on learning a single vector representation for each node, which has been recently criticized for not being capable of modeling multiple aspects of a node. To capture the multiple aspects of each node, existing studies mainly rely on offline graph clustering performed prior to the actual embedding, which results in the cluster membership of each node (i.e., node aspect distribution) fixed throughout training of the embedding model. We argue that this not only makes each node always have the same aspect distribution regardless of its dynamic context, but also hinders the end-to-end training of the model that eventually leads to the final embedding quality largely dependent on the clustering. In this paper, we propose a novel end-to-end …"
Carl J. Yang,"A review on knowledge graphs for healthcare: Resources, applications, and promises",2023,https://arxiv.org/abs/2306.04802,"Healthcare knowledge graphs (HKGs) are valuable tools for organizing biomedical concepts and their relationships with interpretable structures. The recent advent of large language models (LLMs) has paved the way for building more comprehensive and accurate HKGs. This, in turn, can improve the reliability of generated content and enable better evaluation of LLMs. However, the challenges of HKGs such as regarding data heterogeneity and limited coverage are not fully understood, highlighting the need for detailed reviews. This work provides the first comprehensive review of HKGs. It summarizes the pipeline and key techniques for HKG construction, as well as the common utilization approaches, i.e., model-free and model-based. The existing HKG resources are also organized based on the data types they capture and application domains they cover, along with relevant statistical information (Resource available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase). At the application level, we delve into the successful integration of HKGs across various health domains, ranging from fine-grained basic science research to high-level clinical decision support and public health. Lastly, the paper highlights the opportunities for HKGs in the era of LLMs. This work aims to serve as a valuable resource for understanding the potential and opportunities of HKG in health research."
Carl J. Yang,Certifiable robustness to discrete adversarial perturbations for factorization machines,2020,https://dl.acm.org/doi/abs/10.1145/3397271.3401087,"Factorization machines (FMs) have been widely adopted to model the discrete feature interactions in recommender systems. Despite their great success, currently there is no study of their robustness to discrete adversarial perturbations. Whether modifying a certain number of the discrete input features has a dramatic effect on the FM's prediction? Although there exist robust training methods for FMs, they neglect the discrete property of input features and lack of an effective mechanism to verify the model robustness.In our work, we propose the first method for the certifiable robustness of factorization machines with respect to the discrete perturbation on input features. If an instance is certifiably robust, it is guaranteed to be robust (under the considered space) no matter what the perturbations and attack models are. Likewise, we provide non-robust certificates via the existence of discrete adversarial perturbations that …"
Carl J. Yang,Federated node classification over graphs with latent link-type heterogeneity,2023,https://dl.acm.org/doi/abs/10.1145/3543507.3583471," Federated learning (FL) aims to train powerful and generalized global models without putting distributed data together, which has been shown effective in various domains of machine learning. The non-IIDness of data across local clients has been a major challenge for FL. In graphs, one specifically important perspective of non-IIDness is manifested in the link-type heterogeneity underlying homogeneous graphs– the seemingly uniform links captured in most real-world networks can carry different levels of homophily or semantics of relations, while the exact sets and distributions of such latent link-types can further differ across local clients. Through our preliminary data analysis, we are motivated to design a new graph FL framework that can simultaneously discover latent link-types and model message-passing w.r.t. the discovered link-types through the collaboration of distributed local clients. Specifically, we …"
Carl J. Yang,Metacare++: Meta-learning with hierarchical subtyping for cold-start diagnosis prediction in healthcare data,2022,https://dl.acm.org/doi/abs/10.1145/3477495.3532020,"Cold-start diagnosis prediction is a challenging task for AI in healthcare, where often only a few visits per patient and a few observations per disease can be exploited. Although meta-learning is widely adopted to address the data sparsity problem in general domains, directly applying it to healthcare data is less effective, since it is unclear how to capture both the temporal relations in clinical visits and the complicated relations among syndromic diseases for precise personalized diagnosis. To this end, we first propose a novel Meta-learning framework for cold-start diagnosis prediction in healthCare data (MetaCare). By explicitly encoding the effects of disease progress over time as a generalization prior, MetaCare dynamically predicts future diagnosis and timestamp for infrequent patients. Then, to model complicated relations among rare diseases, we propose to utilize domain knowledge of hierarchical relations …"
Carl J. Yang,Knowledge-infused prompting: Assessing and advancing clinical text data generation with large language models,2023,https://arxiv.org/abs/2311.00287,"Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation using LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, ClinGen, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 7 clinical NLP tasks and 16 datasets reveals that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and significantly enriching the diversity of generated training instances. We will publish our code and all the generated data in \url{https://github.com/ritaranx/ClinGen}."
Carl J. Yang,Counterfactual and factual reasoning over hypergraphs for interpretable clinical predictions on ehr,2022,https://proceedings.mlr.press/v193/xu22a.html,"Electronic Health Record modeling is crucial for digital medicine. However, existing models ignore higher-order interactions among medical codes and their causal relations towards downstream clinical predictions. To address such limitations, we propose a novel framework CACHE, to provide effective and insightful clinical predictions based on hypergraph representation learning and counterfactual and factual reasoning techniques. Experiments on two real EHR datasets show the superior performance of CACHE. Case studies with a domain expert illustrate a preferred capability of CACHE in generating clinically meaningful interpretations towards the correct predictions."
Carl J. Yang,How can graph neural networks help document retrieval: A case study on cord19 with concept map generation,2022,https://link.springer.com/chapter/10.1007/978-3-030-99739-7_9,"Graph neural networks (GNNs), as a group of powerful tools for representation learning on irregular data, have manifested superiority in various downstream tasks. With unstructured texts represented as concept maps, GNNs can be exploited for tasks like document retrieval. Intrigued by how can GNNs help document retrieval, we conduct an empirical study on a large-scale multi-discipline dataset CORD-19. Results show that instead of the complex structure-oriented GNNs such as GINs and GATs, our proposed semantics-oriented graph functions achieve better and more stable performance based on the BM25 retrieved candidates. Our insights in this case study can serve as a guideline for future work to develop effective GNNs with appropriate semantics-oriented inductive biases for textual reasoning tasks like document retrieval and classification. All code for this case study is available at https://github.com …"
Carl J. Yang,Graph clustering with embedding propagation,2020,https://ieeexplore.ieee.org/abstract/document/9378031/,"In the past decade, the amount of attributed network data has skyrocketed, and the problem of identifying their underlying group structures has received significant attention. By leveraging both attribute and link information, recent state-of-the-art network clustering methods have achieved significant improvements on relatively clean datasets. However, the noisy nature of real-world attributed networks has long been over-looked, which leads to degraded performance facing missing or inaccurate attributes and links. In this work, we overcome such weaknesses by marrying the strengths of clustering and embedding on attributed networks. Specifically, we propose GRACE (GRAph Clustering with Embedding propagation), to simultaneously learn network representations and identify net-work clusters in an end-to-end manner. It employs deep denoise autoencoders to generate robust network embeddings from node …"
Carl J. Yang,Ehragent: Code empowers large language models for few-shot complex tabular reasoning on electronic health records,2024,https://arxiv.org/abs/2401.07128,"Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent, an LLM agent empowered with a code interface, to autonomously generate and execute code for multi-tabular reasoning within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on three real-world multi-tabular EHR datasets show that EHRAgent outperforms the strongest baseline by up to 29.6% in success rate. EHRAgent leverages the emerging few-shot learning capabilities of LLMs, enabling autonomous code generation and execution to tackle complex clinical tasks with minimal demonstrations."
Carl J. Yang,When to pre-train graph neural networks? from data generation perspective!,2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599548,"In recent years, graph pre-training has gained significant attention, focusing on acquiring transferable knowledge from unlabeled graph data to improve downstream performance. Despite these recent endeavors, the problem of negative transfer remains a major concern when utilizing graph pre-trained models to downstream tasks. Previous studies made great efforts on the issue of what to pre-train and how to pre-train by designing a variety of graph pre-training and fine-tuning strategies. However, there are cases where even the most advanced ""pre-train and fine-tune"" paradigms fail to yield distinct benefits. This paper introduces a generic framework W2PGNN to answer the crucial question of when to pre-train (.e., in what situations could we take advantage of graph pre-training) before performing effortful pre-training or fine-tuning. We start from a new perspective to explore the complex generative mechanisms …"
Carl J. Yang,Neighborhood-regularized self-training for learning with few labels,2023,https://ojs.aaai.org/index.php/AAAI/article/view/26260,"Training deep neural networks (DNNs) with limited supervision has been a popular research topic as it can significantly alleviate the annotation burden. Self-training has been successfully applied in semi-supervised learning tasks, but one drawback of self-training is that it is vulnerable to the label noise from incorrect pseudo labels. Inspired by the fact that samples with similar labels tend to share similar representations, we develop a neighborhood-based sample selection approach to tackle the issue of noisy pseudo labels. We further stabilize self-training via aggregating the predictions from different rounds during sample selection. Experiments on eight tasks show that our proposed method outperforms the strongest self-training baseline with 1.83% and 2.51% performance gain for text and graph datasets on average. Our further analysis demonstrates that our proposed data selection strategy reduces the noise of pseudo labels by 36.8% and saves 57.3% of the time when compared with the best baseline. Our code and appendices will be uploaded to: https://github. com/ritaranx/NeST."
Carl J. Yang,Lightweight visual question answering using scene graphs,2021,https://dl.acm.org/doi/abs/10.1145/3459637.3482218,"Visual question answering (VQA) is a challenging problem in machine perception, which requires a deep joint understanding of both visual and textual data. Recent research has advanced the automatic generation of high-quality scene graphs from images, while powerful yet elegant models like graph neural networks (GNNs) have shown great power in reasoning over graph-structured data. In this work, we propose to bridge the gap between scene graph generation and VQA by leveraging GNNs. In particular, we design a new model called Conditional Enhanced Graph ATtention network (CE-GAT) to encode pairs of visual and semantic scene graphs with both node and edge features, which is seamlessly integrated with a textual question encoder to generate answers through question-graph conditioning. Moreover, to alleviate the training difficulties of CE-GAT towards VQA, we enforce more useful inductive …"
Carl J. Yang,Weakly-supervised scientific document classification via retrieval-augmented multi-stage training,2023,https://dl.acm.org/doi/abs/10.1145/3539618.3592085,"Scientific document classification is a critical task for a wide range of applications, but the cost of collecting human-labeled data can be prohibitive. We study scientific document classification using label names only. In scientific domains, label names often include domain-specific concepts that may not appear in the document corpus, making it difficult to match labels and documents precisely. To tackle this issue, we propose WanDeR, which leverages dense retrieval to perform matching in the embedding space to capture the semantics of label names. We further design the label name expansion module to enrich its representations. Lastly, a self-training step is used to refine the predictions. The experiments on three datasets show that WanDeR outperforms the best baseline by 11.9%. Our code will be published at https://github.com/ritaranx/wander."
Carl J. Yang,Learning task-aware effective brain connectivity for fmri analysis with graph neural networks,2022,https://ieeexplore.ieee.org/abstract/document/10020955/,"Functional magnetic resonance imaging (fMRI) has become one of the most common imaging modalities for brain function analysis. Recently, graph neural networks (GNN) have been adopted for fMRI analysis with superior performance. Unfortunately, traditional functional brain networks are mainly constructed based on similarities among region of interests (ROI), which are noisy and agnostic to the downstream prediction tasks and can lead to inferior results for GNN-based models. To better adapt GNNs for fMRI analysis, we propose TBDS, an end-to-end framework based on Task-aware Brain connectivity DAG (short for Directed Acyclic Graph) Structure generation for fMRI analysis. The key component of TBDS is the brain network generator which adopts a DAG learning approach to transform the raw time-series into task-aware brain connectivities. Besides, we design an additional contrastive regularization to …"
Carl J. Yang,Evaluation and mitigation of agnosia in multimodal large language models,2023,https://scholar.google.com/scholar?cluster=8282578524278667850&hl=en&oi=scholarr,
Carl J. Yang,Multi-facet recommender networks with spherical optimization,2021,https://ieeexplore.ieee.org/abstract/document/9458802/,"Implicit feedback is widely explored by modern recommender systems. Since the feedback is often sparse and imbalanced, it poses great challenges to the learning of complex interactions among users and items. Metric learning has been proposed to capture user-item interactions from implicit feedback, but existing methods only represent users and items in a single metric space, ignoring the fact that users can have multiple preferences and items can have multiple properties, which leads to potential conflicts limiting their performance in recommendation. To capture the multiple facets of user preferences and item properties while resolving their potential conflicts, we propose the novel framework of Multi-fAcet Recommender networks with Spherical optimization (MARS). By designing a cross-facet similarity measurement, we project users and items into multiple metric spaces for fine-grained representation learning …"
Carl J. Yang,Ram-ehr: Retrieval augmentation meets clinical predictions on electronic health records,2024,https://arxiv.org/abs/2403.00815,"We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \url{https://github.com/ritaranx/RAM-EHR}."
Carl J. Yang,Ehragent: Code empowers large language models for complex tabular reasoning on electronic health records,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240107128S/abstract,"Large language models (LLMs) have demonstrated exceptional capabilities in planning and tool utilization as autonomous agents, but few have been developed for medical problem-solving. We propose EHRAgent1, an LLM agent empowered with a code interface, to autonomously generate and execute code for complex clinical tasks within electronic health records (EHRs). First, we formulate an EHR question-answering task into a tool-use planning process, efficiently decomposing a complicated task into a sequence of manageable actions. By integrating interactive coding and execution feedback, EHRAgent learns from error messages and improves the originally generated code through iterations. Furthermore, we enhance the LLM agent by incorporating long-term memory, which allows EHRAgent to effectively select and build upon the most relevant successful cases from past experiences. Experiments on …"
Carl J. Yang,Ptgb: Pre-train graph neural networks for brain network analysis,2023,https://arxiv.org/abs/2305.14376,"The human brain is the central hub of the neurobiological system, controlling behavior and cognition in complex ways. Recent advances in neuroscience and neuroimaging analysis have shown a growing interest in the interactions between brain regions of interest (ROIs) and their impact on neural development and disorder diagnosis. As a powerful deep model for analyzing graph-structured data, Graph Neural Networks (GNNs) have been applied for brain network analysis. However, training deep models requires large amounts of labeled data, which is often scarce in brain network datasets due to the complexities of data acquisition and sharing restrictions. To make the most out of available training data, we propose PTGB, a GNN pre-training framework that captures intrinsic brain network structures, regardless of clinical outcomes, and is easily adaptable to various downstream tasks. PTGB comprises two key components: (1) an unsupervised pre-training technique designed specifically for brain networks, which enables learning from large-scale datasets without task-specific labels; (2) a data-driven parcellation atlas mapping pipeline that facilitates knowledge transfer across datasets with different ROI systems. Extensive evaluations using various GNN models have demonstrated the robust and superior performance of PTGB compared to baseline methods."
Carl J. Yang,Data-free adversarial knowledge distillation for graph neural networks,2022,https://arxiv.org/abs/2205.03811,"Graph neural networks (GNNs) have been widely used in modeling graph structured data, owing to its impressive performance in a wide range of practical applications. Recently, knowledge distillation (KD) for GNNs has enabled remarkable progress in graph model compression and knowledge transfer. However, most of the existing KD methods require a large volume of real data, which are not readily available in practice, and may preclude their applicability in scenarios where the teacher model is trained on rare or hard to acquire datasets. To address this problem, we propose the first end-to-end framework for data-free adversarial knowledge distillation on graph structured data (DFAD-GNN). To be specific, our DFAD-GNN employs a generative adversarial network, which mainly consists of three components: a pre-trained teacher model and a student model are regarded as two discriminators, and a generator is utilized for deriving training graphs to distill knowledge from the teacher model into the student model. Extensive experiments on various benchmark models and six representative datasets demonstrate that our DFAD-GNN significantly surpasses state-of-the-art data-free baselines in the graph classification task."
Carl J. Yang,Deep generation of heterogeneous networks,2021,https://ieeexplore.ieee.org/abstract/document/9679028/,"Heterogeneous graphs are ubiquitous data structures that can inherently capture multi-type and multi-modal interactions between objects. In recent years, research on encoding heterogeneous graph into latent representations have enjoyed a rapid increase. However, its reverse process, namely how to construct heterogeneous graphs from underlying representations and distributions have not been well explored due to several challenges in 1) modeling the local heterogeneous semantic distribution; 2) preserving the graph-structured distributions over the local semantics; and 3) characterizing the global heterogeneous graph distributions. To address these challenges, we propose a novel framework for heterogeneous graph generation (HGEN) that jointly captures the semantic, structural, and global distributions of heterogeneous graphs. Specifically, we propose a heterogeneous walk generator that hierarchically …"
Carl J. Yang,Transformer-based hierarchical clustering for brain network analysis,2023,https://ieeexplore.ieee.org/abstract/document/10230606/,"Brain networks, graphical models such as those constructed from MRI, have been widely used in pathological prediction and analysis of brain functions. Within the complex brain system, differences in neuronal connection strengths parcellate the brain into various functional modules (network communities), which are critical for brain analysis. However, identifying such communities within the brain has been a non-trivial issue due to the complexity of neuronal interactions. In this work, we propose a novel interpretable transformer-based model for joint hierarchical cluster identification and brain network classification. Extensive experimental results on real-world brain network datasets show that with the help of hierarchical clustering, the model achieves increased accuracy and reduced runtime complexity while providing plausible insight into the functional organization of brain regions."
Carl J. Yang,Better with less: A data-active perspective on pre-training graph neural networks,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/b29adb4bf2364acec8fb402ef731bb3b-Abstract-Conference.html,"Pre-training on graph neural networks (GNNs) aims to learn transferable knowledge for downstream tasks with unlabeled data, and it has recently become an active research area. The success of graph pre-training models is often attributed to the massive amount of input data. In this paper, however, we identify the curse of big data phenomenon in graph pre-training: more training data do not necessarily lead to better downstream performance. Motivated by this observation, we propose a better-with-less framework for graph pre-training: fewer, but carefully chosen data are fed into a GNN model to enhance pre-training. The proposed pre-training pipeline is called the data-active graph pre-training (APT) framework, and is composed of a graph selector and a pre-training model. The graph selector chooses the most representative and instructive data points based on the inherent properties of graphs as well as predictive uncertainty. The proposed predictive uncertainty, as feedback from the pre-training model, measures the confidence level of the model in the data. When fed with the chosen data, on the other hand, the pre-training model grasps an initial understanding of the new, unseen data, and at the same time attempts to remember the knowledge learned from previous data. Therefore, the integration and interaction between these two components form a unified framework (APT), in which graph pre-training is performed in a progressive and iterative way. Experiment results show that the proposed APT is able to obtain an efficient pre-training model with fewer training data and better downstream performance."
Carl J. Yang,Enhancing recommendation with automated tag taxonomy construction in hyperbolic space,2022,https://ieeexplore.ieee.org/abstract/document/9835344/,"The sparse interactions between users and items on the web have aggravated the difficulty of their representations in recommender systems. Existing approaches leverage tags to alleviate the data sparsity problem, so as to enhance the performance and interpretability of recommendation. However, directly using flat item tags fails to fully exploit the hierarchical relations in data, but tag taxonomies are not always available. To this end, we propose TaxoRec to jointly construct a tag taxonomy automatically and perform recommendation accurately in hyperbolic space. Specifically, we first leverage hyperbolic space and enable the optimization of a discrete taxonomy structure via a representation-aware scoring function and an adaptive clustering algorithm, and preserve the hierarchical structure for interpretability. Then, we propose to capture the complex relations among users, items, and tags in a unified hyperbolic …"
Carl J. Yang,Hypergraph transformers for ehr-based clinical predictions,2023,https://pmc.ncbi.nlm.nih.gov/articles/PMC10283128/,"Electronic health records (EHR) data contain rich information about patients’ health conditions including diagnosis, procedures, medications and etc., which have been widely used to facilitate digital medicine. Despite its importance, it is often non-trivial to learn useful representations for patients’ visits that support downstream clinical predictions, as each visit contains massive and diverse medical codes. As a result, the complex interactions among medical codes are often not captured, which leads to substandard predictions. To better model these complex relations, we leverage hypergraphs, which go beyond pairwise relations to jointly learn the representations for visits and medical codes. We also propose to use the self-attention mechanism to automatically identify the most relevant medical codes for each visit based on the downstream clinical predictions with better generalization power. Experiments on two …"
Carl J. Yang,Bmretriever: Tuning large language models as better biomedical text retrievers,2024,https://arxiv.org/abs/2404.18443,"Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the deficiency of sufficient publicly annotated biomedical data and computational resources. We present BMRetriever, a series of dense retrievers for enhancing biomedical retrieval via unsupervised pre-training on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify BMRetriever's efficacy on various biomedical applications. BMRetriever also exhibits strong parameter efficiency, with the 410M variant outperforming baselines up to 11.7 times larger, and the 2B variant matching the performance of models with over 5B parameters. The training data and model checkpoints are released at \url{https://huggingface.co/BMRetriever} to ensure transparency, reproducibility, and application to new domains."
Carl J. Yang,Dynamic brain transformer with multi-level attention for functional brain network analysis,2023,https://ieeexplore.ieee.org/abstract/document/10313480/,"Recent neuroimaging studies have highlighted the importance of network-centric brain analysis, particularly with functional magnetic resonance imaging. The emergence of Deep Neural Networks has fostered a substantial interest in predicting clinical outcomes and categorizing individuals based on brain networks. However, the conventional approach involving static brain network analysis offers limited potential in capturing the dynamism of brain function. Although recent studies have attempted to harness dynamic brain networks, their high dimensionality and complexity present substantial challenges. This paper proposes a novel methodology, Dynamic bRAin Transformer (DART), which combines static and dynamic brain networks for more effective and nuanced brain function analysis. Our model uses the static brain network as a baseline, integrating dynamic brain networks to enhance performance against …"
Carl J. Yang,Guardagent: Safeguard llm agents by a guard agent via knowledge-enabled reasoning,2024,https://arxiv.org/abs/2406.09187,"The rapid advancement of large language models (LLMs) has catalyzed the deployment of LLM-powered agents across numerous applications, raising new concerns regarding their safety and trustworthiness. Existing methods for enhancing the safety of LLMs are not directly transferable to LLM-powered agents due to their diverse objectives and output modalities. In this paper, we propose GuardAgent, the first LLM agent as a guardrail to other LLM agents. Specifically, GuardAgent oversees a target LLM agent by checking whether its inputs/outputs satisfy a set of given guard requests defined by the users. GuardAgent comprises two steps: 1) creating a task plan by analyzing the provided guard requests, and 2) generating guardrail code based on the task plan and executing the code by calling APIs or using external engines. In both steps, an LLM is utilized as the core reasoning component, supplemented by in-context demonstrations retrieved from a memory module. Such knowledge-enabled reasoning allows GuardAgent to understand various textual guard requests and accurately ""translate"" them into executable code that provides reliable guardrails. Furthermore, GuardAgent is equipped with an extendable toolbox containing functions and APIs and requires no additional LLM training, which underscores its generalization capabilities and low operational overhead. Additionally, we propose two novel benchmarks: an EICU-AC benchmark for assessing privacy-related access control for healthcare agents and a Mind2Web-SC benchmark for safety evaluation for web agents. We show the effectiveness of GuardAgent on these two …"
Carl J. Yang,Medadapter: Efficient test-time adaptation of large language models towards medical reasoning,2024,https://arxiv.org/abs/2405.03000,"Despite their improved capabilities in generation and reasoning, adapting large language models (LLMs) to the biomedical domain remains challenging due to their immense size and corporate privacy. In this work, we propose MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter effectively adapts the original model by fine-tuning only a small BERT-sized adapter to rank candidate solutions generated by LLMs. Experiments demonstrate that MedAdapter effectively adapts both white-box and black-box LLMs in biomedical reasoning, achieving average performance improvements of 25.48% and 11.31%, respectively, without requiring extensive computational resources or sharing data with third parties. MedAdapter also yields superior performance when combined with train-time adaptation, highlighting a flexible and complementary solution to existing adaptation methods. Faced with the challenges of balancing model performance, computational resources, and data privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective, and transparent solution for adapting LLMs to the biomedical domain."
Carl J. Yang,Hiprompt: Few-shot biomedical knowledge fusion via hierarchy-oriented prompting,2023,https://dl.acm.org/doi/abs/10.1145/3539618.3591997,"Medical decision-making processes can be enhanced by comprehensive biomedical knowledge bases, which require fusing knowledge graphs constructed from different sources via a uniform index system. The index system often organizes biomedical terms in a hierarchy to provide the aligned entities with fine-grained granularity. To address the challenge of scarce supervision in the biomedical knowledge fusion (BKF) task, researchers have proposed various unsupervised methods. However, these methods heavily rely on ad-hoc lexical and structural matching algorithms, which fail to capture the rich semantics conveyed by biomedical entities and terms. Recently, neural embedding models have proved effective in semantic-rich tasks, but they rely on sufficient labeled data to be adequately trained. To bridge the gap between the scarce-labeled BKF and neural embedding models, we propose HiPrompt, a …"
Carl J. Yang,Controllable gradient item retrieval,2021,https://dl.acm.org/doi/abs/10.1145/3442381.3449963," In this paper, we identify and study an important problem of gradient item retrieval. We define the problem as retrieving a sequence of items with a gradual change on a certain attribute, given a reference item and a modification text. For example, after a customer saw a white dress, she/he wants to buy a similar one but more floral on it. The extent of ”more floral” is subjective, thus prompting one floral dress is hard to satisfy the customer’s needs. A better way is to present a sequence of products with increasingly floral attributes based on the white dress, and allow the customer to select the most satisfactory one from the sequence. Existing item retrieval methods mainly focus on whether the target items appear at the top of the retrieved sequence, but ignore the demand for retrieving a sequence of products with gradual change on a certain attribute. To deal with this problem, we propose a weakly-supervised method …"
Carl J. Yang,Musegraph: Graph-oriented instruction tuning of large language models for generic graph mining,2024,https://arxiv.org/abs/2403.04780,"Graphs with abundant attributes are essential in modeling interconnected entities and improving predictions in various real-world applications. Traditional Graph Neural Networks (GNNs), which are commonly used for modeling attributed graphs, need to be re-trained every time when applied to different graph tasks and datasets. Although the emergence of Large Language Models (LLMs) has introduced a new paradigm in natural language processing, the generative potential of LLMs in graph mining remains largely under-explored. To this end, we propose a novel framework MuseGraph, which seamlessly integrates the strengths of GNNs and LLMs and facilitates a more effective and generic approach for graph mining across different tasks and datasets. Specifically, we first introduce a compact graph description via the proposed adaptive input generation to encapsulate key information from the graph under the constraints of language token limitations. Then, we propose a diverse instruction generation mechanism, which distills the reasoning capabilities from LLMs (e.g., GPT-4) to create task-specific Chain-of-Thought-based instruction packages for different graph tasks. Finally, we propose a graph-aware instruction tuning with a dynamic instruction package allocation strategy across tasks and datasets, ensuring the effectiveness and generalization of the training process. Our experimental results demonstrate significant improvements in different graph tasks, showcasing the potential of our MuseGraph in enhancing the accuracy of graph-oriented downstream tasks while keeping the generation powers of LLMs."
Carl J. Yang,Contrastive intra-and inter-modality generation for enhancing incomplete multimedia recommendation,2023,https://dl.acm.org/doi/abs/10.1145/3581783.3612362,"With the rapid growth of multimedia-sharing platforms (e.g. Twitter and TikTok), multimedia recommender systems have become fundamental for helping users alleviate information overload and discover items of interest. Existing multimedia recommendation methods often incorporate various auxiliary modalities (e.g., visual, textual, and acoustic) to describe item characteristics and improve task performance. However, these methods usually assume that each item is associated with complete modalities, ignoring the prevalence of missing modality issues in real-world scenarios. To deal with the challenge of missing modalities, in this paper, we propose a novel framework of Contrastive Intra- and Inter-Modality Generation (CI2MG) for enhancing incomplete multimedia recommendation. We first develop a contrastive intra- and inter-modality generation module for the missing modalities, where the intra-modality …"
Carl J. Yang,Evaluation and enhancement of semantic grounding in large vision-language models,2023,https://arxiv.org/abs/2309.04041,"Large Vision-Language Models (LVLMs) offer remarkable benefits for a variety of vision-language tasks. However, a challenge hindering their application in real-world scenarios, particularly regarding safety, robustness, and reliability, is their constrained semantic grounding ability, which pertains to connecting language to the physical-world entities or concepts referenced in images. Therefore, a crucial need arises for a comprehensive study to assess the semantic grounding ability of widely used LVLMs. Despite the significance, sufficient investigation in this direction is currently lacking. Our work bridges this gap by designing a pipeline for generating large-scale evaluation datasets covering fine-grained semantic information, such as color, number, material, etc., along with a thorough assessment of seven popular LVLMs' semantic grounding ability. Results highlight prevalent misgrounding across various aspects and degrees. To address this issue, we propose a data-centric enhancement method that aims to improve LVLMs' semantic grounding ability through multimodal instruction tuning on fine-grained conversations. Experiments on enhanced LVLMs demonstrate notable improvements in addressing misgrounding issues."
Carl J. Yang,Deep dag learning of effective brain connectivity for fmri analysis,2023,https://ieeexplore.ieee.org/abstract/document/10230429/,"Functional magnetic resonance imaging (fMRI) has become one of the most common imaging modalities for brain function analysis. Recently, graph neural networks (GNN) have been adopted for fMRI analysis with superior performance. Unfortunately, traditional functional brain networks are mainly constructed based on similarities among region of interests (ROIs), which are noisy and can lead to inferior results for GNN models. To better adapt GNNs for fMRI analysis, we propose DABNet, a Deep DAG learning framework based on Brain Networks for fMRI analysis. DABNet adopts a brain network generator module, which harnesses the DAG learning approach to transform the raw time-series into effective brain connectivities. Experiments on two fMRI datasets demonstrate the efficacy of DABNet. The generated brain networks also highlight the prediction-related brain regions and thus provide interpretations for …"
Carl J. Yang,R-mixup: Riemannian mixup for biological networks,2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599483,"Biological networks are commonly used in biomedical and healthcare domains to effectively model the structure of complex biological systems with interactions linking biological entities. However, due to their characteristics of high dimensionality and low sample size, directly applying deep learning models on biological networks usually faces severe overfitting. In this work, we propose R-MIXUP, a Mixup-based data augmentation technique that suits the symmetric positive definite (SPD) property of adjacency matrices from biological networks with optimized training efficiency. The interpolation process in R-MIXUP leverages the log-Euclidean distance metrics from the Riemannian manifold, effectively addressing the swelling effect and arbitrarily incorrect label issues of vanilla Mixup. We demonstrate the effectiveness of R-MIXUP with five real-world biological network datasets on both regression and classification …"
Carl J. Yang,Motif-guided heterogeneous graph deep generation,2023,https://link.springer.com/article/10.1007/s10115-023-01863-0,"The complex systems in the real-world are commonly associated with multiple types of objects and relations, and heterogeneous graphs are ubiquitous data structures that can inherently represent multimodal interactions between objects. Generating high-quality heterogeneous graphs allows us to understand the implicit distribution of heterogeneous graphs and provides benchmarks for downstream heterogeneous representation learning tasks. Existing works are limited to either merely generating the graph topology with neglecting local semantic information or only generating the graph without preserving the higher-order structural information and the global heterogeneous distribution in generated graphs. To this end, we formulate a general, end-to-end framework— HGEN for generating novel heterogeneous graphs with a newly proposed heterogeneous walk generator. On top of HGEN, we further develop a …"
Carl J. Yang,Revisiting citation prediction with cluster-aware text-enhanced heterogeneous graph neural networks,2023,https://ieeexplore.ieee.org/abstract/document/10184723/,"Numerous papers get published all the time. However, some papers are born to be well-cited while others are not. In this work, we revisit the important problem of citation prediction, by focusing on the important yet realistic prediction on the average number of citations a paper will attract per year. The task is nonetheless challenging because many correlated factors underlie the potential impact of a paper, such as the prestige of its authors, the authority of its publishing venue, and the significance of the problems/techniques/applications it studies. To jointly model these factors, we propose to construct a heterogeneous publication network of nodes including papers, authors, venues, and terms. Moreover, we devise a novel heterogeneous graph neural network (HGN) to jointly embed all types of nodes and links, towards the modeling of research impact and its propagation. Beyond graph heterogeneity, we find it also …"
Carl J. Yang,Neural concept map generation for effective document classification with interpretable structured summarization,2020,https://dl.acm.org/doi/abs/10.1145/3397271.3401312,"Concept maps provide concise structured representations for documents regarding their important concepts and interaction links, which have been widely used for document summarization and downstream tasks. However, the construction of concept maps often relies heavily on heuristic design and auxiliary tools. Recent popular neural network models, on the other hand, are shown effective in tasks across various domains, but are short in interpretability and prone to overfitting. In this work, we bridge the gap between concept map construction and neural network models, by designing doc2graph, a novel weakly-supervised text-to-graph neural network, which generates concept maps in the middle and is trained towards document-level tasks like document classification. In our experiments, doc2graph outperforms both its traditional baselines and neural counterparts by significant margins in document …"
Carl J. Yang,Dynamic activation of clients and parameters for federated learning over heterogeneous graphs,2023,https://ieeexplore.ieee.org/abstract/document/10184557/,"The data generated in many real-world applications can be modeled as heterogeneous graphs of multi-typed entities (nodes) and relations (links). Nowadays, such data are commonly generated and stored by distributed clients, making direct centralized model training unpractical. While the data in each client are prone to biased local distributions, generalizable global models are still in frequent need for large-scale applications. However, the large number of clients enforce significant computational overhead due to the communication and synchronization among the clients, whereas the biased local data distributions indicate that not all clients and parameters should be computed and updated at all times. Motivated by specifically designed preliminary studies on training a state-of-the-art heterogeneous graph neural network (HGN) with the vanilla FedAvg framework, in this work, we propose to leverage the …"
Carl J. Yang,Dpar: Decoupled graph neural networks with node-level differential privacy,2024,https://dl.acm.org/doi/abs/10.1145/3589334.3645531,"Graph Neural Networks (GNNs) have achieved great success in learning with graph-structured data. Privacy concerns have also been raised for the trained models which could expose the sensitive information of graphs including both node features and the structure information. In this paper, we aim to achieve node-level differential privacy (DP) for training GNNs so that a node and its edges are protected. Node DP is inherently difficult for GNNs because all direct and multi-hop neighbors participate in the calculation of gradients for each node via layer-wise message passing and there is no bound on how many direct and multi-hop neighbors a node can have, so existing DP methods will result in high privacy cost or poor utility due to high node sensitivity. We propose a D ecoupled GNN with Differentially P rivate A pproximate Personalized PageR ank (DPAR) for training GNNs with an enhanced privacy-utility …"
Carl J. Yang,Llms-based few-shot disease predictions using ehr: A novel approach combining predictive agent reasoning and critical agent instruction,2024,https://arxiv.org/abs/2403.15464,"Electronic health records (EHRs) contain valuable patient data for health-related prediction tasks, such as disease prediction. Traditional approaches rely on supervised learning methods that require large labeled datasets, which can be expensive and challenging to obtain. In this study, we investigate the feasibility of applying Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives. We evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies. Furthermore, we propose a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent. Our results demonstrate that with the proposed approach, LLMs can achieve decent few-shot performance compared to traditional supervised learning methods in EHR-based disease predictions, suggesting its potential for health-oriented applications."
Carl J. Yang,Multi-view brain network analysis with cross-view missing network generation,2022,https://ieeexplore.ieee.org/abstract/document/9995283/,"Parkinson’s Disease (PD), one of the most common neurological disorders, has long been a challenge in public health clinical diagnosis as well as scientific understanding. Recently, there has been an upsurge of interest in brain network analysis which benefits the understanding of brain functions and early detection of neurological disorders extensively. Multi-view brain networks with different connectivity patterns among regions of interests (ROIs) can be constructed to reflect different and complementary perspectives of the brain connectivity profile. However, the extraction of such multi-view brain networks relies on the availability of multiple neuroimaging modalities and heavy data preprocessing, which often leads to severe missing data in either view. The cross-view missing issue hinders the pragmaticality of multi-view representation learning and downstream analysis. In this work, we formulate the novel …"
Carl J. Yang,Towards training graph neural networks with node-level differential privacy,2022,https://scholar.google.com/scholar?cluster=10115829413610805929&hl=en&oi=scholarr,
Carl J. Yang,GCN for HIN via implicit utilization of attention and meta-paths,2021,https://ieeexplore.ieee.org/abstract/document/9627584/,"Heterogeneous information network (HIN) embedding, aiming to map the structure and semantic information in a HIN to distributed representations, has drawn considerable research attention. Graph neural networks for HIN embeddings typically adopt a hierarchical attention (including node-level and meta-path-level attentions) to capture the information from meta-path-based neighbors. However, this complicated attention structure often cannot achieve the function of selecting meta-paths due to severe overfitting. Moreover, when propagating information, these methods do not distinguish direct (one-hop) meta-paths from indirect (multi-hop) ones. But from the perspective of network science, direct relationships are often believed to be more essential, which can only be used to model direct information propagation. To address these limitations, we propose a novel neural network method via implicitly utilizing …"
Carl J. Yang,Structure-aware hard negative mining for heterogeneous graph contrastive learning,2021,https://arxiv.org/abs/2108.13886,"Recently, heterogeneous Graph Neural Networks (GNNs) have become a de facto model for analyzing HGs, while most of them rely on a relative large number of labeled data. In this work, we investigate Contrastive Learning (CL), a key component in self-supervised approaches, on HGs to alleviate the label scarcity problem. We first generate multiple semantic views according to metapaths and network schemas. Then, by pushing node embeddings corresponding to different semantic views close to each other (positives) and pulling other embeddings apart (negatives), one can obtain informative representations without human annotations. However, this CL approach ignores the relative hardness of negative samples, which may lead to suboptimal performance. Considering the complex graph structure and the smoothing nature of GNNs, we propose a structure-aware hard negative mining scheme that measures hardness by structural characteristics for HGs. By synthesizing more negative nodes, we give larger weights to harder negatives with limited computational overhead to further boost the performance. Empirical studies on three real-world datasets show the effectiveness of our proposed method. The proposed method consistently outperforms existing state-of-the-art methods and notably, even surpasses several supervised counterparts."
Carl J. Yang,Unveiling implicit deceptive patterns in multi-modal fake news via neuro-symbolic reasoning,2024,https://ojs.aaai.org/index.php/AAAI/article/view/28677,"In the current Internet landscape, the rampant spread of fake news, particularly in the form of multi-modal content, poses a great social threat. While automatic multi-modal fake news detection methods have shown promising results, the lack of explainability remains a significant challenge. Existing approaches provide superficial explainability by displaying learned important components or views from well-trained networks, but they often fail to uncover the implicit deceptive patterns that reveal how fake news is fabricated.  To address this limitation, we begin by predefining three typical deceptive patterns, namely image manipulation, cross-modal inconsistency, and image repurposing, which shed light on the mechanisms underlying fake news fabrication. Then, we propose a novel Neuro-Symbolic Latent Model called NSLM, that not only derives accurate judgments on the veracity of news but also uncovers the implicit deceptive patterns as explanations. Specifically, the existence of each deceptive pattern is expressed as a two-valued learnable latent variable, which is acquired through amortized variational inference and weak supervision based on symbolic logic rules.  Additionally, we devise pseudo-siamese networks to capture distinct deceptive patterns effectively. Experimental results on two real-world datasets demonstrate that our NSLM achieves the best performance in fake news detection while providing insightful explanations of deceptive patterns."
Carl J. Yang,Secure network release with link privacy,2020,https://www.academia.edu/download/94380281/2005.00455v1.pdf,"Many data mining and analytical tasks rely on the abstraction of networks (graphs) to summarize relational structures among individuals (nodes). Since relational data are often sensitive, we aim to seek effective approaches to release utility-preserved yet privacy-protected structured data. In this paper, we leverage the differential privacy (DP) framework, to formulate and enforce rigorous privacy constraints on deep graph generation models, with a focus on edge-DP to guarantee individual link privacy. In particular, we enforce edge-DP by injecting Gaussian noise to the gradients of a link prediction based graph generation model, and ensure data utility by improving structure learning with structure-oriented graph comparison. Extensive experiments on two real-world network datasets show that our proposed DPGGEN model is able to generate networks with effectively preserved global structure and rigorously protected individual link privacy."
Carl J. Yang,Komen: Domain knowledge guided interaction recommendation for emerging scenarios,2022,https://dl.acm.org/doi/abs/10.1145/3485447.3512177," User-User interaction recommendation, or interaction recommendation, is an indispensable service in social platforms, where the system automatically predicts with whom a user wants to interact. In real-world social platforms, we observe that user interactions may occur in diverse scenarios, and new scenarios constantly emerge, such as new games or sales promotions. There are two challenges in these emerging scenarios: (1) The behavior of users on the emerging scenarios could be different from existing ones due to the diversity among scenarios; (2) Emerging scenarios may only have scarce user behavioral data for model learning. Towards these two challenges, we present KoMen, a Domain Knowledge Guided Meta-learning framework for Interaction Recommendation. KoMen first learns a set of global model parameters shared among all scenarios and then quickly adapts the parameters for an emerging …"
Carl J. Yang,Shift-robust node classification via graph adversarial clustering,2022,https://arxiv.org/abs/2203.15802,"Graph Neural Networks (GNNs) are de facto node classification models in graph structured data. However, during testing-time, these algorithms assume no data shift, i.e., . Domain adaption methods can be adopted for data shift, yet most of them are designed to only encourage similar feature distribution between source and target data. Conditional shift on classes can still affect such adaption. Fortunately, graph yields graph homophily across different data distributions. In response, we propose Shift-Robust Node Classification (SRNC) to address these limitations. We introduce an unsupervised cluster GNN on target graph to group the similar nodes by graph homophily. An adversarial loss with label information on source graph is used upon clustering objective. Then a shift-robust classifier is optimized on training graph and adversarial samples on target graph, which are generated by cluster GNN. We conduct experiments on both open-set shift and representation-shift, which demonstrates the superior accuracy of SRNC on generalizing to test graph with data shift. SRNC is consistently better than previous SoTA domain adaption algorithm on graph that progressively use model predictions on target graph for training."
Carl J. Yang,Multimodal fusion of ehr in structures and semantics: Integrating clinical records and notes with hypergraph and llm,2024,https://arxiv.org/abs/2403.08818,"Electronic Health Records (EHRs) have become increasingly popular to support clinical decision-making and healthcare in recent decades. EHRs usually contain heterogeneous information, such as structural data in tabular form and unstructured data in textual notes. Different types of information in EHRs can complement each other and provide a more complete picture of the health status of a patient. While there has been a lot of research on representation learning of structured EHR data, the fusion of different types of EHR data (multimodal fusion) is not well studied. This is mostly because of the complex medical coding systems used and the noise and redundancy present in the written notes. In this work, we propose a new framework called MINGLE, which integrates both structures and semantics in EHR effectively. Our framework uses a two-level infusion strategy to combine medical concept semantics and clinical note semantics into hypergraph neural networks, which learn the complex interactions between different types of data to generate visit representations for downstream prediction. Experiment results on two EHR datasets, the public MIMIC-III and private CRADLE, show that MINGLE can effectively improve predictive performance by 11.83% relatively, enhancing semantic integration as well as multimodal fusion for structural and textual EHR data."
Carl J. Yang,Deep efficient private neighbor generation for subgraph federated learning,2024,https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.92,"Behemoth graphs are often fragmented and separately stored by multiple data owners as distributed subgraphs in many realistic applications. Without harming data privacy, it is natural to consider the subgraph federated learning (subgraph FL) scenario, where each local client holds a subgraph of the entire global graph, to obtain globally generalized graph mining models. To overcome the unique challenge of incomplete information propagation on local subgraphs due to missing cross-subgraph neighbors, previous works resort to the augmentation of local neighborhoods through the joint FL of missing neighbor generators and GNNs. Yet their technical designs have profound limitations regarding the utility, efficiency, and privacy goals of FL. In this work, we propose FedDEP to comprehensively tackle these challenges in subgraph FL. FedDEP consists of a series of novel technical designs: (1) Deep neighbor …"
Carl J. Yang,Automatic hypergraph generation for enhancing recommendation with sparse optimization,2023,https://ieeexplore.ieee.org/abstract/document/10336546/,"With the rapid growth of activities on the web, large amounts of interaction data on multimedia platforms are easily accessible, including e-commerce, music sharing, and social media. By discovering various interests of users, recommender systems can improve user satisfaction without accessing overwhelming personal information. Compared to graph-based models, hypergraph-based collaborative filtering has the ability to model higher-order relations besides pair-wise relations among users and items, where the hypergraph structures are mainly obtained from specialized data or external knowledge. However, the above well-constructed hypergraph structures are often not readily available in every situation. To this end, we first propose a novel framework named HGRec, which can enhance recommendation via automatic hypergraph generation. By exploiting the clustering mechanism based on the user/item similarity, we …"
Carl J. Yang,Biomedical visual instruction tuning with clinician preference alignment,2024,https://arxiv.org/abs/2406.13173,"Recent advancements in multimodal foundation models have showcased impressive capabilities in understanding and reasoning with visual and textual information. Adapting these foundation models trained for general usage to specialized domains like biomedicine requires large-scale domain-specific instruction datasets. While existing works have explored curating such datasets automatically, the resultant datasets are not explicitly aligned with domain expertise. In this work, we propose a data-centric framework, Biomedical Visual Instruction Tuning with Clinician Preference Alignment (BioMed-VITAL), that incorporates clinician preferences into both stages of generating and selecting instruction data for tuning biomedical multimodal foundation models. First, during the generation stage, we prompt the GPT-4V generator with a diverse set of clinician-selected demonstrations for preference-aligned data candidate generation. Then, during the selection phase, we train a separate selection model, which explicitly distills clinician and policy-guided model preferences into a rating function to select high-quality data for medical instruction tuning. Results show that the model tuned with the instruction-following data from our method demonstrates a significant improvement in open visual chat (18.5% relatively) and medical VQA (win rate up to 81.73%). Our instruction-following data and models are available at BioMed-VITAL.github.io."
Carl J. Yang,Open visual knowledge extraction via relation-oriented multimodality model prompting,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/49d1cf22327c51331cbd52bcb76a09a6-Abstract-Conference.html,"Images contain rich relational knowledge that can help machines understand the world. Existing methods on visual knowledge extraction often rely on the pre-defined format (eg, sub-verb-obj tuples) or vocabulary (eg, relation types), restricting the expressiveness of the extracted knowledge. In this work, we take a first exploration to a new paradigm of open visual knowledge extraction. To achieve this, we present OpenVik which consists of an open relational region detector to detect regions potentially containing relational knowledge and a visual knowledge generator that generates format-free knowledge by prompting the large multimodality model with the detected region of interest. We also explore two data enhancement techniques for diversifying the generated format-free visual knowledge. Extensive knowledge quality evaluations highlight the correctness and uniqueness of the extracted open visual knowledge by OpenVik. Moreover, integrating our extracted knowledge across various visual reasoning applications shows consistent improvements, indicating the real-world applicability of OpenVik."
Carl J. Yang,Weakly supervised concept map generation through task-guided graph translation,2023,https://ieeexplore.ieee.org/abstract/document/10059210/,"Recent years have witnessed the rapid development of concept map generation techniques due to their advantages in providing well-structured summarization of knowledge from free texts. Traditional unsupervised methods do not generate task-oriented concept maps, whereas deep generative models require large amounts of training data. In this work, we present  GT-D2G  (Graph Translation-based Document To Graph), an automatic concept map generation framework that leverages generalized NLP pipelines to derive semantic-rich initial graphs, and translates them into more concise structures under the weak supervision of downstream task labels. The concept maps generated by  GT-D2G  can provide interpretable summarization of structured knowledge for the input texts, which are demonstrated through human evaluation and case studies on three real-world corpora. Further experiments on the …"
Carl J. Yang,Pre-train graph neural networks for brain network analysis,2022,https://ieeexplore.ieee.org/abstract/document/10020314/,"Human brains, controlling behaviors and cognition, are at the center of complex neurobiological systems. Recent studies in neuroscience and neuroimaging analysis have reached a consensus that interactions among brain regions of interest (ROIs) are driving factors for neural development and disorders. Graph neural networks (GNNs) as a powerful tool for analyzing graph-structured data are naturally applied to the analysis of brain networks. However, training of deep learning models including GNNs often requires a significant amount of labeled data. Due to the complicated data acquisition process and restrictions on data sharing, brain network datasets are still small compared to other types of graphs (e.g., social networks, molecules, proteins). Moreover, real clinical tasks (e.g., mental disorder analysis) are often conducted on local datasets with even smaller scales and larger noises. To this end, we propose …"
Carl J. Yang,Machine Learning for Health,2022,https://scholar.google.com/scholar?cluster=2602554070496678878&hl=en&oi=scholarr,
Carl J. Yang,Integrating group homophily and individual personality of topics can better model network communities,2020,https://ieeexplore.ieee.org/abstract/document/9338379/,"Community detection is an important research field in the understanding of networks. The definition of network communities focuses on denser intracommunity links and sparpser intercommunity links. It cannot explain the fundamental generation mechanisms of the two types of links, which is challenging to reveal. Unfortunately, none of existing works can solve this challenge which is important for accurately modeling community structures. This paper investigates a typical category of networks which possess contents on links. Based on analyses of real networks, we get an observation that nodes with distinctive personality regarding content topics are more active across communities, while nodes without it are more active inside a community, behaving in a similar way known as homophily. This observation provides clues to the generation of intracommunity and intercommunity links. Based on above observation, this …"
Carl J. Yang,Boosting reward model with preference-conditional multi-aspect synthetic data generation,2024,https://arxiv.org/abs/2407.16008,"Reward models (RMs) are crucial for aligning large language models (LLMs) with human preferences. They are trained using preference datasets where each example consists of one input prompt, two responses, and a preference label. As curating a high-quality human labeled preference dataset is both time-consuming and expensive, people often rely on existing powerful LLMs for preference label generation. This can potentially introduce noise and impede RM training. In this work, we present RMBoost, a novel synthetic preference data generation paradigm to boost reward model quality. Unlike traditional methods, which generate two responses before obtaining the preference label, RMBoost first generates one response and selects a preference label, followed by generating the second more (or less) preferred response conditioned on the pre-selected preference label and the first response. This approach offers two main advantages. First, RMBoost reduces labeling noise since preference pairs are constructed intentionally. Second, RMBoost facilitates the creation of more diverse responses by incorporating various quality aspects (e.g., helpfulness, relevance, completeness) into the prompts. We conduct extensive experiments across three diverse datasets and demonstrate that RMBoost outperforms other synthetic preference data generation techniques and significantly boosts the performance of four distinct reward models."
Carl J. Yang,PromptLink: Leveraging large language models for cross-source biomedical concept linking,2024,https://dl.acm.org/doi/abs/10.1145/3626772.3657904,"Linking (aligning) biomedical concepts across diverse data sources enables various integrative analyses, but it is challenging due to the discrepancies in concept naming conventions. Various strategies have been developed to overcome this challenge, such as those based on string-matching rules, manually crafted thesauri, and machine learning models. However, these methods are constrained by limited prior biomedical knowledge and can hardly generalize beyond the limited amounts of rules, thesauri, or training samples. Recently, large language models (LLMs) have exhibited impressive results in diverse biomedical NLP tasks due to their unprecedentedly rich prior knowledge and strong zero-shot prediction abilities. However, LLMs suffer from issues including high costs, limited context length, and unreliable predictions. In this research, we propose PromptLink, a novel biomedical concept linking …"
Carl J. Yang,Gc-bench: A benchmark framework for graph condensation with new insights,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240616715G/abstract,"Graph condensation (GC) is an emerging technique designed to learn a significantly smaller graph that retains the essential information of the original graph. This condensed graph has shown promise in accelerating graph neural networks while preserving performance comparable to those achieved with the original, larger graphs. Additionally, this technique facilitates downstream applications such as neural architecture search and enhances our understanding of redundancy in large graphs. Despite the rapid development of GC methods, a systematic evaluation framework remains absent, which is necessary to clarify the critical designs for particular evaluative aspects. Furthermore, several meaningful questions have not been investigated, such as whether GC inherently preserves certain graph properties and offers robustness even without targeted design efforts. In this paper, we introduce GC-Bench, a …"
Carl J. Yang,Uncertainty-aware pre-trained foundation models for patient risk prediction via gaussian process,2024,https://dl.acm.org/doi/abs/10.1145/3589335.3651456,"Patient risk prediction models are crucial as they enable healthcare providers to proactively identify and address potential health risks. Large pre-trained foundation models offer remarkable performance in risk prediction tasks by analyzing multimodal patient data. However, a notable limitation of pre-trained foundation models lies in their deterministic predictions (i.e., lacking the ability to acknowledge uncertainty). We propose Gaussian Process-based foundation models to enable the generation of accurate predictions with instance-level uncertainty quantification, thus allowing healthcare professionals to make more informed and cautious decisions. Our proposed approach is principled and architecture-agnostic. Experimental results show that our proposed approach achieves competitive performance on classical classification metrics. Moreover, we observe that the accuracy of certain predictions is much higher …"
Carl J. Yang,Casper: Causality-aware spatiotemporal graph neural networks for spatiotemporal time series imputation,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240311960J/abstract,"Spatiotemporal time series is the foundation of understanding human activities and their impacts, which is usually collected via monitoring sensors placed at different locations. The collected data usually contains missing values due to various failures, which have significant impact on data analysis. To impute the missing values, a lot of methods have been introduced. When recovering a specific data point, most existing methods tend to take into consideration all the information relevant to that point regardless of whether they have a cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, eg, background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths between the input and output, in other words, they establish non-causal correlations between the input and output. Over …"
Carl J. Yang,Adapting a generative pretrained transformer achieves sota performance in assessing diverse physiological functions using only photoplethysmography signals: A gpt-ppg approach,2024,https://openreview.net/forum?id=hfgdwxbNOW,"This study introduces a novel application of a Genera-tive Pre-trained Transformer (GPT) model tailored for photoplethysmography (PPG) signals, serving as a foun-dation model for various downstream tasks. Adapting the standard GPT architecture to suit the continuous characteristics of PPG signals, our approach demon-strates promising results. After pre-training on our exten-sive dataset that contains more than 200 million 30s PPG samples, the model shows performance comparable to or surpassing current state-of-the-art (SOTA) methods in tasks like heart rate estimation. A standout feature of our GPT model is its inherent capability to perform gen-erative tasks such as signal denoising effectively, with-out the need for further finetuning. This success is at-tributed to the generative nature of the GPT framework. Looking ahead, we aim to further explore its generative abilities and investigate its implication on its other downstream tasks."
Carl J. Yang,Srda: Mobile sensing based fluid overload detection for end stage kidney disease patients using sensor relation dual autoencoder,2023,https://proceedings.mlr.press/v209/tang23b.html,"Chronic kidney disease (CKD) is a life-threatening and prevalent disease. CKD patients, especially end-stage kidney disease (ESKD) patients on hemodial-ysis, suffer from kidney failures and are unable to remove excessive fluid, causing fluid overload and multiple morbidities including death. Current so-lutions for fluid overtake monitoring such as ultra-sonography and biomarkers assessment are cumber-some, discontinuous, and can only be performed in the clinic. In this paper, we propose SRDA, a latent graph learning powered fluid overload detection sys-tem based on Sensor Relation Dual Autoencoder to detect excessive fluid consumption of EKSD patients based on passively collected bio-behavioral data from smartwatch sensors. Experiments using real-world mobile sensing data indicate that SRDA outper-forms the state-of-the-art baselines in both F1 score and recall, and demonstrate the potential of ubiqui-tous sensing for ESKD fluid intake management."
Carl J. Yang,PV2TEA: Patching visual modality to textual-established information extraction,2023,https://arxiv.org/abs/2306.01016,"Information extraction, e.g., attribute value extraction, has been extensively studied and formulated based only on text. However, many attributes can benefit from image-based extraction, like color, shape, pattern, among others. The visual modality has long been underutilized, mainly due to multimodal annotation difficulty. In this paper, we aim to patch the visual modality to the textual-established attribute information extractor. The cross-modality integration faces several unique challenges: (C1) images and textual descriptions are loosely paired intra-sample and inter-samples; (C2) images usually contain rich backgrounds that can mislead the prediction; (C3) weakly supervised labels from textual-established extractors are biased for multimodal training. We present PV2TEA, an encoder-decoder architecture equipped with three bias reduction schemes: (S1) Augmented label-smoothed contrast to improve the cross-modality alignment for loosely-paired image and text; (S2) Attention-pruning that adaptively distinguishes the visual foreground; (S3) Two-level neighborhood regularization that mitigates the label textual bias via reliability estimation. Empirical results on real-world e-Commerce datasets demonstrate up to 11.74% absolute (20.97% relatively) F1 increase over unimodal baselines."
Carl J. Yang,Cross-modal data augmentation for tasks of different modalities,2022,https://ieeexplore.ieee.org/abstract/document/9982421/,"Data augmentation has become one of the keys to alleviating the over-fitting of models on training data and improving the generalization capabilities on testing data. Most existing data augmentation methods only focus on one modality, which is incapable when facing multiple data modalities. Some prior works try to interpolate with random coefficients in the latent space to generate new samples, which can generically work for any data modality. However, these works ignore the extra information conveyed by multimodality data. In fact, the extra information in one modality can provide semantic directions to generate more meaningful samples in another modality. This paper proposes Cross-modal Data Augmentation (CMDA), a simple yet effective data augmentation method to alleviate the over-fitting issue and improve the generalization performance. We evaluate CMDA on unsupervised and supervised tasks of different …"
Carl J. Yang,Open-World Taxonomy and Knowledge Graph Co-Learning.,2022,http://www.cs.emory.edu/~jyang71/files/hakegcn.pdf,"Taxonomies and knowledge graphs (KGs), which represent real-world entities’ abstract concepts and properties/behaviors/facts, constitute the essential information in knowledge bases (KBs). However, most existing KBs are constructed under the closed-world assumption, which often corresponds to a fixed schema and requires ad-hoc canonicalization to integrate new knowledge. To empower KBs towards easy accommodation of emerging entities and relations, we propose to create open-world TaxoKGs based on existing automatically constructed taxonomies and open KGs, where taxonomies serve to provide a loosely-defined schema and mitigate the reliance on ad-hoc canonicalization. To further improve the completeness of TaxoKG, we collect several new benchmark datasets towards the development of HakeGCN, an innovative hierarchy-aware graph-friendly model for TaxoKG completion. Through extensive experiments, we demonstrate HakeGCN to outperform various state-of-the-art KB completion methods on both taxonomy concept prediction and KG relation prediction tasks based on both standard metrics and human evaluations. The benchmark datasets and the implementation of HakeGCN are available at https://github. com/lujiaying/Open-World-TaxoKG-CoLearning."
Carl J. Yang,Subgraph federated learning over heterogeneous graphs,2022,https://www.cs.emory.edu/~jyang71/files/fedhgn.pdf,"Heterogeneous graphs containing multiple types of nodes and links are widely used to model complex real-world data mining applications. Nowadays, it is common that large and informative heterographs are separately collected and stored by multiple data owners. Therefore, it is natural to consider the federated learning across distributed heterographs, where each local owner holds a sub-heterograph that contains private nodes whose information cannot be shared with others and whose behaviors may be biased from the distribution of the global heterograph (the union of all sub-heterographs). Towards this innovative yet demanded setting, we propose two major techniques:(1) FedHG, which trains a typeaware GCN model using a sample-based normalization over FedAvg to integrate multi-types of node features, link structures, and task labels across sub-heterographs;(2) FedHG+, which jointly trains a type-aware missing neighbor generator with the type-aware GCN to deal with incomplete sub-heterogeneous neighborhoods. We theoretically analyze the effectiveness of both FedHG and FedHG+, regarding their expressiveness in capturing heterogeneous higherorder relations and neighborhood distributions, both extended with generalization analysis on the federated learning setting. Empirical results on two real-world heterograph datasets from different applications with synthesized distributed sub-heterographs demonstrate the effectiveness and efficiency of our proposed techniques."
Carl J. Yang,Effective and interpretable fMRI analysis via functional brain network generation,2021,https://arxiv.org/abs/2107.11247,"Recent studies in neuroscience show great potential of functional brain networks constructed from fMRI data for popularity modeling and clinical predictions. However, existing functional brain networks are noisy and unaware of downstream prediction tasks, while also incompatible with recent powerful machine learning models of GNNs. In this work, we develop an end-to-end trainable pipeline to extract prominent fMRI features, generate brain networks, and make predictions with GNNs, all under the guidance of downstream prediction tasks. Preliminary experiments on the PNC fMRI data show the superior effectiveness and unique interpretability of our framework."
Carl J. Yang,Fedgraphnn: A federated learning system and benchmark for graph neural networks. arXiv 2021,2021,https://scholar.google.com/scholar?cluster=6790771198405795872&hl=en&oi=scholarr,
Carl J. Yang,A pure transformer pretraining framework on text-attributed graphs,2024,https://arxiv.org/abs/2406.13873,"Pretraining plays a pivotal role in acquiring generalized knowledge from large-scale data, achieving remarkable successes as evidenced by large models in CV and NLP. However, progress in the graph domain remains limited due to fundamental challenges such as feature heterogeneity and structural heterogeneity. Recently, increasing efforts have been made to enhance node feature quality with Large Language Models (LLMs) on text-attributed graphs (TAGs), demonstrating superiority to traditional bag-of-words or word2vec techniques. These high-quality node features reduce the previously critical role of graph structure, resulting in a modest performance gap between Graph Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs). Motivated by this, we introduce a feature-centric pretraining perspective by treating graph structure as a prior and leveraging the rich, unified feature space to learn refined interaction patterns that generalizes across graphs. Our framework, Graph Sequence Pretraining with Transformer (GSPT), samples node contexts through random walks and employs masked feature reconstruction to capture pairwise proximity in the LLM-unified feature space using a standard Transformer. By utilizing unified text representations rather than varying structures, our framework achieves significantly better transferability among graphs within the same domain. GSPT can be easily adapted to both node classification and link prediction, demonstrating promising empirical success on various datasets."
Carl J. Yang,Logical Relation Modeling and Mining in Hyperbolic Space for Recommendation,2024,https://ieeexplore.ieee.org/abstract/document/10598032/,"The sparse interactions between users and items have aggravated the difficulty of their representations in recommender systems. Existing methods leverage tags to alleviate the sparsity problem but ignore prevalent logical relations among items and tags (e.g., membership, hierarchy, and exclusion), which can be leveraged to enhance the accuracy of modeling user preferences and conducting recommendations. To this end, we propose to extract logical relations among item tags from existing tag taxonomies and exploit the individual strengths of the Poincaré and the Lorentz models in hyperbolic space for logical relation modeling towards enhanced recommendations. Moreover, we find that the logical relations directly extracted from existing tag taxonomies can be inaccurate and coarse. Therefore, we further devise innovative consistency-based and granularity- based weighting mechanisms based on user …"
Carl J. Yang,Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes,2024,https://arxiv.org/abs/2401.13588,
Carl J. Yang,Fusion modeling: combining clinical and imaging data to advance cardiac care,2023,https://www.ahajournals.org/doi/abs/10.1161/CIRCIMAGING.122.014533,"In addition to the traditional clinical risk factors, an increasing amount of imaging biomarkers have shown value for cardiovascular risk prediction. Clinical and imaging data are captured from a variety of data sources during multiple patient encounters and are often analyzed independently. Initial studies showed that fusion of both clinical and imaging features results in superior prognostic performance compared with traditional scores. There are different approaches to fusion modeling, combining multiple data resources to optimize predictions, each with its own advantages and disadvantages. However, manual extraction of clinical and imaging data is time and labor intensive and often not feasible in clinical practice. An automated approach for clinical and imaging data extraction is highly desirable. Convolutional neural networks and natural language processing can be utilized for the extraction of electronic medical …"
Carl J. Yang,"Mug: A multimodal classification benchmark on game data with tabular, textual, and visual fields",2023,https://arxiv.org/abs/2302.02978,"Previous research has demonstrated the advantages of integrating data from multiple sources over traditional unimodal data, leading to the emergence of numerous novel multimodal applications. We propose a multimodal classification benchmark MuG with eight datasets that allows researchers to evaluate and improve their models. These datasets are collected from four various genres of games that cover tabular, textual, and visual modalities. We conduct multi-aspect data analysis to provide insights into the benchmark, including label balance ratios, percentages of missing features, distributions of data within each modality, and the correlations between labels and input modalities. We further present experimental results obtained by several state-of-the-art unimodal classifiers and multimodal classifiers, which demonstrate the challenging and multimodal-dependent properties of the benchmark. MuG is released at https://github.com/lujiaying/MUG-Bench with the data, tutorials, and implemented baselines."
Carl J. Yang,Structure-Preserving Graph Kernel for Brain Network Classification,2022,https://ieeexplore.ieee.org/abstract/document/9761456/,"Brain network analysis is of great importance in clinical diagnosis and treatments. In this paper, we present a novel graph-based kernel learning approach for brain network classification. Specifically, we demonstrate how to exploit the natural graph structure of brain networks to encode prior knowledge in the kernel using the tensor product operator. For each brain network, we first proposed to apply sparse matrix factorization with a symmetric constraint to extract tensor product based approximation. We then used them to derive a structure-persevering symmetric graph kernel to be fed into the support vector machine (SVM). Quantitative evaluations on challenging EEG-based emotion recognition tasks with respect to different frequency bands demonstrate the superior performance of our proposed method, compared with the state-of-the-art traditional and deep learning methods. Together, results show that relevant …"
Carl J. Yang,User-guided clustering in heterogeneous information networks via motif-based comprehensive transcription,2020,https://link.springer.com/chapter/10.1007/978-3-030-46150-8_22,"Heterogeneous information networks (HINs) with rich semantics are ubiquitous in real-world applications. For a given HIN, many reasonable clustering results with distinct semantic meaning can simultaneously exist. User-guided clustering is hence of great practical value for HINs where users provide labels to a small portion of nodes. To cater to a broad spectrum of user guidance evidenced by different expected clustering results, carefully exploiting the signals residing in the data is potentially useful. Meanwhile, as one type of complex networks, HINs often encapsulate higher-order interactions that reflect the interlocked nature among nodes and edges. Network motifs, sometimes referred to as meta-graphs, have been used as tools to capture such higher-order interactions and reveal the many different semantics. We therefore approach the problem of user-guided clustering in HINs with network motifs. In this …"
Carl J. Yang,Integrating Planning into Single-Turn Long-Form Text Generation,2024,https://arxiv.org/abs/2410.06203,"Generating high-quality, in-depth textual documents, such as academic papers, news articles, Wikipedia entries, and books, remains a significant challenge for Large Language Models (LLMs). In this paper, we propose to use planning to generate long form content. To achieve our goal, we generate intermediate steps via an auxiliary task that teaches the LLM to plan, reason and structure before generating the final text. Our main novelty lies in a single auxiliary task that does not require multiple rounds of prompting or planning. To overcome the scarcity of training data for these intermediate steps, we leverage LLMs to generate synthetic intermediate writing data such as outlines, key information and summaries from existing full articles. Our experiments demonstrate on two datasets from different domains, namely the scientific news dataset SciNews and Wikipedia datasets in KILT-Wiki and FreshWiki, that LLMs fine-tuned with the auxiliary task generate higher quality documents. We observed +2.5% improvement in ROUGE-Lsum, and a strong 3.60 overall win/loss ratio via human SxS evaluation, with clear wins in organization, relevance, and verifiability."
Carl J. Yang,Contrastive Unlearning: A Contrastive Approach to Machine Unlearning,2024,https://arxiv.org/abs/2401.10458,"Machine unlearning aims to eliminate the influence of a subset of training samples (i.e., unlearning samples) from a trained model. Effectively and efficiently removing the unlearning samples without negatively impacting the overall model performance is still challenging. In this paper, we propose a contrastive unlearning framework, leveraging the concept of representation learning for more effective unlearning. It removes the influence of unlearning samples by contrasting their embeddings against the remaining samples so that they are pushed away from their original classes and pulled toward other classes. By directly optimizing the representation space, it effectively removes the influence of unlearning samples while maintaining the representations learned from the remaining samples. Experiments on a variety of datasets and models on both class unlearning and sample unlearning showed that contrastive unlearning achieves the best unlearning effects and efficiency with the lowest performance loss compared with the state-of-the-art algorithms."
Carl J. Yang,"Enhancing personalized healthcare via capturing disease severity, interaction, and progression",2023,https://ieeexplore.ieee.org/abstract/document/10415752/,"Personalized diagnosis prediction based on electronic health records (EHR) of patients is a promising yet challenging task for AI in healthcare. Existing studies typically ignore the heterogeneity of diseases across different patients. For example, diabetes can have different complications across different patients (e.g., hyperlipidemia and circulatory disorder), which requires personalized diagnoses and treatments. Specifically, existing models fail to consider 1) varying severity of the same diseases for different patients, 2) complex interactions among syndromic diseases, and 3) dynamic progression of chronic diseases. In this work, we propose to perform personalized diagnosis prediction based on EHR data via capturing disease severity, interaction, and progression. In particular, we enable personalized disease representations via severity-driven embeddings at the disease level. Then, at the visit level, we propose …"
Carl J. Yang,Knowledge-infused prompting improves clinical text generation with large language models,2023,https://openreview.net/forum?id=wK2y7ZhPvU,"Clinical natural language processing requires methods that can address domain-specific challenges, such as complex medical terminology and clinical contexts.  Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources.  To address this challenge, we propose ClinGen, which infuses knowledge into synthetic clinical text generation using LLMs for clinical NLP tasks. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation.  Extensive studies across 7 clinical NLP tasks and 16 datasets reveal that ClinGen consistently enhances performance across various tasks, effectively aligning the distribution of real datasets and enriching the diversity of generated training instances."
Carl J. Yang,Graph federated learning with hidden representation sharing,2022,https://arxiv.org/abs/2212.12158,"Learning on Graphs (LoG) is widely used in multi-client systems when each client has insufficient local data, and multiple clients have to share their raw data to learn a model of good quality. One scenario is to recommend items to clients with limited historical data and sharing similar preferences with other clients in a social network. On the other hand, due to the increasing demands for the protection of clients' data privacy, Federated Learning (FL) has been widely adopted: FL requires models to be trained in a multi-client system and restricts sharing of raw data among clients. The underlying potential data-sharing conflict between LoG and FL is under-explored and how to benefit from both sides is a promising problem. In this work, we first formulate the Graph Federated Learning (GFL) problem that unifies LoG and FL in multi-client systems and then propose sharing hidden representation instead of the raw data of neighbors to protect data privacy as a solution. To overcome the biased gradient problem in GFL, we provide a gradient estimation method and its convergence analysis under the non-convex objective. In experiments, we evaluate our method in classification tasks on graphs. Our experiment shows a good match between our theory and the practice."
Carl J. Yang,Finding high-quality item attributes for recommendation,2022,https://ieeexplore.ieee.org/abstract/document/9910961/,"The sparse interactions between users and items on the web have aggravated the difficulty of their representations in recommender systems. Existing approaches leverage item attributes (e.g., item categories and tags) to alleviate the data sparsity problem, so as to enhance the performance and interpretability of recommendation. However, directly using all attributes of items cannot avoid the negative impacts of low-quality attributes, where manually labeling the quality of attributes is time-consuming. To this end, we propose HQRec to jointly measure the quality of attributes automatically and perform recommendation accurately. Specifically, we first analyze the different qualities among item attributes, and propose to leverage item categories to select high-quality tags via category-guided quality measurement and direction-aware optimization in an unsupervised fashion. Then, we propose to capture the complex …"
Carl J. Yang,Dynamic network anomaly modeling of cell-phone call detail records for infectious disease surveillance,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3542678,"Global monitoring of novel diseases and outbreaks is crucial for pandemic prevention. To this end, movement data from cell-phones is already used to augment epidemiological models. Recent work has posed individual cell-phone metadata as a universal data source for syndromic surveillance for two key reasons: (1) these records are already collected for billing purposes in virtually every country and (2) they could allow deviations from people's routine behaviors during symptomatic illness to be detected, both in terms of mobility and social interactions. In this paper, we develop the necessary models to conduct population-level infectious disease surveillance by using cell-phone metadata individually linked with health outcomes. Specifically, we propose GraphDNA---a model that builds Graph neural networks (GNNs) into Dynamic Network Anomaly detection. Using cell-phone call records (CDR) linked with …"
Carl J. Yang,Shift-robust node classification via graph clustering co-training,2022,https://openreview.net/forum?id=CXm7uzRlvxf,"It is widely known that machine learning models only achieve sub-optimal performance when testing data exhibit distribution shift against training \ie, . Although Graph Neural Networks (GNNs) have become de facto models for semi-supervised learning tasks, they suffer even more from distribution shift because multiple types of shifts origin from not only node features but graph structures. Existing domain adaptation methods only work for specific type of shifts. In response, we propose Shift-Robust Node Classification (SRNC) - a unified domain adaptation framework for different kinds of distribution shifts on graph. Specifically, we co-train an unsupervised cluster GNN, which captures the data distribution by graph homophily on target graph. Then a shift-robust classifier is optimized on training graph and pseudo samples from target graph, which are provided by cluster GNN. Compared to the existing domain adaptation algorithms on graph, our approach works for both open-set and close-set shifts with convergence guarantees. In our experiments, the classification accuracy is improved at least  against the second-best baseline under open-set shifts. On time-evolving graph with close-set shift, existing domain adaption algorithms can barely improve the generalization if not worse. SRNC is still able to mitigate the negative effect (  absolute improvements) of the shift across different testing-times."
Carl J. Yang,Brainnnexplainer: an interpretable graph neural network framework for brain network based disease analysis. arXiv,2021,https://scholar.google.com/scholar?cluster=7379650741249757458&hl=en&oi=scholarr,
Carl J. Yang,Piecing It All Together: Verifying Multi-Hop Multimodal Claims,2024,https://arxiv.org/abs/2411.09547,"Existing claim verification datasets often do not require systems to perform complex reasoning or effectively interpret multimodal evidence. To address this, we introduce a new task: multi-hop multimodal claim verification. This task challenges models to reason over multiple pieces of evidence from diverse sources, including text, images, and tables, and determine whether the combined multimodal evidence supports or refutes a given claim. To study this task, we construct MMCV, a large-scale dataset comprising 16k multi-hop claims paired with multimodal evidence, generated and refined using large language models, with additional input from human feedback. We show that MMCV is challenging even for the latest state-of-the-art multimodal large language models, especially as the number of reasoning hops increases. Additionally, we establish a human performance benchmark on a subset of MMCV. We hope this dataset and its evaluation task will encourage future research in multimodal multi-hop claim verification."
Carl J. Yang,Brainode: Dynamic brain signal analysis via graph-aided neural ordinary differential equations,2024,https://ieeexplore.ieee.org/abstract/document/10913768/,"Brain network analysis is vital for understanding the neural interactions regarding brain structures and functions, and identifying potential biomarkers for clinical phenotypes. However, widely used brain signals such as Blood Oxygen Level Dependent (BOLD) time series generated from functional Magnetic Resonance Imaging (fMRI) often manifest three challenges: (1) missing values, (2) irregular samples, and (3) sampling misalignment, due to instrumental limitations, impacting down-stream brain network analysis and clinical outcome predictions. In this work, we propose a novel model called BrainODE to achieve continuous modeling of dynamic brain signals using Ordinary Differential Equations (ODE). By learning latent initial values and neural ODE functions from irregular time series, BrainODE effectively reconstructs brain signals at any time point, mitigating the aforementioned three data challenges of brain …"
Carl J. Yang,Simrag: Self-improving retrieval-augmented generation for adapting large language models to specialized domains,2024,https://arxiv.org/abs/2410.17952,"Retrieval-augmented generation (RAG) enhances the question-answering (QA) abilities of large language models (LLMs) by integrating external knowledge. However, adapting general-purpose RAG systems to specialized fields such as science and medicine poses unique challenges due to distribution shifts and limited access to domain-specific data. To tackle this, we propose SimRAG, a self-training approach that equips the LLM with joint capabilities of question answering and question generation for domain adaptation. Our method first fine-tunes the LLM on instruction-following, question-answering, and search-related data. Then, it prompts the same LLM to generate diverse domain-relevant questions from unlabeled corpora, with an additional filtering strategy to retain high-quality synthetic examples. By leveraging these self-generated synthetic examples, the LLM can improve their performance on domain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone sizes and three domains, demonstrate that SimRAG outperforms baselines by 1.2\%--8.6\%."
Carl J. Yang,HypMix: Hyperbolic Representation Learning for Graphs with Mixed Hierarchical and Non-hierarchical Structures,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679940,"Heterogeneous networks contain multiple types of nodes and links, with some link types encapsulating hierarchical structure over entities. Hierarchical relationships can codify information such as subcategories or one entity being subsumed by another and are often used for organizing conceptual knowledge into a tree-structured graph. Hyperbolic embedding models learn node representations in a hyperbolic space suitable for preserving the hierarchical structure. Unfortunately, current hyperbolic embedding models only implicitly capture the hierarchical structure, failing to distinguish between node types, and they only assume a single tree. In practice, many networks contain a mixture of hierarchical and non-hierarchical structures, and the hierarchical relations may be represented as multiple trees with complex structures, such as sharing certain entities. In this work, we propose a new hyperbolic representation …"
Carl J. Yang,Causality-aware spatiotemporal graph neural networks for spatiotemporal time series imputation,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679642,"Spatiotemporal time series are usually collected via monitoring sensors placed at different locations, which usually contain missing values due to various failures, such as mechanical damages and Internet outages. Imputing the missing values is crucial for analyzing time series. When recovering a specific data point, most existing methods consider all the information relevant to that point regardless of the cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths and establish non-causal correlations between the input and output. Over-exploiting these non-causal correlations could cause overfitting. In this paper, we first revisit spatiotemporal time series imputation from a causal perspective and show how to …"
Carl J. Yang,Interpretable Spatio-Temporal Embedding for Brain Structural-Effective Network with Ordinary Differential Equation,2024,https://link.springer.com/chapter/10.1007/978-3-031-72069-7_22,"The MRI-derived brain network serves as a pivotal instrument in elucidating both the structural and functional aspects of the brain, encompassing the ramifications of diseases and developmental processes. However, prevailing methodologies, often focusing on synchronous BOLD signals from functional MRI (fMRI), may not capture directional influences among brain regions and rarely tackle temporal functional dynamics. In this study, we first construct the brain-effective network via the dynamic causal model. Subsequently, we introduce an interpretable graph learning framework termed Spatio-Temporal Embedding ODE (STE-ODE). This framework incorporates specifically designed directed node embedding layers, aiming at capturing the dynamic interplay between structural and effective networks via an ordinary differential equation (ODE) model, which characterizes spatial-temporal brain dynamics. Our …"
Carl J. Yang,Empowering graph neural network-based computational drug repositioning with large language model-inferred knowledge representation,2024,https://link.springer.com/article/10.1007/s12539-024-00654-7,"Computational drug repositioning, through predicting drug-disease associations (DDA), offers significant potential for discovering new drug indications. Current methods incorporate graph neural networks (GNN) on drug-disease heterogeneous networks to predict DDAs, achieving notable performances compared to traditional machine learning and matrix factorization approaches. However, these methods depend heavily on network topology, hampered by incomplete and noisy network data, and overlook the wealth of biomedical knowledge available. Correspondingly, large language models (LLMs) excel in graph search and relational reasoning, which can possibly enhance the integration of comprehensive biomedical knowledge into drug and disease profiles. In this study, we first investigate the contribution of LLM-inferred knowledge representation in drug repositioning and DDA prediction. A zero-shot …"
Carl J. Yang,GC4NC: A Benchmark Framework for Graph Condensation on Node Classification with New Insights,2024,https://arxiv.org/abs/2406.16715,"Graph condensation (GC) is an emerging technique designed to learn a significantly smaller graph that retains the essential information of the original graph. This condensed graph has shown promise in accelerating graph neural networks while preserving performance comparable to those achieved with the original, larger graphs. Additionally, this technique facilitates downstream applications like neural architecture search and deepens our understanding of redundancies in large graphs. Despite the rapid development of GC methods, particularly for node classification, a unified evaluation framework is still lacking to systematically compare different GC methods or clarify key design choices for improving their effectiveness. To bridge these gaps, we introduce \textbf{GC4NC}, a comprehensive framework for evaluating diverse GC methods on node classification across multiple dimensions including performance, efficiency, privacy preservation, denoising ability, NAS effectiveness, and transferability. Our systematic evaluation offers novel insights into how condensed graphs behave and the critical design choices that drive their success. These findings pave the way for future advancements in GC methods, enhancing both performance and expanding their real-world applications. Our code is available at \url{https://github.com/Emory-Melody/GraphSlim/tree/main/benchmark}."
Carl J. Yang,BoxCare: A Box Embedding Model for Disease Representation and Diagnosis Prediction in Healthcare Data,2024,https://dl.acm.org/doi/abs/10.1145/3589335.3651448,"Diagnosis prediction is becoming crucial to develop healthcare plans for patients based on Electronic Health Records (EHRs). Existing works usually enhance diagnosis prediction via learning accurate disease representation, where many of them try to capture inclusive relations based on the hierarchical structures of existing disease ontologies such as those provided by ICD-9 codes. However, they overlook exclusive relations that can reflect different and complementary perspectives of the ICD-9 structures, and thus fail to accurately represent relations among diseases and ICD-9 codes. To this end, we propose to project disease embeddings and ICD-9 code embeddings into boxes, where a box is an axis-aligned hyperrectangle with a geometric region and two boxes can clearly ""include"" or ""exclude"" each other. Upon box embeddings, we further obtain patient embeddings via aggregating the disease …"
Carl J. Yang,Federated learning for cross-institution brain network analysis,2024,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12927/129270J/Federated-learning-for-cross-institution-brain-network-analysis/10.1117/12.3005883.short,"Recent advancements in neuroimaging techniques have sparked a growing interest in understanding the complex interactions between anatomical regions of interest (ROIs), forming into brain networks that play a crucial role in various clinical tasks, such as neural pattern discovery and disorder diagnosis. In recent years, graph neural networks (GNNs) have emerged as powerful tools for analyzing network data. However, due to the complexity of data acquisition and regulatory restrictions, brain network studies remain limited in scale and are often confined to local institutions. These limitations greatly challenge GNN models to capture useful neural circuitry patterns and deliver robust downstream performance. As a distributed machine learning paradigm, federated learning (FL) provides a promising solution in addressing resource limitation and privacy concerns, by enabling collaborative learning across local …"
Carl J. Yang,Contrastive unlearning: A contrastive approach to machine unlearning,2024,https://openreview.net/forum?id=lgnAEBE1Xq,"Machine unlearning aims to eliminate the influence of a subset of training samples (i.e., unlearning samples) from a trained model. Effectively and efficiently removing the unlearning samples without negatively impacting the overall model performance is challenging. Existing works mainly exploit input and output space and classification loss, which can result in ineffective unlearning or performance loss. In addition, they utilize on unlearning or remaining samples ineffectively, sacrificing either unlearning efficacy or efficiency. Our main insight is that direct optimization on the representation space utilizing both unlearning and remaining samples can effectively remove influence of unlearning samples while maintaining representations learned from remaining samples. We propose a contrastive unlearning framework, leveraging the concept of representation learning for more effective unlearning. It removes the influence of unlearning samples by contrasting their embeddings against the remaining samples' embeddings so that their embeddings are closer to the embeddings of unseen samples. Experiments on a variety of datasets and models on both class unlearning and sample unlearning showed that contrastive unlearning achieves the best unlearning effects and efficiency with the lowest performance loss compared with the state-of-the-art algorithms."
Carl J. Yang,Graph Neural Network Modeling of Web Search Activity for Real-time Pandemic Forecasting,2023,https://ieeexplore.ieee.org/abstract/document/10337253/,"The utilization of web search activity for pandemic forecasting has significant implications for managing disease spread and informing policy decisions. However, web search records tend to be noisy and influenced by geographical location, making it difficult to develop large-scale models. While regularized linear models have been effective in predicting the spread of respiratory illnesses like COVID-19, they are limited to specific locations. The lack of incorporation of neighboring areas’ data and the inability to transfer models to new locations with limited data has impeded further progress.To address these limitations, this study proposes a novel self-supervised message-passing neural network (SMPNN) framework for modeling local and cross-location dynamics in pandemic forecasting. The SMPNN framework utilizes an MPNN module to learn cross-location dependencies through self-supervised learning and …"
Carl J. Yang,FedBrain: federated training of graph neural networks for connectome-based brain imaging analysis,2023,https://www.worldscientific.com/doi/abs/10.1142/9789811286421_0017,"Recent advancements in neuroimaging techniques have sparked a growing interest in understanding the complex interactions between anatomical regions of interest (ROIs), forming into brain networks that play a crucial role in various clinical tasks, such as neural pattern discovery and disorder diagnosis. In recent years, graph neural networks (GNNs) have emerged as powerful tools for analyzing network data. However, due to the complexity of data acquisition and regulatory restrictions, brain network studies remain limited in scale and are often confined to local institutions. These limitations greatly challenge GNN models to capture useful neural circuitry patterns and deliver robust downstream performance. As a distributed machine learning paradigm, federated learning (FL) provides a promising solution in addressing resource limitation and privacy concerns, by enabling collaborative learning across local …"
Carl J. Yang,A Bird's-Eye Tutorial of Graph Attention Architectures,2022,https://arxiv.org/abs/2206.02849,"Graph Neural Networks (GNNs) have shown tremendous strides in performance for graph-structured problems especially in the domains of natural language processing, computer vision and recommender systems. Inspired by the success of the transformer architecture, there has been an ever-growing body of work on attention variants of GNNs attempting to advance the state of the art in many of these problems. Incorporating ""attention"" into graph mining has been viewed as a way to overcome the noisiness, heterogenity and complexity associated with graph-structured data as well as to encode soft-inductive bias. It is hence crucial and advantageous to study these variants from a bird's-eye view to assess their strengths and weaknesses. We provide a systematic and focused tutorial centered around attention based GNNs in a hope to benefit researchers dealing with graph-structured problems. Our tutorial looks at GNN variants from the point of view of the attention function and iteratively builds the reader's understanding of different graph attention variants."
Carl J. Yang,Better with less: Data-active pre-training of graph neural networks,2022,https://openreview.net/forum?id=663Cl-KetJ,"Recently, pre-training on graph neural networks (GNNs) has become an active research area and is used to learn transferable knowledge for downstream tasks with unlabeled data. The success of graph pre-training models is often attributed to the massive amount of input data. In this paper, however, we identify the curse of big data phenomenon in graph pre-training: more training samples and graph datasets do not necessarily lead to better performance. Motivated by this observation, we propose a better-with-less framework for graph pre-training: few, but carefully chosen data are fed into a GNN model to enhance pre-training. This novel pre-training pipeline is called the data-active graph pre-training (APT) framework, and is composed of a graph selector and a pre-training model. The graph selector chooses the most representative and instructive data points based on the inherent properties of graphs as well as the predictive uncertainty. The proposed uncertainty, as feedback from the pre-training model, measures the confidence level of the model to the data. When fed with the chosen data, on the other hand, the pre-training model grasps an initial understanding of the new, unseen data, and at the same time attempts to remember the knowledge learnt from the previous data. Therefore, the integration and interaction between these two components form a unified framework, in which graph pre-training is performed in a progressive way. Experiment results show that the proposed APT framework is able to obtain an efficient pre-training model with fewer training data and better downstream performance."
Carl J. Yang,A simple but tough-to-beat baseline for fMRI time-series classification,2024,https://www.sciencedirect.com/science/article/pii/S1053811924004063,"Current neuroimaging studies frequently use complex machine learning models to classify human fMRI data, distinguishing healthy and disordered brains, often to validate new methods or enhance prediction accuracy. Yet, where prediction accuracy is a concern, our results suggest that precision in prediction does not always require such sophistication. When a classifier as simple as logistic regression is applied to feature-engineered fMRI data, it can match or even outperform more sophisticated recent models. Classification of the raw time series fMRI data generally benefits from complex parameter-rich models. However, this complexity often pushes them into the class of black-box models. Yet, we found that a relatively simple model can consistently outperform much more complex classifiers in both accuracy and speed. This model applies the same multi-layer perceptron repeatedly across time and averages …"
Carl J. Yang,Correlation-Aware Graph Convolutional Networks for Multi-Label Node Classification,2024,https://arxiv.org/abs/2411.17350,"Multi-label node classification is an important yet under-explored domain in graph mining as many real-world nodes belong to multiple categories rather than just a single one. Although a few efforts have been made by utilizing Graph Convolution Networks (GCNs) to learn node representations and model correlations between multiple labels in the embedding space, they still suffer from the ambiguous feature and ambiguous topology induced by multiple labels, which reduces the credibility of the messages delivered in graphs and overlooks the label correlations on graph data. Therefore, it is crucial to reduce the ambiguity and empower the GCNs for accurate classification. However, this is quite challenging due to the requirement of retaining the distinctiveness of each label while fully harnessing the correlation between labels simultaneously. To address these issues, in this paper, we propose a Correlation-aware Graph Convolutional Network (CorGCN) for multi-label node classification. By introducing a novel Correlation-Aware Graph Decomposition module, CorGCN can learn a graph that contains rich label-correlated information for each label. It then employs a Correlation-Enhanced Graph Convolution to model the relationships between labels during message passing to further bolster the classification process. Extensive experiments on five datasets demonstrate the effectiveness of our proposed CorGCN."
Carl J. Yang,Federated node classification over distributed ego-networks with secure contrastive embedding sharing,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679834,"Federated learning on graphs (a.k.a., federated graph learning - FGL) has recently received increasing attention due to its capacity to enable collaborative learning over distributed graph datasets without compromising local clients' data privacy. In previous works, clients of FGL typically represent institutes or organizations that possess sets of entire graphs (e.g., molecule graphs in biochemical research) or parts of a larger graph (e.g., sub-user networks of e-commerce platforms). However, another natural paradigm exists where clients act as remote devices retaining the graph structures of local neighborhoods centered around the device owners (i.e., ego-networks), which can be modeled for specific graph applications such as user profiling on social ego-networks and infection prediction on contact ego-networks. FGL in such novel yet realistic ego-network settings faces the unique challenge of incomplete …"
Carl J. Yang,From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR,2024,https://arxiv.org/abs/2406.05682,"Electronic Health Records (EHRs) contain rich patient information and are crucial for clinical research and practice. In recent years, deep learning models have been applied to EHRs, but they often rely on massive features, which may not be readily available for all patients. We propose HTP-Star, which leverages hypergraph structures with a pretrain-then-finetune framework for modeling EHR data, enabling seamless integration of additional features. Additionally, we design two techniques, namely (1) Smoothness-inducing Regularization and (2) Group-balanced Reweighting, to enhance the model's robustness during fine-tuning. Through experiments conducted on two real EHR datasets, we demonstrate that HTP-Star consistently outperforms various baselines while striking a balance between patients with basic and extra features."
Carl J. Yang,Evaluation of General Large Language Models in Understanding Clinical Concepts Extracted from Adult Critical Care Electronic Health Record Notes,2024,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4734730,"Objective The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance in various applications. While LLMs have shown promise in standardized medical exams, their performance in actual clinical applications has been underexplored. We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods We investigated the performance of three widely available general LLMs (GPT-4, GPT-3.5, and text-davinci-003) in understanding and processing real-world clinical notes. Text from 150 clinical notes was mapped with MetaMap to standardized medical concepts aligned with the Unified Medical Language System (UMLS) and then adjudicated by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using a range of different prompts for an in-depth analysis. The performance of fine-tuned LLaMA 2 was compared with other LLMs in zero-shots. The performance of LLMs was also tested using 6 different qualitative performance metrics. Results We developed a dataset featuring 2,288 clinical concepts annotated and adjudicated by 9 multidisciplinary clinicians. In 3 different tasks, GPT-4 showed overall superior performance compared to other LLMs. In comparing different prompting strategies, GPT-4 demonstrated consistently high performance across all prompts. This finding indicates that such an advanced model does not require extensive prompt engineering to …"
Carl J. Yang,Brainsteam: A practical pipeline for connectome-based fmri analysis towards subject classification,2023,https://www.worldscientific.com/doi/abs/10.1142/9789811286421_0005,"Functional brain networks represent dynamic and complex interactions among anatomical regions of interest (ROIs), providing crucial clinical insights for neural pattern discovery and disorder diagnosis. In recent years, graph neural networks (GNNs) have proven immense success and effectiveness in analyzing structured network data. However, due to the high complexity of data acquisition, resulting in limited training resources of neuroimaging data, GNNs, like all deep learning models, suffer from overfitting. Moreover, their capability to capture useful neural patterns for downstream prediction is also adversely affected. To address such challenge, this study proposes BrainSTEAM, an integrated framework featuring a spatio-temporal module that consists of an EdgeConv GNN model, an autoencoder network, and a Mixup strategy. In particular, the spatio-temporal module aims to dynamically segment the time …"
Carl J. Yang,Multi-facet graph mining with contextualized projections,2020,https://www.ideals.illinois.edu/items/117092,"The goal of my doctoral research is to develop a new generation of graph mining techniques, centered around my proposed idea of multi-facet contextualized projections, for more systematic, flexible, and scalable knowledge discovery around massive, complex, and noisy real-world context-rich networks across various domains. Traditional graph theories largely overlook network contexts, whereas state-of-the-art graph mining algorithms simply regard them as associative attributes and brutally employ machine learning models developed in individual domains (eg, convolutional neural networks in computer vision, recurrent neural networks in natural language processing) to handle them jointly. As such, essentially different contexts (eg, temporal, spatial, textual, visual) are mixed up in a messy, unstable, and uninterpretable way, while the correlations between graph topologies and contexts remain a mystery, which further renders the development of real-world mining systems less principled and ineffective. To overcome such barriers, my research harnesses the power of multi-facet context modeling and focuses on the principle of contextualized projections, which provides generic but subtle solutions to knowledge discovery over graphs with the mixtures of various semantic contexts."
Carl J. Yang,Preliminary analysis of the impact of lab results on large language model generated differential diagnoses,2025,https://www.nature.com/articles/s41746-025-01556-8,"Differential diagnosis (DDx) is crucial for medicine as it helps healthcare providers systematically distinguish between conditions that share similar symptoms. This study evaluates the influence of lab test results on DDx accuracy generated by large language models (LLMs). Clinical vignettes from 50 randomly selected case reports from PMC-Patients were created, incorporating demographics, symptoms, and lab data. Five LLMs—GPT-4, GPT-3.5, Llama-2-70b, Claude-2, and Mixtral-8x7B—were tested to generate Top 10, Top 5, and Top 1 DDx with and without lab data. Results show that incorporating lab data enhances accuracy by up to 30% across models. GPT-4 achieved the highest performance, with Top 1 accuracy of 55% (0.41–0.69) and lenient accuracy reaching 79% (0.68–0.90). Statistically significant improvements (Holm-adjusted p values < 0.05) were observed, with GPT-4 and Mixtral excelling. Lab …"
Carl J. Yang,Privacy-Enhancing Paradigms within Federated Multi-Agent Systems,2025,https://arxiv.org/abs/2503.08175,"LLM-based Multi-Agent Systems (MAS) have proven highly effective in solving complex problems by integrating multiple agents, each performing different roles. However, in sensitive domains, they face emerging privacy protection challenges. In this paper, we introduce the concept of Federated MAS, highlighting the fundamental differences between Federated MAS and traditional FL. We then identify key challenges in developing Federated MAS, including: 1) heterogeneous privacy protocols among agents, 2) structural differences in multi-party conversations, and 3) dynamic conversational network structures. To address these challenges, we propose Embedded Privacy-Enhancing Agents (EPEAgent), an innovative solution that integrates seamlessly into the Retrieval-Augmented Generation (RAG) phase and the context retrieval stage. This solution minimizes data flows, ensuring that only task-relevant, agent-specific information is shared. Additionally, we design and generate a comprehensive dataset to evaluate the proposed paradigm. Extensive experiments demonstrate that EPEAgent effectively enhances privacy protection while maintaining strong system performance. The code will be availiable at https://github.com/ZitongShi/EPEAgent"
Carl J. Yang,Identifying Evidence Subgraphs for Financial Risk Detection via Graph Counterfactual and Factual Reasoning,2025,https://arxiv.org/abs/2503.06441,"Company financial risks pose a significant threat to personal wealth and national economic stability, stimulating increasing attention towards the development of efficient andtimely methods for monitoring them. Current approaches tend to use graph neural networks (GNNs) to model the momentum spillover effect of risks. However, due to the black-box nature of GNNs, these methods leave much to be improved for precise and reliable explanations towards company risks. In this paper, we propose CF3, a novel Counterfactual and Factual learning method for company Financial risk detection, which generates evidence subgraphs on company knowledge graphs to reliably detect and explain company financial risks. Specifically, we first propose a meta-path attribution process based on Granger causality, selecting the meta-paths most relevant to the target node labels to construct an attribution subgraph. Subsequently, we propose anedge-type-aware graph generator to identify important edges, and we also devise a layer-based feature masker to recognize crucial node features. Finally, we utilize counterfactual-factual reasoning and a loss function based on attribution subgraphs to jointly guide the learning of the graph generator and feature masker. Extensive experiments on three real-world datasets demonstrate the superior performance of our method compared to state-of-the-art approaches in the field of financial risk detection."
Carl J. Yang,Are Your LLM-based Text-to-SQL Models Secure? Exploring SQL Injection via Backdoor Attacks,2025,https://arxiv.org/abs/2503.05445,"Large language models (LLMs) have shown state-of-the-art results in translating natural language questions into SQL queries (Text-to-SQL), a long-standing challenge within the database community. However, security concerns remain largely unexplored, particularly the threat of backdoor attacks, which can introduce malicious behaviors into models through fine-tuning with poisoned datasets. In this work, we systematically investigate the vulnerabilities of LLM-based Text-to-SQL models and present ToxicSQL, a novel backdoor attack framework. Our approach leverages stealthy {semantic and character-level triggers} to make backdoors difficult to detect and remove, ensuring that malicious behaviors remain covert while maintaining high model accuracy on benign inputs. Furthermore, we propose leveraging SQL injection payloads as backdoor targets, enabling the generation of malicious yet executable SQL queries, which pose severe security and privacy risks in language model-based SQL development. We demonstrate that injecting only 0.44% of poisoned data can result in an attack success rate of 79.41%, posing a significant risk to database security. Additionally, we propose detection and mitigation strategies to enhance model reliability. Our findings highlight the urgent need for security-aware Text-to-SQL development, emphasizing the importance of robust defenses against backdoor threats."
Carl J. Yang,Subgraph Federated Learning for Local Generalization,2025,https://arxiv.org/abs/2503.03995,"Federated Learning (FL) on graphs enables collaborative model training to enhance performance without compromising the privacy of each client. However, existing methods often overlook the mutable nature of graph data, which frequently introduces new nodes and leads to shifts in label distribution. Since they focus solely on performing well on each client's local data, they are prone to overfitting to their local distributions (i.e., local overfitting), which hinders their ability to generalize to unseen data with diverse label distributions. In contrast, our proposed method, FedLoG, effectively tackles this issue by mitigating local overfitting. Our model generates global synthetic data by condensing the reliable information from each class representation and its structural information across clients. Using these synthetic data as a training set, we alleviate the local overfitting problem by adaptively generalizing the absent knowledge within each local dataset. This enhances the generalization capabilities of local models, enabling them to handle unseen data effectively. Our model outperforms baselines in our proposed experimental settings, which are designed to measure generalization power to unseen data in practical scenarios. Our code is available at https://github.com/sung-won-kim/FedLoG"
Carl J. Yang,Node-level Contrastive Unlearning on Graph Neural Networks,2025,https://arxiv.org/abs/2503.02959,"Graph unlearning aims to remove a subset of graph entities (i.e. nodes and edges) from a graph neural network (GNN) trained on the graph. Unlike machine unlearning for models trained on Euclidean-structured data, effectively unlearning a model trained on non-Euclidean-structured data, such as graphs, is challenging because graph entities exhibit mutual dependencies. Existing works utilize graph partitioning, influence function, or additional layers to achieve graph unlearning. However, none of them can achieve high scalability and effectiveness without additional constraints. In this paper, we achieve more effective graph unlearning by utilizing the embedding space. The primary training objective of a GNN is to generate proper embeddings for each node that encapsulates both structural information and node feature representations. Thus, directly optimizing the embedding space can effectively remove the target nodes' information from the model. Based on this intuition, we propose node-level contrastive unlearning (Node-CUL). It removes the influence of the target nodes (unlearning nodes) by contrasting the embeddings of remaining nodes and neighbors of unlearning nodes. Through iterative updates, the embeddings of unlearning nodes gradually become similar to those of unseen nodes, effectively removing the learned information without directly incorporating unseen data. In addition, we introduce a neighborhood reconstruction method that optimizes the embeddings of the neighbors in order to remove influence of unlearning nodes to maintain the utility of the GNN model. Experiments on various graph data and models show that …"
Carl J. Yang,Scalable Graph Condensation with Evolving Capabilities,2025,https://arxiv.org/abs/2502.17614,"Graph data has become a pivotal modality due to its unique ability to model relational datasets. However, real-world graph data continues to grow exponentially, resulting in a quadratic increase in the complexity of most graph algorithms as graph sizes expand. Although graph condensation (GC) methods have been proposed to address these scalability issues, existing approaches often treat the training set as static, overlooking the evolving nature of real-world graph data. This limitation leads to inefficiencies when condensing growing training sets. In this paper, we introduce GECC (Graph Evolving Clustering Condensation), a scalable graph condensation method designed to handle large-scale and evolving graph data. GECC employs a traceable and efficient approach by performing class-wise clustering on aggregated features. Furthermore, it can inherits previous condensation results as clustering centroids when the condensed graph expands, thereby attaining an evolving capability. This methodology is supported by robust theoretical foundations and demonstrates superior empirical performance. Comprehensive experiments show that GECC achieves better performance than most state-of-the-art graph condensation methods while delivering an around 1,000x speedup on large datasets."
Carl J. Yang,End-to-End Deep Learning for Structural Brain Imaging: A Unified Framework,2025,https://arxiv.org/abs/2502.18523,"Brain imaging analysis is fundamental in neuroscience, providing valuable insights into brain structure and function. Traditional workflows follow a sequential pipeline-brain extraction, registration, segmentation, parcellation, network generation, and classification-treating each step as an independent task. These methods rely heavily on task-specific training data and expert intervention to correct intermediate errors, making them particularly burdensome for high-dimensional neuroimaging data, where annotations and quality control are costly and time-consuming. We introduce UniBrain, a unified end-to-end framework that integrates all processing steps into a single optimization process, allowing tasks to interact and refine each other. Unlike traditional approaches that require extensive task-specific annotations, UniBrain operates with minimal supervision, leveraging only low-cost labels (i.e., classification and extraction) and a single labeled atlas. By jointly optimizing extraction, registration, segmentation, parcellation, network generation, and classification, UniBrain enhances both accuracy and computational efficiency while significantly reducing annotation effort. Experimental results demonstrate its superiority over existing methods across multiple tasks, offering a more scalable and reliable solution for neuroimaging analysis. Our code and data can be found at https://github.com/Anonymous7852/UniBrain"
Carl J. Yang,ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated Learning in Brain Imaging Analysis,2025,https://arxiv.org/abs/2502.12180,"Multimodal Federated Learning (MFL) has emerged as a promising approach for collaboratively training multimodal models across distributed clients, particularly in healthcare domains. In the context of brain imaging analysis, modality incompleteness presents a significant challenge, where some institutions may lack specific imaging modalities (e.g., PET, MRI, or CT) due to privacy concerns, device limitations, or data availability issues. While existing work typically assumes modality completeness or oversimplifies missing-modality scenarios, we simulate a more realistic setting by considering both client-level and instance-level modality incompleteness in this study. Building on this realistic simulation, we propose ClusMFL, a novel MFL framework that leverages feature clustering for cross-institutional brain imaging analysis under modality incompleteness. Specifically, ClusMFL utilizes the FINCH algorithm to construct a pool of cluster centers for the feature embeddings of each modality-label pair, effectively capturing fine-grained data distributions. These cluster centers are then used for feature alignment within each modality through supervised contrastive learning, while also acting as proxies for missing modalities, allowing cross-modal knowledge transfer. Furthermore, ClusMFL employs a modality-aware aggregation strategy, further enhancing the model's performance in scenarios with severe modality incompleteness. We evaluate the proposed framework on the ADNI dataset, utilizing structural MRI and PET scans. Extensive experimental results demonstrate that ClusMFL achieves state-of-the-art performance compared to various baseline …"
Carl J. Yang,Abstract WP175: Predicting Post-Stroke Cognitive Impairment (PSCI) Using Multiple Machine Learning Approaches,2025,https://www.ahajournals.org/doi/abs/10.1161/str.56.suppl_1.WP175,"Background: Post-stroke cognitive impairment (PSCI) is a condition characterized by cognitive decline that occurs after a stroke. PSCI affects up to 60% of stroke survivors. Early detection of those at high risk for PSCI is essential for timely intervention and personalized care. Electronic health records (EHRs) contain valuable data that can be leveraged by machine learning to predict PSCI, potentially enhancing patient outcomes. This study focuses on developing and validating machine learning models to predict PSCI, aiming to enable earlier diagnosis and improve post-stroke care.Methods: 7956 all-type stroke patients (including Ischemic&Hemorrhagic stroke) treated between 2012 and 2021 were extracted from Emory Healthcare system. We employed multiple methods to predict PSCI, using ICD codes and prescribed medications that were available up to the discharge of index strokes. First, we utilized traditional …"
Carl J. Yang,Abstract TMP102: Title: Prediction of Post-Stroke AF in ESUS Patients is Enhanced by Combining Expert-Derived Predictors and Embedding of Full Diagnostic Codes using Pre-Trained Hypergraph Neural Networks,2025,https://www.ahajournals.org/doi/abs/10.1161/str.56.suppl_1.TMP102,"Background: Atrial Fibrillation (AF) occurs in about one-fourth of patients with Embolic Stroke of Undetermined Source (ESUS). Accurate prediction of post-stroke AF upon discharge from an index stroke admission informs a personalized post-stroke monitoring strategy of AF and interventions. While clinical risk scores predict AF, machine learning (ML) models have shown superior performance.However, traditional ML approaches only use expert-derived predictors available in an electronic health record (EHR) and thus may miss variables that would potentially increase the accuracy of prediction.Aims: This study aims to enhance AF prediction by augmenting expert-derived predictors with an unbiased selection of full diagnostic codes and medication histories up to index strokes. Through embedding learning with hypergraph neural networks, we generate compact representations of high-dimensional data to …"
Carl J. Yang,Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?,2025,https://arxiv.org/abs/2501.17207,"Functional brain connectome is crucial for deciphering the neural mechanisms underlying cognitive functions and neurological disorders. Graph deep learning models have recently gained tremendous popularity in this field. However, their actual effectiveness in modeling the brain connectome remains unclear. In this study, we re-examine graph deep learning models based on four large-scale neuroimaging studies encompassing diverse cognitive and clinical outcomes. Surprisingly, we find that the message aggregation mechanism, a hallmark of graph deep learning models, does not help with predictive performance as typically assumed, but rather consistently degrades it. To address this issue, we propose a hybrid model combining a linear model with a graph attention network through dual pathways, achieving robust predictions and enhanced interpretability by revealing both localized and global neural connectivity patterns. Our findings urge caution in adopting complex deep learning models for functional brain connectome analysis, emphasizing the need for rigorous experimental designs to establish tangible performance gains and perhaps more importantly, to pursue improvements in model interpretability."
Carl J. Yang,Mining Social Determinants of Health for Heart Failure Patient 30-Day Readmission via Large Language Model,2025,https://arxiv.org/abs/2502.12158,"Heart Failure (HF) affects millions of Americans and leads to high readmission rates, posing significant healthcare challenges. While Social Determinants of Health (SDOH) such as socioeconomic status and housing stability play critical roles in health outcomes, they are often underrepresented in structured EHRs and hidden in unstructured clinical notes. This study leverages advanced large language models (LLMs) to extract SDOHs from clinical text and uses logistic regression to analyze their association with HF readmissions. By identifying key SDOHs (e.g. tobacco usage, limited transportation) linked to readmission risk, this work also offers actionable insights for reducing readmissions and improving patient care."
Carl J. Yang,FedGrAINS: Personalized SubGraph Federated Learning with Adaptive Neighbor Sampling,2025,https://arxiv.org/abs/2501.12592,"Graphs are crucial for modeling relational and biological data. As datasets grow larger in real-world scenarios, the risk of exposing sensitive information increases, making privacy-preserving training methods like federated learning (FL) essential to ensure data security and compliance with privacy regulations. Recently proposed personalized subgraph FL methods have become the de-facto standard for training personalized Graph Neural Networks (GNNs) in a federated manner while dealing with the missing links across clients' subgraphs due to privacy restrictions. However, personalized subgraph FL faces significant challenges due to the heterogeneity in client subgraphs, such as degree distributions among the nodes, which complicate federated training of graph models. To address these challenges, we propose \textit{FedGrAINS}, a novel data-adaptive and sampling-based regularization method for subgraph FL. FedGrAINS leverages generative flow networks (GFlowNets) to evaluate node importance concerning clients' tasks, dynamically adjusting the message-passing step in clients' GNNs. This adaptation reflects task-optimized sampling aligned with a trajectory balance objective. Experimental results demonstrate that the inclusion of \textit{FedGrAINS} as a regularizer consistently improves the FL performance compared to baselines that do not leverage such regularization."
Carl J. Yang,MaSH: Maximal Separating Poincaré Hyperplanes for Hierarchical Imbalanced Learning,2025,https://www.cs.emory.edu/~jyang71/files/mash.pdf,"Learning representations in hyperbolic space has gained popularity due to its advantageous properties for encoding hierarchical data [23, 25, 29, 30, 34]. The ability to encode hierarchies stems from the fact that the volume of hyperbolic space grows exponentially with an increase in radius, mirroring the discrete property of trees where"
Carl J. Yang,Large Language Model Empowered Logical Relations Mining for Personalized Recommendation,2025,https://www.cs.emory.edu/~jyang71/files/relrec.pdf,"In personalized recommendations, users often express complex logical requirements, involving the intersection of multiple preferences over heterogeneous graphs containing users, items, and external knowledge. Existing methods for mining logical relations face challenges in scalability and often overlook the semantics of relations, which are essential for uncovering higher-order connections and addressing incomplete relations within the graph. To tackle these challenges, we propose RelRec, a novel approach that leverages large language models (LLMs) to mine logical relations and satisfy users’ logical requirements in personalized recommendation tasks. Specifically, the framework begins with the extraction of userdriven logical relations, followed by a rule-based logical relation mining module that integrates both semantic and structural information using the capabilities of LLMs. By uncovering higher-order logical relations, our approach effectively refines the heterogeneous graph for reasoning capacity and recommendation accuracy. Extensive experiments on real-world datasets demonstrate that RelRec significantly outperforms existing methods."
Carl J. Yang,Integrating Large Language Models and Knowledge Graphs for Next-level AGI,2025,https://www.cs.emory.edu/~jyang71/files/klm-tutorial.pdf,"Large language models (LLMs), due to their emergent ability and generalizability, are making new waves in developing Artificial General Intelligence (AGI). However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs) are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to integrating LLMs and KGs together and simultaneously leveraging their advantages to achieve AGI’s ultimate goal: to reason, adapt, and synthesize knowledge with human-level nuance and factual accuracy.This tutorial aims to bridge this gap by presenting a comprehensive overview of the unification of LLMs and KGs for next-level AGI. Specifically, we will cover three key frameworks:(1) KG-enhanced LLMs, which focus on augmenting LLMs with KGs for pre-training, fine-tuning, and inference, thereby enriching the LLMs’ factual and contextual accuracy;(2) LLM-augmented KGs, which leverage LLMs to assist in tasks such as KG completion, construction, and question answering, ultimately facilitating KG scalability and adaptability; and (3) Synergized LLM-KG Systems and Applications, where LLMs and KGs function symbiotically to enable real-time, bidirectional reasoning, transforming static knowledge structures into dynamic, AGI-driven frameworks. Through this tutorial, participants …"
Carl J. Yang,MedAssist: LLM-Empowered Medical Assistant for Assisting the Scrutinization and Comprehension of Electronic Health Records,2025,https://www.cs.emory.edu/~jyang71/files/medassist.pdf,"Efficiently comprehending diagnosis and treatment plans remains a significant challenge for both medical professionals and patients, particularly when dealing with rare or newly emerging diseases and specific combinations of comorbidities. We present MedAssist, a large language model (LLM)-empowered medical assistant designed to support the scrutinization and comprehension of electronic health records (EHRs). MedAssist leverages two key components: medical knowledge retrieval, which retrieves the latest and most comprehensive medical knowledge snippets from the web, and data retrieval, which extracts diagnosis and treatment plans for similar patients from existing EHR databases. By integrating these capabilities into user-friendly interfaces, MedAssist bridges critical gaps in medical knowledge accessibility and understanding, and advances patient care in realistic clinical scenarios."
Carl J. Yang,How to Use Graph Data in the Wild to Help Graph Anomaly Detection?,2025,https://www.cs.emory.edu/~jyang71/files/wild-gad.pdf,"In recent years, graph anomaly detection has gained considerable attention and has found extensive applications in various domains such as social, financial, and communication networks. However, anomalies in graph-structured data present unique challenges, including label scarcity, ill-defined anomalies, and varying anomaly types, making supervised or semi-supervised methods unreliable. Researchers often adopt unsupervised approaches to address these challenges, assuming that anomalies deviate significantly from the normal data distribution. Yet, when the available data is insufficient, capturing the normal distribution accurately and comprehensively becomes difficult. To overcome this limitation, we propose to utilize external graph data (ie, graph data in the wild) to help anomaly detection tasks. This naturally raises the question: How can we use external data to help graph anomaly detection task? Central to our framework is a unified database, UniWildGraph, which comprises a large and diverse collection of graph data with broad domain coverage, ample data volume, and a unified feature space. We further develop selection criteria based on representativity and diversity to identify the most suitable external data for each anomaly detection task. Extensive experiments on six real-world test datasets demonstrate the effectiveness of Wild-GAD. Compared to the baseline methods, our framework has an average 18% AUCROC and 32% AUCPR improvement over the best-competing methods."
Carl J. Yang,Deep Graph Neural Networks via Posteriori-Sampling-based Node-Adaptative Residual Module,2024,https://proceedings.neurips.cc/paper_files/paper/2024/hash/7e0dc9ccba0f1333be13a3f9dc2b3138-Abstract-Conference.html,"Graph Neural Networks (GNNs), a type of neural network that can learn from graph-structured data through neighborhood information aggregation, have shown superior performance in various downstream tasks. However, as the number of layers increases, node representations becomes indistinguishable, which is known as over-smoothing. To address this issue, many residual methods have emerged. In this paper, we focus on the over-smoothing issue and related residual methods. Firstly, we revisit over-smoothing from the perspective of overlapping neighborhood subgraphs, and based on this, we explain how residual methods can alleviate over-smoothing by integrating multiple orders neighborhood subgraphs to avoid the indistinguishability of the single high-order neighborhood subgraphs. Additionally, we reveal the drawbacks of previous residual methods, such as the lack of node adaptability and severe loss of high-order neighborhood subgraph information, and propose a\textbf {Posterior-Sampling-based, Node-Adaptive Residual module (PSNR)}. We theoretically demonstrate that PSNR can alleviate the drawbacks of previous residual methods. Furthermore, extensive experiments verify the superiority of the PSNR module in fully observed node classification and missing feature scenarios. Our codeis available at\href {https://github. com/jingbo02/PSNR-GNN}{https://github. com/jingbo02/PSNR-GNN}."
Carl J. Yang,Gra-CRC-miRTar: The pre-trained nucleotide-to-graph neural networks to identify potential miRNA targets in colorectal cancer,2024,https://www.sciencedirect.com/science/article/pii/S2001037024002484,"Colorectal cancer (CRC) is the third most diagnosed cancer and the second deadliest cancer worldwide representing a major public health problem. In recent years, increasing evidence has shown that microRNA (miRNA) can control the expression of targeted human messenger RNA (mRNA) by reducing their abundance or translation, acting as oncogenes or tumor suppressors in various cancers, including CRC. Due to the significant up-regulation of oncogenic miRNAs in CRC, elucidating the underlying mechanism and identifying dysregulated miRNA targets may provide a basis for improving current therapeutic interventions. In this paper, we proposed Gra-CRC-miRTar, a pre-trained nucleotide-to-graph neural network framework, for identifying potential miRNA targets in CRC. Different from previous studies, we constructed two pre-trained models to encode RNA sequences and transformed them into de Bruijn …"
Carl J. Yang,Multi-task Learning for Brain Network Analysis in the ABCD Study,2024,https://ieeexplore.ieee.org/abstract/document/10913627/,"The Adolescent Brain Cognitive Development study provides a rich data resource for exploring the associations between brain network and cognitive, personality, and mental health measures in adolescents. To leverage this rich dataset, we propose a novel multi-task learning framework that predicts these measures from multi-view brain network data using a graph transformer architecture. Our approach learns shared representations across tasks while allowing for task-specific predictions, improving performance compared to single-task learning. Ablation studies reveal the importance of our proposed techniques of Batch-Wise Loss Balancing and Target Standardization in ensuring successful multi-task learning. Furthermore, we develop innovative visualization techniques based on integrated gradients to interpret the learned task correlations and identify influential brain network edges for each task. Our findings …"
Carl J. Yang,Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes,2024,https://arxiv.org/abs/2411.02523,"Differential diagnosis is crucial for medicine as it helps healthcare providers systematically distinguish between conditions that share similar symptoms. This study assesses the impact of lab test results on differential diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from 50 case reports from PubMed Central were created incorporating patient demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b, Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx with and without lab data. A comprehensive evaluation involving GPT-4, a knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving 55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and Mixtral excelling, though exact match rates were low. Lab tests, including liver function, metabolic/toxicology panels, and serology/immune tests, were generally interpreted correctly by LLMs for differential diagnosis."
Carl J. Yang,Measuring Spiritual Values and Bias of Large Language Models,2024,https://arxiv.org/abs/2410.11647,"Large language models (LLMs) have become integral tool for users from various backgrounds. LLMs, trained on vast corpora, reflect the linguistic and cultural nuances embedded in their pre-training data. However, the values and perspectives inherent in this data can influence the behavior of LLMs, leading to potential biases. As a result, the use of LLMs in contexts involving spiritual or moral values necessitates careful consideration of these underlying biases. Our work starts with verification of our hypothesis by testing the spiritual values of popular LLMs. Experimental results show that LLMs' spiritual values are quite diverse, as opposed to the stereotype of atheists or secularists. We then investigate how different spiritual values affect LLMs in social-fairness scenarios e.g., hate speech identification). Our findings reveal that different spiritual values indeed lead to different sensitivity to different hate target groups. Furthermore, we propose to continue pre-training LLMs on spiritual texts, and empirical results demonstrate the effectiveness of this approach in mitigating spiritual bias."
Carl J. Yang,LENS: label sparsity-tolerant adversarial learning on spatial deceptive reviews,2024,https://link.springer.com/article/10.1007/s10707-024-00529-5,"Online businesses and websites have recently become the main target of fake reviews, where fake reviews are intentionally composed to manipulate the business ratings positively or negatively. Most of existing works to detect fake reviews are supervised methods, whose performance highly depends on the amount, quality, and variety of the labeled data, which are often non-trivial to obtain in practice. In this paper, we propose a semi-supervised label sparsity-tolerant framework, LENS, for fake review detection by mining spatial knowledge and learning distributions of embedded topics. LENS builds on two key observations. (1) Spatial knowledge revealed in spatial entities and their co-occurring latent topic distributions may indicate the review authenticity. (2) Distributions of the embedded topics (the contextual distribution) may exhibit important patterns to differentiate between real and fake reviews. Specifically …"
Carl J. Yang,FedKDD: International Joint Workshop on Federated Learning for Data Mining and Graph Analytics,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671490,"Deep Learning has facilitated various high-stakes applications such as crime detection, urban planning, drug discovery, and healthcare. Its continuous success hinges on learning from massive data in miscellaneous sources, ranging from data with independent distributions to graph-structured data capturing intricate inter-sample relationships. Scaling up the data access requires global collaboration from distributed data owners. Yet, centralizing all data sources to an untrustworthy centralized server will put users' data at risk of privacy leakage or regulation violation. Federated Learning (FL) is a de facto decentralized learning framework that enables knowledge aggregation from distributed users without exposing private data. Though promising advances are witnessed for FL, new challenges are emerging when integrating FL with the rising needs and opportunities in data mining, graph analytics, foundation …"
Carl J. Yang,Representation Learning of Temporal Graphs with Structural Roles,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671854,"Temporal graph representation learning has drawn considerable attention in recent years. Most existing works mainly focus on modeling local structural dependencies of temporal graphs. However, underestimating the inherent global structural role information in many real-world temporal graphs inevitably leads to sub-optimal graph representations. To overcome this shortcoming, we propose a novel Role-based Temporal Graph Convolution Network (RTGCN) that fully leverages the global structural role information in temporal graphs. Specifically, RTGCN can effectively capture the static global structural roles by using hypergraph convolution neural networks. To capture the evolution of nodes' structural roles, we further design structural role-based gated recurrent units. Finally, we integrate structural role proximity in our objective function to preserve global structural similarity, further promoting temporal graph …"
Carl J. Yang,TACCO: Task-guided Co-clustering of Clinical Concepts and Patient Visits for Disease Subtyping based on EHR Data,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671594,"The growing availability of well-organized Electronic Health Records (EHR) data has enabled the development of various machine learning models towards disease risk prediction. However, existing risk prediction methods overlook the heterogeneity of complex diseases, failing to model the potential disease subtypes regarding their corresponding patient visits and clinical concept subgroups. In this work, we introduce TACCO, a novel framework that jointly discovers clusters of clinical concepts and patient visits based on a hypergraph modeling of EHR data. Specifically, we develop a novel self-supervised co-clustering framework that can be guided by the risk prediction task of specific diseases. Furthermore, we enhance the hypergraph model of EHR data with textual embeddings and enforce the alignment between the clusters of clinical concepts and patient visits through a contrastive objective. Comprehensive …"
Carl J. Yang,ExpertODE: Continuous Diagnosis Prediction with Expert Enhanced Neural Ordinary Differential Equations,2024,https://ieeexplore.ieee.org/abstract/document/10687504/,"Continuous diagnosis prediction based on multi-modal electronic health records (EHRs) of patients is a promising yet challenging task for AI in healthcare. Existing studies ignore abundant domain knowledge of diseases (e.g., specific medical terms and their interrelations) in textual EHRs, which fails to accurately predict disease progression and assist in sequential diagnosis prediction. To this end, we first propose an Expert enhanced neural Ordinary Differential Equations (ExpertODE) framework for continuous diagnosis prediction. In particular, we first propose a novel Mixture of Language Experts (MoLE) module to enhance disease embeddings with domain knowledge. Furthermore, we propose a Contrastive Neural Ordinary Differential Equation (CNODE) module to continuously model temporal correlations of disease progression, and implement a unified contrastive learning framework to jointly optimize the …"
Carl J. Yang,Enhancing Progressive Diagnosis Prediction in Healthcare with Continuous Normalizing Flows,2024,https://dl.acm.org/doi/abs/10.1145/3589335.3651457,"Progressive diagnosis prediction in healthcare is a promising yet challenging task. Existing studies usually assume a pre-defined prior for generating patient distributions (e.g., Gaussian). However, the inferred approximate posterior can deviate from the real-world distribution, which further affects the modeling of continuous disease progression over time. To alleviate such inference bias, we propose an enhanced progressive diagnostic prediction model (i.e., ProCNF), which integrates continuous normalizing flows (CNF) and neural ordinary differential equations (ODEs) to achieve more accurate approximations of patient health trajectories while capturing the continuity underlying disease progression. We first learn patient embeddings with CNF to construct a complex posterior approximation of patient distributions. Then, we devise a CNF-enhanced neural ODE module for progressive diagnostic prediction, which …"
Carl J. Yang,Systematic Evaluation of General Large Language Models for Contextually Assessed Semantic Concepts From Unstructured Critical Care Data,2024,https://www.atsjournals.org/doi/pdf/10.1164/ajrccm-conference.2024.209.1_MeetingAbstracts.A5060,"Backgrounds While large language models (LLMs) have shown promise in standardized medical exams, their direct applicability and efficiency in real clinical practice have been underexplored. Traditional evaluations based on question-answering formats do not fully capture the nuanced contexts and requirements of clinical environments. We sought to develop a systematic evaluation method for LLMs with human expert (clinicians) annotation. Materials and Methods We investigated the performance of three LLMs (GPT-4, GPT-3.5, and text-davinci-003) in general domains for understanding and processing real-world clinical notes after mapping the free biomedical text to standardized medical concepts aligned with the Unified Medical Language System with the MetaMap. Using MIMIC-III, we identified 150 clinical notes that contain i) diseases and syndromes, ii) signs and symptoms, and iii) mental and behavioral …"
Carl J. Yang,Convergent Brain Connectome Analysis with Brain Graph Transformers,2024,https://www.cs.emory.edu/~jyang71/files/brainntf-isbi.pdf,"Modern neuroscience has increasingly recognized the intricate complexity of the brain’s wiring structure and its functional dynamics. Neuroimaging studies are now embracing a network-based model of the brain, abstracting it as an interconnected web of Regions of Interest (ROIs), linked either by anatomical tracts or functional associations. This connectome perspective facilitates our understanding of neural disorders and the complex nature of brain-behavior relationships. Traditional brain connectome analysis, requiring extensive feature engineering and using shallow models, often falls short in capturing complex network structures [1]. Recently, deep models such as Graph Neural Networks (GNNs) have been shown promising in brain connetome analysis by learning graph representations [2], but GNNs’ efficacy is challenged by the dense real-velued edges in brain networks. Concurrently, the Graph Transformer (GT) architecture has emerged as a powerful tool, with recent applications in brain connectome analysis [3, 4, 5]. Nevertheless, an in-depth and systematic study of GTs’ compatibility with brain connectome analysis remains under-explored. Moreover, existing studies focus solely on individual-level interpretations over important network connections via attention mechanisms, overlooking the potential to identify shared connectome patterns among subjects with similar functionalities, disorders, or behavioral traits.In this work, we present a pioneering exploration at the intersection of GT and the unique requirements of brain connectome analysis. Building on this, we suggest a set of general recipes for effective GT designs and propose a …"
Carl J. Yang,Multi-task Learning for Brain Connectome Analysis in the ABCD study,2024,https://www.cs.emory.edu/~jyang71/files/brainmtl-isbi.pdf,"Neuroimaging studies increasingly use network-oriented analysis to understand the human brain in healthy and diseased individuals. Neuroscience research has provided ample evidence that these neural circuits play a crucial role in explaining the differences in brain function between populations [1]. The Adolescent Brain Cognitive Development (ABCD) study [2] is the largest and long-term study of brain development and child health in US. It provides a vast brain development dataset in a diverse population, including fMRI and abundant biological and behavioral survey results. This dataset offers an opportunity to explore the relationship between intricate brain connections and rich behavioral data. There is a recent trend of using brain networks derived from neuroimaging data such as fMRI to predict various clinical outcomes. These models are then analyzed to determine the potential correlation between functional brain networks and clinical outcomes. For instance, Li et al.[3] proposed a GNN model to predict clinical targets and then discovered task-specific neurological biomarkers. Furthermore, Chen et al.[1] built individual models for each behavior task in the ABCD study and analyzed these models to capture relations across the various behaviors.Instead of training an individual model for each task, in this work, we simultaneously train 35 tasks together with the rest-state functional brain networks from 7327 samples in the ABCD study via Multi-task Learning (MTL). MTL is a framework that enables multiple learning tasks to share their knowledge, resulting in improved generalization abilities. The backbone model used is the Brain …"
Carl J. Yang,Helper Recommendation with seniority control in Online Health Community,2024,https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.29,"Online health communities (OHCs) provide an essential platform for patients with similar health conditions to share experiences and offer moral support. However, many time-sensitive questions from patients often remain unanswered due to the multitude of threads and the random nature of patient visits in OHCs. Traditional recommendation systems solely based on similarity for recommendations cannot be directly applied in OHCs. They tend to overlook the influence of patients' dynamically changing features (e.g., health stages), affecting their ability to provide meaningful responses to questions. To address this, we propose a novel recommender system scenario designed for OHCs, which differs from traditional recommender systems in several ways. Firstly, it's challenging to model the social support factors that form helper-seeker links in OHCs. Secondly, the impact of patients' historical activities is complex to …"
Carl J. Yang,FedAA: Using Non-sensitive Modalities to Improve Federated Learning while Preserving Image Privacy,2023,https://dl.acm.org/doi/abs/10.1145/3581783.3611953,"Federated learning aims to train a better global model without sharing the sensitive training samples (usually images) of local clients. Since the sample distributions in local clients tend to be different from each other (i.e., non-IID), one of the major challenges for federated learning is to alleviate model degradation when aggregating local models. The degradation can be attributed to the weight divergence that quantifies the difference of local models from different training processes. Furthermore, non-IID also results in feature space heterogeneity during local training, making neurons of local models in the same location have different functions and further exacerbating weight divergence. In this paper, we demonstrate that the problem can be solved by sharing information from the non-sensitive modality (e.g., metadata, non-sensitive descriptions, etc.) while keeping the sensitive information of images protected. In …"
Carl J. Yang,Dynamic Brain Transformer with Multi-level Attention for Brain Network Analysis,2023,https://par.nsf.gov/biblio/10520885,"Recent neuroimaging studies have highlighted the importance of network-centric brain analysis, particularly with functional magnetic resonance imaging. The emergence of Deep Neural Networks has fostered a substantial interest in predicting clinical outcomes and categorizing individuals based on brain networks. However, the conventional approach involving static brain network analysis offers limited potential in capturing the dynamism of brain function. Although recent studies have attempted to harness dynamic brain networks, their high dimensionality and complexity present substantial challenges. This paper proposes a novel methodology, Dynamic bRAin Transformer (DART), which combines static and dynamic brain networks for more effective and nuanced brain function analysis. Our model uses the static brain network as a baseline, integrating dynamic brain networks to enhance performance against traditional methods. We innovatively employ attention mechanisms, enhancing model explainability and exploiting the dynamic brain network’s temporal variations. The proposed approach offers a robust solution to the low signal-to-noise ratio of blood-oxygen-leveldependent signals, a recurring issue in direct DNN modeling. It also provides valuable insights into which brain circuits or dynamic networks contribute more to final predictions. As such, DRAT shows a promising direction in neuroimaging studies, contributing to the comprehensive understanding of brain organization and the role of neural circuits."
Carl J. Yang,Deep Graph Neural Networks via Flexible Subgraph Aggregation,2023,https://openreview.net/forum?id=RI6HFZFu3B,"Graph neural networks (GNNs), a type of neural network that can learn from graph-structured data and learn the representation of nodes through aggregating neighborhood information, have shown superior performance in various downstream tasks. However, it is known that the performance of GNNs degrades gradually as the number of layers increases. In this paper, we evaluate the expressive power of GNN from the perspective of subgraph aggregation. We reveal the potential cause of performance degradation for traditional deep GNNs, i.e., aggregated subgraph overlap, and we theoretically illustrate the fact that previous residual-based GNNs exploit the aggregation results of 1 to k hop subgraphs to improve the effectiveness. Further, we find that the utilization of different subgraphs by previous models is often inflexible. Based on this, we propose a sampling-based node-level residual module (SNR) that can achieve a more flexible utilization of different hops of subgraph aggregation by introducing node-level parameters sampled from a learnable distribution. Extensive experiments show that the performance of GNNs with the our proposed SNR module outperform a comprehensive set of baselines."
Carl J. Yang,The 1st International Workshop on Federated Learning with Graph Data (FedGraph),2022,https://dl.acm.org/doi/abs/10.1145/3511808.3557495,"The field of graph data mining, one of the most important AI research areas, has been revolutionized by graph neural networks (GNNs), which benefit from training on real-world graph data with millions to billions of nodes and links. Unfortunately, the training data and process of GNNs involving graphs beyond millions of nodes are extremely costly on a centralized server, if not impossible. Moreover, due to the increasing concerns about data privacy, emerging data from realistic applications are naturally fragmented, forming distributed private graphs of multiple ''data silos"", among which direct transferring of data is forbidden. The nascent field of federated learning (FL), which aims to enable individual clients to jointly train their models while keeping their local data decentralized and completely private, is a promising paradigm for large-scale distributed and private training of GNNs. øurs aims to bring together …"
Carl J. Yang,Introduction to GraphBLAS,2022,https://api.taylorfrancis.com/content/chapters/edit/download?identifierName=doi&identifierValue=10.1201/9781003033707-24&type=chapterpdf,"Graphs are powerful tools for modeling complex problems because of their simplicity and generality [Staudt et al. 2016, Bergamini & Meyerhenke 2016]. For this reason, the field of graph algorithms has become one of the pillars of theoretical computer science, informing research in such diverse areas as combinatorial optimization, complexity theory, and topology. Graph algorithms have been adapted and implemented by the military, commercial industry, and researchers in academia, and have become essential in controlling the power grid, telephone systems, and, of course, computer networks. Graphs are among the most important abstract data structures in computer science, and the algorithms that operate on them are critical to applications in bioinformatics [Georganas et al. 2014], computer networks, and social media [Ediger et al. 2010, Ediger et al. 2011, Riedy et al. 2012, Riedy & Bader 2013]. Parallel …"
Carl J. Yang,TAXOGAN: Hierarchical Network Representation Learning via Taxonomy Guided Generative Adversarial Networks,2021,https://par.nsf.gov/biblio/10331936,"Network representation learning aims at transferring node proximity in networks into distributed vectors, which can be leveraged in various downstream applications. Recent research has shown that nodes in a network can often be organized in latent hierarchical structures, but without a particular underlying taxonomy, the learned node embedding is less useful nor interpretable. In this work, we aim to improve network embedding by modeling the conditional node proximity in networks indicated by node labels residing in real taxonomies. In the meantime, we also aim to model the hierarchical label proximity in the given taxonomies, which is too coarse by solely looking at the hierarchical topologies. Comprehensive experiments and case studies demonstrate the utility of TAXOGAN."
Liang Zhao,"Graph Neural Networks: Foundations, Frontiers, and Applications",2021,https://dl.acm.org/doi/abs/10.1145/3534678.3542609,"The field of graph neural networks (GNNs) has seen rapid and incredible strides over the recent years. Graph neural networks, also known as deep learning on graphs, graph representation learning, or geometric deep learning, have become one of the fastest-growing research topics in machine learning, especially deep learning. This wave of research at the intersection of graph theory and deep learning has also influenced other fields of science, including recommendation systems, computer vision, natural language processing, inductive logic programming, program synthesis, software mining, automated planning, cybersecurity, and intelligent transportation. However, as the field rapidly grows, it has been extremely challenging to gain a global perspective of the developments of GNNs. Therefore, we feel the urgency to bridge the above gap and have a comprehensive tutorial on this fast-growing yet challenging …"
Liang Zhao,FedAT: A High-Performance and Communication-Efficient Federated Learning System with Asynchronous Tiers,2021,https://dl.acm.org/doi/abs/10.1145/3458817.3476211,"Federated learning (FL) involves training a model over massive distributed devices, while keeping the training data localized and private. This form of collaborative learning exposes new tradeoffs among model convergence speed, model accuracy, balance across clients, and communication cost, with new challenges including: (1) straggler problem---where clients lag due to data or (computing and network) resource heterogeneity, and (2) communication bottleneck---where a large number of clients communicate their local updates to a central server and bottleneck the server. Many existing FL methods focus on optimizing along only one single dimension of the tradeoff space. Existing solutions use asynchronous model updating or tiering-based, synchronous mechanisms to tackle the straggler problem. However, asynchronous methods can easily create a communication bottleneck, while tiering may introduce …"
Liang Zhao,A Systematic Survey on Deep Generative Models for Graph Generation,2022,https://ieeexplore.ieee.org/abstract/document/9920219/,"Graphs are important data representations for describing objects and their relationships, which appear in a wide diversity of real-world scenarios. As one of a critical problem in this area, graph generation considers learning the distributions of given graphs and generating more novel graphs. Owing to their wide range of applications, generative models for graphs, which have a rich history, however, are traditionally hand-crafted and only capable of modeling a few statistical properties of graphs. Recent advances in deep generative models for graph generation is an important step towards improving the fidelity of generated graphs and paves the way for new kinds of applications. This article provides an extensive overview of the literature in the field of deep generative models for graph generation. First, the formal definition of deep generative models for the graph generation and the preliminary knowledge are …"
Liang Zhao,Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey,2023,https://arxiv.org/abs/2305.18703,"Large language models (LLMs) have significantly advanced the field of natural language processing (NLP), providing a highly useful, task-agnostic foundation for a wide range of applications. However, directly applying LLMs to solve sophisticated problems in specific domains meets many hurdles, caused by the heterogeneity of domain data, the sophistication of domain knowledge, the uniqueness of domain objectives, and the diversity of the constraints (e.g., various social norms, cultural conformity, religious beliefs, and ethical standards in the domain applications). Domain specification techniques are key to make large language models disruptive in many applications. Specifically, to solve these hurdles, there has been a notable increase in research and practices conducted in recent years on the domain specialization of LLMs. This emerging field of study, with its substantial potential for impact, necessitates a comprehensive and systematic review to better summarize and guide ongoing work in this area. In this article, we present a comprehensive survey on domain specification techniques for large language models, an emerging direction critical for large language model applications. First, we propose a systematic taxonomy that categorizes the LLM domain-specialization techniques based on the accessibility to LLMs and summarizes the framework for all the subcategories as well as their relations and differences to each other. Second, we present an extensive taxonomy of critical application domains that can benefit dramatically from specialized LLMs, discussing their practical significance and open challenges. Last, we offer our insights …"
Liang Zhao,Event Prediction in the Big Data Era: A Systematic Survey,2021,https://dl.acm.org/doi/abs/10.1145/3450287,"Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing …"
Liang Zhao,Deep Graph Representation Learning and Optimization for Influence Maximization,2023,https://proceedings.mlr.press/v202/ling23b.html,"Influence maximization (IM) is formulated as selecting a set of initial users from a social network to maximize the expected number of influenced users. Researchers have made great progresses to design various traditional methods, yet both theoretical design and performance gain are close to their limits. In the past few years, learning-based IM methods have emerged to achieve stronger generalization ability to unknown graphs than traditional ones. However, the development of learning-based IM methods is still limited by fundamental obstacles, including 1) the difficulty of effectively solving the objective function; 2) the difficulty of characterizing the diversified and underlying diffusion patterns; and 3) the difficulty of adapting the solution under various node-centrality-constrained IM variants. To cope with the above challenges, we design a novel framework DeepIM to generatively characterize the latent representation of seed sets, and we propose to learn the diversified information diffusion pattern in a data-driven and end-to-end manner. Finally, we design a novel objective function to infer optimal seed sets under flexible node-centrality-based budget constraints. Extensive analyses are conducted over both synthetic and real-world datasets to demonstrate the overall performance of DeepIM."
Liang Zhao,Taking the pulse of COVID-19: A spatiotemporal perspective,2020,https://www.tandfonline.com/doi/abs/10.1080/17538947.2020.1809723,"The sudden outbreak of the Coronavirus disease (COVID-19) swept across the world in early 2020, triggering the lockdowns of several billion people across many countries, including China, Spain, India, the U.K., Italy, France, Germany, Brazil, Russia, and the U.S. The transmission of the virus accelerated rapidly with the most confirmed cases in the U.S., India, Russia, and Brazil. In response to this national and global emergency, the NSF Spatiotemporal Innovation Center brought together a taskforce of international researchers and assembled implementation strategies to rapidly respond to this crisis, for supporting research, saving lives, and protecting the health of global citizens. This perspective paper presents our collective view on the global health emergency and our effort in collecting, analyzing, and sharing relevant data on global policy and government responses, human mobility, environmental impact …"
Liang Zhao,Machine Learning-Based Delay-Aware UAV Detection and Operation Mode Identification over Encrypted Wi-Fi Traffic,2020,https://ieeexplore.ieee.org/abstract/document/8933072/,"The consumer unmanned aerial vehicle (UAV) market has grown significantly over the past few years. Despite its huge potential in spurring economic growth by supporting various applications, the increase of consumer UAVs poses potential risks to public security and personal privacy. To minimize the risks, efficiently detecting and identifying invading UAVs is in urgent need for both invasion detection and forensics purposes. Aiming to complement the existing physical detection mechanisms, we propose a machine learning-based framework for fast UAV identification over encrypted Wi-Fi traffic. It is motivated by the observation that many consumer UAVs use Wi-Fi links for control and video streaming. The proposed framework extracts features derived only from packet size and inter-arrival time of encrypted Wi-Fi traffic, and can efficiently detect UAVs and identify their operation modes. In order to reduce the online …"
Liang Zhao,Bridging the gap between spatial and spectral domains: A unified framework for graph neural networks,2023,https://dl.acm.org/doi/abs/10.1145/3627816,"Deep learning’s performance has been extensively recognized recently. Graph neural networks (GNNs) are designed to deal with graph-structural data that classical deep learning does not easily manage. Since most GNNs were created using distinct theories, direct comparisons are impossible. Prior research has primarily concentrated on categorizing existing models, with little attention paid to their intrinsic connections. The purpose of this study is to establish a unified framework that integrates GNNs based on spectral graph and approximation theory. The framework incorporates a strong integration between spatial- and spectral-based GNNs while tightly associating approaches that exist within each respective domain."
Liang Zhao,Beyond efficiency: A systematic survey of resource-efficient large language models,2024,https://arxiv.org/abs/2401.00625,"The burgeoning field of Large Language Models (LLMs), exemplified by sophisticated models like OpenAI's ChatGPT, represents a significant advancement in artificial intelligence. These models, however, bring forth substantial challenges in the high consumption of computational, memory, energy, and financial resources, especially in environments with limited resource capabilities. This survey aims to systematically address these challenges by reviewing a broad spectrum of techniques designed to enhance the resource efficiency of LLMs. We categorize methods based on their optimization focus: computational, memory, energy, financial, and network resources and their applicability across various stages of an LLM's lifecycle, including architecture design, pretraining, finetuning, and system design. Additionally, the survey introduces a nuanced categorization of resource efficiency techniques by their specific resource types, which uncovers the intricate relationships and mappings between various resources and corresponding optimization techniques. A standardized set of evaluation metrics and datasets is also presented to facilitate consistent and fair comparisons across different models and techniques. By offering a comprehensive overview of the current sota and identifying open research avenues, this survey serves as a foundational reference for researchers and practitioners, aiding them in developing more sustainable and efficient LLMs in a rapidly evolving landscape."
Liang Zhao,Heterogeneous temporal graph neural network,2022,https://epubs.siam.org/doi/abs/10.1137/1.9781611977172.74,"Graph neural networks (GNNs) have been broadly studied on dynamic graphs for their representation learning, majority of which focus on graphs with homogeneous structures in the spatial domain. However, many real-world graphs - i.e., heterogeneous temporal graphs (HTGs) - evolve dynamically in the context of heterogeneous graph structures. The dynamics associated with heterogeneity have posed new challenges for HTG representation learning. To solve this problem, in this paper, we propose heterogeneous temporal graph neural network (HTGNN) to integrate both spatial and temporal dependencies while preserving the heterogeneity to learn node representations over HTGs. Specifically, in each layer of HTGNN, we propose a hierarchical aggregation mechanism, including intra-relation, inter-relation, and across-time aggregations, to jointly model heterogeneous spatial dependencies and temporal …"
Liang Zhao,Deep Graph Translation,2022,https://ieeexplore.ieee.org/abstract/document/9737289/,"Deep generative models for graphs have recently achieved great successes in modeling and generating graphs for studying networks in biology, engineering, and social sciences. However, they are typically unconditioned generative models that have no control over the target graphs given a source graph. In this article, we propose a novel graph-translation-generative-adversarial-nets (GT-GAN) model that transforms the source graphs into their target output graphs. GT-GAN consists of a graph translator equipped with innovative graph convolution and deconvolution layers to learn the translation mapping considering both global and local features. A new conditional graph discriminator is proposed to classify the target graphs by conditioning on source graphs while training. Extensive experiments on multiple synthetic and real-world datasets in the domain of cybernetworks, the Internet of Things, and neuroscience …"
Liang Zhao,GRAG: Graph Retrieval-Augmented Generation,2025,https://arxiv.org/abs/2405.16506,"Naive Retrieval-Augmented Generation (RAG) focuses on individual documents during retrieval and, as a result, falls short in handling networked documents which are very popular in many applications such as citation graphs, social media, and knowledge graphs. To overcome this limitation, we introduce Graph Retrieval-Augmented Generation (GRAG), which tackles the fundamental challenges in retrieving textual subgraphs and integrating the joint textual and topological information into Large Language Models (LLMs) to enhance its generation. To enable efficient textual subgraph retrieval, we propose a novel divide-and-conquer strategy that retrieves the optimal subgraph structure in linear time. To achieve graph context-aware generation, incorporate textual graphs into LLMs through two complementary views-the text view and the graph view-enabling LLMs to more effectively comprehend and utilize the graph context. Extensive experiments on graph reasoning benchmarks demonstrate that in scenarios requiring multi-hop reasoning on textual graphs, our GRAG approach significantly outperforms current state-of-the-art RAG methods."
Liang Zhao,Interpretable Deep Graph Generation with Node-Edge Co-Disentanglement,2020,https://dl.acm.org/doi/abs/10.1145/3394486.3403221,"Disentangled representation learning has recently attracted a significant amount of attention, particularly in the field of image representation learning. However, learning the disentangled representations behind a graph remains largely unexplored, especially for the attributed graph with both node and edge features. Disentanglement learning for graph generation has substantial new challenges including 1) the lack of graph deconvolution operations to jointly decode node and edge attributes; and 2) the difficulty in enforcing the disentanglement among latent factors that respectively influence: i) only nodes, ii) only edges, and iii) joint patterns between them. To address these challenges, we propose a new disentanglement enhancement framework for deep generative models for attributed graphs. In particular, a novel variational objective is proposed to disentangle the above three types of latent factors, with novel …"
Liang Zhao,GraphGT: Machine Learning Datasets for Deep Graph Generation and Transformation,2021,,
Liang Zhao,Temporal Domain Generalization with Drift-Aware Dynamic Neural Network,2023,https://arxiv.org/abs/2205.10664,"Temporal domain generalization is a promising yet extremely challenging area where the goal is to learn models under temporally changing data distributions and generalize to unseen data distributions following the trends of the change. The advancement of this area is challenged by: 1) characterizing data distribution drift and its impacts on models, 2) expressiveness in tracking the model dynamics, and 3) theoretical guarantee on the performance. To address them, we propose a Temporal Domain Generalization with Drift-Aware Dynamic Neural Network (DRAIN) framework. Specifically, we formulate the problem into a Bayesian framework that jointly models the relation between data and model dynamics. We then build a recurrent graph generation scenario to characterize the dynamic graph-structured neural networks learned across different time points. It captures the temporal drift of model parameters and data distributions and can predict models in the future without the presence of future data. In addition, we explore theoretical guarantees of the model performance under the challenging temporal DG setting and provide theoretical analysis, including uncertainty and generalization error. Finally, extensive experiments on several real-world benchmarks with temporal drift demonstrate the effectiveness and efficiency of the proposed method."
Liang Zhao,Generating Tertiary Protein Structures via Interpretable Graph Variational Autoencoders,2021,https://academic.oup.com/bioinformaticsadvances/article-abstract/1/1/vbab036/6446026,"Modeling the structural plasticity of protein molecules remains challenging. Most research has focused on obtaining one biologically active structure. This includes the recent AlphaFold2 that has been hailed as a breakthrough for protein modeling. Computing one structure does not suffice to understand how proteins modulate their interactions and even evade our immune system. Revealing the structure space available to a protein remains challenging. Data-driven approaches that learn to generate tertiary structures are increasingly garnering attention. These approaches exploit the ability to represent tertiary structures as contact or distance maps and make direct analogies with images to harness convolution-based generative adversarial frameworks from computer vision. Since such opportunistic analogies do not allow capturing highly structured data, current deep models struggle to …"
Liang Zhao,Source localization of graph diffusion via variational autoencoders for graph inverse problems,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539288,"Graph diffusion problems such as the propagation of rumors, computer viruses, or smart grid failures are ubiquitous and societal. Hence it is usually crucial to identify diffusion sources according to the current graph diffusion observations. Despite its tremendous necessity and significance in practice, source localization, as the inverse problem of graph diffusion, is extremely challenging as it is ill-posed: different sources may lead to the same graph diffusion patterns. Different from most traditional source localization methods, this paper focuses on a probabilistic manner to account for the uncertainty of different candidate sources. Such endeavors require to overcome significant challenges along the way including: 1) the uncertainty in graph diffusion source localization is hard to be quantified; 2) the complex patterns of the graph diffusion sources are difficult to be probabilistically characterized; 3) the generalization under …"
Liang Zhao,Going Beyond XAI: A Systematic Survey for Explanation-Guided Learning,2024,https://dl.acm.org/doi/abs/10.1145/3644073,"As the societal impact of Deep Neural Networks (DNNs) grows, the goals for advancing DNNs become more complex and diverse, ranging from improving a conventional model accuracy metric to infusing advanced human virtues such as fairness, accountability, transparency, and unbiasedness. Recently, techniques in Explainable Artificial Intelligence (XAI) have been attracting considerable attention and have tremendously helped Machine Learning (ML) engineers in understand AI models. However, at the same time, we started to witness the emerging need beyond XAI among AI communities; based on the insights learned from XAI, how can we better empower ML engineers in steering their DNNs so that the model’s reasonableness and performance can be improved as intended? This article provides a timely and extensive literature overview of the field Explanation-Guided Learning (EGL), a domain of …"
Liang Zhao,An invertible graph diffusion neural network for source localization,2022,https://dl.acm.org/doi/abs/10.1145/3485447.3512155," Localizing the source of graph diffusion phenomena, such as misinformation propagation, is an important yet extremely challenging task in the real world. Existing source localization models typically are heavily dependent on the hand-crafted rules and only tailored for certain domain-specific applications. Unfortunately, a large portion of the graph diffusion process for many applications is still unknown to human beings so it is important to have expressive models for learning such underlying rules automatically. Recently, there is a surge of research body on expressive models such as Graph Neural Networks (GNNs) for automatically learning the underlying graph diffusion. However, source localization is instead the inverse of graph diffusion, which is a typical inverse problem in graphs that is well-known to be ill-posed because there can be multiple solutions and hence different from the traditional (semi …"
Liang Zhao,GNES: Learning to Explain Graph Neural Networks,2021,https://ieeexplore.ieee.org/abstract/document/9679041/,"In recent years, graph neural networks (GNNs) and the research on their explainability are experiencing rapid developments and achieving significant progress. Many methods are proposed to explain the predictions of GNNs, focusing on “how to generate explanations” However, research questions like “whether the GNN explanations are inaccurate”, “what if the explanations are inaccurate”, and “how to adjust the model to generate more accurate explanations” have not been well explored. To address the above questions, this paper proposes a GNN Explanation Supervision (GNES) 1 framework to adaptively learn how to explain GNNs more correctly. Specifically, our framework jointly optimizes both model prediction and model explanation by enforcing both whole graph regularization and weak supervision on model explanations. For the graph regularization, we propose a unified explanation formulation for both …"
Liang Zhao,Mitigating Cache-Based Side-Channel Attacks through Randomization: A Comprehensive System and Architecture Level Analysis,2020,https://ieeexplore.ieee.org/abstract/document/9116340/,"Cache hierarchy was designed to allow CPU cores to process instructions faster by bridging the significant latency gap between the main memory and processor. In addition, various cache replacement algorithms are proposed to predict future data and instructions to boost the performance of the computer systems. However, recently proposed cache-based Side-Channel Attacks (SCAs) have shown to effectively exploiting such a hierarchical cache design. The cache-based SCAs are exploiting the hardware vulnerabilities to steal secret information from users by observing cache access patterns of cryptographic applications and thus are emerging as a serious threat to the security of the computer systems. Prior works on mitigating the cache-based SCAs have mainly focused on cache partitioning techniques and/or randomization of mapping between main memory. However, such solutions though effective, require …"
Liang Zhao,Deep Generative Model for Periodic Graphs,2022,https://proceedings.neurips.cc/paper_files/paper/2022/hash/e89e8f84626197942b36a82e524c2529-Abstract-Conference.html,"Periodic graphs are graphs consisting of repetitive local structures, such as crystal nets and polygon mesh. Their generative modeling has great potential in real-world applications such as material design and graphics synthesis. Classical models either rely on domain-specific predefined generation principles (eg, in crystal net design), or follow geometry-based prescribed rules. Recently, deep generative models have shown great promise in automatically generating general graphs. However, their advancement into periodic graphs has not been well explored due to several key challenges in 1) maintaining graph periodicity; 2) disentangling local and global patterns; and 3) efficiency in learning repetitive patterns. To address them, this paper proposes Periodical-Graph Disentangled Variational Auto-encoder (PGD-VAE), a new deep generative model for periodic graphs that can automatically learn, disentangle, and generate local and global graph patterns. Specifically, we develop a new periodic graph encoder consisting of global-pattern encoder and local-pattern encoder that ensures to disentangle the representation into global and local semantics. We then propose a new periodic graph decoder consisting of local structure decoder, neighborhood decoder, and global structure decoder, as well as the assembler of their outputs that guarantees periodicity. Moreover, we design a new model learning objective that helps ensure the invariance of local-semantic representations for the graphs with the same local structure. Comprehensive experimental evaluations have been conducted to demonstrate the effectiveness of the proposed method."
Liang Zhao,Disentangled Dynamic Graph Deep Generation,2021,https://epubs.siam.org/doi/abs/10.1137/1.9781611976700.83,"Deep generative models for graphs have exhibited promising performance in ever-increasing domains such as design of molecules (i.e, graph of atoms) and structure prediction of proteins (i.e., graph of amino acids). Existing work typically focuses on static rather than dynamic graphs, which are actually very important in the applications such as protein folding, molecule reactions, and human mobility. Extending existing deep generative models from static to dynamic graphs is a challenging task, which requires to handle the factorization of static and dynamic characteristics as well as mutual interactions among node and edge patterns. Here, this paper proposes a novel framework of factorized deep generative models to achieve interpretable dynamic graph generation. Various generative models are proposed to characterize conditional independence among node, edge, static, and dynamic factors. Then …"
Liang Zhao,Controllable Data Generation by Deep Learning: A Review,2024,https://dl.acm.org/doi/abs/10.1145/3648609,"Designing and generating new data under targeted properties has been attracting various critical applications such as molecule design, image editing and speech synthesis. Traditional hand-crafted approaches heavily rely on expertise experience and intensive human efforts, yet still suffer from the insufficiency of scientific knowledge and low throughput to support effective and efficient data generation. Recently, the advancement of deep learning has created the opportunity for expressive methods to learn the underlying representation and properties of data. Such capability provides new ways of determining the mutual relationship between the structural patterns and functional properties of the data and leveraging such relationships to generate structural data, given the desired properties. This article is a systematic review that explains this promising research area, commonly known as controllable deep data …"
Liang Zhao,Aligning Eyes between Humans and Deep Neural Network through Interactive Attention Alignment,2022,https://dl.acm.org/doi/abs/10.1145/3555590,"While Deep Neural Networks (DNNs) are deriving the major innovations through their powerful automation, we are also witnessing the peril behind automation as a form of bias, such as automated racism, gender bias, and adversarial bias. As the societal impact of DNNs grows, finding an effective way to steer DNNs to align their behavior with the human mental model has become indispensable in realizing fair and accountable models. While establishing the way to adjust DNNs to ""think like humans'' is in pressing need, there have been few approaches aiming to capture how ""humans would think'' when DNNs introduce biased reasoning in seeing a new instance. We propose Interactive Attention Alignment (IAA), a framework that uses the methods for visualizing model attention, such as saliency maps, as an interactive medium that humans can leverage to unveil the cases of DNN's biased reasoning and directly …"
Liang Zhao,Generative Deep Learning for Macromolecular Structure and Dynamics,2021,https://www.sciencedirect.com/science/article/pii/S0959440X20302086,"Much scientific enquiry across disciplines is founded upon a mechanistic treatment of dynamic systems that ties form to function. A highly visible instance of this is in molecular biology, where characterizing macromolecular structure and dynamics is central to a detailed, molecular-level understanding of biological processes in the living cell. The current computational paradigm utilizes optimization as the generative process for modeling both structure and structural dynamics. Computational biology researchers are now attempting to wield generative models employing deep neural networks as an alternative computational paradigm. In this review, we summarize such efforts. We highlight progress and shortcomings. More importantly, we expose challenges that macromolecular structure poses to deep generative models and take this opportunity to introduce the structural biology community to several recent …"
Liang Zhao,Res: A robust framework for guiding visual explanation,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539419,"Despite the fast progress of explanation techniques in modern Deep Neural Networks (DNNs) where the main focus is handling ""how to generate the explanations"", advanced research questions that examine the quality of the explanation itself (e.g., ""whether the explanations are accurate"") and improve the explanation quality (e.g., ""how to adjust the model to generate more accurate explanations when explanations are inaccurate"") are still relatively under-explored. To guide the model toward better explanations, techniques in explanation supervision - which add supervision signals on the model explanation - have started to show promising effects on improving both the generalizability as and intrinsic interpretability of Deep Neural Networks. However, the research on supervising explanations, especially in vision-based applications represented through saliency maps, is in its early stage due to several inherent …"
Liang Zhao,Cognitive and scalable technique for securing IoT networks against malware epidemics,2020,https://ieeexplore.ieee.org/abstract/document/9149589/,"The sheer volume of IoT networks being deployed today presents a major “attack surface” and poses significant security risks at a scale never encountered before. In other words, a single IoT device/node that gets infected with malware has the potential to spread the malicious activities across the network, eventually ceasing the network functionality or compromising the network. Simply detecting and quarantining the malware in IoT networks does not guarantee preventing malware propagation. On the other hand, use of traditional control theory for malware confinement is not effective, as most of the existing works do not consider real-time malware control strategies that can be implemented using uncertain infection information from the nodes in the network or have the containment problem decoupled from network performance. In response, in this work, we propose a two-pronged approach with malware detection …"
Liang Zhao,Property Controllable Variational Autoencoder via Invertible Mutual Dependence,2021,https://openreview.net/forum?id=tYxG_OMs9WE,"Deep generative models have made important progress towards modeling complex, high dimensional data via learning latent representations. Their usefulness is nevertheless often limited by a lack of control over the generative process or a poor understanding of the latent representation. To overcome these issues, attention is now focused on discovering latent variables correlated to the data properties and ways to manipulate these properties. This paper presents the new Property controllable VAE (PCVAE), where a new Bayesian model is proposed to inductively bias the latent representation using explicit data properties via novel group-wise and property-wise disentanglement. Each data property corresponds seamlessly to a latent variable, by innovatively enforcing invertible mutual dependence between them. This allows us to move along the learned latent dimensions to control specific properties of the generated data with great precision. Quantitative and qualitative evaluations confirm that the PCVAE outperforms the existing models by up to 28% in capturing and 65% in manipulating the desired properties."
Liang Zhao,Balancing specialized and general skills in llms: The impact of modern tuning and data strategy,2023,https://arxiv.org/abs/2310.04945,"This paper introduces a multifaceted methodology for fine-tuning and evaluating large language models (LLMs) for specialized monetization tasks. The goal is to balance general language proficiency with domain-specific skills. The methodology has three main components: 1) Carefully blending in-domain and general-purpose data during fine-tuning to achieve an optimal balance between general and specialized capabilities; 2) Designing a comprehensive evaluation framework with 45 questions tailored to assess performance on functionally relevant dimensions like reliability, consistency, and business impact; 3) Analyzing how model size and continual training influence metrics to guide efficient resource allocation during fine-tuning. The paper details the design, data collection, analytical techniques, and results validating the proposed frameworks. It aims to provide businesses and researchers with actionable insights on effectively adapting LLMs for specialized contexts. We also intend to make public the comprehensive evaluation framework, which includes the 45 tailored questions and their respective scoring guidelines, to foster transparency and collaboration in adapting LLMs for specialized tasks."
Liang Zhao,Adaptive Kernel Graph Neural Network,2022,https://ojs.aaai.org/index.php/AAAI/article/view/20664,"Graph neural networks (GNNs) have demonstrated great success in representation learning for graph-structured data. The layer-wise graph convolution in GNNs is shown to be powerful at capturing graph topology. During this process, GNNs are usually guided by pre-defined kernels such as Laplacian matrix, adjacency matrix, or their variants. However, the adoptions of pre-defined kernels may restrain the generalities to different graphs: mismatch between graph and kernel would entail sub-optimal performance. For example, GNNs that focus on low-frequency information may not achieve satisfactory performance when high-frequency information is significant for the graphs, and vice versa. To solve this problem, in this paper, we propose a novel framework-ie, namely Adaptive Kernel Graph Neural Network (AKGNN)-which learns to adapt to the optimal graph kernel in a unified manner at the first attempt. In the proposed AKGNN, we first design a data-driven graph kernel learning mechanism, which adaptively modulates the balance between all-pass and low-pass filters by modifying the maximal eigenvalue of the graph Laplacian. Through this process, AKGNN learns the optimal threshold between high and low frequency signals to relieve the generality problem. Later, we further reduce the number of parameters by a parameterization trick and enhance the expressive power by a global readout function. Extensive experiments are conducted on acknowledged benchmark datasets and promising results demonstrate the outstanding performance of our proposed AKGNN by comparison with state-of-the-art GNNs. The source code is publicly …"
Liang Zhao,Generative Adversarial Learning of Protein Tertiary Structures,2021,https://www.mdpi.com/1420-3049/26/5/1209,"Protein molecules are inherently dynamic and modulate their interactions with different molecular partners by accessing different tertiary structures under physiological conditions. Elucidating such structures remains challenging. Current momentum in deep learning and the powerful performance of generative adversarial networks (GANs) in complex domains, such as computer vision, inspires us to investigate GANs on their ability to generate physically-realistic protein tertiary structures. The analysis presented here shows that several GAN models fail to capture complex, distal structural patterns present in protein tertiary structures. The study additionally reveals that mechanisms touted as effective in stabilizing the training of a GAN model are not all effective, and that performance based on loss alone may be orthogonal to performance based on the quality of generated datasets. A novel contribution in this study is the demonstration that Wasserstein GAN strikes a good balance and manages to capture both local and distal patterns, thus presenting a first step towards more powerful deep generative models for exploring a possibly very diverse set of structures supporting diverse activities of a protein molecule in the cell."
Liang Zhao,Unsupervised Deep Subgraph Anomaly Detection,2022,https://ieeexplore.ieee.org/abstract/document/10027633/,"Effectively mining anomalous subgraphs in networks is crucial for many application scenarios, such as disease outbreak detection, financial fraud detection, and activity monitoring in social networks. Identifying anomalous subgraphs is extremely challenging due to their complex topological structures and high-dimensional attributes, various notions of anomalies, and the exponentially large subgraph space in a given graph. Existing classical shallow models typically rely on handcrafted anomaly measure functions, which cannot handle common situations when such prior knowledge is unavailable. Recently, deep learning-based methods provide an end-to-end way that learns the anomaly measure functions. However, although they have achieved great success in detecting node-level, edge-level, and graph-level anomalies, detecting anomalous at the subgraph level has been largely under-explored due to …"
Liang Zhao,Disentangled Spatiotemporal Graph Generative Model,2022,https://ojs.aaai.org/index.php/AAAI/article/view/20607,"Spatiotemporal graph represents a crucial data structure where the nodes and edges are embedded in a geometric space and their attribute values can evolve dynamically over time. Nowadays, spatiotemporal graph data is becoming increasingly popular and important, ranging from microscale (eg protein folding), to middle-scale (eg dynamic functional connectivity), to macro-scale (eg human mobility network). Although disentangling and understanding the correlations among spatial, temporal, and graph aspects have been a long-standing key topic in network science, they typically rely on network processes hypothesized by human knowledge. They usually fit well towards the properties that the predefined principles are tailored for, but usually cannot do well for the others, especially for many key domains where the human has yet very limited knowledge such as protein folding and biological neuronal networks. In this paper, we aim at pushing forward the modeling and understanding of spatiotemporal graphs via new disentangled deep generative models. Specifically, a new Bayesian model is proposed that factorizes spatiotemporal graphs into spatial, temporal, and graph factors as well as the factors that explain the interplay among them. A variational objective function and new mutual information thresholding algorithms driven by information bottleneck theory have been proposed to maximize the disentanglement among the factors with theoretical guarantees. Qualitative and quantitative experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed model over the state-of-the-arts by up to 69.2% for …"
Liang Zhao,Deep Generative Model for Spatial Networks,2021,https://dl.acm.org/doi/abs/10.1145/3447548.3467394,"Spatial networks represent crucial data structures where the nodes and edges are embedded in a geometric space. Nowadays, spatial network data is becoming increasingly popular and important, ranging from microscale (e.g., protein structures), to middle-scale (e.g., biological neural networks), to macro-scale (e.g., mobility networks). Although, modeling and understanding the generative process of spatial networks are very important, they remain largely under-explored due to the significant challenges in automatically modeling and distinguishing the independency and correlation among various spatial and network factors. To address these challenges, we first propose a novel objective for joint spatial-network disentanglement from the perspective of information bottleneck as well as a novel optimization algorithm to optimize the intractable objective. Based on this, a spatial-network variational autoencoder …"
Liang Zhao,Interpretable Molecular Graph Generation via Monotonic Constraints,2022,https://epubs.siam.org/doi/abs/10.1137/1.9781611977172.9,"Designing molecules with specific properties is a long-lasting research problem and is central to advancing crucial domains such as drug discovery and material science. Recent advances in deep graph generative models treat molecule design as graph generation problems which provide new opportunities toward the breakthrough of this long-lasting problem. Existing models, however, have many shortcomings, including poor interpretability and controllability toward desired molecular properties. This paper focuses on new methodologies for molecule generation with interpretable and controllable deep generative models, by proposing new monotonically-regularized graph variational autoencoders. The proposed models learn to represent the molecules with latent variables and then learn the correspondence between them and molecule properties parameterized by polynomial functions. To further improve the …"
Liang Zhao,Beyond Text: A Deep Dive into Large Language Models' Ability on Understanding Graph Data,2023,https://arxiv.org/abs/2310.04944,"Large language models (LLMs) have achieved impressive performance on many natural language processing tasks. However, their capabilities on graph-structured data remain relatively unexplored. In this paper, we conduct a series of experiments benchmarking leading LLMs on diverse graph prediction tasks spanning node, edge, and graph levels. We aim to assess whether LLMs can effectively process graph data and leverage topological structures to enhance performance, compared to specialized graph neural networks. Through varied prompt formatting and task/dataset selection, we analyze how well LLMs can interpret and utilize graph structures. By comparing LLMs' performance with specialized graph models, we offer insights into the strengths and limitations of employing LLMs for graph analytics. Our findings provide insights into LLMs' capabilities and suggest avenues for further exploration in applying them to graph analytics."
Liang Zhao,Metagraph aggregated heterogeneous graph neural network for illicit traded product identification in underground market,2020,https://ieeexplore.ieee.org/abstract/document/9338341/,"The emerging underground markets (e.g., Hack Forums) have been widely used by cybercriminals to trade in illicit products or services, which have played a vital role in the cybercriminal ecosystem. In order to combat the evolving cybercrimes, in this paper, we propose and develop an intelligent framework (named PIdentifier) to automate the analysis of Hack Forums for the identification of illicit traded products in private contracts at the first attempt (i.e., to evade the law enforcement, a private contract is a contract between a vendor and a buyer where the traded product and its detail are invisible). In PIdentifier, based on the large-scale extracted user profiles, user posts (i.e., threads and comments) and different types of relations within the complex ecosystem in Hack Forums, we first introduce an attributed heterogeneous information network (AHIN) to model the rich semantics and complex relations among multi-type …"
Liang Zhao,Toward Model Parallelism for Deep Neural Network based on Gradient-free ADMM Framework,2020,https://ieeexplore.ieee.org/abstract/document/9338293/,"Alternating Direction Method of Multipliers (ADMM) has recently been proposed as a potential alternative optimizer to the Stochastic Gradient Descent(SGD) for deep learning problems. This is because ADMM can solve gradient vanishing and poor conditioning problems. Moreover, it has shown good scalability in many large-scale deep learning applications. However, there still lacks a parallel ADMM computational framework for deep neural networks because of layer dependency among variables. In this paper, we propose a novel parallel deep learning ADMM framework (pdADMM) to achieve layer parallelism: parameters in each layer of neural networks can be updated independently in parallel. The convergence of the proposed pdADMM to a critical point is theoretically proven under mild conditions. The convergence rate of the pdADMM is proven to be o(1/k) where k is the number of iterations. Extensive …"
Liang Zhao,Cyber-guided deep neural network for malicious repository detection in github,2020,https://ieeexplore.ieee.org/abstract/document/9194501/,"As the largest source code repository, GitHub has played a vital role in modern social coding ecosystem to generate production software. Despite the apparent benefits of such social coding paradigm, its potential security risks have been largely overlooked (e.g., malicious codes or repositories could be easily embedded and distributed). To address this imminent issue, in this paper, we propose a novel framework (named GitCyber) to automate malicious repository detection in GitHub at the first attempt. In GitCyber, we first extract code contents from the repositories hosted in GitHub as the inputs for deep neural network (DNN), and then we incorporate cybersecurity domain knowledge modeled by heterogeneous information network (HIN) to design cyber-guided loss function in the learning objective of the DNN to assure the classification performance while preserving consistency with the observational domain …"
Liang Zhao,Estimating the circuit de-obfuscation runtime based on graph deep learning,2020,https://ieeexplore.ieee.org/abstract/document/9116544/,"Circuit obfuscation has been proposed to protect digital integrated circuits (ICs) from different security threats such as reverse engineering by introducing ambiguity in the circuit, i.e., the addition of the logic gates whose functionality cannot be determined easily by the attacker. In order to conquer such defenses, techniques such as Boolean satisfiability-checking (SAT)-based attacks were introduced. SAT-attack can potentially decrypt the obfuscated circuits. However, the deobfuscation runtime could have a large span ranging from few milliseconds to a few years or more, depending on the number and location of obfuscated gates, the topology of the obfuscated circuit and obfuscation technique used. To ensure the security of the deployed obfuscation mechanism, it is essential to accurately pre-estimate the deobfuscation time. Thereby one can optimize the deployed defense in order to maximize the deobfuscation …"
Liang Zhao,TG-GAN: Continuous-time temporal graph deep generative models with time-validity constraints,2021,https://dl.acm.org/doi/abs/10.1145/3442381.3449818," Deep generative models of graph-structured data have become popular in very recent years. Although initial research has focused on static graphs in applications such as molecular design and social networks, many challenges involve temporal graphs whose topology and attribute values evolve dynamically over time. Sophisticated and unknown network processes that affect temporal graphs cannot be captured adequately by prescribed models. Application areas include social mobility networks and catastrophic cybersecurity failures. These web-scale applications challenge current deep graph generative models with the need to capture 1) time-validity constraints, 2) time and topological distributions, and 3) joint time and graph encoding and decoding. Here, we propose the “Temporal Graph Generative Adversarial Network” (TG-GAN) for continuous-time graph generation with time-validity constraints 1. TG-GAN …"
Liang Zhao,Contrast Pattern Mining in Paired Multivariate Time Series of Controlled Driving Behavior Experiment,2020,https://dl.acm.org/doi/abs/10.1145/3397272,"The controlled experiment is an important scientific method for researchers seeking to determine the influence of the intervention, by interpreting the contrast patterns between the temporal observations from control and experimental groups (i.e., paired multivariate time series (PMTS)). Due to recent technological advances and the growing popularity of sensing technology such as in-vehicle sensors and activity trackers, time series data is experiencing explosive growth in both size and complexity. This is threatening to overwhelm the interpretation of control experiments, which conventionally rely on human analysts. Thus, it is imperative to develop automated methods that are expected to simultaneously characterize and detect the interpretable contrast patterns in PMTS generated by controlled experiments. However, a few challenges prohibit existing methods from directly addressing this problem: (1) handling the …"
Liang Zhao,Representation Learning on Spatial Networks,2021,https://proceedings.neurips.cc/paper/2021/hash/12e35d9186dd72fe62fd039385890b9c-Abstract.html,"Spatial networks are networks for which the nodes and edges are constrained by geometry and embedded in real space, which has crucial effects on their topological properties. Although tremendous success has been achieved in spatial and network representation separately in recent years, there exist very little works on the representation of spatial networks. Extracting powerful representations from spatial networks requires the development of appropriate tools to uncover the pairing of both spatial and network information in the appearance of node permutation invariant, and rotation and translation invariant. Hence it can not be modeled merely with either spatial or network models individually. To address these challenges, this paper proposes a generic framework for spatial network representation learning. Specifically, a provably information-lossless and roto-translation invariant representation of spatial information on networks is presented. Then a higher-order spatial network convolution operation that adapts to our proposed representation is introduced. To ensure efficiency, we also propose a new approach that relied on sampling random spanning trees to reduce the time and memory complexity from  to . We demonstrate the strength of our proposed framework through extensive experiments on both synthetic and real-world datasets. The code for the proposed model is available at\url {https://github. com/rollingstonezz/SGMP_code}."
Liang Zhao,Nonconvex Generalization of Alternating Direction Method of Multipliers for Nonlinear Equality Constrained Problems,2021,https://www.sciencedirect.com/science/article/pii/S2666720721000035,"The classic Alternating Direction Method of Multipliers (ADMM) is a popular framework to solve linear-equality constrained problems. In this paper, we extend the ADMM naturally to nonlinear equality-constrained problems, called neADMM. The difficulty of neADMM is to solve nonconvex subproblems. We provide globally optimal solutions to them in two important applications. Experiments on synthetic and real-world datasets demonstrate excellent performance and scalability of our proposed neADMM over existing state-of-the-start methods."
Liang Zhao,Self-Paced Robust Learning for Leveraging Clean Labels in Noisy Data,2020,https://ojs.aaai.org/index.php/AAAI/article/view/6166,"The success of training accurate models strongly depends on the availability of a sufficient collection of precisely labeled data. However, real-world datasets contain erroneously labeled data samples that substantially hinder the performance of machine learning models. Meanwhile, well-labeled data is usually expensive to obtain and only a limited amount is available for training. In this paper, we consider the problem of training a robust model by using large-scale noisy data in conjunction with a small set of clean data. To leverage the information contained via the clean labels, we propose a novel self-paced robust learning algorithm (SPRL) that trains the model in a process from more reliable (clean) data instances to less reliable (noisy) ones under the supervision of well-labeled data. The self-paced learning process hedges the risk of selecting corrupted data into the training set. Moreover, theoretical analyses on the convergence of the proposed algorithm are provided under mild assumptions. Extensive experiments on synthetic and real-world datasets demonstrate that our proposed approach can achieve a considerable improvement in effectiveness and robustness to existing methods."
Liang Zhao,Uncertainty Quantification for In-Context Learning of Large Language Models,2024,https://arxiv.org/abs/2402.10189,"In-context learning has emerged as a groundbreaking ability of Large Language Models (LLMs) and revolutionized various fields by providing a few task-relevant demonstrations in the prompt. However, trustworthy issues with LLM's response, such as hallucination, have also been actively discussed. Existing works have been devoted to quantifying the uncertainty in LLM's response, but they often overlook the complex nature of LLMs and the uniqueness of in-context learning. In this work, we delve into the predictive uncertainty of LLMs associated with in-context learning, highlighting that such uncertainties may stem from both the provided demonstrations (aleatoric uncertainty) and ambiguities tied to the model's configurations (epistemic uncertainty). We propose a novel formulation and corresponding estimation method to quantify both types of uncertainties. The proposed method offers an unsupervised way to understand the prediction of in-context learning in a plug-and-play fashion. Extensive experiments are conducted to demonstrate the effectiveness of the decomposition. The code and data are available at: https://github.com/lingchen0331/UQ_ICL."
Liang Zhao,Deep Generation of Heterogeneous Networks,2021,https://ieeexplore.ieee.org/abstract/document/9679028/,"Heterogeneous graphs are ubiquitous data structures that can inherently capture multi-type and multi-modal interactions between objects. In recent years, research on encoding heterogeneous graph into latent representations have enjoyed a rapid increase. However, its reverse process, namely how to construct heterogeneous graphs from underlying representations and distributions have not been well explored due to several challenges in 1) modeling the local heterogeneous semantic distribution; 2) preserving the graph-structured distributions over the local semantics; and 3) characterizing the global heterogeneous graph distributions. To address these challenges, we propose a novel framework for heterogeneous graph generation (HGEN) that jointly captures the semantic, structural, and global distributions of heterogeneous graphs. Specifically, we propose a heterogeneous walk generator that hierarchically …"
Liang Zhao,BEAN: Interpretable and Efficient Learning with Biologically-Enhanced Artificial Neuronal Assembly,2021,https://www.frontiersin.org/articles/10.3389/fnbot.2021.567482/full,"Deep neural networks (DNNs) are known for extracting useful information from large amounts of data. However, the representations learned in DNNs are typically hard to interpret, especially in dense layers. One crucial issue of the classical DNN model such as multilayer perceptron (MLP) is that neurons in the same layer of DNNs are conditionally independent of each other, which makes co-training and emergence of higher modularity difficult. In contrast to DNNs, biological neurons in mammalian brains display substantial dependency patterns. Specifically, biological neural networks encode representations by so-called neuronal assemblies: groups of neurons interconnected by strong synaptic interactions and sharing joint semantic content. The resulting population coding is essential for human cognitive and mnemonic processes. Here, we propose a novel Biologically Enhanced Artificial Neuronal assembly (BEAN) regularization to model neuronal correlations and dependencies, inspired by cell assembly theory from neuroscience. Experimental results show that BEAN enables the formation of interpretable neuronal functional clusters and consequently promotes a sparse, memory/computation-efficient network without loss of model performance. Moreover, our few-shot learning experiments demonstrate that BEAN could also enhance the generalizability of the model when training samples are extremely limited."
Liang Zhao,Interpretable molecule generation via disentanglement learning,2020,https://dl.acm.org/doi/abs/10.1145/3388440.3414709,"Designing molecules with specific structural and functional properties (e.g., drug-likeness and water solubility) is central to advancing drug discovery and material science, but it poses outstanding challenges both in wet and dry laboratories. The search space is vast and rugged. Recent advances in deep generative models are motivating new computational approaches building over deep learning to tackle the molecular space. Despite rapid advancements, state-of-the-art deep generative models for molecule generation have many limitations, including lack of interpretability. In this paper we address this limitation by proposing a generic framework for interpretable molecule generation based on novel disentangled deep graph generative models with property control. Specifically, we propose a disentanglement enhancement strategy for graphs. We also propose new deep neural architecture to achieve the above …"
Liang Zhao,Time Series Clustering in Linear Time Complexity,2021,https://link.springer.com/article/10.1007/s10618-021-00798-w,"With the increasing power of data storage and advances in data generation and collection technologies, large volumes of time series data become available and the content is changing rapidly. This requires data mining methods to have low time complexity to handle the huge and fast-changing data. This article presents a novel time series clustering algorithm that has linear time complexity. The proposed algorithm partitions the data by checking some randomly selected symbolic patterns in the time series. We provide theoretical analysis to show that group structures in the data can be revealed from this process. We evaluate the proposed algorithm extensively on all 128 datasets from the well-known UCR time series archive, and compare with the state-of-the-art approaches with statistical analysis. The results show that the proposed method achieves better accuracy compared with other rival methods. We …"
Liang Zhao,Large Language Models for Spatial Trajectory Patterns Mining,2024,https://dl.acm.org/doi/abs/10.1145/3681765.3698467,"Identifying anomalous human spatial trajectory patterns can indicate dynamic changes in mobility behavior with applications in domains like infectious disease monitoring and elderly care. Recent advancements in large language models (LLMs) have demonstrated their ability to reason in a manner akin to humans. This presents significant potential for analyzing temporal patterns in human mobility. In this paper, we conduct empirical studies to assess the capabilities of leading LLMs like GPT-4 and Claude-2 in detecting anomalous behaviors from mobility data, by comparing to specialized methods. Our key findings demonstrate that LLMs can attain reasonable anomaly detection performance even without any specific cues. In addition, providing contextual clues about potential irregularities could further enhances their prediction efficacy. Moreover, LLMs can provide reasonable explanations for their judgments …"
Liang Zhao,Saliency-regularized Deep Multi-task Learning,2022,https://dl.acm.org/doi/abs/10.1145/3534678.3539442,"Multi-task learning (MTL) is a framework that enforces multiple learning tasks to share their knowledge to improve their generalization abilities. While shallow multi-task learning can learn task relations, it can only handle pre-defined features. Modern deep multi-task learning can jointly learn latent features and task sharing, but they are obscure in task relation. Also, they pre-define which layers and neurons should share across tasks and cannot learn adaptively. To address these challenges, this paper proposes a new multi-task learning framework that jointly learns latent features and explicit task relations by complementing the strength of existing shallow and deep multitask learning scenarios. Specifically, we propose to model the task relation as the similarity between tasks' input gradients, with a theoretical analysis of their equivalency. In addition, we innovatively propose a multi-task learning objective that …"
Liang Zhao,Spatio-temporal Event Forecasting Using Incremental Multi-source Feature Learning,2021,https://dl.acm.org/doi/abs/10.1145/3464976,"The forecasting of significant societal events such as civil unrest and economic crisis is an interesting and challenging problem which requires both timeliness, precision, and comprehensiveness. Significant societal events are influenced and indicated jointly by multiple aspects of a society, including its economics, politics, and culture. Traditional forecasting methods based on a single data source find it hard to cover all these aspects comprehensively, thus limiting model performance. Multi-source event forecasting has proven promising but still suffers from several challenges, including (1) geographical hierarchies in multi-source data features, (2) hierarchical missing values, (3) characterization of structured feature sparsity, and (4) difficulty in model’s online update with incomplete multiple sources. This article proposes a novel feature learning model that concurrently addresses all the above challenges. Specifically …"
Liang Zhao,Online decision trees with fairness,2020,https://arxiv.org/abs/2010.08146,"While artificial intelligence (AI)-based decision-making systems are increasingly popular, significant concerns on the potential discrimination during the AI decision-making process have been observed. For example, the distribution of predictions is usually biased and dependents on the sensitive attributes (e.g., gender and ethnicity). Numerous approaches have therefore been proposed to develop decision-making systems that are discrimination-conscious by-design, which are typically batch-based and require the simultaneous availability of all the training data for model learning. However, in the real-world, the data streams usually come on the fly which requires the model to process each input data once ""on arrival"" and without the need for storage and reprocessing. In addition, the data streams might also evolve over time, which further requires the model to be able to simultaneously adapt to non-stationary data distributions and time-evolving bias patterns, with an effective and robust trade-off between accuracy and fairness. In this paper, we propose a novel framework of online decision tree with fairness in the data stream with possible distribution drifting. Specifically, first, we propose two novel fairness splitting criteria that encode the data as well as possible, while simultaneously removing dependence on the sensitive attributes, and further adapts to non-stationary distribution with fine-grained control when needed. Second, we propose two fairness decision tree online growth algorithms that fulfills different online fair decision-making requirements. Our experiments show that our algorithms are able to deal with discrimination in massive and …"
Liang Zhao,Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First?,2023,https://proceedings.neurips.cc/paper_files/paper/2023/hash/a07e5160196058120105ad7cb3505d3c-Abstract-Conference.html,"Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github. com/rollingstonezz/Curriculumlearningfor_GNNs"
Liang Zhao,Small Molecule Generation via Disentangled Representation Learning,2022,https://academic.oup.com/bioinformatics/article-abstract/38/12/3200/6576627,"Expanding our knowledge of small molecules beyond what is known in nature or designed in wet laboratories promises to significantly advance cheminformatics, drug discovery, biotechnology and material science. In silico molecular design remains challenging, primarily due to the complexity of the chemical space and the non-trivial relationship between chemical structures and biological properties. Deep generative models that learn directly from data are intriguing, but they have yet to demonstrate interpretability in the learned representation, so we can learn more about the relationship between the chemical and biological space. In this article, we advance research on disentangled representation learning for small molecule generation. We build on recent work by us and others on deep graph generative frameworks, which capture atomic interactions via a graph-based representation …"
Liang Zhao,Towards Expressive Spectral-Temporal Graph Neural Networks for Time Series Forecasting,2025,https://ieeexplore.ieee.org/abstract/document/10902626/,"Time series forecasting has remained a focal point due to its vital applications in sectors such as energy management and transportation planning. Spectral-temporal graph neural network is a promising abstraction underlying most time series forecasting models that are based on graph neural networks (GNNs). However, more is needed to know about the underpinnings of this branch of methods. In this paper, we establish a theoretical framework that unravels the expressive power of spectral-temporal GNNs. Our results show that linear spectral-temporal GNNs are universal under mild assumptions, and their expressive power is bounded by our extended first-order Weisfeiler-Leman algorithm on discrete-time dynamic graphs. To make our findings useful in practice on valid instantiations, we discuss related constraints in detail and outline a theoretical blueprint for designing spatial and temporal modules in spectral …"
Liang Zhao,"A survey on knowledge graphs for healthcare: Resources, applications, and promises",2023,https://scholar.google.com/scholar?cluster=10795607586935336120&hl=en&oi=scholarr,
Liang Zhao,Factorized deep generative models for end-to-end trajectory generation with spatiotemporal validity constraints,2022,https://dl.acm.org/doi/abs/10.1145/3557915.3560994,"A growing number of research areas such as location-based social networks, intelligent transportation systems, and urban computing utilize large amounts of trajectory data for benchmarking data management approaches and analysis methods. Given the general lackness of available large datasets, realistic synthetic trajectory datasets become important. This work proposes deep generative models for trajectory data that can learn disentangled models for sophisticated latent patterns. Existing methods rely on predefined heuristics and cannot learn the unknown underlying generative mechanisms. The proposed novel deep generative VAE-like models factorize global and local semantics (habits vs. random routing change). We further develop new inference strategies based on variational inference and constrained optimization to encapsulate spatiotemporal validity. New deep neural network architectures are …"
Liang Zhao,Deep Geometric Neural Network for Spatial Interpolation,2022,https://dl.acm.org/doi/abs/10.1145/3557915.3561008,"Spatial interpolation is the task to interpolate the targeted index, such as PM2.5 values and temperature, at arbitrary locations based on the collected geospatial data. It greatly affects the key research topics in geoscience in terms of obtaining heterogeneous spatial information (e.g., soil conditions, precipitation rates, wheat yields) for geographic modeling and decision-making at local, regional, and global scales. Point-based data, collected by ground-level in-situ sensors, serve as an important data source for this task. However, several major challenges still exist: point-based data are sparse and unevenly distributed. More importantly, it is difficult to model the unknown spatial predictive mapping while handling the trade-off between spatial autocorrelation and heterogeneity. Third, representing spatial relations without substantial information loss is also a critical issue. To address these challenges, we propose a …"
Liang Zhao,Hybrid quantum variational autoencoders for representation learning,2021,https://ieeexplore.ieee.org/abstract/document/9799154/,Representation learning is a standard area that has seen many improvements based on machine learning advances. Quantum machine learning advances are now spreading across different application areas such as representation learning. This paper introduces a novel hybrid quantum machine learning approach to representation learning by using a quantum variational circuit that is trainable with traditional gradient descent techniques. We use marketing data to showcase the learning potential of our model.
Liang Zhao,Accelerated Gradient-free Neural Network Training by Multi-convex Alternating Optimization,2021,https://www.sciencedirect.com/science/article/pii/S0925231222001953,"In recent years, even though Stochastic Gradient Descent (SGD) and its variants are well-known for training neural networks, it suffers from limitations such as the lack of theoretical guarantees, vanishing gradients, and excessive sensitivity to input. To overcome these drawbacks, alternating minimization methods have attracted fast-increasing attention recently. As an emerging and open domain, however, several new challenges need to be addressed, including 1) Convergence properties are sensitive to penalty parameters, and 2) Slow theoretical convergence rate. We, therefore, propose a novel monotonous Deep Learning Alternating Minimization (mDLAM) algorithm to deal with these two challenges. Our innovative inequality-constrained formulation infinitely approximates the original problem with non-convex equality constraints, enabling our convergence proof of the proposed mDLAM algorithm regardless of …"
Liang Zhao,Deep Latent-Variable Models for Controllable Molecule Generation,2021,https://ieeexplore.ieee.org/abstract/document/9669692/,"Representation learning via deep generative models is opening a new avenue for small molecule generation in silico. Linking chemical and biological space remains a key challenge. In this paper, we debut a graph-based variational autoencoder framework to address this challenge under the umbrella of disentangled representation learning. The framework permits several inductive biases that connect the learned latent factors to molecular properties. Evaluation on diverse benchmark datasets shows that the resulting models are powerful and open up an exciting line of research on controllable molecule generation in support of cheminformatics, drug discovery, and other application settings."
Liang Zhao,Graph neural network for spatiotemporal data: methods and applications,2023,https://arxiv.org/abs/2306.00012,"In the era of big data, there has been a surge in the availability of data containing rich spatial and temporal information, offering valuable insights into dynamic systems and processes for applications such as weather forecasting, natural disaster management, intelligent transport systems, and precision agriculture. Graph neural networks (GNNs) have emerged as a powerful tool for modeling and understanding data with dependencies to each other such as spatial and temporal dependencies. There is a large amount of existing work that focuses on addressing the complex spatial and temporal dependencies in spatiotemporal data using GNNs. However, the strong interdisciplinary nature of spatiotemporal data has created numerous GNNs variants specifically designed for distinct application domains. Although the techniques are generally applicable across various domains, cross-referencing these methods remains essential yet challenging due to the absence of a comprehensive literature review on GNNs for spatiotemporal data. This article aims to provide a systematic and comprehensive overview of the technologies and applications of GNNs in the spatiotemporal domain. First, the ways of constructing graphs from spatiotemporal data are summarized to help domain experts understand how to generate graphs from various types of spatiotemporal data. Then, a systematic categorization and summary of existing spatiotemporal GNNs are presented to enable domain experts to identify suitable techniques and to support model developers in advancing their research. Moreover, a comprehensive overview of significant applications in the …"
Liang Zhao,Multi-objective Deep Data Generation with Correlated Property Control,2022,https://proceedings.neurips.cc/paper_files/paper/2022/hash/b9c2e8a0bbed5fcfaf62856a3a719ada-Abstract-Conference.html,"Developing deep generative models has been an emerging field due to the ability to model and generate complex data for various purposes, such as image synthesis and molecular design. However, the advance of deep generative models is limited by the challenges to generate objects that possess multiple desired properties because: 1) the existence of complex correlation among real-world properties is common but hard to identify; 2) controlling individual property enforces an implicit partially control of its correlated properties, which is difficult to model; 3) controlling multiple properties under variour manners simultaneously is hard and underexplored. We address these challenges by proposing a novel deep generative framework that recovers semantics and correlation of properties through disentangled latent vectors. The correlation is handled via an explainable mask pooling layer, and properties are precisely retained by the generated objects via the mutual dependence between latent vectors and properties. Our generative model preserves properties of interest while handles correlation and conflicts of properties under a multi-objective optimization framework. The experiments demonstrate our model's superior performance in generating objects with desired properties."
Liang Zhao,Multi-view support vector ordinal regression with data uncertainty,2022,https://www.sciencedirect.com/science/article/pii/S0020025521013487,"Ordinal regression (OR) is a paradigm which learns a prediction model on the data with ordered classes. Despite much progress in OR, the existing OR works learn the classifier from only one view and the multi-view learning in OR has not been considered. What is more, there may exist uncertain information in the multi-view OR data. In this paper, we put forward a novel approach, called multi-view support vector ordinal regression with uncertain data (MORU), which can improve the OR classifier by incorporating the multi-view information and handling the data uncertainty. In our method, a series of parallel hyperplanes are applied to separate the multi-view ordered data, and the uncertain information is considered in the input data. Then, we adopt a heuristic framework to solve the OR learning problem. Experimental results have illustrated that our method obtains superior performance to the existing OR techniques."
Liang Zhao,Motif-guided Heterogeneous Graph Deep Generation,2022,https://link.springer.com/article/10.1007/s10115-023-01863-0,"The complex systems in the real-world are commonly associated with multiple types of objects and relations, and heterogeneous graphs are ubiquitous data structures that can inherently represent multimodal interactions between objects. Generating high-quality heterogeneous graphs allows us to understand the implicit distribution of heterogeneous graphs and provides benchmarks for downstream heterogeneous representation learning tasks. Existing works are limited to either merely generating the graph topology with neglecting local semantic information or only generating the graph without preserving the higher-order structural information and the global heterogeneous distribution in generated graphs. To this end, we formulate a general, end-to-end framework— HGEN for generating novel heterogeneous graphs with a newly proposed heterogeneous walk generator. On top of HGEN, we further develop a …"
Liang Zhao,GNN-based Biomedical Knowledge Graph Mining in Drug Development,2022,https://link.springer.com/chapter/10.1007/978-981-16-6054-2_24,"Drug discovery and development (D3) is an extremely expensive and time consuming process. It takes tens of years and billions of dollars to make a drug successfully on the market from scratch, which makes this process highly inefficient when facing emergencies such as COVID-19. At the same time, a huge amount of knowledge and experience has been accumulated during the D3 process during the past decades. These knowledge are usually encoded in guidelines or biomedical literature, which provides an important resource containing insights that can be informative of the future D3 process. Knowledge graph (KG) is an effective way of organizing the useful information in those literature so that they can be retrieved efficiently. It also bridges the heterogeneous biomedical concepts that are involved in the D3 process. In this chapter we will review the existing biomedical KG and introduce how GNN …"
Liang Zhao,V2V routing in VANET based on fuzzy logic and reinforcement learning,2021,https://www.univagora.ro/jour/index.php/ijccc/article/view/4123,"To ensure the transmission quality of real-time communications on the road, the research of routing protocol is crucial to improve effectiveness of data transmission in Vehicular Ad Hoc Networks (VANETs). The existing work Q-Learning based routing algorithm, QLAODV, is studied and its problems, including slow convergence speed and low accuracy, are found. Hence, we propose a new routing algorithm FLHQRP by considering the characteristics of real-time communication in VANETs in the paper. The virtual grid is introduced to divide the vehicle network into clusters. The node’s centrality and mobility, and bandwidth efficiency are processed by the Fuzzy Logic system to select the most suitable cluster head (CH) with the stable communication links in the cluster. A new heuristic function is also proposed in FLHQRP algorithm. It takes cluster as the environment state of heuristic Q-learning, by considering the delay to guide the forwarding process of the CH. This can speed up the learning convergence, and reduce the impact of node density on the convergence speed and accuracy of Q-learning. The problem of QLAODV is solved in the proposed algorithm since the experimental results show that FLHQRP has many advantages on delivery rate, end-to-end delay, and average hops in different network scenarios."
Liang Zhao,Deep Graph Learning for Circuit Deobfuscation,2021,https://www.frontiersin.org/articles/10.3389/fdata.2021.608286/full,"Circuit obfuscation is a recently proposed defense mechanism to protect the intellectual property (IP) of digital integrated circuits (ICs) from reverse engineering. There have been effective schemes, such as satisfiability (SAT)-checking based attacks that can potentially decrypt obfuscated circuits, which is called deobfuscation. Deobfuscation runtime could be days or years, depending on the layouts of the obfuscated ICs. Hence, accurately pre-estimating the deobfuscation runtime within a reasonable amount of time is crucial for IC designers to optimize their defense. However, it is challenging due to (1) the complexity of graph-structured circuit; (2) the varying-size topology of obfuscated circuits; (3) requirement on efficiency for deobfuscation method. This study proposes a framework that predicts the deobfuscation runtime based on graph deep learning techniques to address the challenges mentioned above. A conjunctive normal form (CNF) bipartite graph is utilized to characterize the complexity of this SAT problem by analyzing the SAT attack method. Multi-order information of the graph matrix is designed to identify the essential features and reduce the computational cost. To overcome the difficulty in capturing the dynamic size of the CNF graph, an energy-based kernel is proposed to aggregate dynamic features into an identical vector space. Then, we designed a framework, Deep Survival Analysis with Graph (DSAG), which integrates energy-based layers and predicts runtime inspired by censored regression in survival analysis. Integrating uncensored data with censored data, the proposed model improves the standard regression significantly …"
Liang Zhao,Dynamic Activation of Clients and Parameters for Federated Learning over Heterogeneous Graphs,2023,https://ieeexplore.ieee.org/abstract/document/10184557/,"The data generated in many real-world applications can be modeled as heterogeneous graphs of multi-typed entities (nodes) and relations (links). Nowadays, such data are commonly generated and stored by distributed clients, making direct centralized model training unpractical. While the data in each client are prone to biased local distributions, generalizable global models are still in frequent need for large-scale applications. However, the large number of clients enforce significant computational overhead due to the communication and synchronization among the clients, whereas the biased local data distributions indicate that not all clients and parameters should be computed and updated at all times. Motivated by specifically designed preliminary studies on training a state-of-the-art heterogeneous graph neural network (HGN) with the vanilla FedAvg framework, in this work, we propose to leverage the …"
Liang Zhao,Dr. Emotion: Disentangled Representation Learning for Emotion Analysis on Social Media to Improve Community Resilience in the COVID-19,2021,https://dl.acm.org/doi/abs/10.1145/3442381.3449961," During the pandemic caused by coronavirus disease (COVID-19), social media has played an important role by enabling people to discuss their experiences and feelings of this global crisis. To help combat the prolonged pandemic that has exposed vulnerabilities impacting community resilience, in this paper, based on our established large-scale COVID-19 related social media data, we propose and develop an integrated framework (named Dr.Emotion) to learn disentangled representations of social media posts (i.e., tweets) for emotion analysis and thus to gain deep insights into public perceptions towards COVID-19. In Dr.Emotion, for given social media posts, we first post-train a transformer-based model to obtain the initial post embeddings. Since users may implicitly express their emotions in social media posts which could be highly entangled with other descriptive information in the post content, to address …"
Liang Zhao,Distilling large language models for text-attributed graph learning,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679830,"Text-Attributed Graphs (TAGs) are graphs of connected textual documents. Graph models can efficiently learn TAGs, but their training heavily relies on human-annotated labels, which are scarce or even unavailable in many applications. Large language models (LLMs) have recently demonstrated remarkable capabilities in few-shot and zero-shot TAG learning, but they suffer from scalability, cost, and privacy issues. Therefore, in this work, we focus on synergizing LLMs and graph models with their complementary strengths by distilling the power of LLMs into a local graph model on TAG learning. To address the inherent gaps between LLMs (generative models for texts) and graph models (discriminative models for graphs), we propose first to let LLMs teach an interpreter with rich rationale and then let a student model mimic the interpreter's reasoning without LLMs' rationale. We convert LLM's textual rationales to …"
Liang Zhao,Magi: Multi-annotated explanation-guided learning,2023,http://openaccess.thecvf.com/content/ICCV2023/html/Zhang_MAGI_Multi-Annotated_Explanation-Guided_Learning_ICCV_2023_paper.html,"Explanation supervision is a technique in which the model is guided by human-generated explanations during training. This technique aims to improve the predictability of the model by incorporating human understanding of the prediction process into the training phase. This is a challenging task since it relies on the accuracy of human annotation labels. To obtain high-quality explanation annotations, using multiple annotations to do explanation supervision is a reasonable method. However, how to use multiple annotations to improve accuracy is particularly challenging due to the following: 1) The noisiness of annotations from different annotators; 2) The lack of pre-given information about the corresponding relationship between annotations and annotators; 3) Missing annotations since some images are not labeled by all annotators. To solve these challenges, we propose a Multi-annotated explanation-guided learning (MAGI) framework to do explanation supervision with comprehensive and high-quality generated annotations. We first propose a novel generative model to generate annotations from all annotators and infer them using a newly proposed variational inference-based technique by learning the characteristics of each annotator. We also incorporate an alignment mechanism into the generative model to infer the correspondence between annotations and annotators in the training process. Extensive experiments on two datasets from the medical imaging domain demonstrate the effectiveness of our proposed framework in handling noisy annotations while obtaining superior prediction performance compared with previous SOTA."
Liang Zhao,Distribution strategy optimization of standalone hybrid WT/PV system based on different solar and wind resources for rural applications,2022,https://www.mdpi.com/1996-1073/15/14/5307,"The characteristics of solar and wind energy determine that the optimization of a standalone hybrid wind turbine (WT)/photovoltaic panel (PV) system depends on the natural resources of the installation location. In order to ensure system reliability and improve the resource utilization, a method for determining the installed capacity ratio of a hybrid renewable energy system is required. This study proposes a calculation method to optimize the installed capacity ratio, considering the system reliability to meet the needs of the hybrid system to adapt to different natural resources. In this paper, a standalone hybrid WT/PV system to provide electricity for rural areas is designed. Taking the power supply guarantee rate and electricity supply continuity as indicators, the system is simulated by using the Transient System Simulator solver. The results show that the recommended installed capacity ratio of the WT and PV is 5:1 when the total solar irradiation is less than 5040 MJ/(m2·a) and the annual average wind velocity is in the range of 3.0~3.5 m/s. When the annual average wind velocity is in the range of 2.0~3.0 m/s, the PV plays an increasingly significant role in the hybrid system and exceeds the WT if the total solar irradiation is greater than 6300 MJ/(m2·a). However, if the total solar irradiation and the annual average wind velocity are less than 5040 MJ/(m2·a) and 2.0 m/s, respectively, it is not recommended to use the standalone hybrid system because it cannot meet the power demand. These conclusions provide guidance for the distribution strategies of the standalone hybrid WT/PV system within different natural resources."
Liang Zhao,Modeling Health Stage Development of Patients with Dynamic Attributed Graphs in Online Health Communities,2022,https://ieeexplore.ieee.org/abstract/document/9684988/,"In this paper, we propose a novel DynAttGraph2Seq framework to model complex dynamic transitions of an individual user's activities and the textual information of the posts over time in online health forums and learning how these correspond to his/her health stage. To achieve this, we first formulate the transition of user activities as a dynamic attributed graph with multi-attributed nodes that evolves over time, then formalize the health stage inference task as a dynamic attributed graph to sequence learning problem. Our proposed model consists of a novel dynamic graph encoder along with a two-level sequential encoder to capture the semantic features from user posts and an interpretable sequence decoder that learn the mapping between a sequence of time-evolving user activity graphs as well as user posts to a sequence of target health stages. We go on to propose new dynamic graph regularization and …"
Liang Zhao,CPM: A general feature dependency pattern mining framework for contrast multivariate time series,2021,https://www.sciencedirect.com/science/article/pii/S0031320320305148,"With recent advances in sensor technology, multivariate time series data are becoming extremely large with sophisticated but insightful inter-variable dependency patterns. Mining contrast dependency patterns in controlled experiments can help quantify the differences between control and experimental time series, however, overwhelms practitioners’ capability. Existing methods suffer from determining whether the differences are caused by the intervention or by different states. We propose a novel Contrast Pattern Mining (CPM) framework to find the intervention-related differences by jointly determining and characterizing the dynamic states in both time series via multivariate Gaussian distributions. Under the CPM framework, we not only propose a new covariance-based contrast pattern model, but also integrate our previous proposed partial correlation-based model as a special case. An efficient generic algorithm …"
Liang Zhao,SparseLLM: Towards Global Pruning for Pre-trained Language Models,2024,https://arxiv.org/abs/2402.17946,"The transformative impact of large language models (LLMs) like LLaMA and GPT on natural language processing is countered by their prohibitive computational demands. Pruning has emerged as a pivotal compression strategy, introducing sparsity to enhance both memory and computational efficiency. Yet, traditional global pruning is impractical for LLMs due to scalability issues, while local pruning, despite its efficiency, leads to suboptimal solutions. Addressing these challenges, we propose SparseLLM, a novel framework that redefines the global pruning process into manageable, coordinated subproblems, allowing for resource-efficient optimization with global optimality. SparseLLM's approach, which conceptualizes LLMs as a chain of modular functions and leverages auxiliary variables for problem decomposition, not only facilitates a pragmatic application on LLMs but also demonstrates significant performance improvements, particularly in high-sparsity regimes where it surpasses current state-of-the-art methods."
Liang Zhao,PolygonGNN: Representation Learning for Polygonal Geometries with Heterogeneous Visibility Graph,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671738,"Polygon representation learning is essential for diverse applications, encompassing tasks such as shape coding, building pattern classification, and geographic question answering. While recent years have seen considerable advancements in this field, much of the focus has been on single polygons, overlooking the intricate inner- and inter-polygonal relationships inherent in multipolygons. To address this gap, our study introduces a comprehensive framework specifically designed for learning representations of polygonal geometries, particularly multipolygons. Central to our approach is the incorporation of a heterogeneous visibility graph, which seamlessly integrates both inner- and inter-polygonal relationships. To enhance computational efficiency and minimize graph redundancy, we implement a heterogeneous spanning tree sampling method. Additionally, we devise a rotation-translation invariant geometric …"
Liang Zhao,Improving open information extraction with large language models: A study on demonstration uncertainty,2023,https://arxiv.org/abs/2309.03433,"Open Information Extraction (OIE) task aims at extracting structured facts from unstructured text, typically in the form of (subject, relation, object) triples. Despite the potential of large language models (LLMs) like ChatGPT as a general task solver, they lag behind state-of-the-art (supervised) methods in OIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant context from relevant relations and generate structured output due to the restrictions on fine-tuning the model. Second, LLMs generates responses autoregressively based on probability, which makes the predicted relations lack confidence. In this paper, we assess the capabilities of LLMs in improving the OIE task. Particularly, we propose various in-context learning strategies to enhance LLM's instruction-following ability and a demonstration uncertainty quantification module to enhance the confidence of the generated relations. Our experiments on three OIE benchmark datasets show that our approach holds its own against established supervised methods, both quantitatively and qualitatively."
Liang Zhao,Knowledge-enhanced neural machine reasoning: A review,2023,https://arxiv.org/abs/2302.02093,"Knowledge-enhanced neural machine reasoning has garnered significant attention as a cutting-edge yet challenging research area with numerous practical applications. Over the past few years, plenty of studies have leveraged various forms of external knowledge to augment the reasoning capabilities of deep models, tackling challenges such as effective knowledge integration, implicit knowledge mining, and problems of tractability and optimization. However, there is a dearth of a comprehensive technical review of the existing knowledge-enhanced reasoning techniques across the diverse range of application domains. This survey provides an in-depth examination of recent advancements in the field, introducing a novel taxonomy that categorizes existing knowledge-enhanced methods into two primary categories and four subcategories. We systematically discuss these methods and highlight their correlations, strengths, and limitations. Finally, we elucidate the current application domains and provide insight into promising prospects for future research."
Liang Zhao,Knowledge-enhanced prompt for open-domain commonsense reasoning,2023,https://www.researchgate.net/profile/Chen-Ling-30/publication/365598097_Knowledge-enhanced_Prompt_for_Open-domain_Commonsense_Reasoning/links/6379649e1766b34c543c7f2d/Knowledge-enhanced-Prompt-for-Open-domain-Commonsense-Reasoning.pdf,"Neural language models for commonsense reasoning often formulate the problem as a QA task and make predictions based on learned representations of language after finetuning. However, without providing any finetuning data and predefined answer candidates, can neural language models still answer commonsense reasoning questions only relying on external knowledge? In this work, we investigate a unique yet challenging problem-open-domain commonsense reasoning that aims to answer questions without providing any answer candidates and finetuning examples. Our proposed method leverages neural language models to iteratively retrieve reasoning chains on the external knowledge base, which does not require task-specific supervision. The reasoning chains can help to identify the most precise answer to the commonsense question and its corresponding knowledge statements to justify the answer choice. We conduct experiments on two commonsense benchmark datasets. Compared to other approaches, our proposed method achieves better performance both quantitatively and qualitatively."
Liang Zhao,Toward quantized model parallelism for graph-augmented mlps based on gradient-free admm framework,2022,https://ieeexplore.ieee.org/abstract/document/9992210/,"While graph neural networks (GNNs) are popular in the deep learning community, they suffer from several challenges including over-smoothing, over-squashing, and gradient vanishing. Recently, a series of models have attempted to relieve these issues by first augmenting the node features and then imposing node-wise functions based on multilayer perceptron (MLP), which are widely referred to as graph-augmented MLP (GA-MLP) models. However, while GA-MLP models enjoy deeper architectures for better accuracy, their efficiency largely deteriorates. Moreover, popular acceleration techniques such as stochastic-version or data-parallelism cannot be effectively applied due to the dependency among samples (i.e., nodes) in graphs. To address these issues, in this article, instead of data parallelism, we propose a parallel graph deep learning Alternating Direction Method of Multipliers (pdADMM-G) framework to …"
Liang Zhao,Black-box node injection attack for graph neural networks,2022,https://arxiv.org/abs/2202.09389,"Graph Neural Networks (GNNs) have drawn significant attentions over the years and been broadly applied to vital fields that require high security standard such as product recommendation and traffic forecasting. Under such scenarios, exploiting GNN's vulnerabilities and further downgrade its classification performance become highly incentive for adversaries. Previous attackers mainly focus on structural perturbations of existing graphs. Although they deliver promising results, the actual implementation needs capability of manipulating the graph connectivity, which is impractical in some circumstances. In this work, we study the possibility of injecting nodes to evade the victim GNN model, and unlike previous related works with white-box setting, we significantly restrict the amount of accessible knowledge and explore the black-box setting. Specifically, we model the node injection attack as a Markov decision process and propose GA2C, a graph reinforcement learning framework in the fashion of advantage actor critic, to generate realistic features for injected nodes and seamlessly merge them into the original graph following the same topology characteristics. Through our extensive experiments on multiple acknowledged benchmark datasets, we demonstrate the superior performance of our proposed GA2C over existing state-of-the-art methods. The data and source code are publicly accessible at: https://github.com/jumxglhf/GA2C."
Liang Zhao,"Yuanqi Du, Sivani Tadepalli, Liang Zhao, and Amarda Shehu. Generating tertiary protein structures via interpretable graph variational autoencoders",2021,https://scholar.google.com/scholar?cluster=2295662060820911241&hl=en&oi=scholarr,
Liang Zhao,Large-scale Cost-aware Classification Using Feature Computational Dependency Graph.,2020,,
Liang Zhao,Zero-shot link prediction in knowledge graphs with large language models,2024,https://ieeexplore.ieee.org/abstract/document/10884231/,"Zero-shot link prediction (ZSLP) on knowledge graphs aims at automatically identifying relations between given entities. Existing methods primarily employ auxiliary information to predict tail entity given head entity and its relation, yet face challenges due to the occasional unavailability of such detailed information and the inherent simplicity of predicting tail entities based on semantic similarities. Even though Large Language Models (LLMs) offer a promising solution to predict unobserved relations between the head and tail entity in a zero-shot manner, their performance is still restricted due to the inability to leverage all the (exponentially many) paths' information between two entities, which are critical in collectively indicating their relation types. To address this, in this work, we introduce a Condensed Transition Graph Framework for Zero-Shot Link Prediction (CTLP), which encodes all the paths' information in linear …"
Liang Zhao,"A review on knowledge graphs for healthcare: Resources, applications, and promises",2023,https://arxiv.org/abs/2306.04802,"Healthcare knowledge graphs (HKGs) are valuable tools for organizing biomedical concepts and their relationships with interpretable structures. The recent advent of large language models (LLMs) has paved the way for building more comprehensive and accurate HKGs. This, in turn, can improve the reliability of generated content and enable better evaluation of LLMs. However, the challenges of HKGs such as regarding data heterogeneity and limited coverage are not fully understood, highlighting the need for detailed reviews. This work provides the first comprehensive review of HKGs. It summarizes the pipeline and key techniques for HKG construction, as well as the common utilization approaches, i.e., model-free and model-based. The existing HKG resources are also organized based on the data types they capture and application domains they cover, along with relevant statistical information (Resource available at https://github.com/lujiaying/Awesome-HealthCare-KnowledgeBase). At the application level, we delve into the successful integration of HKGs across various health domains, ranging from fine-grained basic science research to high-level clinical decision support and public health. Lastly, the paper highlights the opportunities for HKGs in the era of LLMs. This work aims to serve as a valuable resource for understanding the potential and opportunities of HKG in health research."
Liang Zhao,Pinball loss support vector data description for outlier detection,2022,https://link.springer.com/article/10.1007/s10489-022-03237-5,"Support vector data description (SVDD) has been widely used in outlier detection. The conventional SVDD employs the hinge loss function and the sphere classifier is decided by only a small amount of data around the sphere surface (namely support vectors), which makes it sensitive to noise and unstable for re-sampling. In this paper, we put forward a novel support vector data description method with pinball loss (pin-SVDD). In our method, all the training data, including those lying inside the sphere, is decisive to the sphere classifier. A small amount of noisy data has little influence on the classifier, which makes our method more robust to noise and achieve scatter minimization in the sphere center. Pin-SVDD has two main merits. (1) Different from the conventional SVDD which employs the hinge loss function and is sensitive to noise, pin-SVDD applies the pinball loss which makes our method more robust to …"
Liang Zhao,DeepGAR: Deep Graph Learning for Analogical Reasoning,2022,https://ieeexplore.ieee.org/abstract/document/10027755/,"Analogical reasoning is the process of discovering and mapping correspondences from a target subject to a base subject. As the most well-known computational method of analogical reasoning, Structure-Mapping Theory (SMT) abstracts both target and base subjects into relational graphs and forms the cognitive process of analogical reasoning by finding a corresponding subgraph (i.e., correspondence) in the target graph that is aligned with the base graph. However, incorporating deep learning for SMT is still under-explored due to several obstacles: 1) the combinatorial complexity of searching for the correspondence in the target graph; 2) the correspondence mining is restricted by various cognitive theory-driven constraints. To address both challenges, we propose a novel framework for Analogical Reasoning (DeepGAR) that identifies the correspondence between source and target domains by assuring …"
Liang Zhao,Multi-view partial label machine,2022,https://www.sciencedirect.com/science/article/pii/S0020025521011920,"In partial label learning (PLL), each instance is associated with a set of candidate labels, among which there is only ground-truth label. PLL aims to identify the ground-truth label out of these candidate labels. Most of the existing PLL approaches are proposed to handle the single-view PLL problem, and the multi-view PLL problem has not been addressed. In this paper, we propose a novel multi-view paunknown."
Liang Zhao,Teg-db: A comprehensive dataset and benchmark of textual-edge graphs,2024,https://proceedings.neurips.cc/paper_files/paper/2024/hash/7054d2c49863c1c41be1d53f4377b82a-Abstract-Datasets_and_Benchmarks_Track.html,"Text-Attributed Graphs (TAGs) augment graph structures with natural language descriptions, facilitating detailed depictions of data and their interconnections across various real-world settings. However, existing TAG datasets predominantly feature textual information only at the nodes, with edges typically represented by mere binary or categorical attributes. This lack of rich textual edge annotations significantly limits the exploration of contextual relationships between entities, hindering deeper insights into graph-structured data. To address this gap, we introduce Textual-Edge Graphs Datasets and Benchmark (TEG-DB), a comprehensive and diverse collection of benchmark textual-edge datasets featuring rich textual descriptions on nodes and edges. The TEG-DB datasets are large-scale and encompass a wide range of domains, from citation networks to social networks. In addition, we conduct extensive benchmark experiments on TEG-DB to assess the extent to which current techniques, including pre-trained language models, graph neural networks, and their combinations, can utilize textual node and edge information. Our goal is to elicit advancements in textual-edge graph research, specifically in developing methodologies that exploit rich textual node and edge descriptions to enhance graph analysis and provide deeper insights into complex real-world networks. The entire TEG-DB project is publicly accessible as an open-source repository on Github, accessible at https://github. com/Zhuofeng-Li/TEG-Benchmark."
Liang Zhao,Position-aware parameter efficient fine-tuning approach for reducing positional bias in llms,2024,https://arxiv.org/abs/2404.01430,"Recent advances in large language models (LLMs) have enhanced their ability to process long input contexts. This development is particularly crucial for tasks that involve retrieving knowledge from an external datastore, which can result in long inputs. However, recent studies show a positional bias in LLMs, demonstrating varying performance depending on the location of useful information within the input sequence. In this study, we conduct extensive experiments to investigate the root causes of positional bias. Our findings indicate that the primary contributor to LLM positional bias stems from the inherent positional preferences of different models. We demonstrate that merely employing prompt-based solutions is inadequate for overcoming the positional preferences. To address this positional bias issue of a pre-trained LLM, we developed a Position-Aware Parameter Efficient Fine-Tuning (PAPEFT) approach which is composed of a data augmentation technique and a parameter efficient adapter, enhancing a uniform attention distribution across the input context. Our experiments demonstrate that the proposed approach effectively reduces positional bias, improving LLMs' effectiveness in handling long context sequences for various tasks that require externally retrieved knowledge."
Liang Zhao,Designing a direct feedback loop between humans and convolutional neural networks through local explanations,2023,https://dl.acm.org/doi/abs/10.1145/3610187,"The local explanation provides heatmaps on images to explain how Convolutional Neural Networks (CNNs) derive their output. Due to its visual straightforwardness, the method has been one of the most popular explainable AI (XAI) methods for diagnosing CNNs. Through our formative study (S1), however, we captured ML engineers' ambivalent perspective about the local explanation as a valuable and indispensable envision in building CNNs versus the process that exhausts them due to the heuristic nature of detecting vulnerability. Moreover, steering the CNNs based on the vulnerability learned from the diagnosis seemed highly challenging. To mitigate the gap, we designed DeepFuse, the first interactive design that realizes the direct feedback loop between a user and CNNs in diagnosing and revising CNN's vulnerability using local explanations. DeepFuse helps CNN engineers to systemically search …"
Liang Zhao,Essa: Explanation iterative supervision via saliency-guided data augmentation,2023,https://dl.acm.org/doi/abs/10.1145/3580305.3599336,"Explanation supervision is a technique in which the model is guided by human-generated explanations during training. This technique aims to improve both the interpretability and predictability of the model by incorporating human understanding into the training process. Since explanation supervision requires a large scale of training data, the data augmentation technique is necessary to be applied to increase the size and diversity of the original dataset. However, data augmentation on sophisticated data like medical images is particularly challenging due to the following: 1) scarcity of data in training the learning-based data augmenter, 2) difficulty in generating realistic and sophisticated images, and 3) difficulty in ensuring the augmented data indeed boosts the performance of explanation-guided learning. To solve these challenges, we propose an Explanation Iterative Supervision via Saliency-guided Data …"
Liang Zhao,Tutorials at the web conference 2023,2023,https://dl.acm.org/doi/abs/10.1145/3543873.3587713, This paper summarizes the content of the 28 tutorials that have been given at The Web Conference 2023.
Liang Zhao,Open-ended Commonsense Reasoning with Unrestricted Answer Candidates,2023,https://par.nsf.gov/servlets/purl/10520951,"Open-ended Commonsense Reasoning is defined as solving a commonsense question without providing 1) a short list of answer candidates and 2) a pre-defined answer scope. Conventional ways of formulating the commonsense question into a question-answering form or utilizing external knowledge to learn retrieval-based methods are less applicable in the open-ended setting due to an inherent challenge. Without pre-defining an answer scope or a few candidates, open-ended commonsense reasoning entails predicting answers by searching over an extremely large searching space. Moreover, most questions require implicit multi-hop reasoning, which presents even more challenges to our problem. In this work, we leverage pre-trained language models to iteratively retrieve reasoning paths on the external knowledge base, which does not require task-specific supervision. The reasoning paths can help to identify the most precise answer to the commonsense question. We conduct experiments on two commonsense benchmark datasets. Compared to other approaches, our proposed method achieves better performance both quantitatively and qualitatively. Our code and data are available at: https://github. com/lingchen0331/KEEP."
Liang Zhao,STGEN: Deep Continuous-time Spatiotemporal Graph Generation,2022,https://link.springer.com/chapter/10.1007/978-3-031-26409-2_21,"Spatiotemporal graph generation has realistic social significance since it unscrambles the underlying distribution of spatiotemporal graphs from another perspective and fuels substantial spatiotemporal data mining tasks. Generative models for temporal and spatial networks respectively cannot be easily generalized to spatiotemporal graph generation due to their incapability of capturing: 1) mutually influenced graph and spatiotemporal distribution, 2) spatiotemporal-validity constraints, and 3) characteristics of multi-modal spatiotemporal properties. To this end, we propose a generic and end-to-end framework for spatiotemporal graph generation (STGEN) that jointly captures the graph, temporal, and spatial distributions of spatiotemporal graphs. Particularly, STGEN learns the multi-modal distribution of spatiotemporal graphs via learning the distribution of spatiotemporal walks based on a new heterogeneous …"
Liang Zhao,Deep graph spectral evolution networks for graph topological evolution,2021,https://ojs.aaai.org/index.php/AAAI/article/view/16903,"Characterizing the underlying mechanism of graph topological evolution from a source graph to a target graph has attracted fast increasing attention in the deep graph learning domain. However, it is very challenging to build expressive and efficient models that can handle global and local evolution patterns between source and target graphs. On the other hand, graph topological evolution has been investigated in the graph signal processing domain historically, but it involves intensive labors to manually determine suitable prescribed spectral models and prohibitive difficulty to fit their potential combinations and compositions. To address these challenges, this paper proposes the deep Graph Spectral Evolution Network (GSEN) for modeling the graph topology evolution problem by the composition of newly-developed generalized graph kernels. GSEN can effectively fit a wide range of existing graph kernels and their combinations and compositions with the theoretical guarantee and experimental verification. GSEN has outstanding efficiency in terms of time complexity (O (n)) and parameter complexity (O (1)), where n is the number of nodes of the graph. Extensive experiments on multiple synthetic and real-world datasets demonstrate outstanding performance."
Liang Zhao,Transferable Unsupervised Outlier Detection Framework for Human Semantic Trajectories,2024,https://dl.acm.org/doi/abs/10.1145/3678717.3691324,"Semantic trajectories, which enrich spatial-temporal data with textual information such as trip purposes or location activities, are key for identifying outlier behaviors critical to healthcare, social security, and urban planning. Traditional outlier detection relies on heuristic rules, which requires domain knowledge and limits its ability to identify unseen outliers. Besides, there lacks a comprehensive approach that can jointly consider multi-modal data across spatial, temporal, and textual dimensions. Addressing the need for a domain-agnostic model, we propose the Transferable Outlier Detection for Human Semantic Trajectories (TOD4Traj) framework. TOD4Traj first introduces a modality feature unification module to align diverse data feature representations, enabling the integration of multi-modal information and enhancing transferability across different datasets. A contrastive learning module is further proposed for …"
Liang Zhao,Prompt-based Domain Discrimination for Multi-source Time Series Domain Adaptation,2024,https://openreview.net/forum?id=nhSncKcJiB,"Time series domain adaptation stands as a pivotal and intricate challenge with diverse applications, including but not limited to human activity recognition, sleep stage classification, and machine fault diagnosis. Despite the numerous domain adaptation techniques proposed to tackle this complex problem, they primarily focus on domain adaptation from a single source domain. Yet, it is more crucial to investigate domain adaptation from multiple domains due to the potential for greater improvements. To address this, three important challenges need to be overcome: 1). The lack of exploration to utilize domain-specific information for domain adaptation, 2). The difficulty to learn domain-specific information that changes over time, and 3). The difficulty to evaluate learned domain-specific information. In order to tackle these challenges simultaneously, in this paper, we introduce PrOmpt-based domaiN Discrimination (POND …"
Liang Zhao,XAI benchmark for visual explanation,2023,https://arxiv.org/abs/2310.08537,"The rise of deep learning has ushered in significant progress in computer vision (CV) tasks, yet the ""black box"" nature of these models often precludes interpretability. This challenge has spurred the development of Explainable Artificial Intelligence (XAI) by generating explanations to AI's decision-making process. An explanation is aimed to not only faithfully reflect the true reasoning process (i.e., faithfulness) but also align with humans' reasoning (i.e., alignment). Within XAI, visual explanations employ visual cues to elucidate the reasoning behind machine learning models, particularly in image processing, by highlighting images' critical areas important to predictions. Despite the considerable body of research in visual explanations, standardized benchmarks for evaluating them are seriously underdeveloped. In particular, to evaluate alignment, existing works usually merely illustrate a few images' visual explanations, or hire some referees to report the explanation quality under ad-hoc questionnaires. However, this cannot achieve a standardized, quantitative, and comprehensive evaluation. To address this issue, we develop a benchmark for visual explanation, consisting of eight datasets with human explanation annotations from various domains, accommodating both post-hoc and intrinsic visual explanation methods. Additionally, we devise a visual explanation pipeline that includes data loading, explanation generation, and method evaluation. Our proposed benchmarks facilitate a fair evaluation and comparison of visual explanation methods. Building on our curated collection of datasets, we benchmarked eight existing visual explanation …"
Liang Zhao,Deep Spatial Domain Generalization,2022,https://ieeexplore.ieee.org/abstract/document/10027666/,"Spatial autocorrelation and spatial heterogeneity widely exist in spatial data, which make the traditional machine learning model perform badly. Spatial domain generalization is a spatial extension of domain generalization, which can generalize to unseen spatial domains in continuous 2D space. Specifically, it learns a model under varying data distributions that generalizes to unseen domains. Although tremendous success has been achieved in domain generalization, there exist very few works on spatial domain generalization. The advancement of this area is challenged by: 1) Difficulty in characterizing spatial heterogeneity, and 2) Difficulty in obtaining predictive models for unseen locations without training data. To address these challenges, this paper proposes a generic framework for spatial domain generalization. Specifically, We develop the spatial interpolation graph neural network 1 that handles spatial …"
Liang Zhao,RAPTA: A Hierarchical Representation Learning Solution For Real-Time Prediction of Path-Based Static Timing Analysis,2022,https://dl.acm.org/doi/abs/10.1145/3526241.3530831,"This paper presents RAPTA, a customized Representation-learning Architecture for automation of feature engineering and predicting the result of Path-based Timing-Analysis early in the physical design cycle. RAPTA offers multiple advantages compared to prior work: 1) It has superior accuracy with errors std ranges 3.9ps~16.05ps in 32nm technology. 2) RAPTA's architecture does not change with feature-set size, 3) RAPTA does not require manual input feature engineering. To the best of our knowledge, this is the first work, in which Bidirectional Long Short-Term Memory (Bi-LSTM) representation learning is used to digest raw information for feature engineering, where generation of latent features and Multilayer Perceptron (MLP) based regression for timing prediction can be trained end-to-end."
Liang Zhao,Graph Neural Networks: Graph Generation,2022,https://link.springer.com/chapter/10.1007/978-981-16-6054-2_11,"In this chapter, we first review a few classic probabilistic models for graph generation including the ErdŐs–Rényi model and the stochastic block model. Then we introduce several representative modern graph generative models that leverage deep learning techniques like graph neural networks, variational auto-encoders, deep auto-regressive models, and generative adversarial networks. At last, we conclude the chapter with a discussion on potential future directions."
Liang Zhao,Schematic Memory Persistence and Transience for Efficient and Robust Continual Learning,2021,https://www.sciencedirect.com/science/article/pii/S0893608021003166,"Continual learning is considered a promising step toward next-generation Artificial Intelligence (AI), where deep neural networks (DNNs) make decisions by continuously learning a sequence of different tasks akin to human learning processes. It is still quite primitive, with existing works focusing primarily on avoiding (catastrophic) forgetting. However, since forgetting is inevitable given bounded memory and unbounded task loads, ‘how to reasonably forget’ is a problem continual learning must address in order to reduce the performance gap between AIs and humans, in terms of (1) memory efficiency, (2) generalizability, and (3) robustness when dealing with noisy data. To address this, we propose a novel ScheMAtic memory peRsistence and Transience (SMART)1 framework for continual learning with external memory that builds on recent advances in neuroscience. The efficiency and generalizability are …"
Liang Zhao,A novel simulated annealing based routing algorithm in F-SDNs,2020,https://ieeexplore.ieee.org/abstract/document/9162933/,"In recent years, routing algorithms have attracted tremendous research attentions in Flying Ad hoc Networks (FANETs) in order to provide efficient networking to fulfill the demand of Intelligent Transport System (ITS). Due to the lack of a global network information in FANETs, existing routing algorithms still have many issues in finding the optimal next-hop node, suffering low packet delivery rate and high delay. With the inclusion of Flying-Software Defined Network (F-SDN), providing global network information has eased the routing and forwarding of data for Unmanned Aerial Vehicles (UAVs). In this paper, we introduce a new routing algorithm by our Modified Simulated Annealing (MSA) algorithm to increase performance of networking in dense environments. The experimental results show the proposed algorithm outperforms the standard algorithm in the finding of routing paths in F-SDNs."
Liang Zhao,Chinese reverse M&As in the Netherlands: Chinese managers’ trust building practices,2020,https://www.emerald.com/insight/content/doi/10.1108/CMS-11-2018-0748/full/html,"Building trust is critical in reverse mergers and acquisitions (M&As), attributed to the divergence of governance and culture between the East and the West. This paper aims to explore the barriers and trust-building practices of Chinese managers in reverse M&As in developed countries.The primary data set of this research contains case studies of two Chinese M&A deals and in-depth interviews with managers and advisories in the Netherlands.This research finds that the divergences of decision-making structure, communication style and trust orientation generate barriers to the trust building in Chinese reverse M&As. The third-party advisory participation helps to build cognition-based trust of acquired company managers on Chinese acquiring company managers through providing information and explanation, fitting Chinese buyers in the Western M&A procedure and …"
Liang Zhao,Political-llm: Large language models in political science,2024,https://arxiv.org/abs/2412.06864,"In recent years, large language models (LLMs) have been widely adopted in political science tasks such as election prediction, sentiment analysis, policy impact assessment, and misinformation detection. Meanwhile, the need to systematically understand how LLMs can further revolutionize the field also becomes urgent. In this work, we--a multidisciplinary team of researchers spanning computer science and political science--present the first principled framework termed Political-LLM to advance the comprehensive understanding of integrating LLMs into computational political science. Specifically, we first introduce a fundamental taxonomy classifying the existing explorations into two perspectives: political science and computational methodologies. In particular, from the political science perspective, we highlight the role of LLMs in automating predictive and generative tasks, simulating behavior dynamics, and improving causal inference through tools like counterfactual generation; from a computational perspective, we introduce advancements in data preparation, fine-tuning, and evaluation methods for LLMs that are tailored to political contexts. We identify key challenges and future directions, emphasizing the development of domain-specific datasets, addressing issues of bias and fairness, incorporating human expertise, and redefining evaluation criteria to align with the unique requirements of computational political science. Political-LLM seeks to serve as a guidebook for researchers to foster an informed, ethical, and impactful use of Artificial Intelligence in political science. Our online resource is available at: http://political-llm.org/."
Liang Zhao,Deep graph representation learning for influence maximization with accelerated inference,2024,https://www.sciencedirect.com/science/article/pii/S0893608024005732,"Selecting a set of initial users from a social network in order to maximize the envisaged number of influenced users is known as influence maximization (IM). Researchers have achieved significant advancements in the theoretical design and performance gain of several classical approaches, but these advances are almost reaching their pinnacle. Learning-based IM approaches have emerged recently with a higher generalization to unknown graphs than conventional methods. The development of learning-based IM methods is still constrained by a number of fundamental hardships, including (1) solving the objective function efficiently, (2) struggling to characterize the diverse underlying diffusion patterns, and (3) adapting the solution to different node-centrality-constrained IM variants. To address the aforementioned issues, we design a novel framework DeepIM for generatively characterizing the latent …"
Liang Zhao,Taxonomy Tree Generation from Citation Graph,2024,https://arxiv.org/abs/2410.03761,"Constructing taxonomies from citation graphs is essential for organizing scientific knowledge, facilitating literature reviews, and identifying emerging research trends. However, manual taxonomy construction is labor-intensive, time-consuming, and prone to human biases, often overlooking pivotal but less-cited papers. In this paper, to enable automatic hierarchical taxonomy generation from citation graphs, we propose HiGTL (Hierarchical Graph Taxonomy Learning), a novel end-to-end framework guided by human-provided instructions or preferred topics. Specifically, we propose a hierarchical citation graph clustering method that recursively groups related papers based on both textual content and citation structure, ensuring semantically meaningful and structurally coherent clusters. Additionally, we develop a novel taxonomy node verbalization strategy that iteratively generates central concepts for each cluster, leveraging a pre-trained large language model (LLM) to maintain semantic consistency across hierarchical levels. To further enhance performance, we design a joint optimization framework that fine-tunes both the clustering and concept generation modules, aligning structural accuracy with the quality of generated taxonomies. Extensive experiments demonstrate that HiGTL effectively produces coherent, high-quality taxonomies."
Liang Zhao,ELAD: Explanation-Guided Large Language Models Active Distillation,2024,https://arxiv.org/abs/2402.13098,"The deployment and application of Large Language Models (LLMs) is hindered by their memory inefficiency, computational demands, and the high costs of API inferences. Traditional distillation methods, which transfer the capabilities of LLMs to smaller models, often fail to determine whether the knowledge has been sufficiently transferred, potentially resulting in high costs or incomplete distillation. In this paper, we propose an Explanation-Guided LLMs Active Distillation (ELAD) framework that employs an active learning strategy to optimize the balance between annotation costs and model performance. To improve efficient sample selection, we introduce an explanation-guided sample selection method that identifies samples challenging its reasoning by exploiting uncertainties in explanation steps. Additionally, we present a customized LLM-annotated explanation revision technique where the teacher model detects and corrects flaws in the student model's reasoning. Our experiments across various reasoning datasets demonstrate that our framework significantly enhances the efficiency of LLM knowledge distillation."
Liang Zhao,Robust Explanation Supervision for False Positive Reduction in Pulmonary Nodule Detection,2024,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.16937,"Lung cancer is the deadliest and second most common cancer in the United States due to the lack of symptoms for early diagnosis. Pulmonary nodules are small abnormal regions that can be potentially correlated to the occurrence of lung cancer. Early detection of these nodules is critical because it can significantly improve the patient's survival rates. Thoracic thin‐sliced computed tomography (CT) scanning has emerged as a widely used method for diagnosing and prognosis lung abnormalities.The standard clinical workflow of detecting pulmonary nodules relies on radiologists to analyze CT images to assess the risk factors of cancerous nodules. However, this approach can be error‐prone due to the various nodule formation causes, such as pollutants and infections. Deep learning (DL) algorithms have recently demonstrated remarkable success in medical image classification and …"
Liang Zhao,Multi-Prompt Fine-Tuning of Foundation Models for Enhanced Medical Image Segmentation,2024,https://link.springer.com/chapter/10.1007/978-3-031-63592-2_7,"The Segment Anything Model (SAM) is a powerful foundation model that introduced revolutionary advancements in natural image segmentation. However, its performance remains sub-optimal when delineating the intricate structure of biomedical images, where multiple organs and tissues intertwine in a single image. In this study, we introduce a novel fine-tuning framework that leverages SAM’s ability to bundle and process multiple prompts per image and seeks to improve SAM’s performance in medical images. We first curated a medical image dataset that consists of CT scans of lesions in various organs, each with two annotations for organs and lesions respectively. Then, we fine-tuned SAM’s mask decoder within our framework by batching both bounding boxes generated from ground truth masks as reference. The batched prompt strategy we introduced not only addresses the inherent complexity and …"
Liang Zhao,Saliency-guided hidden associative replay for continual learning,2023,https://arxiv.org/abs/2310.04334,"Continual Learning is a burgeoning domain in next-generation AI, focusing on training neural networks over a sequence of tasks akin to human learning. While CL provides an edge over traditional supervised learning, its central challenge remains to counteract catastrophic forgetting and ensure the retention of prior tasks during subsequent learning. Amongst various strategies to tackle this, replay based methods have emerged as preeminent, echoing biological memory mechanisms. However, these methods are memory intensive, often preserving entire data samples, an approach inconsistent with humans selective memory retention of salient experiences. While some recent works have explored the storage of only significant portions of data in episodic memory, the inherent nature of partial data necessitates innovative retrieval mechanisms. Current solutions, like inpainting, approximate full data reconstruction from partial cues, a method that diverges from genuine human memory processes. Addressing these nuances, this paper presents the Saliency Guided Hidden Associative Replay for Continual Learning. This novel framework synergizes associative memory with replay-based strategies. SHARC primarily archives salient data segments via sparse memory encoding. Importantly, by harnessing associative memory paradigms, it introduces a content focused memory retrieval mechanism, promising swift and near-perfect recall, bringing CL a step closer to authentic human memory processes. Extensive experimental results demonstrate the effectiveness of our proposed method for various continual learning tasks."
Liang Zhao,Distributed graph neural network training with periodic historical embedding synchronization,2022,https://www.researchgate.net/profile/Guangji-Bai-2/publication/361023266_Distributed_Graph_Neural_Network_Training_with_Periodic_Historical_Embedding_Synchronization/links/62d09d0597bb9e6b07b3df0b/Distributed-Graph-Neural-Network-Training-with-Periodic-Historical-Embedding-Synchronization.pdf,"Despite the recent success of Graph Neural Networks (GNNs), it remains challenging to train a GNN on large graphs (eg, with over millions of nodes & billions of edges), which are prevalent in various graph-based applications such as social networks, recommender systems, and knowledge graphs. Traditional sampling-based methods accelerate GNN by dropping edges and nodes, which impairs the graph integrity and model performance. Differently, distributed GNN algorithms, which accelerate GNN training by utilizing multiple computing devices, can be classified into two types:"" partition-based"" methods enjoy low communication cost but suffer from information loss due to dropped edges, while"" propagation-based"" methods avoid information loss but suffer prohibitive communication overhead caused by neighbor explosion. To jointly address these problems, this paper proposes DIstributed Graph Embedding SynchronizaTion (DIGEST), a novel distributed GNN training framework that synergizes the complementary strength of both categories of existing methods. During subgraph parallel training, we propose to let each device store the historical embedding of its neighbors in other subgraphs. Therefore, our method does not discard any neighbors in other subgraphs (which leads to information loss), nor does it updates them intensively (which leads to communication cost). This effectively avoids (1) the intensive computation on explosively-increasing neighbors and (2) excessive communications across different devices. We proved that the approximation error induced by the staleness of historical embedding can be upper bounded and it …"
Liang Zhao,Optimal resource allocation for multimedia applications offloading in mobile edge computing,2021,https://ieeexplore.ieee.org/abstract/document/9568722/,"Thanks to the development of the technologies in the wireless communications and Internet of Things (IoT), the adoption of mobile devices is growing rapidly. Accordingly, the number of multimedia applications like face recognition and augmented reality generated from various mobile devices is growing at an unprecedented rate. The processing of these multimedia applications needs a lot of computation resources and has to be processed as quickly as possible. However, as these mobile devices have limited computation resources, the undesirable response delay will occur. By offloading the multimedia applications to the edge cloud close to the access point (AP) or the cellular base station (BS), mobile edge computing (MEC) is considered as a prospective approach to improve the quality of service (QoS) and enhance the computing capacity of mobile devices. Multimedia applications offloading in a MEC system …"
Liang Zhao,TG-GAN: Deep Generative Models for Continuously-time Temporal Graph Generation,2021,https://scholar.google.com/scholar?cluster=4823616110268596424&hl=en&oi=scholarr,
Liang Zhao,Staleness-Alleviated Distributed GNN Training via Online Dynamic-Embedding Prediction,2025,https://arxiv.org/abs/2308.13466,"Despite the recent success of Graph Neural Networks (GNNs), it remains challenging to train GNNs on large-scale graphs due to neighbor explosions. As a remedy, distributed computing becomes a promising solution by leveraging abundant computing resources (e.g., GPU). However, the node dependency of graph data increases the difficulty of achieving high concurrency in distributed GNN training, which suffers from the massive communication overhead. To address it, Historical value approximation is deemed a promising class of distributed training techniques. It utilizes an offline memory to cache historical information (e.g., node embedding) as an affordable approximation of the exact value and achieves high concurrency. However, such benefits come at the cost of involving dated training information, leading to staleness, imprecision, and convergence issues. To overcome these challenges, this paper proposes SAT (Staleness-Alleviated Training), a novel and scalable distributed GNN training framework that reduces the embedding staleness adaptively. The key idea of SAT is to model the GNN's embedding evolution as a temporal graph and build a model upon it to predict future embedding, which effectively alleviates the staleness of the cached historical embedding. We propose an online algorithm to train the embedding predictor and the distributed GNN alternatively and further provide a convergence analysis. Empirically, we demonstrate that SAT can effectively reduce embedding staleness and thus achieve better performance and convergence speed on multiple large-scale graph datasets."
Liang Zhao,Source Localization for Cross Network Information Diffusion,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671624,"Source localization aims to locate information diffusion sources only given the diffusion observation, which has attracted extensive attention in the past few years. Existing methods are mostly tailored for single networks and may not be generalized to handle more complex networks like cross-networks. Cross-network is defined as two interconnected networks, where one network's functionality depends on the other. Source localization on cross-networks entails locating diffusion sources on the source network by only giving the diffused observation in the target network. The task is challenging due to challenges including: 1) diffusion sources distribution modeling; 2) jointly considering both static and dynamic node features; and 3) heterogeneous diffusion patterns learning. In this work, we propose a novel method, namely CNSL, to handle the three primary challenges. Specifically, we propose to learn the distribution …"
Liang Zhao,Gene-associated Disease Discovery Powered by Large Language Models,2024,https://arxiv.org/abs/2401.09490,"The intricate relationship between genetic variation and human diseases has been a focal point of medical research, evidenced by the identification of risk genes regarding specific diseases. The advent of advanced genome sequencing techniques has significantly improved the efficiency and cost-effectiveness of detecting these genetic markers, playing a crucial role in disease diagnosis and forming the basis for clinical decision-making and early risk assessment. To overcome the limitations of existing databases that record disease-gene associations from existing literature, which often lack real-time updates, we propose a novel framework employing Large Language Models (LLMs) for the discovery of diseases associated with specific genes. This framework aims to automate the labor-intensive process of sifting through medical literature for evidence linking genetic variations to diseases, thereby enhancing the efficiency of disease identification. Our approach involves using LLMs to conduct literature searches, summarize relevant findings, and pinpoint diseases related to specific genes. This paper details the development and application of our LLM-powered framework, demonstrating its potential in streamlining the complex process of literature retrieval and summarization to identify diseases associated with specific genetic variations."
Liang Zhao,Ordinal regression with pinball loss,2023,https://ieeexplore.ieee.org/abstract/document/10082947/,"Ordinal regression (OR) aims to solve multiclass classification problems with ordinal classes. Support vector OR (SVOR) is a typical OR algorithm and has been extensively used in OR problems. In this article, based on the characteristics of OR problems, we propose a novel pinball loss function and present an SVOR method with pinball loss (pin-SVOR). Pin-SVOR is fundamentally different from traditional SVOR with hinge loss. Traditional SVOR employs the hinge loss function, and the classifier is determined by only a few data points near the class boundary, called support vectors, which may lead to a noise sensitive and re-sampling unstable classifier. Distinctively, pin-SVOR employs the pinball loss function. It attaches an extra penalty to correctly classified data that lies inside the class, such that all the training data is involved in deciding the classifier. The data near the middle of each class has a small penalty …"
Liang Zhao,Saliency-Augmented Memory Completion for Continual Learning,2023,https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch28,"Continual Learning (CL) is considered a key step toward next-generation Artificial Intelligence. Among various methods, replay-based approaches that maintain and replay a small episodic memory of previous samples are one of the most successful strategies against catastrophic forgetting. However, since forgetting is inevitable given bounded memory and unbounded tasks, ‘how to forget’ is a problem continual learning must address. Therefore, beyond simply avoiding (catastrophic) forgetting, an under-explored issue is how to reasonably forget while ensuring the merits of human memory, including 1) storage efficiency, 2) generalizability, and 3) some interpretability. To achieve these simultaneously, our paper proposes a new saliency-augmented memory completion framework for continual learning, inspired by recent discoveries in memory completion/separation in cognitive neuroscience. Specifically, we …"
Liang Zhao,Functional connectivity prediction with deep learning for graph transformation,2022,https://ieeexplore.ieee.org/abstract/document/9869631/,"Inferring resting-state functional connectivity (FC) from anatomical brain wiring, known as structural connectivity (SC), is of enormous significance in neuroscience for understanding biological neuronal networks and treating mental diseases. Both SC and FC are networks where the nodes are brain regions, and in SC, the edges are the physical fiber nerves among the nodes, while in FC, the edges are the nodes’ coactivation relations. Despite the importance of SC and FC, until very recently, the rapidly growing research body on this topic has generally focused on either linear models or computational models that rely heavily on heuristics and simple assumptions regarding the mapping between FC and SC. However, the relationship between FC and SC is actually highly nonlinear and complex and contains considerable randomness; additional factors, such as the subject’s age and health, can also significantly …"
Liang Zhao,"DeepSpatial'22: The 3rd International Workshop on Deep Learning for Spatiotemporal Data, Applications, and Systems",2022,https://dl.acm.org/doi/abs/10.1145/3534678.3542905,"With the advancement of GPS and remote sensing technologies and the pervasiveness of smartphones and IoT devices, an enormous amount of spatiotemporal data are being collected from various domains. Knowledge discovery from spatiotemporal data is crucial in addressing many grand societal challenges, ranging from flood disaster management to monitoring coastal hazards, and from autonomous driving to disease forecasting. The recent success in deep learning technologies in computer vision and natural language processing provides new opportunities for spatiotemporal data mining, but existing deep learning techniques also face unique spatiotemporal challenges (e.g., autocorrelation, non-stationarity, physics awareness). This workshop provides a premium platform for researchers from both academia and industry to exchange ideas on the opportunities, challenges, and cutting-edge techniques …"
Liang Zhao,Multi-task manifold learning for partial label learning,2022,https://www.sciencedirect.com/science/article/pii/S0020025522003966,"In partial label learning (PLL), each instance is associated with a candidate label set, and only one label is ground-truth. PLL aims to identify the ground-truth label out of these candidate labels. Most of the existing PLL approaches focus on single-task PLL, and ignore the auxiliary information of the related tasks. This paper puts forward a novel multi-task manifold learning method for partial label learning (MT-PLL), which learns multiple PLL tasks jointly, and incorporates the auxiliary information of the related tasks to improve the performance of PLL classifiers. MT-PLL assumes that the graph manifold structure guides the generation of labeling confidence for instances in each task. In addition, the information of related tasks can be used to boost the performance of the overall classification model. Then, a heuristic framework is used to optimize the objective function. Numerical experiments have demonstrated that MT …"
Liang Zhao,"Deep Graph Transformation for Attributed, Directed, and Signed Networks",2021,https://link.springer.com/article/10.1007/s10115-021-01553-9,"Generalized from image and language translation, the goal of graph translation or transformation is to generate a graph of the target domain on the condition of an input graph of the source domain. Existing works are limited to either merely generating the node attributes of graphs with fixed topology or only generating the graph topology without allowing the node attributes to change. They are prevented from simultaneously generating both node and edge attributes due to: (1) difficulty in modeling the iterative, interactive, and asynchronous process of both node and edge translation and (2) difficulty in learning and preserving the inherent consistency between the nodes and edges in generated graphs. A general, end-to-end framework for jointly generating node and edge attributes is needed for real-world problems. In this paper, this generic problem of multi-attributed graph translation is named and a novel …"
Liang Zhao,Multi-relational graph convolutional networks for skeleton-based action recognition,2020,https://ieeexplore.ieee.org/abstract/document/9443675/,"In motion, the interaction relationship between the human body parts is diversified. However, the existing action recognition methods based on the graph convolution neural networks (GCNs) can only deal with a single relation of skeletons. Even some works describe different relations of the skeleton, the adjacency matrices of different relation graphs are added together. This paper proposes a multi-relational GCNs for action recognition following the idea of describing different relations between entities by knowledge graphs. The natural connection relation, symmetric connection relation, and global connection relation of the human body parts are modeled respectively. The features of the relations are transmitted and integrated through the network, which can improve the representation ability of features. Meanwhile, this paper proposes a two-stream multi-relational graph convolution networks (2S-MRGCNs), which …"
Liang Zhao,Slow Perception: Let's Perceive Geometric Figures Step-by-step,2024,https://arxiv.org/abs/2412.20631,"Recently, ""visual o1"" began to enter people's vision, with expectations that this slow-thinking design can solve visual reasoning tasks, especially geometric math problems. However, the reality is that current LVLMs (Large Vision Language Models) can hardly even accurately copy a geometric figure, let alone truly understand the complex inherent logic and spatial relationships within geometric shapes. We believe accurate copying (strong perception) is the first step to visual o1. Accordingly, we introduce the concept of ""slow perception"" (SP), which guides the model to gradually perceive basic point-line combinations, as our humans, reconstruct complex geometric structures progressively. There are two-fold stages in SP: a) perception decomposition. Perception is not instantaneous. In this stage, complex geometric figures are broken down into basic simple units to unify geometry representation. b) perception flow, which acknowledges that accurately tracing a line is not an easy task. This stage aims to avoid ""long visual jumps"" in regressing line segments by using a proposed ""perceptual ruler"" to trace each line stroke-by-stroke. Surprisingly, such a human-like perception manner enjoys an inference time scaling law -- the slower, the better. Researchers strive to speed up the model's perception in the past, but we slow it down again, allowing the model to read the image step-by-step and carefully."
Liang Zhao,MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization,2024,https://arxiv.org/abs/2402.16898,"Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as well as conduct extensive analyses on both synthetic and real-world datasets to validate our MIM-Reasoner's performance."
Liang Zhao,SST: Multi-Scale Hybrid Mamba-Transformer Experts for Long-Short Range Time Series Forecasting,2024,https://arxiv.org/abs/2404.14757,"Despite significant progress in time series forecasting, existing forecasters often overlook the heterogeneity between long-range and short-range time series, leading to performance degradation in practical applications. In this work, we highlight the need of distinct objectives tailored to different ranges. We point out that time series can be decomposed into global patterns and local variations, which should be addressed separately in long- and short-range time series. To meet the objectives, we propose a multi-scale hybrid Mamba-Transformer experts model State Space Transformer (SST). SST leverages Mamba as an expert to extract global patterns in coarse-grained long-range time series, and Local Window Transformer (LWT), the other expert to focus on capturing local variations in fine-grained short-range time series. With an input-dependent mechanism, State Space Model (SSM)-based Mamba is able to selectively retain long-term patterns and filter out fluctuations, while LWT employs a local window to enhance locality-awareness capability, thus effectively capturing local variations. To adaptively integrate the global patterns and local variations, a long-short router dynamically adjusts contributions of the two experts. SST achieves superior performance with scaling linearly  on time series length . The comprehensive experiments demonstrate the SST can achieve SOTA results in long-short range time series forecasting while maintaining low memory footprint and computational cost. The code of SST is available at https://github.com/XiongxiaoXu/SST."
Liang Zhao,3DPFIX: Improving Remote Novices' 3D Printing Troubleshooting Experience through Human-AI Collaboration Design,2024,,
Liang Zhao,Deep Spatial Prediction via Heterogeneous Multi-source Self-supervision,2023,https://dl.acm.org/doi/abs/10.1145/3605358,"Spatial prediction is to predict the values of the targeted variable, such as PM2.5 values and temperature, at arbitrary locations based on the collected geospatial data. It greatly affects the key research topics in geoscience in terms of obtaining heterogeneous spatial information (e.g., soil conditions, precipitation rates, wheat yields) for geographic modeling and decision-making at local, regional, and global scales. In situ data, collected by ground-level in situ sensors, and remote sensing data, collected by satellite or aircraft, are two important data sources for this task. In situ data are relatively accurate while sparse and unevenly distributed. Remote sensing data cover large spatial areas, but are coarse with low spatiotemporal resolution and prone to interference. How to synergize the complementary strength of these two data types is still a grand challenge. Moreover, it is difficult to model the unknown spatial …"
Liang Zhao,Sign-regularized multi-task learning,2023,https://arxiv.org/abs/2102.11191,"Multi-task learning is a framework that enforces different learning tasks to share their knowledge to improve their generalization performance. It is a hot and active domain that strives to handle several core issues; particularly, which tasks are correlated and similar, and how to share the knowledge among correlated tasks. Existing works usually do not distinguish the polarity and magnitude of feature weights and commonly rely on linear correlation, due to three major technical challenges in: 1) optimizing the models that regularize feature weight polarity, 2) deciding whether to regularize sign or magnitude, 3) identifying which tasks should share their sign and/or magnitude patterns. To address them, this paper proposes a new multi-task learning framework that can regularize feature weight signs across tasks. We innovatively formulate it as a biconvex inequality constrained optimization with slacks and propose a new efficient algorithm for the optimization with theoretical guarantees on generalization performance and convergence. Extensive experiments on multiple datasets demonstrate the proposed methods' effectiveness, efficiency, and reasonableness of the regularized feature weighted patterns."
Liang Zhao,Sign-regularized multi-task learning,2023,https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch89,"Multi-task learning is a framework that enforces different tasks to share their knowledge to improve the generalization performance. It is a long-standing active domain that strives to handle several core issues including which tasks are correlated and similar and how to share the knowledge among correlated tasks. Existing works usually do not distinguish the polarity and magnitude of feature weights and commonly rely on linear correlation, due to three major technical challenges in: 1) optimizing the models that regularize feature weight polarity, 2) deciding whether to regularize sign or magnitude, 3) identifying which tasks should share their sign and/or magnitude patterns. To address them, this paper proposes a new multi-task learning framework that can regularize feature weight signs across tasks, beyond the conventional framework for feature weight regularization. We innovatively formulate such sign …"
Liang Zhao,Ground truth explanation dataset for chemical property prediction on molecular graphs,2022,https://chemrxiv.org/engage/chemrxiv/article-details/6394242f04bc66042d0ffc94,"Interpretation of chemistry on an atomic scale improves with explainable artificial intelligence (XAI). The parts of the molecule with the most significant influence on the chemical property of interest can be visualized with atomwise and bondwise attributions. Nonetheless, the attributions from different XAI methods regularly disagree substantially, causing uncertainty about which explainability is correct. To determine a ground truth for attributions, we define chemical operations which avoid alchemical steps or approximations and allow extracting one attribution per atom or bond from existing datasets of chemical properties. This general procedure allows generating large datasets of ground truth attributions. The approach allowed us to create a ground truth explanation dataset with more than 5 million data points for the HOMO-LUMO gap chemical property. This open-source dataset of atomistic ground truth explainability may serve as a reference for XAI approaches."
Liang Zhao,Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-Sentence Dependency Graph,2022,https://ojs.aaai.org/index.php/AAAI/article/view/21407,"We target the task of cross-lingual Machine Reading Comprehension (MRC) in the direct zero-shot setting, by incorporating syntactic features from Universal Dependencies (UD), and the key features we use are the syntactic relations within each sentence. While previous work has demonstrated effective syntax-guided MRC models, we propose to adopt the inter-sentence syntactic relations, in addition to the rudimentary intra-sentence relations, to further utilize the syntactic dependencies in the multi-sentence input of the MRC task. In our approach, we build the Inter-Sentence Dependency Graph (ISDG) connecting dependency trees to form global syntactic relations across sentences. We then propose the ISDG encoder that encodes the global dependency graph, addressing the inter-sentence relations via both one-hop and multi-hop dependency paths explicitly. Experiments on three multilingual MRC datasets (XQuAD, MLQA, TyDiQA-GoldP) show that our encoder that is only trained on English is able to improve the zero-shot performance on all 14 test sets covering 8 languages, with up to 3.8 F1/5.2 EM improvement on-average, and 5.2 F1/11.2 EM on certain languages. Further analysis shows the improvement can be attributed to the attention on the cross-linguistically consistent syntactic path. Our code is available at https://github. com/lxucs/multilingual-mrc-isdg."
Liang Zhao,Convergence and Applications of ADMM on the Multi-convex Problems,2022,https://link.springer.com/chapter/10.1007/978-3-031-05936-0_3,"In recent years, although the Alternating Direction Method of Multipliers (ADMM) has been empirically applied widely to many multi-convex applications, delivering an impressive performance in areas such as nonnegative matrix factorization and sparse dictionary learning, there remains a dearth of generic work on proposed ADMM with a convergence guarantee under mild conditions. In this paper, we propose a generic ADMM framework with multiple coupled variables in both objective and constraints. Convergence to a Nash point is proven with a sublinear convergence rate o(1/k). Two important applications are discussed as special cases under our proposed ADMM framework. Extensive experiments on ten real-world datasets demonstrate the proposed framework’s effectiveness, scalability, and convergence properties. We have released our code at https://github.com/xianggebenben/miADMM."
Liang Zhao,Graph Neural Networks: AutoML,2022,https://link.springer.com/chapter/10.1007/978-981-16-6054-2_17,"Graph neural networks (GNNs) are efficient deep learning tools to analyze networked data. Being widely applied in graph analysis tasks, the rapid evolution of GNNs has led to a growing number of novel architectures. In practice, both neural architecture construction and training hyperparameter tuning are crucial to the node representation learning and the final model performance. However, as the graph data characteristics vary significantly in the real-world systems, given a specific scenario, rich human expertise and tremendous laborious trials are required to identify a suitable GNN architecture and training hyperparameters. Recently, automated machine learning (AutoML) has shown its potential in finding the optimal solutions automatically for machine learning applications. While releasing the burden of the manual tuning process, AutoML could guarantee access of the optimal solution without extensive …"
Liang Zhao,A convergent admm framework for efficient neural network training,2021,https://arxiv.org/abs/2112.11619,"As a well-known optimization framework, the Alternating Direction Method of Multipliers (ADMM) has achieved tremendous success in many classification and regression applications. Recently, it has attracted the attention of deep learning researchers and is considered to be a potential substitute to Gradient Descent (GD). However, as an emerging domain, several challenges remain unsolved, including 1) The lack of global convergence guarantees, 2) Slow convergence towards solutions, and 3) Cubic time complexity with regard to feature dimensions. In this paper, we propose a novel optimization framework to solve a general neural network training problem via ADMM (dlADMM) to address these challenges simultaneously. Specifically, the parameters in each layer are updated backward and then forward so that parameter information in each layer is exchanged efficiently. When the dlADMM is applied to specific architectures, the time complexity of subproblems is reduced from cubic to quadratic via a dedicated algorithm design utilizing quadratic approximations and backtracking techniques. Last but not least, we provide the first proof of convergence to a critical point sublinearly for an ADMM-type method (dlADMM) under mild conditions. Experiments on seven benchmark datasets demonstrate the convergence, efficiency, and effectiveness of our proposed dlADMM algorithm."
Liang Zhao,Integrating memory-mapping and N-dimensional hash function for fast and efficient grid-based climate data query,2021,https://www.tandfonline.com/doi/abs/10.1080/19475683.2020.1743354,"Database systems are pervasive components in the current big data era. However, efficiently managing and querying grid-based or array-based multidimensional climate data are still beyond the capabilities of most databases. The mismatch between the array data model and relational data model limited the performance to query multidimensional data in a traditional database when data volume hits a cap. Even a trivial data retrieval on large multidimensional datasets in a relational database is time-consuming and requires enormous storage space. Given the scientific interests and application demands on time-sensitive spatiotemporal data query and analysis, there is an urgent need for efficient data storage and fast data retrieval solutions on large multidimensional datasets. In this paper, we introduce a method for multidimensional data storing and accessing, which includes a new hash function algorithm that …"
Liang Zhao,Traffic Flow Forecasting,2021,https://scholar.google.com/scholar?cluster=15989466304507887372&hl=en&oi=scholarr,
Liang Zhao,Community-based Layer-wise Distributed Training of Graph Convolutional Networks,2021,https://arxiv.org/abs/2112.09335,"The Graph Convolutional Network (GCN) has been successfully applied to many graph-based applications. Training a large-scale GCN model, however, is still challenging: Due to the node dependency and layer dependency of the GCN architecture, a huge amount of computational time and memory is required in the training process. In this paper, we propose a parallel and distributed GCN training algorithm based on the Alternating Direction Method of Multipliers (ADMM) to tackle the two challenges simultaneously. We first split GCN layers into independent blocks to achieve layer parallelism. Furthermore, we reduce node dependency by dividing the graph into several dense communities such that each of them can be trained with an agent in parallel. Finally, we provide solutions for all subproblems in the community-based ADMM algorithm. Preliminary results demonstrate that our proposed community-based ADMM training algorithm can lead to more than triple speedup while achieving the best performance compared with state-of-the-art methods."
Liang Zhao,Online and Distributed Robust Regressions with Extremely Noisy Labels,2021,https://dl.acm.org/doi/abs/10.1145/3473038,"In today’s era of big data, robust least-squares regression becomes a more challenging problem when considering the extremely corrupted labels along with explosive growth of datasets. Traditional robust methods can handle the noise but suffer from several challenges when applied in huge dataset including (1) computational infeasibility of handling an entire dataset at once, (2) existence of heterogeneously distributed corruption, and (3) difficulty in corruption estimation when data cannot be entirely loaded. This article proposes online and distributed robust regression approaches, both of which can concurrently address all the above challenges. Specifically, the distributed algorithm optimizes the regression coefficients of each data block via heuristic hard thresholding and combines all the estimates in a distributed robust consolidation. In addition, an online version of the distributed algorithm is proposed to …"
Liang Zhao,A Review of Routing Protocols for Wireless Body Area Networks for Miner Safety,2020,https://ieeexplore.ieee.org/abstract/document/9443671/,"Monitoring the physical body indexes of working of mining industry is very essential. It is mainly because the complex operational environment of the underground mining field is more critical and requiring higher standards of body condition of the miners. However, it is still particularly hard to gather all types of body information in real-time if we apply the traditional wired network. In addition, even we apply the Bluetooth or Wi-Fi based e-watch or wristband, only limited typed data including heart rate can be collected and monitored which is far not enough for the hazard mining operation work. Thus, constructing Wireless Body Area Network (WBAN) is the optimal solution for such miner application. In particular, networking efficiency is extremely important in WBAN to enable the real-time data collection and analysis. Therefore, in this paper, we first introduce a list of well-known routing protocols of WBAN. Second, we …"
Liang Zhao,TG-GAN: Continuous-time temporal graph generation with deep generative models,2020,https://arxiv.org/abs/2005.08323,"The recent deep generative models for static graphs that are now being actively developed have achieved significant success in areas such as molecule design. However, many real-world problems involve temporal graphs whose topology and attribute values evolve dynamically over time, including important applications such as protein folding, human mobility networks, and social network growth. As yet, deep generative models for temporal graphs are not yet well understood and existing techniques for static graphs are not adequate for temporal graphs since they cannot 1) encode and decode continuously-varying graph topology chronologically, 2) enforce validity via temporal constraints, or 3) ensure efficiency for information-lossless temporal resolution. To address these challenges, we propose a new model, called ``Temporal Graph Generative Adversarial Network'' (TG-GAN) for continuous-time temporal graph generation, by modeling the deep generative process for truncated temporal random walks and their compositions. Specifically, we first propose a novel temporal graph generator that jointly model truncated edge sequences, time budgets, and node attributes, with novel activation functions that enforce temporal validity constraints under recurrent architecture. In addition, a new temporal graph discriminator is proposed, which combines time and node encoding operations over a recurrent architecture to distinguish the generated sequences from the real ones sampled by a newly-developed truncated temporal random walk sampler. Extensive experiments on both synthetic and real-world datasets demonstrate TG-GAN significantly …"
Liang Zhao,"GeoAI 2019 workshop report: The 3nd ACM SIGSPATIAL International Workshop on GeoAI: AI for Geographic Knowledge Discovery: Seattle, WA, USA-November 5, 2019",2020,https://dl.acm.org/doi/abs/10.1145/3383653.3383662,"Nowadays artificial intelligence (AI) is bringing tremendous opportunities and challenges to geospatial research. Big data enable computers to observe and learn the world from many different perspectives, while high performance machines support the development, training, and deployment of AI models within reasonable amount of time. Recent years have witnessed significant advances in the integration of geospatial study and AI in both academia and industry. There have already been many successful studies for both physical environment and human society. Focusing on modeling the physical nature, research has shown that deep learning can improve the representation of clouds that are smaller than the grid resolutions of climate models. Examining the human society, AI and natural language processing methods, such as word embeddings, help quantify changes in stereotypes and attitudes toward women …"
Liang Zhao,Tunable Subnetwork Splitting for Model-parallelism of Neural Network Training,2020,https://arxiv.org/abs/2009.04053,"Alternating minimization methods have recently been proposed as alternatives to the gradient descent for deep neural network optimization. Alternating minimization methods can typically decompose a deep neural network into layerwise subproblems, which can then be optimized in parallel. Despite the significant parallelism, alternating minimization methods are rarely explored in training deep neural networks because of the severe accuracy degradation. In this paper, we analyze the reason and propose to achieve a compelling trade-off between parallelism and accuracy by a reformulation called Tunable Subnetwork Splitting Method (TSSM), which can tune the decomposition granularity of deep neural networks. Two methods gradient splitting Alternating Direction Method of Multipliers (gsADMM) and gradient splitting Alternating Minimization (gsAM) are proposed to solve the TSSM formulation. Experiments on five benchmark datasets show that our proposed TSSM can achieve significant speedup without observable loss of training accuracy. The code has been released at https://github.com/xianggebenben/TSSM."
Liang Zhao,FedSpaLLM: Federated pruning of large language models,2025,https://arxiv.org/abs/2410.14852,"Large Language Models (LLMs) achieve state-of-the-art performance but are challenging to deploy due to their high computational and storage demands. Pruning can reduce model size, yet existing methods assume public access to calibration data, which is impractical for privacy-sensitive applications. To address the challenge of pruning LLMs in privacy-preserving settings, we propose FedSpaLLM, the first federated learning framework designed specifically for pruning LLMs. FedSpaLLM enables clients to prune their models locally based on private data while accounting for system heterogeneity and maintaining communication efficiency. Our framework introduces several key innovations: (1) a novel -norm aggregation function that ensures only non-zero weights are averaged across clients, preserving important model parameters; (2) an adaptive mask expansion technique that meets global sparsity targets while accommodating client-specific pruning decisions; and (3) a layer sampling strategy that reduces communication overhead and personalizes the pruning process based on client resources. Extensive experiments show that FedSpaLLM improves pruning performance in diverse federated settings. The source code will be released upon publication."
Liang Zhao,POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt Tuning,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671721,"Time series domain adaptation stands as a pivotal and intricate challenge with diverse applications, including but not limited to human activity recognition, sleep stage classification, and machine fault diagnosis. Despite the numerous domain adaptation techniques proposed to tackle this complex problem, they primarily focus on domain adaptation from a single source domain. Yet, it is more crucial to investigate domain adaptation from multiple domains due to the potential for greater improvements. To address this, three important challenges need to be overcome: 1). The lack of exploration to utilize domain-specific information for domain adaptation, 2). The difficulty to learn domain-specific information that changes over time, and 3). The difficulty to evaluate learned domain-specific information. In order to tackle these challenges simultaneously, in this paper, we introduce PrOmpt-based domaiN Discrimination …"
Liang Zhao,DUE: Dynamic Uncertainty-Aware Explanation Supervision via 3D Imputation,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671641,"Explanation supervision aims to enhance deep learning models by integrating additional signals to guide the generation of model explanations, showcasing notable improvements in both the predictability and explainability of the model. However, the application of explanation supervision to higher-dimensional data, such as 3D medical images, remains an under-explored domain. Challenges associated with supervising visual explanations in the presence of an additional dimension include: 1) spatial correlation changed, 2) lack of direct 3D annotations, and 3) uncertainty varies across different parts of the explanation. To address these challenges, we propose a Dynamic Uncertainty-aware Explanation supervision (DUE\footnoteCode available at: https://github.com/AlexQilong/DUE.) framework for 3D explanation supervision that ensures uncertainty-aware explanation guidance when dealing with sparsely …"
Liang Zhao,Visual Attention Prompted Prediction and Learning,2024,https://arxiv.org/abs/2310.08420,"Visual explanation (attention)-guided learning uses not only labels but also explanations to guide model reasoning process. While visual attention-guided learning has shown promising results, it requires a large number of explanation annotations that are time-consuming to prepare. However, in many real-world situations, it is usually desired to prompt the model with visual attention without model retraining. For example, when doing AI-assisted cancer classification on a medical image, users (e.g., clinicians) can provide the AI model with visual attention prompt on which areas are indispensable and which are precluded. Despite its promising objectives, achieving visual attention-prompted prediction presents several major challenges: 1) How can the visual prompt be effectively integrated into the model's reasoning process? 2) How should the model handle samples that lack visual prompts? 3) What is the impact on the model's performance when a visual prompt is imperfect? This paper introduces a novel framework for attention-prompted prediction and learning, utilizing visual prompts to steer the model's reasoning process. To improve performance in non-prompted situations and align it with prompted scenarios, we propose a co-training approach for both non-prompted and prompted models, ensuring they share similar parameters and activations. Additionally, for instances where the visual prompt does not encompass the entire input image, we have developed innovative attention prompt refinement methods. These methods interpolate the incomplete prompts while maintaining alignment with the model's explanations. Extensive …"
Liang Zhao,TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing Graph and Text Mutual Transformations,2024,https://arxiv.org/abs/2405.16800,"Text-Attributed Graphs (TAGs) enhance graph structures with natural language descriptions, enabling detailed representation of data and their relationships across a broad spectrum of real-world scenarios. Despite the potential for deeper insights, existing TAG representation learning primarily relies on supervised methods, necessitating extensive labeled data and limiting applicability across diverse contexts. This paper introduces a new self-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA), which overcomes these constraints by integrating TAGs' structural and semantic dimensions. TAGA constructs two complementary views: Text-of-Graph view, which organizes node texts into structured documents based on graph topology, and the Graph-of-Text view, which converts textual nodes and connections into graph data. By aligning representations from both views, TAGA captures joint textual and structural information. In addition, a novel structure-preserving random walk algorithm is proposed for efficient training on large-sized TAGs. Our framework demonstrates strong performance in zero-shot and few-shot scenarios across eight real-world datasets."
Liang Zhao,Continuous temporal domain generalization,2024,https://arxiv.org/abs/2405.16075,"Temporal Domain Generalization (TDG) addresses the challenge of training predictive models under temporally varying data distributions. Traditional TDG approaches typically focus on domain data collected at fixed, discrete time intervals, which limits their capability to capture the inherent dynamics within continuous-evolving and irregularly-observed temporal domains. To overcome this, this work formalizes the concept of Continuous Temporal Domain Generalization (CTDG), where domain data are derived from continuous times and are collected at arbitrary times. CTDG tackles critical challenges including: 1) Characterizing the continuous dynamics of both data and models, 2) Learning complex high-dimensional nonlinear dynamics, and 3) Optimizing and controlling the generalization across continuous temporal domains. To address them, we propose a Koopman operator-driven continuous temporal domain generalization (Koodos) framework. We formulate the problem within a continuous dynamic system and leverage the Koopman theory to learn the underlying dynamics; the framework is further enhanced with a comprehensive optimization strategy equipped with analysis and control driven by prior knowledge of the dynamics patterns. Extensive experiments demonstrate the effectiveness and efficiency of our approach. The code can be found at: https://github.com/Zekun-Cai/Koodos."
Liang Zhao,Dynamic identification of important nodes in complex networks based on the KPDN–INCC method,2024,https://www.nature.com/articles/s41598-024-56226-8,"This article focuses on the cascading failure problem and node importance evaluation method in complex networks. To address the issue of identifying important nodes in dynamic networks, the method used in static networks is introduced and the necessity of re-evaluating node status during node removal is proposed. Studies have found that the methods for identifying dynamic and static network nodes are two different directions, and most literature only uses dynamic methods to verify static methods. Therefore, it is necessary to find suitable node evaluation methods for dynamic networks. Based on this, this article proposes a method that integrates local and global correlation properties. In terms of global features, we introduce an improved k-shell method with fusion degree to improve the resolution of node ranking. In terms of local features, we introduce Solton factor and structure hole factor improved by INCC …"
Liang Zhao,Artificial intelligence for climate smart forestry: a forward looking vision,2023,https://ieeexplore.ieee.org/abstract/document/10431570/,"Forests and forest ecosystems are vital to our social, economic, and environmental well-being. However, climate change and climate-driven disturbances (CDDs) are undermining the health and resilience of forests worldwide and pose significant uncertainty to sustainable forest management. Climate-smart forestry (CSF) remains a grand challenge in practice due to our limited knowledge of how forests respond to climate change and our abilities to collect related information to empower decision making. Rapid advances in artificial intelligence (AI) can offer a timely opportunity to address the challenges in CSF. We argue that the AI-enabled, next-generation CSF can be achievable through synergistically coordinated and transdisciplinary efforts that develop and advance foundational and use-inspired AI technologies that can lead to building next-generation forest decision support systems."
Liang Zhao,Surrocbm: Concept bottleneck surrogate models for generative post-hoc explanation,2023,https://arxiv.org/abs/2310.07698,"Explainable AI seeks to bring light to the decision-making processes of black-box models. Traditional saliency-based methods, while highlighting influential data segments, often lack semantic understanding. Recent advancements, such as Concept Activation Vectors (CAVs) and Concept Bottleneck Models (CBMs), offer concept-based explanations but necessitate human-defined concepts. However, human-annotated concepts are expensive to attain. This paper introduces the Concept Bottleneck Surrogate Models (SurroCBM), a novel framework that aims to explain the black-box models with automatically discovered concepts. SurroCBM identifies shared and unique concepts across various black-box models and employs an explainable surrogate model for post-hoc explanations. An effective training strategy using self-generated data is proposed to enhance explanation quality continuously. Through extensive experiments, we demonstrate the efficacy of SurroCBM in concept discovery and explanation, underscoring its potential in advancing the field of explainable AI."
Liang Zhao,Beyond One-Model-Fits-All: A Survey of Domain Specialization for Large Language Models. CoRR abs/2305.18703 (2023),2023,https://scholar.google.com/scholar?cluster=5894203120762971483&hl=en&oi=scholarr,
Liang Zhao,Factorized Deep Generative Models for Trajectory Generation with Spatiotemporal-Validity Constraints,2022,https://arxiv.org/abs/2009.09333,"Trajectory data generation is an important domain that characterizes the generative process of mobility data. Traditional methods heavily rely on predefined heuristics and distributions and are weak in learning unknown mechanisms. Inspired by the success of deep generative neural networks for images and texts, a fast-developing research topic is deep generative models for trajectory data which can learn expressively explanatory models for sophisticated latent patterns. This is a nascent yet promising domain for many applications. We first propose novel deep generative models factorizing time-variant and time-invariant latent variables that characterize global and local semantics, respectively. We then develop new inference strategies based on variational inference and constrained optimization to encapsulate the spatiotemporal validity. New deep neural network architectures have been developed to implement the inference and generation models with newly-generalized latent variable priors. The proposed methods achieved significant improvements in quantitative and qualitative evaluations in extensive experiments."
Liang Zhao,Distributed Graph Neural Network Training with Periodic Stale Representation Synchronization,2022,https://arxiv.org/abs/2206.00057,"Despite the recent success of Graph Neural Networks, it remains challenging to train a GNN on large graphs with millions of nodes and billions of edges, which are prevalent in many graph-based applications. Traditional sampling-based methods accelerate GNN training by dropping edges and nodes, which impairs the graph integrity and model performance. Differently, distributed GNN algorithms accelerate GNN training by utilizing multiple computing devices and can be classified into two types: ""partition-based"" methods enjoy low communication costs but suffer from information loss due to dropped edges, while ""propagation-based"" methods avoid information loss but suffer from prohibitive communication overhead caused by the neighbor explosion. To jointly address these problems, this paper proposes DIGEST (DIstributed Graph reprEsentation SynchronizaTion), a novel distributed GNN training framework that synergizes the complementary strength of both categories of existing methods. We propose to allow each device to utilize the stale representations of its neighbors in other subgraphs during subgraph parallel training. This way, our method preserves global graph information from neighbors to avoid information loss and reduce communication costs. Our convergence analysis demonstrates that DIGEST enjoys a state-of-the-art convergence rate. Extensive experimental evaluation on large, real-world graph datasets shows that DIGEST achieves up to 21.82 speedups without compromising performance compared to state-of-the-art distributed GNN training frameworks."
Liang Zhao,Convergence and Applications of Alternating Direction Method of Multipliers on the Multi-convex Problems,2022,https://scholar.google.com/scholar?cluster=14651611286749751141&hl=en&oi=scholarr,
Liang Zhao,Graph Neural Networks,2022,https://scholar.google.com/scholar?cluster=10308276396017195588&hl=en&oi=scholarr,
Liang Zhao,"Yuanqi Du, Yinkai Wang, Yanfang Ye",2022,https://scholar.google.com/scholar?cluster=17367487772241613413&hl=en&oi=scholarr,
Liang Zhao,"Hengning Can, Yanfang Ye, and Liang Zhao. Disentangled Spatiotemporal Graph Generative Model",2022,https://scholar.google.com/scholar?cluster=6112592538434834510&hl=en&oi=scholarr,
Liang Zhao,"The 28th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2020) virtual, online, USA November 3--6, 2020: conference report",2021,https://dl.acm.org/doi/abs/10.1145/3447994.3447997,"This report describes the development and finalization of the 28th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2020), held virtually online, November 3-6, 2020. The attendance for the 2020 conference was 999, the highest in the history of ACM SIGSPATIAL."
Liang Zhao,Online dynamic multi-source feature learning and its application to spatio-temporal event forecasting,2021,https://par.nsf.gov/servlets/purl/10292367,"The forecasting of significant societal events such as civil unrest and economic crisis is an interesting and challenging problem which requires both timeliness, precision, and comprehensiveness. Significant societal events are influenced and indicated jointly by multiple aspects of a society, including its economics, politics, and culture. Traditional forecasting methods based on a single data source find it hard to cover all these aspects comprehensively, thus limiting model performance. Multi-source event forecasting has proven promising but still suffers from several challenges, including 1) geographical hierarchies in multi-source data features, 2) hierarchical missing values, 3) characterization of structured feature sparsity, and 4) difficulty in model’s online update with incomplete multiple sources. This paper proposes a novel feature learning model that concurrently addresses all the above challenges. Specifically, given multi-source data from different geographical levels, we design a new forecasting model by characterizing the lower-level features’ dependence on higher-level features. To handle the correlations amidst structured feature sets and deal with missing values among the coupled features, we propose a novel feature learning model based on an 𝑁th-order strong hierarchy and fused-overlapping group Lasso. An efficient algorithm is developed to optimize model parameters and ensure global optima. More importantly, to enable the model update in real time, the online learning algorithm is formulated and active set techniques are leveraged to resolve the crucial challenge when new patterns of missing features appear in real time …"
Liang Zhao,Analysis of LTE and NR Shared Spectrum Based on Traffic Load,2020,https://link.springer.com/chapter/10.1007/978-981-33-4102-9_114,"Deploying LTE and NR n41 band at 2.6 GHz can resolve both 4G capacity crisis and 5G coverage shortage, and also can accelerate rapid network construction and deployment. Meanwhile, TDD system means a time division system, in which the time slot synchronization needs to be configured precisely in the network. The transmission ratio of the uplink and downlink sub-frame is the same. Also, the uplink and downlink conversion points need remain same.Current 4G network load and handset penetration also need be concerned. In this paper, the network capacity planning in the process of NR n41 in 2.6 GHz band and cooperative LTE-NR networking is analyzed. This paper further plans the time slot alignment to be considered when sharing Active Antenna Unit (AAU) solution in collaborative networking is offered. Meanwhile, the time slot alignment is further planned to achieve NR and LTE …"
Liang Zhao,From interatomic distances to protein tertiary structures with a deep convolutional neural network,2020,https://dl.acm.org/doi/abs/10.1145/3388440.3414699,"Elucidating biologically-active protein structures remains a daunting task both in the wet and dry laboratory, and many proteins lack structural characterization. This lack of knowledge continues to motivate the development of computational methods for protein structure prediction. Methods are diverse in their approaches, and recent efforts have debuted deep learning-based methods for various sub-problems within the larger problem of protein structure prediction. In this paper, we focus on such a sub-problem, the reconstruction of three-dimensional structures consistent with given inter-atomic distances. Inspired by a recent architecture put forward in the larger context of generative frameworks, we design and evaluate a deep convolutional network model on experimentally- and computationally-obtained tertiary structures. Comparison with convex and stochastic optimization-based methods shows that the deep …"
Liang Zhao,Unhackable temporal rewarding for scalable video mllms,2025,https://arxiv.org/abs/2502.12081,"In the pursuit of superior video-processing MLLMs, we have encountered a perplexing paradox: the ""anti-scaling law"", where more data and larger models lead to worse performance. This study unmasks the culprit: ""temporal hacking"", a phenomenon where models shortcut by fixating on select frames, missing the full video narrative. In this work, we systematically establish a comprehensive theory of temporal hacking, defining it from a reinforcement learning perspective, introducing the Temporal Perplexity (TPL) score to assess this misalignment, and proposing the Unhackable Temporal Rewarding (UTR) framework to mitigate the temporal hacking. Both theoretically and empirically, TPL proves to be a reliable indicator of temporal modeling quality, correlating strongly with frame activation patterns. Extensive experiments reveal that UTR not only counters temporal hacking but significantly elevates video comprehension capabilities. This work not only advances video-AI systems but also illuminates the critical importance of aligning proxy rewards with true objectives in MLLM development."
Liang Zhao,Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions,2025,https://arxiv.org/abs/2502.18470,"Spatial reasoning remains a challenge for Large Language Models (LLMs), which struggle with spatial data retrieval and reasoning. We propose Spatial Retrieval-Augmented Generation (Spatial-RAG), a framework that extends RAG to spatial tasks by integrating sparse spatial retrieval (spatial databases) and dense semantic retrieval (LLM-based similarity). A multi-objective ranking strategy balances spatial constraints and semantic relevance, while an LLM-guided generator ensures coherent responses. Experiments on a real-world tourism dataset show that Spatial-RAG significantly improves spatial question answering, bridging the gap between LLMs and spatial intelligence."
Liang Zhao,Deep Multi-Task Learning for Spatio-Temporal Incomplete Qualitative Event Forecasting,2024,https://ieeexplore.ieee.org/abstract/document/10679926/,"Forecasting spatiotemporal social events has significant benefits for society to provide the proper amounts and types of resources to manage catastrophes and any accompanying societal risks. Nevertheless, forecasting event subtypes are far more complex than merely extending binary prediction to cover multiple subtypes because of spatial heterogeneity, experiencing a partial set of event subtypes, subtle discrepancy among different event subtypes, nature of the event subtype, spatial correlation of event subtypes. We present Deep multi-task learning for spatio-temporal incomplete qualitative event forecasting (DETECTIVE) framework to effectively forecast the subtypes of future events by addressing all these issues. This formulates spatial locations into tasks to handle spatial heterogeneity in event subtypes and learns a joint deep representation of subtypes across tasks. This has the adaptability to be used for …"
Liang Zhao,Link Prediction on Textual Edge Graphs,2024,https://arxiv.org/abs/2405.16606,"Textual-edge Graphs (TEGs), characterized by rich text annotations on edges, are increasingly significant in network science due to their ability to capture rich contextual information among entities. Existing works have proposed various edge-aware graph neural networks (GNNs) or let language models directly make predictions. However, they often fall short of fully capturing the contextualized semantics on edges and graph topology, respectively. This inadequacy is particularly evident in link prediction tasks that require a comprehensive understanding of graph topology and semantics between nodes. In this paper, we present a novel framework - Link2Doc, designed especially for link prediction on textual-edge graphs. Specifically, we propose to summarize neighborhood information between node pairs as a human-written document to preserve both semantic and topology information. A self-supervised learning model is then utilized to enhance GNN's text-understanding ability from language models. Empirical evaluations, including link prediction, edge classification, parameter analysis, runtime comparison, and ablation studies, on four real-world datasets demonstrate that Link2Doc achieves generally better performance against existing edge-aware GNNs and pre-trained language models in predicting links on TEGs."
Liang Zhao,Quantifying uncertainty in graph neural network explanations,2024,https://www.frontiersin.org/articles/10.3389/fdata.2024.1392662/full,"In recent years, analyzing the explanation for the prediction of Graph Neural Networks (GNNs) has attracted increasing attention. Despite this progress, most existing methods do not adequately consider the inherent uncertainties stemming from the randomness of model parameters and graph data, which may lead to overconfidence and misguiding explanations. However, it is challenging for most of GNN explanation methods to quantify these uncertainties since they obtain the prediction explanation in a post-hoc and model-agnostic manner without considering the randomness of graph data and model parameters. To address the above problems, this paper proposes a novel uncertainty quantification framework for GNN explanations. For mitigating the randomness of graph data in the explanation, our framework accounts for two distinct data uncertainties, allowing for a direct assessment of the uncertainty in GNN explanations. For mitigating the randomness of learned model parameters, our method learns the parameter distribution directly from the data, obviating the need for assumptions about specific distributions. Moreover, the explanation uncertainty within model parameters is also quantified based on the learned parameter distributions. This holistic approach can integrate with any post-hoc GNN explanation methods. Empirical results from our study show that our proposed method sets a new standard for GNN explanation performance across diverse real-world graph benchmarks."
Liang Zhao,STES: A Spatiotemporal Explanation Supervision Framework,2024,https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.9,"Explanation supervision is a technique that guides a deep learning model to have correct attention during training and thus improve both the interpretability and predictability of the model. However, the exploration of explanation supervision methods for spatiotemporal prediction has been limited. In this paper, we propose a framework for explanation-supervised spatiotemporal forecasting which aims to explicitly incorporate human-annotated spatiotemporal explanations as supervision signals, achieved by introducing a unique objective that integrates human explanations for general spa-tiotemporal predictive models. Specifically, to extend the explanation supervision technique to spatiotemporal prediction, our framework addresses several inherent challenges associated with spatiotemporal data. Firstly, it tackles the difficulty of identifying and correcting the spatiotemporal reasoning process. Secondly, it …"
Liang Zhao,Self-Similar Graph Neural Network for Hierarchical Graph Learning,2024,https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.4,"Many real-world networks, such as graph-structured molecules or social networks, exhibit latent hierarchical structures at many different resolutions. Existing hierarchical graph neural networks (GNNs) mainly focus on modifying graph global pooling regions into partitioned clusters, while keeping the convolutional layers unchanged. However, these approaches may suffer from a loss of expressive power in learned representations due to the uncontrolled growth of the neighborhood, leading to a failure in capturing true hierarchies. Furthermore, many real-world hierarchical graphs possess an underlying fractal structure, which is crucial to unraveling the formation mechanism of networks. Unfortunately, existing hierarchical GNNs often overlook this important aspect of graph hierarchy. To tackle these challenges, this paper proposes a generic framework for hierarchical network representation learning. We propose …"
Liang Zhao,Committee member,2024,https://ieeexplore.ieee.org/abstract/document/10748301/,"The 2024 3 rd  International Conference on Artificial Intelligence, Internet of Things and Cloud Computing Technology (AIoTC 2024) was successfully held from September 13 th  to 15 th , 2024, right in Wuhan, China via hybrid form. Over the three days, we witnessed an extraordinary gathering of intellects from around the globe who shared their cutting-edge research, insights, and experiences in the fields of Artificial Intelligence (AI), Internet of Things (IoT) and Cloud Computing, making the conference a crucible of innovation and knowledge exchange."
Liang Zhao,Open-ended Commonsense Reasoning with Unrestricted Answer Scope,2023,https://arxiv.org/abs/2310.11672,"Open-ended Commonsense Reasoning is defined as solving a commonsense question without providing 1) a short list of answer candidates and 2) a pre-defined answer scope. Conventional ways of formulating the commonsense question into a question-answering form or utilizing external knowledge to learn retrieval-based methods are less applicable in the open-ended setting due to an inherent challenge. Without pre-defining an answer scope or a few candidates, open-ended commonsense reasoning entails predicting answers by searching over an extremely large searching space. Moreover, most questions require implicit multi-hop reasoning, which presents even more challenges to our problem. In this work, we leverage pre-trained language models to iteratively retrieve reasoning paths on the external knowledge base, which does not require task-specific supervision. The reasoning paths can help to identify the most precise answer to the commonsense question. We conduct experiments on two commonsense benchmark datasets. Compared to other approaches, our proposed method achieves better performance both quantitatively and qualitatively."
Liang Zhao,JGAT: A joint spatio-temporal graph attention model for brain decoding,2023,https://arxiv.org/abs/2306.05286,"The decoding of brain neural networks has been an intriguing topic in neuroscience for a well-rounded understanding of different types of brain disorders and cognitive stimuli. Integrating different types of connectivity, e.g., Functional Connectivity (FC) and Structural Connectivity (SC), from multi-modal imaging techniques can take their complementary information into account and therefore have the potential to get better decoding capability. However, traditional approaches for integrating FC and SC overlook the dynamical variations, which stand a great chance to over-generalize the brain neural network. In this paper, we propose a Joint kernel Graph Attention Network (JGAT), which is a new multi-modal temporal graph attention network framework. It integrates the data from functional Magnetic Resonance Images (fMRI) and Diffusion Weighted Imaging (DWI) while preserving the dynamic information at the same time. We conduct brain-decoding tasks with our JGAT on four independent datasets: three of 7T fMRI datasets from the Human Connectome Project (HCP) and one from animal neural recordings. Furthermore, with Attention Scores (AS) and Frame Scores (FS) computed and learned from the model, we can locate several informative temporal segments and build meaningful dynamical pathways along the temporal domain for the HCP datasets. The URL to the code of JGAT model: https://github.com/BRAINML-GT/JGAT."
Liang Zhao,Domain Generalization Deep Graph Transformation,2023,https://arxiv.org/abs/2305.11389,"Graph transformation that predicts graph transition from one mode to another is an important and common problem. Despite much progress in developing advanced graph transformation techniques in recent years, the fundamental assumption typically required in machine-learning models that the testing and training data preserve the same distribution does not always hold. As a result, domain generalization graph transformation that predicts graphs not available in the training data is under-explored, with multiple key challenges to be addressed including (1) the extreme space complexity when training on all input-output mode combinations, (2) difference of graph topologies between the input and the output modes, and (3) how to generalize the model to (unseen) target domains that are not in the training data. To fill the gap, we propose a multi-input, multi-output, hypernetwork-based graph neural network (MultiHyperGNN) that employs a encoder and a decoder to encode topologies of both input and output modes and semi-supervised link prediction to enhance the graph transformation task. Instead of training on all mode combinations, MultiHyperGNN preserves a constant space complexity with the encoder and the decoder produced by two novel hypernetworks. Comprehensive experiments show that MultiHyperGNN has a superior performance than competing models in both prediction and domain generalization tasks."
Liang Zhao,On Unsupervised Reconstruction with Dressed Multilayered Variational Quantum Circuits,2022,https://ieeexplore.ieee.org/abstract/document/10216554/,"The advantages of unsupervised quantum machine learning are still under study and appear to be very promising. Trainable variational quantum circuits are one example of successful approaches to combining classic machine learning and quantum. However, there is no clear path toward a quantum advantage for different types of variational circuits. This paper furthers the research efforts in understanding the potential and applications of hybrid quantum circuits. We study different circuits and see how similar they perform in an unsupervised learning task in an autoencoder configuration over a large multimodal dataset."
Liang Zhao,Clip-acqua: Clip autoencoder-based classic-quantum latent space reduction,2022,https://www.rivas.ai/pdfs/rivas2022clip.pdf,"Applications of quantum machine learning algorithms are currently still being studied. Recent work suggests that classical gradient descent techniques can effectively train variational quantum circuits. We propose to train quantum variational circuits to find smaller text and image embeddings that preserve contrastive-learning distances based on CLIP large embeddings. This is a critical task since fine-tuning CLIP to produce low-dimensional embeddings is prohibitively expensive. We introduce CLIP-ACQUA, a model trained in a self-supervised configuration from CLIP embeddings to reduce the latent space. We use CLIP-ACQUA on a sizeable unlabelled corpus of text and images to demonstrate its effectiveness. Our experiments show that we can obtain smaller latent spaces that preserve the original embedding distances inferred during contrastive learning. Furthermore, using our model requires no fine-tuning of CLIP, preserving its original robustness and structure. The data used aids in modeling consumer-to-consumer online marketplaces."
Liang Zhao,Property-Controllable Generation of Quaternary Ammonium Compounds,2022,https://ieeexplore.ieee.org/abstract/document/9995064/,"Designing molecules with desired biological properties remains an outstanding challenge both in the wet and dry laboratories. Meeting this challenge promises great translational impacts across drug discovery, material sciences, biotechnology, and more. Recent momentum in deep learning promises to advance our computational capabilities on molecule generation. In particular, deep graph generative models which treat molecule design as a graph generation problem are allowing us to directly learn from existing databases of small molecules and generate novel, valid molecules. Currently, these models have many shortcomings, including poor controllability of desired molecular properties, especially in practical application where the training data is usually small, noisy, and incomplete. This paper focuses on equipping graph variational autoencoders with the ability to control for desired properties and its …"
Liang Zhao,Graph Neural Networks in Software Mining,2022,https://link.springer.com/chapter/10.1007/978-981-16-6054-2_23,"Software Mining encompasses a broad range of tasks involving software, such as finding the location of a bug in the source code of a program, generating natural language descriptions of software behavior, and detecting when two programs do basically the same thing. Software tends to have an extremely well-defined structure, due to the linguistic confines of source code and the need for programmers to maintain readability and compatibility when working on large teams. A tradition of graph-based representations of software has therefore proliferated. Meanwhile, advances in software repository maintenance have recently helped create very large datasets of source code. The result is fertile ground for Graph Neural Network representations of software to facilitate a plethora of software mining tasks. This chapter will provide a brief history of these representations, describe typical software mining tasks that …"
Liang Zhao,Graph Neural Networks in Computer Vision,2022,https://link.springer.com/chapter/10.1007/978-981-16-6054-2_20,"Recently Graph Neural Networks (GNNs) have been incorporated into many Computer Vision (CV) models. They not only bring performance improvement to many CV-related tasks but also provide more explainable decomposition to these CV models. This chapter provides a comprehensive overview of how GNNs are applied to various CV tasks, ranging from single image classification to crossmedia understanding. It also provides a discussion of this rapidly growing field from a frontier perspective."
Liang Zhao,Beam Pattern Fingerprinting with Missing Features for Spoofing Attack Detection in Millimeter-Wave Networks,2022,https://dl.acm.org/doi/abs/10.1145/3522783.3529522,"As one of the key enabling technologies of 5G wireless communication, millimeter-Wave (mmWave) technology unlocks the ultra-wide bandwidth opportunity in supporting high-throughput (e.g., multi-Gbps) and ultra-low latency applications at much lower cost-per-bit. However, due to the broadcast nature of wireless medium, like sub-6GHz communication, mmWave communication is still subject to various attacks, such as the identity spoofing attacks. Recently, beam pattern fingerprinting using the signal-to-noise-ratio (SNR) traces obtained during the beam sweeping process has been proposed to detect spoofing attacks in mmWave networks. However, a complete beam sweeping that tests all the tx-rx beam pairs is not always applied in practice. That is, to save link initialization or maintenance overhead, the implementation of efficient beam management schemes usually only probes a subset of tx-rx beam pairs …"
Liang Zhao,Intelligent UAV-aided controller placement scheme for software-defined vehicular networks,2021,https://dl.acm.org/doi/abs/10.1145/3457388.3458809,"Recently, researchers have used long short-term memory (LSTM) networks and the bi-directional long short-term memory (Bi-LSTM) networks to process sequence data sets such as vehicle positions in software-defined vehicular networks (SDVN). In this paper, we present a three-component intelligent UAV-aided controller placement scheme (CPP) for SDVN. First, we use Bi-LSTM to model the real-time position of vehicles (traffic flow). Second, we implement a dynamic scheme to place controllers and UAVs (DCUPE) in the network based on the predicted flow. Third, in order to collect real-time traffic information and manage the network, we compute trajectories for the UAVs from real-time Bi-LSTM predictions of vehicle positions and an adaptive artificial bee colony algorithm for the traveling salesman problem (IDABC-TSP). We evaluate our proposed design as a function of energy cost, communication delay, and …"
Liang Zhao,A new teaching-objective achievement based adaptive teaching continuous improvement method,2020,https://ieeexplore.ieee.org/abstract/document/9368409/,"In this paper, an adaptive continuous improvement method for teaching is introduced to meet the new requirements of the engineering education accreditation on the curriculum. Given the teaching-objectives, the teaching method is improved from two aspects, dynamic adjustment in a single round of teaching and continuous improvement in multi-round of teaching. During a semester, the fuzzy S-P table is used to analyze the student scores of assignments and experiments in the current teaching stage, and the teaching strategy in next-stage is fine tuned according to the analysis results to adapt to the actual learning status of students. At the end of each semester, the learning effect of students and the teaching effect of the course are summarized. Then, the analysis results are applied to improve the next round of teaching. The analysis results of the use case of the network interconnection technology course show …"
Liang Zhao,Deep Identification of Propagation Trees,2025,https://arxiv.org/abs/2503.00646,"Understanding propagation structures in graph diffusion processes, such as epidemic spread or misinformation diffusion, is a fundamental yet challenging problem. While existing methods primarily focus on source localization, they cannot reconstruct the underlying propagation trees i.e., ""who infected whom"", which are substantial for tracking the propagation pathways and investigate diffusion mechanisms. In this work, we propose Deep Identification of Propagation Trees (DIPT), a probabilistic framework that infers propagation trees from observed diffused states. DIPT models local influence strengths between nodes and leverages an alternating optimization strategy to jointly learn the diffusion mechanism and reconstruct the propagation structure. Extensive experiments on five real-world datasets demonstrate the effectiveness of DIPT in accurately reconstructing propagation trees."
Liang Zhao,Network Tomography with Path-Centric Graph Neural Network,2025,https://arxiv.org/abs/2502.16430,"Network tomography is a crucial problem in network monitoring, where the observable path performance metric values are used to infer the unobserved ones, making it essential for tasks such as route selection, fault diagnosis, and traffic control. However, most existing methods either assume complete knowledge of network topology and metric formulas-an unrealistic expectation in many real-world scenarios with limited observability-or rely entirely on black-box end-to-end models. To tackle this, in this paper, we argue that a good network tomography requires synergizing the knowledge from both data and appropriate inductive bias from (partial) prior knowledge. To see this, we propose Deep Network Tomography (DeepNT), a novel framework that leverages a path-centric graph neural network to predict path performance metrics without relying on predefined hand-crafted metrics, assumptions, or the real network topology. The path-centric graph neural network learns the path embedding by inferring and aggregating the embeddings of the sequence of nodes that compose this path. Training path-centric graph neural networks requires learning the neural netowrk parameters and network topology under discrete constraints induced by the observed path performance metrics, which motivates us to design a learning objective that imposes connectivity and sparsity constraints on topology and path performance triangle inequality on path performance. Extensive experiments on real-world and synthetic datasets demonstrate the superiority of DeepNT in predicting performance metrics and inferring graph topology compared to state-of-the-art methods."
Liang Zhao,PolyhedronNet: Representation Learning for Polyhedra with Surface-attributed Graph,2025,https://arxiv.org/abs/2502.01814,"Ubiquitous geometric objects can be precisely and efficiently represented as polyhedra. The transformation of a polyhedron into a vector, known as polyhedra representation learning, is crucial for manipulating these shapes with mathematical and statistical tools for tasks like classification, clustering, and generation. Recent years have witnessed significant strides in this domain, yet most efforts focus on the vertex sequence of a polyhedron, neglecting the complex surface modeling crucial in real-world polyhedral objects. This study proposes \textbf{PolyhedronNet}, a general framework tailored for learning representations of 3D polyhedral objects. We propose the concept of the surface-attributed graph to seamlessly model the vertices, edges, faces, and their geometric interrelationships within a polyhedron. To effectively learn the representation of the entire surface-attributed graph, we first propose to break it down into local rigid representations to effectively learn each local region's relative positions against the remaining regions without geometric information loss. Subsequently, we propose PolyhedronGNN to hierarchically aggregate the local rigid representation via intra-face and inter-face geometric message passing modules, to obtain a global representation that minimizes information loss while maintaining rotation and translation invariance. Our experimental evaluations on four distinct datasets, encompassing both classification and retrieval tasks, substantiate PolyhedronNet's efficacy in capturing comprehensive and informative representations of 3D polyhedral objects. Code and data are available at {https://github.com/dyu62 …"
Liang Zhao,CG-RAG: Research Question Answering by Citation Graph Retrieval-Augmented LLMs,2025,https://arxiv.org/abs/2501.15067,"Research question answering requires accurate retrieval and contextual understanding of scientific literature. However, current Retrieval-Augmented Generation (RAG) methods often struggle to balance complex document relationships with precise information retrieval. In this paper, we introduce Contextualized Graph Retrieval-Augmented Generation (CG-RAG), a novel framework that integrates sparse and dense retrieval signals within graph structures to enhance retrieval efficiency and subsequently improve generation quality for research question answering. First, we propose a contextual graph representation for citation graphs, effectively capturing both explicit and implicit connections within and across documents. Next, we introduce Lexical-Semantic Graph Retrieval (LeSeGR), which seamlessly integrates sparse and dense retrieval signals with graph encoding. It bridges the gap between lexical precision and semantic understanding in citation graph retrieval, demonstrating generalizability to existing graph retrieval and hybrid retrieval methods. Finally, we present a context-aware generation strategy that utilizes the retrieved graph-structured information to generate precise and contextually enriched responses using large language models (LLMs). Extensive experiments on research question answering benchmarks across multiple domains demonstrate that our CG-RAG framework significantly outperforms RAG methods combined with various state-of-the-art retrieval approaches, delivering superior retrieval accuracy and generation quality."
Liang Zhao,ACES-GNN: Can Graph Neural Network Learn to Explain Activity Cliffs?,2025,https://chemrxiv.org/engage/chemrxiv/article-details/6781e1ac6dde43c908117cc4,"Graph Neural Networks (GNNs) have revolutionized molecular property prediction by leveraging graph-based representations, yet their opaque decision-making processes hinder broader adoption in drug discovery. This study introduces the Activity-Cliff-Explanation-Supervised GNN (ACES-GNN) framework, designed to simultaneously improve predictive accuracy and interpretability by integrating explanation supervision for activity cliffs (ACs) into GNN training. ACs, defined by structurally similar molecules with significant potency differences, pose challenges for traditional models due to their reliance on shared structural features. By aligning model attributions with chemist-friendly interpretations, the ACES-GNN framework bridges the gap between prediction and explanation. Validated across 30 pharmacological targets, ACES-GNN consistently enhances both predictive accuracy and attribution quality compared to baseline methods. Our results demonstrate a strong correlation between improved predictions and accurate explanations, offering a robust and adaptable framework for addressing the ""intra-scaffold"" generalization problem. This work underscores the potential of explanation-guided learning to advance interpretable artificial intelligence in molecular modeling and drug discovery."
Liang Zhao,End-to-end Trajectory Generation - Contrasting Deep Generative Models and Language Models,2025,https://dl.acm.org/doi/abs/10.1145/3716892,"Due to the limited availability of actual large-scale datasets, realistic synthetic trajectory data play a crucial role in various research domains, including spatiotemporal data mining and data management, and domain-driven research related to transportation planning and urban analytics. Existing generation methods rely on predefined heuristics and cannot learn the unknown underlying generative mechanisms. This work introduces two end-to-end approaches for trajectory generation. The first approach comprises deep generative VAE-like models that factorize global and local semantics (habits vs. random routing change). We further enhance this approach by developing novel inference strategies based on variational inference and constrained optimization to ensure the validity of spatiotemporal aspects. This novel deep neural network architecture implements generative and inference models with dynamic latent …"
Liang Zhao,Dynamic recommender system for chronic disease-focused online health community,2024,https://www.sciencedirect.com/science/article/pii/S0957417424019535,"Unequal distribution of healthcare resources poses a significant challenge in numerous regions and countries worldwide. Online Health Communities (OHCs) serve as pivotal platforms for patients to share treatment experiences and seek emotional support from peers facing similar health challenges. The facilitation of efficient user navigation to relevant sub-communities and topics within OHCs emerges as a critical need. Addressing these complexities, a recommendation system specifically designed for OHCs is proposed to tackle unique challenges such as simultaneous prediction of sub-communities and topics with varying levels of information, capturing the influence of evolving health stages on patient interactions, and ensuring coherent recommendations. To meet these challenges, OHCs are conceptualized as dynamic tripartite graphs that model three primary entities—patients, sub-communities, and topics …"
Liang Zhao,MEGL: Multimodal Explanation-Guided Learning,2024,https://arxiv.org/abs/2411.13053,"Explaining the decision-making processes of Artificial Intelligence (AI) models is crucial for addressing their ""black box"" nature, particularly in tasks like image classification. Traditional eXplainable AI (XAI) methods typically rely on unimodal explanations, either visual or textual, each with inherent limitations. Visual explanations highlight key regions but often lack rationale, while textual explanations provide context without spatial grounding. Further, both explanation types can be inconsistent or incomplete, limiting their reliability. To address these challenges, we propose a novel Multimodal Explanation-Guided Learning (MEGL) framework that leverages both visual and textual explanations to enhance model interpretability and improve classification performance. Our Saliency-Driven Textual Grounding (SDTG) approach integrates spatial information from visual explanations into textual rationales, providing spatially grounded and contextually rich explanations. Additionally, we introduce Textual Supervision on Visual Explanations to align visual explanations with textual rationales, even in cases where ground truth visual annotations are missing. A Visual Explanation Distribution Consistency loss further reinforces visual coherence by aligning the generated visual explanations with dataset-level patterns, enabling the model to effectively learn from incomplete multimodal supervision. We validate MEGL on two new datasets, Object-ME and Action-ME, for image classification with multimodal explanations. Experimental results demonstrate that MEGL outperforms previous approaches in prediction accuracy and explanation quality across both visual …"
Liang Zhao,Unifying Spectral and Spatial Graph Neural Networks,2024,https://dl.acm.org/doi/abs/10.1145/3627673.3679088,"In recent years, Graph Neural Networks (GNNs) have attracted considerable attention. However, the rapid emergence of diverse GNN models, each grounded in different theoretical foundations, complicates the model selection process, as these models are not easily understood within a unified framework. Initial GNNs were constructed using spectral theory, while others were developed based on spatial theory. This theoretical divergence makes direct comparisons difficult. Furthermore, the variety of models within each theoretical domain further complicates their evaluation. In this tutorial, we explore state-of-the-art GNNs and present a comprehensive framework that bridges the spatial and spectral domains, clarifying their interrelationship. This framework deepens our understanding of GNN operations. The tutorial delves into key paradigms, such as spatial and spectral methods, through a synthesis of spectral …"
Liang Zhao,TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models,2024,https://arxiv.org/abs/2410.15268,"Representation learning of Text-Attributed Graphs (TAGs) has garnered significant attention due to its applications in various domains, including recommendation systems and social networks. Despite advancements in TAG learning methodologies, challenges remain in explainability due to the black-box nature of existing TAG representation learning models. This paper presents TAGExplainer, the first method designed to generate natural language explanations for TAG learning. TAGExplainer employs a generative language model that maps input-output pairs to explanations reflecting the model's decision-making process. To address the lack of annotated ground truth explanations in real-world scenarios, we propose first generating pseudo-labels that capture the model's decisions from saliency-based explanations, then the pseudo-label generator is iteratively trained based on three training objectives focusing on faithfulness and brevity via Expert Iteration, to improve the quality of generated pseudo-labels. The high-quality pseudo-labels are finally utilized to train an end-to-end explanation generator model. Extensive experiments are conducted to demonstrate the effectiveness of TAGExplainer in producing faithful and concise natural language explanations."
Liang Zhao,Ontology extension by online clustering with large language model agents,2024,https://www.frontiersin.org/journals/big-data/articles/10.3389/fdata.2024.1463543/full,"An ontology is a structured framework that categorizes entities, concepts, and relationships within a domain to facilitate shared understanding, and it is important in computational linguistics and knowledge representation. In this paper, we propose a novel framework to automatically extend an existing ontology from streaming data in a zero-shot manner. Specifically, the zero-shot ontology extension framework uses online and hierarchical clustering to integrate new knowledge into existing ontologies without substantial annotated data or domain-specific expertise. Focusing on the medical field, this approach leverages Large Language Models (LLMs) for two key tasks: Symptom Typing and Symptom Taxonomy among breast and bladder cancer survivors. Symptom Typing involves identifying and classifying medical symptoms from unstructured online patient forum data, while Symptom Taxonomy organizes and integrates these symptoms into an existing ontology. The combined use of online and hierarchical clustering enables real-time and structured categorization and integration of symptoms. The dual-phase model employs multiple LLMs to ensure accurate classification and seamless integration of new symptoms with minimal human oversight. The paper details the framework's development, experiments, quantitative analyses, and data visualizations, demonstrating its effectiveness in enhancing medical ontologies and advancing knowledge-based systems in healthcare."
Liang Zhao,"The 4th KDD Workshop on Deep Learning for Spatiotemporal Data, Applications, and Systems (DeepSpatial'24)",2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671501,"Over the last decades, a rapidly growing volume of spatiotemporal data has been collected from smartphones and GPS, terrestrial, seaborne, airborne, and spaceborne sensors, as well as computational simulations. Meanwhile, advances in deep learning technologies, especially the recent breakthroughs of generative AI and foundation models such as Large Language Models (LLMs) and Large Vision Models (LVMs), have achieved tremendous success in natural language processing and computer vision applications. There is growing anticipation of the same level of accomplishment of AI on spatiotemporal data in tackling grand societal challenges, such as national water resource management, monitoring coastal hazards, energy and food security, as well as mitigation and adaptation to climate change. When deep learning, especially emerging foundation models, intersects spatiotemporal data in scientific …"
Liang Zhao,Representation Learning of Geometric Trees,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671688,"Geometric trees are characterized by their tree-structured layout and spatially constrained nodes and edges, which significantly impacts their topological attributes. This inherent hierarchical structure plays a crucial role in domains such as neuron morphology and river geomorphology, but traditional graph representation methods often overlook these specific characteristics of tree structures. To address this, we introduce a new representation learning framework tailored for geometric trees. It first features a unique message passing neural network, which is both provably geometrical structure-recoverable and rotation-translation invariant. To address the data label scarcity issue, our approach also includes two innovative training targets that reflect the hierarchical ordering and geometric structure of these geometric trees. This enables fully self-supervised learning without explicit labels. We validate our method's …"
Liang Zhao,Self-consistent Deep Geometric Learning for Heterogeneous Multi-source Spatial Point Data Prediction,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671737,"Multi-source spatial point data prediction is crucial in fields like environmental monitoring and natural resource management, where integrating data from various sensors is the key to achieving a holistic environmental understanding. Existing models in this area often fall short due to their domain-specific nature and lack a strategy for integrating information from various sources in the absence of ground truth labels. Key challenges include evaluating the quality of different data sources and modeling spatial relationships among them effectively. Addressing these issues, we introduce an innovative multi-source spatial point data prediction framework that adeptly aligns information from varied sources without relying on ground truth labels. A unique aspect of our method is the 'fidelity score,' a quantitative measure for evaluating the reliability of each data source. Furthermore, we develop a geo-location-aware graph …"
Liang Zhao,Global explanation supervision for Graph Neural Networks,2024,https://www.frontiersin.org/articles/10.3389/fdata.2024.1410424/full,"With the increasing popularity of Graph Neural Networks (GNNs) for predictive tasks on graph structured data, research on their explainability is becoming more critical and achieving significant progress. Although many methods are proposed to explain the predictions of GNNs, their focus is mainly on “how to generate explanations.” However, other important research questions like “whether the GNN explanations are inaccurate,” “what if the explanations are inaccurate,” and “how to adjust the model to generate more accurate explanations” have gained little attention. Our previous GNN Explanation Supervision (GNES) framework demonstrated effectiveness on improving the reasonability of the local explanation while still keep or even improve the backbone GNNs model performance. In many applications instead of per sample explanations, we need to find global explanations which are reasonable and faithful to the domain data. Simply learning to explain GNNs locally is not an optimal solution to a global understanding of the model. To improve the explainability power of the GNES framework, we propose the Global GNN Explanation Supervision (GGNES) technique which uses a basic trained GNN and a global extension of the loss function used in the GNES framework. This GNN creates local explanations which are fed to a Global Logic-based GNN Explainer, an existing technique that can learn the global Explanation in terms of a logic formula. These two frameworks are then trained iteratively to generate reasonable global explanations. Extensive experiments demonstrate the effectiveness of the proposed model on improving the global …"
Liang Zhao,LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multi-modal Foundation Models,2024,https://arxiv.org/abs/2406.14862,"Deep generative models like VAEs and diffusion models have advanced various generation tasks by leveraging latent variables to learn data distributions and generate high-quality samples. Despite the field of explainable AI making strides in interpreting machine learning models, understanding latent variables in generative models remains challenging. This paper introduces \textit{LatentExplainer}, a framework for automatically generating semantically meaningful explanations of latent variables in deep generative models. \textit{LatentExplainer} tackles three main challenges: inferring the meaning of latent variables, aligning explanations with inductive biases, and handling varying degrees of explainability. Our approach perturbs latent variables, interpreting changes in generated data, and uses multi-modal large language models (MLLMs) to produce human-understandable explanations. We evaluate our proposed method on several real-world and synthetic datasets, and the results demonstrate superior performance in generating high-quality explanations for latent variables. The results highlight the effectiveness of incorporating inductive biases and uncertainty quantification, significantly enhancing model interpretability."
Liang Zhao,Network Interdiction Goes Neural,2024,https://arxiv.org/abs/2405.16409,"Network interdiction problems are combinatorial optimization problems involving two players: one aims to solve an optimization problem on a network, while the other seeks to modify the network to thwart the first player's objectives. Such problems typically emerge in an attacker-defender context, encompassing areas such as military operations, disease spread analysis, and communication network management. The primary bottleneck in network interdiction arises from the high time complexity of using conventional exact solvers and the challenges associated with devising efficient heuristic solvers. GNNs, recognized as a cutting-edge methodology, have shown significant effectiveness in addressing single-level CO problems on graphs, such as the traveling salesman problem, graph matching, and graph edit distance. Nevertheless, network interdiction presents a bi-level optimization challenge, which current GNNs find difficult to manage. To address this gap, we represent network interdiction problems as Mixed-Integer Linear Programming (MILP) instances, then apply a multipartite GNN with sufficient representational capacity to learn these formulations. This approach ensures that our neural network is more compatible with the mathematical algorithms designed to solve network interdiction problems, resulting in improved generalization. Through two distinct tasks, we demonstrate that our proposed method outperforms theoretical baseline models and provides advantages over traditional exact solvers."
Liang Zhao,Deep Causal Generative Models with Property Control,2024,https://arxiv.org/abs/2405.16219,"Generating data with properties of interest by external users while following the right causation among its intrinsic factors is important yet has not been well addressed jointly. This is due to the long-lasting challenge of jointly identifying key latent variables, their causal relations, and their correlation with properties of interest, as well as how to leverage their discoveries toward causally controlled data generation. To address these challenges, we propose a novel deep generative framework called the Correlation-aware Causal Variational Auto-encoder (C2VAE). This framework simultaneously recovers the correlation and causal relationships between properties using disentangled latent vectors. Specifically, causality is captured by learning the causal graph on latent variables through a structural causal model, while correlation is learned via a novel correlation pooling algorithm. Extensive experiments demonstrate C2VAE's ability to accurately recover true causality and correlation, as well as its superiority in controllable data generation compared to baseline models."
Liang Zhao,GraphSL: An Open-Source Library for Graph Source Localization Approaches and Benchmark Datasets,2024,https://arxiv.org/abs/2405.03724,"We introduce GraphSL, a new library for studying the graph source localization problem. graph diffusion and graph source localization are inverse problems in nature: graph diffusion predicts information diffusions from information sources, while graph source localization predicts information sources from information diffusions. GraphSL facilitates the exploration of various graph diffusion models for simulating information diffusions and enables the evaluation of cutting-edge source localization approaches on established benchmark datasets. The source code of GraphSL is made available at Github Repository (https://github.com/xianggebenben/GraphSL). Bug reports and feedback can be directed to the Github issues page (https://github.com/xianggebenben/GraphSL/issues)."
Liang Zhao,Non-Euclidean Spatial Graph Neural Network,2024,https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.18,"Spatial networks are networks whose graph topology is constrained by their embedded spatial space. Understanding the coupled spatial-graph properties is crucial for extracting powerful representations from spatial networks. Therefore, merely combining individual spatial and network representations cannot reveal the underlying interaction mechanism of spatial networks. Besides, existing spatial network representation learning methods can only consider networks embedded in Euclidean space, and can not well exploit the rich geometric information carried by irregular and non-uniform non-Euclidean space. In order to address this issue, in this paper we propose a novel generic framework to learn the representation of spatial networks that are embedded in non-Euclidean manifold space. Specifically, a novel message-passing-based neural network is proposed to combine graph topology and spatial geometry …"
Liang Zhao,Explainable AI for lung nodule detection and classification in CT images,2024,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12927/129272U/Explainable-AI-for-lung-nodule-detection-and-classification-in-CT/10.1117/12.3008472.short,"Lung cancer is the second most prevalent and deadliest cancer in the United States, primarily due to its elusive early symptoms that hinder timely diagnosis. Lung nodules, minute anomalous areas, hold potential significance in lung cancer occurrence. Swift identification of these nodules can significantly enhance patient survival rates. Thoracic thin-sliced Computed Tomography (CT) scanning has emerged as a widely adopted approach for radiologists' diagnosing and prognosticating lung abnormalities. However, human factors can be prone to errors stemming from the multifarious causes underlying nodule formation, including factors like pollutants and infections. The domain of deep learning algorithms has recently showcased remarkable prowess in classifying and segmenting medical images. This study is geared towards the creation of a comprehensive framework that seamlessly integrates explainable AI …"
Liang Zhao,Helper Recommendation with seniority control in Online Health Community,2024,https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.29,"Online health communities (OHCs) provide an essential platform for patients with similar health conditions to share experiences and offer moral support. However, many time-sensitive questions from patients often remain unanswered due to the multitude of threads and the random nature of patient visits in OHCs. Traditional recommendation systems solely based on similarity for recommendations cannot be directly applied in OHCs. They tend to overlook the influence of patients' dynamically changing features (e.g., health stages), affecting their ability to provide meaningful responses to questions. To address this, we propose a novel recommender system scenario designed for OHCs, which differs from traditional recommender systems in several ways. Firstly, it's challenging to model the social support factors that form helper-seeker links in OHCs. Secondly, the impact of patients' historical activities is complex to …"
Liang Zhao,Explaining latent representations of generative models with large multimodal models,2024,https://arxiv.org/abs/2402.01858,"Learning interpretable representations of data generative latent factors is an important topic for the development of artificial intelligence. With the rise of the large multimodal model, it can align images with text to generate answers. In this work, we propose a framework to comprehensively explain each latent variable in the generative models using a large multimodal model. We further measure the uncertainty of our generated explanations, quantitatively evaluate the performance of explanation generation among multiple large multimodal models, and qualitatively visualize the variations of each latent variable to learn the disentanglement effects of different generative models on explanations. Finally, we discuss the explanatory capabilities and limitations of state-of-the-art large multimodal models."
Liang Zhao,Cross-tissue Graph Attention Networks for Semi-supervised Gene Expression Prediction,2024,https://www.biorxiv.org/content/10.1101/2024.11.15.623881.abstract,"High-throughput biotechnologies have significantly advanced precision medicine by enabling the exploitation of global gene expression patterns to enhance our understanding of disease etiology, progression, and treatment options. However, the tissue-specific nature of gene expression presents a challenge, particularly for less accessible tissues such as the brain, underscoring the need for computational methods to accurately impute gene expression in these critical but hard-to-reach tissues. While several attempts to impute gene expression in tissue-specific contexts have shown promising results, their reliance on regression analysis faces limitations due to the inability to capture complex, nonlinear relationships in gene expression patterns. In contrast, modern machine learning techniques, particularly graph neural networks, have demonstrated superior performance by efficiently modeling the intricate interactions among genes across different tissues. Therefore, we introduce gene expression imputation with Graph Attention Networks (gemGAT), a novel approach leveraging Graph Attention Networks (GATs) to enhance gene expression prediction across different tissues. gemGAT distinguishes itself by predicting the expression of all genes simultaneously, utilizing the full spectrum of genomic data to account for gene co-expressions and non-linear relationships. Validated through extensive experiments with Genotype-Tissue Expression (GTEx) data and a case study from the Alzheimer's Disease Neuroimaging Initiative (ADNI), gemGAT demonstrates superior performance over existing methods by efficiently capturing non-linear gene co …"
Liang Zhao,Estimation of daily PM2. 5 concentration using a geographically weighted neural network,2023,https://scholar.google.com/scholar?cluster=11560286591581546500&hl=en&oi=scholarr,
Liang Zhao,Fast and adaptive dynamics-on-graphs to dynamics-of-graphs translation,2023,https://www.frontiersin.org/articles/10.3389/fdata.2023.1274135/full,"Numerous networks in the real world change with time, producing dynamic graphs such as human mobility networks and brain networks. Typically, the “dynamics on graphs” (e.g., changing node attribute values) are visible, and they may be connected to and suggestive of the “dynamics of graphs” (e.g., evolution of the graph topology). Due to two fundamental obstacles, modeling and mapping between them have not been thoroughly explored: (1) the difficulty of developing a highly adaptable model without solid hypotheses and (2) the ineffectiveness and slowness of processing data with varying granularity. To solve these issues, we offer a novel scalable deep echo-state graph dynamics encoder for networks with significant temporal duration and dimensions. A novel neural architecture search (NAS) technique is then proposed and tailored for the deep echo-state encoder to ensure strong learnability. Extensive experiments on synthetic and actual application data illustrate the proposed method's exceptional effectiveness and efficiency."
Liang Zhao,Controllable Data Generation Via Iterative Data-Property Mutual Mappings,2023,https://arxiv.org/abs/2310.07683,"Deep generative models have been widely used for their ability to generate realistic data samples in various areas, such as images, molecules, text, and speech. One major goal of data generation is controllability, namely to generate new data with desired properties. Despite growing interest in the area of controllable generation, significant challenges still remain, including 1) disentangling desired properties with unrelated latent variables, 2) out-of-distribution property control, and 3) objective optimization for out-of-distribution property control. To address these challenges, in this paper, we propose a general framework to enhance VAE-based data generators with property controllability and ensure disentanglement. Our proposed objective can be optimized on both data seen and unseen in the training set. We propose a training procedure to train the objective in a semi-supervised manner by iteratively conducting mutual mappings between the data and properties. The proposed framework is implemented on four VAE-based controllable generators to evaluate its performance on property error, disentanglement, generation quality, and training time. The results indicate that our proposed framework enables more precise control over the properties of generated samples in a short training time, ensuring the disentanglement and keeping the validity of the generated samples."
Liang Zhao,Transferable Deep Clustering Model,2023,https://arxiv.org/abs/2310.04946,"Deep learning has shown remarkable success in the field of clustering recently. However, how to transfer a trained clustering model on a source domain to a target domain by leveraging the acquired knowledge to guide the clustering process remains challenging. Existing deep clustering methods often lack generalizability to new domains because they typically learn a group of fixed cluster centroids, which may not be optimal for the new domain distributions. In this paper, we propose a novel transferable deep clustering model that can automatically adapt the cluster centroids according to the distribution of data samples. Rather than learning a fixed set of centroids, our approach introduces a novel attention-based module that can adapt the centroids by measuring their relationship with samples. In addition, we theoretically show that our model is strictly more powerful than some classical clustering algorithms such as k-means or Gaussian Mixture Model (GMM). Experimental results on both synthetic and real-world datasets demonstrate the effectiveness and efficiency of our proposed transfer learning framework, which significantly improves the performance on target domain and reduces the computational cost."
Liang Zhao,Similarity-Based Gossip Learning for Generative Adversarial Networks,2023,https://ieeexplore.ieee.org/abstract/document/10297386/,"Generative Adversarial Networks (GANs) have shown remarkable results in tasks such as image generation and data augmentation, but traditional centralized training methods often require a large number of computational resources and high-speed network connections, making it difficult to apply them to large-scale and distributed scenarios. In this paper, we propose a distributed GAN training method based on Gossip Learning, which realizes decentralized communication and collaborative learning among clients. We also use the Meta-Learning framework to improve the model's generalization ability in few-shot settings. We employ similarity-based neighbor selection in the Gossip algorithm to make collaborative learning more efficient. Experiments on various datasets showed that compared to traditional centralized training methods, using Gossip Learning significantly improves the training performance of GAN …"
Liang Zhao,Fast and Scalable Unsupervised Deep Subgraph Anomaly Detection,2023,https://www.researchsquare.com/article/rs-2652525/latest,"Mining anomalous subgraphs in networks is a crucial task in various application scenarios, such as disease outbreak detection, financial fraud detection, and activity monitoring in social networks. However, identifying anomalous subgraphs is a challenging problem due to their complex topological structures, high-dimensional attributes, various notions of anomalies, and the exponentially large subgraph searching space in a given graph. Classical shallow models typically rely on handcrafted anomaly measure functions, which are not effective when prior knowledge is unavailable. To address this issue, deep learning-based methods have been proposed as an end-to-end way of learning anomaly measure functions. However, while these methods have been successful in detecting node-level, edge-level, and graph-level anomalies, detecting anomalous subgraphs has been largely underex-plored due to …"
Liang Zhao,Infinitely deep graph transformation networks,2023,https://ieeexplore.ieee.org/abstract/document/10415694/,"This work develops a node-edge co-evolution model for attributed graph transformation, where both the node and edge attributes undergo changes due to complex interactions. Due to two fundamental obstacles, learning and approximating attributed graph transformation have not been thoroughly explored: 1) the difficulty of jointly considering four types of atomic interactions including nodes-to-edges, nodes-to-nodes, edges-to-nodes, and edges-to-edges interactions. 2) the difficulty of capturing iterative long-range interactions between nodes and edges. To solve these issues, we offer a novel and scalable equilibrium model, NEC ∞ , with node-edge message passing and edge-node message passing. Additionally, we propose an efficient optimization algorithm that is based on implicit gradient theorem and includes a theoretical analysis of NEC ∞ . The effectiveness and efficiency of the proposed model have …"
Liang Zhao,Accuracy Indoor Localization Based on Fuzzy Transfer Learning Model,2022,https://ieeexplore.ieee.org/abstract/document/10189747/,"Location-based services greatly facilitate people’s daily life, which puts forward higher requirements for the location calculation of target objects in different environments. Since the fingerprint positioning method does not require additional special equipment and easy to implement, it has become one of the most attractive solutions. In order to ensure the positioning accuracy, this method requires complete sampling of the fingerprints of the positioning area, so a lot of sampling costs are required. In particular, when sampling buildings with multiple floors, the labor and time of the entire sampling process will increase dramatically. At the same time, certain floors or rooms may not be allowed to open, so their fingerprints cannot be sampled. In fact, the floor structures of buildings are mostly similar or the same, such as office buildings, hotels. Therefore, this paper proposes a fuzzy transfer learning model and builds the …"
Liang Zhao,Constructing Efficient Set of APs Via Spatial Discrimination and Localization Difference,2022,https://ieeexplore.ieee.org/abstract/document/10189551/,"RSSI fingerprint-based localization has been one of the most attractive solutions, since it is free of extra infrastructure and specialized hardware. As wireless networks become more widely used, however, the number of APs for localization has been increasing and then results in ""invalid APs"", nearly APs that are redundant or have a negative impact on locating, and raises the computational overhead in the process of localization. To solve these problems, the previous literatures focused on selecting some efficient APs for localization. These approaches could remove a few of redundant APs and reduce the localization overhead to a certain extent, but the performance of locating will fluctuate significantly. In this paper, we propose a constructing efficient set of APs via spatial discrimination and localization difference, ESAP. First, for a single AP, we use the information gain rate to evaluate its spatial resolution ability …"
Liang Zhao,Future-aware and High-order representation learning for cold-start recommendation,2022,https://ieeexplore.ieee.org/abstract/document/10189623/,"The Cold-start problem is critical but challenging for dynamic recommender systems since new entities (users/items) are added dynamically without any purchasing behavior. Most existing methods solve the problem by building the relationship between cold-start entities and existing entities. However, due to several challenges, such approaches can not effectively handle the cold start in dynamic recommender systems. It is hard to learn and predict dynamically for constantly added entities without any historical interactions. Moreover, it is challenging to characterize cold-start entities precisely for indicating future purchasing with limited information. This paper formalizes the dynamic recommender systems as a time-evolving graph to handle the challenges of modeling the dynamic relations between users and items. Mainly, we design a unified learning framework that can learn future-aware representations for newly …"
Liang Zhao,Generation and Characterization of Quaternary Ammonium Compounds via Deep Learning,2022,https://ieeexplore.ieee.org/abstract/document/9995026/,"Activity characterization, optimization, and generation of small molecules are increasingly active areas of research at the intersection of molecular chemistry and machine learning. Large datasets of small molecules have allowed training deep models that have been shown capable of exploring the underlying chemical space and generating valid, novel, and unique molecules. While this is a noteworthy achievement, what impedes operationalizing these models in the wet laboratory is the ability to link the chemical and biological space of small molecules. A central challenge to this is the lack of activity data on these entities. In this paper we relate a computational pipeline that permits linking the chemical and biological space of an important class of small molecules, quaternary ammonium compounds (QACs). Our experimental collaborators have characterized the activity of many QACs against Staphylococcus …"
Liang Zhao,RES: A Robust Framework for Visual Explanation Supervision,2022,,
Liang Zhao,SL-VAE: Variational Autoencoder for Source Localization in Graph Information Diffusion,2022,,
Liang Zhao,From “Dynamics on Graphs” to “Dynamics of Graphs”: An Adaptive Echo-State Network Solution (Student Abstract),2022,https://ojs.aaai.org/index.php/AAAI/article/view/21692,"Many real-world networks evolve over time, which results in dynamic graphs such as human mobility networks and brain networks. Usually, the “dynamics on graphs”(eg, node attribute values evolving) are observable, and may be related to and indicative of the underlying “dynamics of graphs”(eg, evolving of the graph topology). Traditional RNN-based methods are not adaptive or scalable for learn-ing the unknown mappings between two types of dynamic graph data. This study presents a AD-ESN, and adaptive echo state network that can automatically learn the best neural net-work architecture for certain data while keeping the efficiency advantage of echo state networks. We show that AD-ESN can successfully discover the underlying pre-defined map-ping function and unknown nonlinear map-ping between time series and graphs."
Liang Zhao,Accelerated Gradient-free Neural Network Training by Multi-convex Alternating Optimization Neurocomputing,2022,,
Liang Zhao,An Invertible Graph Diffusion Model for Source Localization,2022,,
Liang Zhao,From “Dynamics on Graphs” to “Dynamics of Graphs”: an Adaptive Echo-State Network Solution,2022,,
Liang Zhao,Generating Tertiary Protein Structures via Interpretable Graph Variational Autoencoders,2022,,
Liang Zhao,Do Multi-Lingual Pre-trained Language Models Reveal Consistent Token Attributions in Different Languages?,2021,https://arxiv.org/abs/2112.12356,"During the past several years, a surge of multi-lingual Pre-trained Language Models (PLMs) has been proposed to achieve state-of-the-art performance in many cross-lingual downstream tasks. However, the understanding of why multi-lingual PLMs perform well is still an open domain. For example, it is unclear whether multi-Lingual PLMs reveal consistent token attributions in different languages. To address this, in this paper, we propose a Cross-lingual Consistency of Token Attributions (CCTA) evaluation framework. Extensive experiments in three downstream tasks demonstrate that multi-lingual PLMs assign significantly different attributions to multi-lingual synonyms. Moreover, we have the following observations: 1) the Spanish achieves the most consistent token attributions in different languages when it is used for training PLMs; 2) the consistency of token attributions strongly correlates with performance in downstream tasks."
Liang Zhao,Incremental Multi-source Feature Learning and its Applications in Spatio-temporal Event Prediction,2021,https://par.nsf.gov/servlets/purl/10279699,"The forecasting of significant societal events such as civil unrest and economic crisis is an interesting and challenging problem which requires both timeliness, precision, and comprehensiveness. Significant societal events are influenced and indicated jointly by multiple aspects of a society, including its economics, politics, and culture. Traditional forecasting methods based on a single data source find it hard to cover all these aspects comprehensively, thus limiting model performance. Multi-source event forecasting has proven promising but still suffers from several challenges, including 1) geographical hierarchies in multi-source data features, 2) hierarchical missing values, 3) characterization of structured feature sparsity, and 4) difficulty in model’s online update with incomplete multiple sources. This paper proposes a novel feature learning model that concurrently addresses all the above challenges. Specifically, given multi-source data from different geographical levels, we design a new forecasting model by characterizing the lower-level features’ dependence on higher-level features. To handle the correlations amidst structured feature sets and deal with missing values among the coupled features, we propose a novel feature learning model based on an 𝑁th-order strong hierarchy and fused-overlapping group Lasso. An efficient algorithm is developed to optimize model parameters and ensure global optima. More importantly, to enable the model update in real time, the online learning algorithm is formulated and active set techniques are leveraged to resolve the crucial challenge when new patterns of missing features appear in real time …"
Liang Zhao,"DeepSpatial'21: 2nd International Workshop on Deep Learning for Spatiotemporal Data, Applications, and Systems",2021,https://dl.acm.org/doi/abs/10.1145/3447548.3469446,"With the advancement of GPS and remote sensing technologies and the pervasiveness of smartphones and mobile devices, large amounts of spatiotemporal data are being collected from various domains. Knowledge discovery from spatiotemporal data is crucial in broad societal applications. Examples range from mapping flooded areas on satellite imagery for disaster response to monitoring crop health for food security, from estimating travel time between locations on Google Maps to forecasting hotspots of diseases like Covid-19 in public health. The recent success in deep learning technologies in computer vision and natural language processing provides unique opportunities for spatiotemporal data mining (e.g., automatically extracting spatial contextual features without manual feature engineering) but also faces unique challenges (e.g., spatial autocorrelation, heterogeneity, multiple scales, and resolutions …"
Liang Zhao,Deep Generative Models for Spatial Networks,2021,,
Liang Zhao,Intelligence-driven mobile networks for smart cities,2021,https://link.springer.com/article/10.1007/s00607-020-00885-8,"For the last twenty years, artificial intelligence (AI) has become a significant technology to influence our daily life with its ability of promoting the quality of living. AI can find the patterns and create actions from the proper amount of data, then make proper decisions for applications. It is promising to involve AI in the smart cities to enable the better intelligent services. Among all services, mobile networking can be also improved by applying AI, in which such enhanced networking will allow broad coverage, high capacity, high resource availability, and extensive connectivity. It will meet the key metrics including bandwidth, jitter, throughput, transmission delay, and availability."
Liang Zhao,Deep Graph Spectral Evolution Networks for Graph Topological Transformation,2021,,
Liang Zhao,"Yuanqi Du, and Liang Zhao. 2021. Property Controllable Variational Auto-encoder via Invertible Mutual Dependence",2021,,
Liang Zhao,Interpretable Molecular Graph Generation via Monotonic Constraints,2021,,
Liang Zhao,Interpretable Property Controlling Molecule Generation,2021,,
Liang Zhao,Metagraph Aggregated Heterogeneous Graph Neural Network for Illicit Traded Product Identification in Underground Market,2020,,
Andreas Züfle,Location-based social network data generation based on patterns of life,2020,https://ieeexplore.ieee.org/abstract/document/9162189/,"Location-based social networks (LBSNs) have been studied extensively in recent years. However, utilizing real-world LBSN data sets yields several weaknesses: sparse and small data sets, privacy concerns, and a lack of authoritative ground-truth. To overcome these weaknesses, we leverage a large-scale LBSN simulation to create a framework to simulate human behavior and to create synthetic but realistic LBSN data based on human patterns of life. Such data not only captures the location of users over time but also their interactions via social networks. Patterns of life are simulated by giving agents (i.e., people) an array of “needs” that they aim to satisfy, e.g., agents go home when they are tired, to restaurants when they are hungry, to work to cover their financial needs, and to recreational sites to meet friends and satisfy their social needs. While existing real-world LBSN data sets are trivially small, the proposed …"
Andreas Züfle,Change of human mobility during COVID-19: A United States case study,2021,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0259031,"With the onset of COVID-19 and the resulting shelter in place guidelines combined with remote working practices, human mobility in 2020 has been dramatically impacted. Existing studies typically examine whether mobility in specific localities increases or decreases at specific points in time and relate these changes to certain pandemic and policy events. However, a more comprehensive analysis of mobility change over time is needed. In this paper, we study mobility change in the US through a five-step process using mobility footprint data. (Step 1) Propose the Delta Time Spent in Public Places (ΔTSPP) as a measure to quantify daily changes in mobility for each US county from 2019-2020. (Step 2) Conduct Principal Component Analysis (PCA) to reduce the ΔTSPP time series of each county to lower-dimensional latent components of change in mobility. (Step 3) Conduct clustering analysis to find counties that exhibit similar latent components. (Step 4) Investigate local and global spatial autocorrelation for each component. (Step 5) Conduct correlation analysis to investigate how various population characteristics and behavior correlate with mobility patterns. Results show that by describing each county as a linear combination of the three latent components, we can explain 59% of the variation in mobility trends across all US counties. Specifically, change in mobility in 2020 for US counties can be explained as a combination of three latent components: 1) long-term reduction in mobility, 2) no change in mobility, and 3) short-term reduction in mobility. Furthermore, we find that US counties that are geographically close are more likely to exhibit a …"
Andreas Züfle,Predicting building types using OpenStreetMap,2022,https://www.nature.com/articles/s41598-022-24263-w,"Having accurate building information is paramount for a plethora of applications, including humanitarian efforts, city planning, scientific studies, and navigation systems. While volunteered geographic information from sources such as OpenStreetMap (OSM) has good building geometry coverage, descriptive attributes such as the type of a building are sparse. To fill this gap, this study proposes a supervised learning-based approach to provide meaningful, semantic information for OSM data without manual intervention. We present a basic demonstration of our approach that classifies buildings into either residential or non-residential types for three study areas: Fairfax County in Virginia (VA), Mecklenburg County in North Carolina (NC), and the City of Boulder in Colorado (CO). The model leverages (i) available OSM tags capturing non-spatial attributes, (ii) geometric and topological properties of the building footprints …"
Andreas Züfle,Mobility Data Science: Dagstuhl Seminar 22021,2022,https://vbn.aau.dk/en/publications/mobility-data-science-dagstuhl-seminar-22021,"This report documents the program and the outcomes of Dagstuhl Seminar 22021"" Mobility Data Science"". This seminar was held January 9-14, 2022, including 47 participants from industry and academia. The goal of this Dagstuhl Seminar was to create a new research community of mobility data science in which the whole is greater than the sum of its parts by bringing together established leaders as well as promising young researchers from all fields related to mobility data science."
Andreas Züfle,Data-driven mobility models for COVID-19 simulation,2020,https://dl.acm.org/doi/abs/10.1145/3423455.3430305,"Agent-based models (ABM) play a prominent role in guiding critical decision-making and supporting the development of effective policies for better urban resilience and response to the COVID-19 pandemic. However, many ABMs lack realistic representations of human mobility, a key process that leads to physical interaction and subsequent spread of disease. Therefore, we propose the application of Latent Dirichlet Allocation (LDA), a topic modeling technique, to foot-traffic data to develop a realistic model of human mobility in an ABM that simulates the spread of COVID-19. In our novel approach, LDA treats POIs as ""words"" and agent home census block groups (CBGs) as ""documents"" to extract ""topics"" of POIs that frequently appear together in CBG visits. These topics allow us to simulate agent mobility based on the LDA topic distribution of their home CBG. We compare the LDA based mobility model with …"
Andreas Züfle,Urban life: a model of people and places,2023,https://link.springer.com/article/10.1007/s10588-021-09348-7,"We introduce the Urban Life agent-based simulation used by the Ground Truth program to capture the innate needs of a human-like population and explore how such needs shape social constructs such as friendship and wealth. Urban Life is a spatially explicit model to explore how urban form impacts agents’ daily patterns of life. By meeting up at places agents form social networks, which in turn affect the places the agents visit. In our model, location and co-location affect all levels of decision making as agents prefer to visit nearby places. Co-location is necessary (but not sufficient) to connect agents in the social network. The Urban Life model was used in the Ground Truth program as a virtual world testbed to produce data in a setting in which the underlying ground truth was explicitly known. Data was provided to research teams to test and validate Human Domain research methods to an extent previously …"
Andreas Züfle,Location-based social simulation for prescriptive analytics of disease spread,2020,https://dl.acm.org/doi/abs/10.1145/3404820.3404828,"Human mobility and social networks have received considerable attention from researchers in recent years. What has been sorely missing is a comprehensive data set that not only addresses geometric movement patterns derived from trajectories, but also provides social networks and causal links as to why movement happens in the first place. To some extent, this challenge is addressed by studying location-based social networks (LBSNs). However, the scope of real-world LBSN data sets is constrained by privacy concerns, a lack of authoritative ground-truth, their sparsity, and small size. To overcome these issues we have infused a novel geographically explicit agent-based simulation framework to simulate human behavior and to create synthetic but realistic LBSN data based on human patterns-of-life (i.e., a geo-social simulation). Such data not only captures the location of users over time, but also their …"
Andreas Züfle,Large language models for spatial trajectory patterns mining,2024,https://dl.acm.org/doi/abs/10.1145/3681765.3698467,"Identifying anomalous human spatial trajectory patterns can indicate dynamic changes in mobility behavior with applications in domains like infectious disease monitoring and elderly care. Recent advancements in large language models (LLMs) have demonstrated their ability to reason in a manner akin to humans. This presents significant potential for analyzing temporal patterns in human mobility. In this paper, we conduct empirical studies to assess the capabilities of leading LLMs like GPT-4 and Claude-2 in detecting anomalous behaviors from mobility data, by comparing to specialized methods. Our key findings demonstrate that LLMs can attain reasonable anomaly detection performance even without any specific cues. In addition, providing contextual clues about potential irregularities could further enhances their prediction efficacy. Moreover, LLMs can provide reasonable explanations for their judgments …"
Andreas Züfle,Mobility Data Science: Perspectives and Challenges,2024,https://dl.acm.org/doi/abs/10.1145/3652158,"Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of Global Positioning System (GPS)–equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated a significant impact in various domains, including traffic management, urban planning, and health sciences. In this article, we present the domain of mobility data science. Towards a unified approach to mobility data science, we present a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state-of-the-art, and describe open challenges for the research community in the coming years."
Andreas Züfle,Massive trajectory data based on patterns of life,2023,https://dl.acm.org/doi/abs/10.1145/3589132.3625592,"Individual human location trajectory and check-in data have been the driving force for human mobility research in recent years. However, existing human mobility datasets are very limited in size and representativeness. For example, one of the largest and most commonly used datasets of individual human location trajectories, GeoLife, captures fewer than two hundred individuals. To help fill this gap, this Data and Resources paper leverages an existing data generator based on fine-grained simulation of individual human patterns of life to produce large-scale trajectory, check-in, and social network data. In this simulation, individual human agents commute between their home and work locations, visit restaurants to eat, and visit recreational sites to meet friends. We provide large datasets of months of simulated trajectories for two example regions in the United States: San Francisco and New Orleans. In addition to …"
Andreas Züfle,Riesz-Quincunx-UNet variational autoencoder for unsupervised satellite image denoising,2023,https://ieeexplore.ieee.org/abstract/document/10176136/,"Multiresolution deep learning approaches, such as the UNet architecture, have achieved high performance in classifying and segmenting images. Most traditional convolutional neural network (CNN) architectures commonly use pooling to enlarge the receptive field, which usually results in irreversible information loss. The UNet architecture avoids this information loss by introducing skip connections that allow the reconstruction of lost information. Leveraging this property of the UNet, this study proposes to include a Riesz-Quincunx (RQ) wavelet transform, which combines: 1) higher order Riesz wavelet transform and 2) orthogonal Quincunx wavelets (commonly used to reduce blur in medical images) inside the UNet to reduce noise in satellite images and their time-series. Combining both approaches, we introduce a hybrid RQ-UNet variational autoencoder (RQUNet-VAE) scheme for image and time series …"
Andreas Züfle,COVID-19 ensemble models using representative clustering,2020,https://dl.acm.org/doi/abs/10.1145/3431843.3431848,"In response to the COVID-19 pandemic, there have been various attempts to develop realistic models to both predict the spread of the disease and evaluate policy measures aimed at mitigation. Different models that operate under different parameters and assumptions produce radically different predictions, creating confusion among policy-makers and the general population and limiting the usefulness of the models. This newsletter article proposes a novel ensemble modeling approach that uses representative clustering to identify where existing model predictions of COVID-19 spread agree and unify these predictions into a smaller set of predictions. The proposed ensemble prediction approach is composed of the following stages: (1) the selection of the ensemble components, (2) the imputation of missing predictions for each component, and (3) representative clustering in application to time-series data to …"
Andreas Züfle,Traffic flow estimation using probe vehicle data,2020,https://ieeexplore.ieee.org/abstract/document/9260081/,"Traffic sensing has been revolutionized with the commoditization of GPS technology. Smartphone navigation applications ubiquitously track vehicles as samples of the overall traffic. This so-called Probe Vehicle Data (PVD) has replaced traditional road-side sensor technologies, such as induction loops and microwave sensors, given its relative low cost, good coverage, and reliability. However, while PVD allows us to assess speed and by extension the overall traffic condition in a road network, this sample-based approach does not provide us with traffic flow, i.e., the number of vehicles passing through an edge of the road network. This paper bridges this gap by proposing and evaluating a range of methods to infer traffic flow for a road network that is ubiquitously observed using probe data but having traffic flow measurements only in very road-side sensor locations. We create Road Segment Archetypes that relate …"
Andreas Züfle,Semantically diverse path search,2020,https://ieeexplore.ieee.org/abstract/document/9162294/,"Location-Based Services are often used to find proximal Points of Interest PoI - e.g., nearby restaurants and museums, police stations, hospitals, etc. - in a plethora of applications. An important recently addressed variant of the problem not only considers the distance/proximity aspect, but also desires semantically diverse locations in the answer-set. For instance, rather than picking several close-by attractions with similar features - e.g., restaurants with similar menus; museums with similar art exhibitions - a tourist may be more interested in a result set that could potentially provide more diverse types of experiences, for as long as they are within an acceptable distance from a given (current) location. Towards that goal, in this work we propose a novel approach to efficiently retrieve a path that will maximize the semantic diversity of the visited PoIs that are within distance limits along a given road network. We introduce a …"
Andreas Züfle,Managing uncertainty in evolving geo-spatial data,2020,https://ieeexplore.ieee.org/abstract/document/9162308/,"Our ability to extract knowledge from evolving spatial phenomena and make it actionable is often impaired by unreliable, erroneous, obsolete, imprecise, sparse, and noisy data. Integrating the impact of this uncertainty is a paramount when estimating the reliability/confidence of any time-varying query result from the underlying input data. The goal of this advanced seminar is to survey solutions for managing, querying and mining uncertain spatial and spatio-temporal data. We survey different models and show examples of how to efficiently enrich query results with reliability information. We discuss both analytical solutions as well as approximate solutions based on geosimulation."
Andreas Züfle,Parallel hub labeling maintenance with high efficiency in dynamic small-world networks,2023,https://ieeexplore.ieee.org/abstract/document/10016676/,"Shortest path computation is a fundamental operation in many application domains and is especially challenging in frequently evolving small-world networks (i.e., graphs in which many nodes can be reached from every other node by a small number of hops). Index-based methods, especially ones based on 2-hop labeling are often used for high query efficiency. However, the evolvements of small-world networks in many realistic scenarios pose the challenge of efficient maintenance of the shortest path index. In this work, we adopt the state-of-the-art Parallel Shortest-distance Labeling (PSL) as the underlying 2-hop labeling construction method, and design algorithms to support its efficient update given edge weight changes (increase and decrease). Specifically, we focus on weighted PSL (WPSL) and propose a propagation-based update mechanism for both synchronous and asynchronous propagation. We also …"
Andreas Züfle,A thematic similarity network approach for analysis of places using volunteered geographic information,2020,https://www.mdpi.com/2220-9964/9/6/385,"The research presented in this paper proposes a thematic network approach to explore rich relationships between places. We connect places in networks through their thematic similarities by applying topic modeling to the textual volunteered geographic information (VGI) pertaining to the places. The network approach enhances previous research involving place clustering using geo-textual information, which often simplifies relationships between places to be either in-cluster or out-of-cluster. To demonstrate our approach, we use as a case study in Manhattan (New York) that compares networks constructed from three different geo-textural data sources—TripAdvisor attraction reviews, TripAdvisor restaurant reviews, and Twitter data. The results showcase how the thematic similarity network approach enables us to conduct clustering analysis as well as node-to-node and node-to-cluster analysis, which is fruitful for understanding how places are connected through individuals’ experiences. Furthermore, by enriching the networks with geodemographic information as node attributes, we discovered that some low-income communities in Manhattan have distinctive restaurant cultures. Even though geolocated tweets are not always related to place they are posted from, our case study demonstrates that topic modeling is an efficient method to filter out the place-irrelevant tweets and therefore refining how of places can be studied."
Andreas Züfle,EPIPOL: An epidemiological patterns of life simulation (demonstration paper),2023,https://dl.acm.org/doi/abs/10.1145/3615898.3628258,"This paper introduces the EPIPOL disease simulation model, constructed upon the Patterns-of-life simulation, designed to produce human trajectory data. Over recent years, a surge in disease simulation models has been observed, each distinctive in its design and functionality. The primary objective of these models is to predict infection patterns for specified diseases in hypothetical settings, based on all available disease characteristics. A challenge that EPIPOL addresses is the typical rigidity of these models, which are often tailored for a specific disease. Thus they demand profound software expertise for modification. In our demonstration, participants will experience the user-friendliness and clarity of EPIPOL by: (1) selecting disease presets to initialize variables; (2) dynamically adjusting these variables during the simulation for enhanced precision; and (3) visualizing disease propagation in any globally mapped …"
Andreas Züfle,Uncertain spatial data management: An overview,2021,https://link.springer.com/chapter/10.1007/978-3-030-55462-0_14,"Both the current trends in technology such as smart phones, general mobile devices, stationary sensors, and satellites as we as a new user mentality of using this technology to voluntarily share enriched location information produces a flood of geo-spatial and geo-spatio-temporal data. This data flood provides a tremendous potential of discovering new and useful knowledge. But in addition to the fact that measurements are imprecise, spatial data is often interpolated between discrete observations. To reduce communication and bandwidth utilization, data is often subjected to a reduction, thereby eliminating some of the known/recorded values. These issues introduce the notion of uncertainty in the context of spatio-temporal data management, an aspect raising imminent need for scalable and flexible solutions. The main scope of this chapter is to survey existing techniques for managing, querying, and mining …"
Andreas Züfle,Towards mobility data science (vision paper),2023,https://arxiv.org/abs/2307.05717,"Mobility data captures the locations of moving objects such as humans, animals, and cars. With the availability of GPS-equipped mobile devices and other inexpensive location-tracking technologies, mobility data is collected ubiquitously. In recent years, the use of mobility data has demonstrated significant impact in various domains including traffic management, urban planning, and health sciences. In this paper, we present the emerging domain of mobility data science. Towards a unified approach to mobility data science, we envision a pipeline having the following components: mobility data collection, cleaning, analysis, management, and privacy. For each of these components, we explain how mobility data science differs from general data science, we survey the current state of the art and describe open challenges for the research community in the coming years."
Andreas Züfle,Spatiotemporal prediction of foot traffic,2021,https://dl.acm.org/doi/abs/10.1145/3486183.3490997,"Foot traffic is a business term to describe the number of customers that enter a point of interest (POI). This work aims to predict future foot traffic: the number of people from each census block group (CBG) that will visit each POI of a study region with potential applications in marketing and advertising. Existing techniques for spatiotemporal prediction of foot traffic use location-based social network data that suffer from sparsity, capturing only a handful of visits per day. This study utilizes highly granular foot traffic data from SafeGraph, a data company that collects mobility data regarding hundreds of millions of visits per day in the United States alone. Using this data, we explore solutions to predict weekly foot traffic data at the POI level. We propose a collaborative filtering approach using tensor factorization on the (POIs x CBGs x Weeks) data tensor. This approach provides us with a de-noised estimation of visits in …"
Andreas Züfle,Semantically diverse paths with range and origin constraints,2021,https://dl.acm.org/doi/abs/10.1145/3474717.3483985,"One of the most popular applications of Location Based Services (LBS) is recommending a Point of Interest (POI) based on user's preferences and geo-locations. However, the existing approaches have not tackled the problem of jointly determining: (a) a sequence of POIs that can be traversed within certain budget (i.e., limit on distance) and simultaneously provide a high-enough diversity; and (b) recommend the best origin (i.e., the hotel) for a given user, so that the desired route of POIs can be traversed within the specified constraints. In this work, we take a first step towards identifying this new problem and formalizing it as a novel type of a query. Subsequently, we present naïve solutions and experimental observations over a real-life datasets, illustrating the trade-offs in terms of (dis)associating the initial location from the rest of the POIs."
Andreas Züfle,The 1st ACM sigspatial international workshop on modeling and understanding the spread of covid-19,2021,https://dl.acm.org/doi/abs/10.1145/3447994.3448007,"In response to the COVID-19 pandemic, a number of spatially-explicit models have been developed to better explain the pathways of the disease, to predict the trajectory of the disease, and to test the effect of different health guidelines and policies on the number of cases and deaths. The 1st ACM SIGSPATIAL International Workshop on Modeling and Understanding the Spread of COVID-19 workshop (COVID'2020) featured research efforts that aim to understand the spatial processes and patterns of COVID-19 spread using a variety of spatial modeling, simulation, and mining approaches. The goal of this workshop was to bring together a range of interdisciplinary researchers in the SIGSPATIAL community in the fields of computer science, spatial modeling, social sciences, and epidemiology. Also, this workshop was advertised for anyone interested in infectious disease data and modelling, including but not limited …"
Andreas Züfle,Vehicle relocation for ride-hailing,2020,https://ieeexplore.ieee.org/abstract/document/9259995/,"Ever increasing traffic and consequential congestion wastes fuel and is a significant contributor to Green House Gas (GHG) emissions. Contributors here include ride-sharing services such as Uber, Lyft, and Didi, with their drivers not only transporting passengers, but also spending a considerable time in traffic searching for new ones. To mitigate their impact, this work proposes a novel algorithm to improve the efficiency the drivers' search for passengers. Our algorithm directs unassigned drivers to locations where new passengers are expected to emerge. We use a non-negative matrix factorization approach to model the time and location of passengers given historical training data. A probabilistic search strategy then guides drivers to nearby locations for which we predict new passengers. To ensure that drivers do not over subscribe to such areas, we randomize destinations and provide each driver with a home …"
Andreas Züfle,Expert-in-the-loop prescriptive analytics using mobility intervention for epidemics,2020,https://www.researchgate.net/profile/Joon-Seok-Kim-2/publication/343906417_Expert-in-the-Loop_Prescriptive_Analytics_using_Mobility_Intervention_for_Epidemics/links/5f479549299bf13c503dedc9/Expert-in-the-Loop-Prescriptive-Analytics-using-Mobility-Intervention-for-Epidemics.pdf,"Due to complexity of social phenomena, it is a big challenge to predict the curves of epidemics that spread via social contacts and to control such epidemics. Misguided policies to mitigate epidemics may result in catastrophic consequences such as financial crisis, massive unemployment, and the surge of the number of critically ill patients exceeding the capacity of hospitals. In particular, under/overestimation of efficacy of interventions can mislead policymakers about perception of evolving situations. To avoid such pitfalls, we propose Expert-in-the-Loop (EITL) prescriptive analytics using mobility intervention for epidemics. Rather than employing a purely data-driven approach, the key advantage of our approach is to leverage experts’ best knowledge in estimating disease spreading and the efficacy of interventions which allows us to efficiently narrow down factors and the scope of combinatorial possible worlds. We introduce our experience to develop Expert-in-the-Loop simulations during the Challenge on Mobility Intervention for Epidemics. We demonstrate that misconceptions about the causality can be corrected in the iterations of consulting with experts, developing simulations, and experimentation."
Andreas Züfle,Introduction to this special issue: Modeling and understanding the spread of COVID-19: (part II),2020,https://dl.acm.org/doi/pdf/10.1145/3431843.3448564,"The emergence of COVID-19 and its rapid spread across the globe has sparked research collaborations and initiatives between investigators from a vast number of disciplines including epidemiologists, social scientists, psychologists, mathematicians, geographers, data scientists, and more-all with the unified aim to better understand, predict, and mitigate the impacts of the disease. Many of these investigators make up the longstanding and interdisciplinary community that is SIGSPATIAL. Research efforts in this community offer a unique perspective for which to study the disease with a focus on the development and implementation of novel modeling, simulation, management, querying, and mining approaches that leverage the power of spatial-temporal data, much of which has increased in resolution and availability in an effort to combat COVID-19. Part I of this Special Issue on Modeling and Understanding the …"
Andreas Züfle,Neural Collaborative Filtering to Detect Anomalies in Human Semantic Trajectories,2024,https://dl.acm.org/doi/abs/10.1145/3681765.3698463,"Human trajectory anomaly detection is critical for applications such as security surveillance and public health, yet most existing methods focus on vehicle-level traffic, with limited attention to human-level trajectories. Due to the inherent sparsity of human trajectory data, machine learning approaches are favored for detecting complex patterns. However, concerns about model biases and robustness have highlighted the need for more transparent and explainable solutions. In this paper, we propose a lightweight anomaly detection model specifically designed to detect anomalies in human trajectories. We propose a Neural Collaborative Filtering approach to model and predict normal mobility. Our method is designed to model users' daily patterns of life without requiring prior knowledge, thereby enhancing performance in scenarios where data is sparse or incomplete, such as in cold start situations. Our algorithm …"
Andreas Züfle,Spatiotemporal disease case prediction using contrastive predictive coding,2022,https://dl.acm.org/doi/abs/10.1145/3557995.3566122,"Time series prediction models have played a vital role in guiding effective policymaking and response during the COVID-19 pandemic by predicting future cases and deaths at the country, state, and county levels. However, for emerging diseases, there is not sufficient historic data to fit traditional supervised prediction models. In addition, such models do not consider human mobility between regions. To mitigate the need for supervised models and to include human mobility data in the prediction, we propose Spatial Probabilistic Contrastive Predictive Coding (SP-CPC) which leverages Contrastive Predictive Coding (CPC), an unsupervised time-series representation learning approach. We augment CPC to incorporate a covariate mobility matrix into the loss function, representing the relative number of individuals traveling between each county on a given day. The proposal distribution learned by the algorithm is …"
Andreas Züfle,Augmenting geostatistics with matrix factorization: a case study for house price estimation,2020,https://www.mdpi.com/2220-9964/9/5/288,"Singular value decomposition (SVD) is ubiquitously used in recommendation systems to estimate and predict values based on latent features obtained through matrix factorization. But, oblivious of location information, SVD has limitations in predicting variables that have strong spatial autocorrelation, such as housing prices which strongly depend on spatial properties such as the neighborhood and school districts. In this work, we build an algorithm that integrates the latent feature learning capabilities of truncated SVD with kriging, which is called SVD-Regression Kriging (SVD-RK). In doing so, we address the problem of modeling and predicting spatially autocorrelated data for recommender engines using real estate housing prices by integrating spatial statistics. We also show that SVD-RK outperforms purely latent features based solutions as well as purely spatial approaches like Geographically Weighted Regression (GWR). Our proposed algorithm, SVD-RK, integrates the results of truncated SVD as an independent variable into a regression kriging approach. We show experimentally, that latent house price patterns learned using SVD are able to improve house price predictions of ordinary kriging in areas where house prices fluctuate locally. For areas where house prices are strongly spatially autocorrelated, evident by a house pricing variogram showing that the data can be mostly explained by spatial information only, we propose to feed the results of SVD into a geographically weighted regression model to outperform the orginary kriging approach."
Andreas Züfle,Transferable Unsupervised Outlier Detection Framework for Human Semantic Trajectories,2024,https://dl.acm.org/doi/abs/10.1145/3678717.3691324,"Semantic trajectories, which enrich spatial-temporal data with textual information such as trip purposes or location activities, are key for identifying outlier behaviors critical to healthcare, social security, and urban planning. Traditional outlier detection relies on heuristic rules, which requires domain knowledge and limits its ability to identify unseen outliers. Besides, there lacks a comprehensive approach that can jointly consider multi-modal data across spatial, temporal, and textual dimensions. Addressing the need for a domain-agnostic model, we propose the Transferable Outlier Detection for Human Semantic Trajectories (TOD4Traj) framework. TOD4Traj first introduces a modality feature unification module to align diverse data feature representations, enabling the integration of multi-modal information and enhancing transferability across different datasets. A contrastive learning module is further proposed for …"
Andreas Züfle,Using Generative Adversarial Networks to Assist Synthetic Population Creation for Simulations,2022,https://ieeexplore.ieee.org/abstract/document/9859422/,Synthetic populations are heavily used in agent-based simulations and microsimulations to create realistic representations of real-world populations. Many existing techniques rely on duplicating or selecting a sample of disaggregated records captured via surveys to generate the entire synthetic population. The challenge here is the potential bias present in the sample of disaggregated records. This paper posits that such disaggregated records can be improved or replaced by training a generative adversarial network (GAN). We present a case study of a 1.1 million population using iterative proportional fitting (IPF). We illustrate that IPF makes a better fit using GAN-based disaggregated records rather than original census-based disaggregated records. Our results show a promising use of GANs for synthetic population generation.
Andreas Züfle,Clustering of adverse events of post-market approved drugs,2021,https://dl.acm.org/doi/abs/10.1145/3469830.3470903," Adverse side effects of a drug may vary over space and time due to different populations, environments, and drug quality. Discovering all side effects during the development process is impossible. Once a drug is approved, observed adverse effects are reported by doctors and patients and made available in the Adverse Event Reporting System provided by the U.S. Food and Drug Administration . Mining such records of reported adverse effects, this study proposes a spatial clustering approach to identify regions that exhibit similar adverse effects. We apply a topic modeling approach on textual representations of reported adverse effects using Latent Dirichlet Allocation. By describing a spatial region as a mixture of the resulting latent topics, we find clusters of regions that exhibit similar (topics of) adverse events for the same drug using Hierarchical Agglomerative Clustering. We investigate the resulting clusters for …"
Andreas Züfle,Investigating permafrost carbon dynamics in Alaska with artificial intelligence,2023,https://iopscience.iop.org/article/10.1088/1748-9326/ad0607/meta,"Positive feedbacks between permafrost degradation and the release of soil carbon into the atmosphere impact land–atmosphere interactions, disrupt the global carbon cycle, and accelerate climate change. The widespread distribution of thawing permafrost is causing a cascade of geophysical and biochemical disturbances with global impacts. Currently, few earth system models account for permafrost carbon feedback (PCF) mechanisms. This research study integrates artificial intelligence (AI) tools and information derived from field-scale surveys across the tundra and boreal landscapes in Alaska. We identify and interpret the permafrost carbon cycling links and feedback sensitivities with GeoCryoAI, a hybridized multimodal deep learning (DL) architecture of stacked convolutionally layered, memory-encoded recurrent neural networks (NN). This framework integrates in-situ measurements and flux tower …"
Andreas Züfle,A hierarchical spatial network index for arbitrarily distributed spatial objects,2021,https://www.mdpi.com/2220-9964/10/12/814,"The range query is one of the most important query types in spatial data processing. Geographic information systems use it to find spatial objects within a user-specified range, and it supports data mining tasks, such as density-based clustering. In many applications, ranges are not computed in unrestricted Euclidean space, but on a network. While the majority of access methods cannot trivially be extended to network space, existing network index structures partition the network space without considering the data distribution. This potentially results in inefficiency due to a very skewed node distribution. To improve range query processing on networks, this paper proposes a balanced Hierarchical Network index (HN-tree) to query spatial objects on networks. The main idea is to recursively partition the data on the network such that each partition has a similar number of spatial objects. Leveraging the HN-tree, we present an efficient range query algorithm, which is empirically evaluated using three different road networks and several baselines and state-of-the-art network indices. The experimental evaluation shows that the HN-tree substantially outperforms existing methods."
Andreas Züfle,Clustering adverse events of COVID-19 vaccines across the United States,2021,https://link.springer.com/chapter/10.1007/978-3-030-89657-7_23,"We study the similarity of adverse effects of COVID-19 vaccines across different states in the United States. We use data of 300,000 COVID-19 vaccine adverse event reports obtained from the Vaccine Adverse Event Reporting System (VAERS). We extract latent topics from the reported adverse events using a topic modeling approach based on Latent Dirichlet allocation (LDA). This approach allows us to represent each U.S. state as a low-dimensional distribution over topics. Using Moran’s index of spatial autocorrelation we show that some of the topics of adverse events exhibit significant spatial autocorrelation, indicating that there exist spatial clusters of nearby states that exhibit similar adverse events. Using Anselin’s local indicator of spatial association we discover and report these clusters. Our results show that adverse events of COVID-19 vaccines vary across states which justifies further research to …"
Andreas Züfle,Efficient data propagation in a computer network,2020,https://patents.google.com/patent/US20200394249A1/en,"BACKGROUND [0003] Nowadays, technical telecommunication or electri cal networks have become ubiquitous in our daily life to receive and share information. Whenever we are navigating the World Wide Web or sending a text message on our cell-phone, we participate in an information network as a node. In such networks, network nodes exchange some sort of information: In wireless sensor networks nodes collect data and aim to ensure that this data is propagated through the network: Either to a destination, such as a server node, or simply to as many other nodes as possible. Abstractly speaking, in all of these networks, nodes aim at propagating their information throughout the network. The event of a successful propagation of information between nodes is subject to inherent uncertainty."
Andreas Züfle,Source Localization for Cross Network Information Diffusion,2024,https://dl.acm.org/doi/abs/10.1145/3637528.3671624,"Source localization aims to locate information diffusion sources only given the diffusion observation, which has attracted extensive attention in the past few years. Existing methods are mostly tailored for single networks and may not be generalized to handle more complex networks like cross-networks. Cross-network is defined as two interconnected networks, where one network's functionality depends on the other. Source localization on cross-networks entails locating diffusion sources on the source network by only giving the diffused observation in the target network. The task is challenging due to challenges including: 1) diffusion sources distribution modeling; 2) jointly considering both static and dynamic node features; and 3) heterogeneous diffusion patterns learning. In this work, we propose a novel method, namely CNSL, to handle the three primary challenges. Specifically, we propose to learn the distribution …"
Andreas Züfle,In Silico Human Mobility Data Science: Leveraging Massive Simulated Mobility Data (Vision Paper),2024,https://dl.acm.org/doi/abs/10.1145/3672557,"Human mobility data science using trajectories or check-ins of individuals has many applications. Recently, we have seen a plethora of research efforts that tackle these applications. However, research progress in this field is limited by a lack of large and representative datasets. The largest and most commonly used dataset of individual human trajectories captures fewer than 200 individuals, while datasets of individual human check-ins capture fewer than 100 check-ins per city per day. Thus, it is not clear if findings from the human mobility data science community would generalize to large populations. Since obtaining massive, representative, and individual-level human mobility data is hard to come by due to privacy considerations, the vision of this work is to embrace the use of data generated by large-scale socially realistic microsimulations. Informed by both real data and leveraging social and behavioral …"
Andreas Züfle,Mining high resolution earth observation data cubes,2021,https://dl.acm.org/doi/abs/10.1145/3469830.3470917,"Earth observation data is collected by ever-expanding fleets of satellites including Landsat1-8, Sentinel1 & Sentinel2, SPOT1-7 and WorldView1-3. These satellites generate at spatial resolutions (pixel size) from 30m to 31cm and provide revisit rates of as frequent as every 5 days. This allows us not only to look at high-resolution images of every corner of the Earth, but also to track events and observe change over time. During the past 5 years, medium spatial resolution satellite data (30 − 10m pixels) have developed very high temporal revisit frequencies of 5-16 days and spatial-temporal structures have been developed to manage these vast data sets. However, high resolution satellite images and rapidly increasing revisit rates create major data management and mining challenges. This work discusses six challenges of integrating observations at different times, from different sensors, at different spatial resolutions …"
Andreas Züfle,The Patterns of Life Human Mobility Simulation,2024,https://dl.acm.org/doi/abs/10.1145/3678717.3691319,"We demonstrate the Patterns of Life Simulation to create realistic simulations of human mobility in a city. This simulation has recently been used to generate massive amounts of trajectory and check-in data. Our demonstration focuses on using the simulation twofold: (1) using the graphical user interface (GUI), and (2) running the simulation headless by disabling the GUI for faster data generation. We further demonstrate how the Patterns of Life simulation can be used to simulate any region on Earth by using publicly available data from OpenStreetMap. Finally, we also demonstrate recent improvements to the scalability of the simulation allows simulating up to 100,000 individual agents for years of simulation time. During our demonstration, as well as offline using our guides on GitHub, participants will learn: (1) The theories of human behavior driving the Patters of Life simulation, (2) how to simulate to generate …"
Andreas Züfle,"Distance, origin and category constrained paths",2023,https://dl.acm.org/doi/abs/10.1145/3596601,"Recommending a Point of Interest (PoI) or a sequence of PoIs to visit based on user’s preferences and geo-locations has been one of the most popular applications of Location-Based Services (LBS). Variants have also been considered which take other factors into consideration, such as broader (implicit or explicit) semantic constraints as well as the limitations on the length of the trip. In this work, we present an efficient algorithmic solution to a novel query – PaDOC (Paths with Distance, Origin, and Category constraints) – which combines the generation of a path that (a) can be traversed within a user-specified budget (e.g., limit on distance), (b) starts at one of the user-specified origin locations (e.g., a hotel), and (c) contains PoIs from a user-specified list of PoI categories. We show that the problem of deciding whether such a path exists is an NP-hard problem. Based on a novel indexing structure, we propose two …"
Andreas Züfle,Phyloview: A system to visualize the ecology of infectious diseases using phylogenetic data,2022,https://ieeexplore.ieee.org/abstract/document/9861153/,"Since the onset of the COVID-19 pandemic, mil-lions of coronavirus sequences have been rapidly deposited in publicly available repositories. The sequences have been used primarily to monitor the evolution and transmission of the virus. In addition, the data can be combined with spatiotemporal information and mapped over space and time to understand transmission dynamics further. For example, the first COVID-19 cases in Australia were genetically related to the dominant strain in Wuhan, China, and spread via international travel. These data are currently available through the Global Initiative on Sharing Avian Influenza Data (GISAID) yet generally remains an untapped resource for data scientists to analyze such multi-dimensional data. Therefore, in this study, we demonstrate a system named Phyloview, a highly interactive visual environment that can be used to examine the spatiotemporal evolution of …"
Andreas Züfle,"Introduction to the Special Issue on Understanding the Spread of COVID-19, Part 2",2022,https://dl.acm.org/doi/abs/10.1145/3568670,"Infectious diseases are transmitted between human hosts when in close contact over space and time. Recently, an unprecedented amount of spatial and spatiotemporal data have been made available that can be used to improve our understanding of the spread of COVID-19 and other infectious diseases. This understanding will be paramount to prepare for future pandemics through spatial algorithms and systems to collect, capture, curate, and analyze complex, multi-scale human movement data to solve problems such as infectious diseases prediction, contact tracing, and risk assessment. In exploring and deepening the conversation around this topic, the eight articles included in the first volume of this special issue employ diverse theoretical perspectives, methodologies, and frameworks, including but not limited to infectious diseases simulation, risk prediction, response policy design, mobility analysis, and case …"
Andreas Züfle,Geosim 2019 workshop report: The 2nd acm sigspatial international workshop on geospatial simulation,2020,https://dl.acm.org/doi/abs/10.1145/3383653.3383661,"Space has long been acknowledged by researchers as a fundamental constraint which shapes our world. As technological changes have transformed the very concept of distance, the relative location and connectivity of geospatial phenomena have remained stubbornly significant in how systems function. At the same time, however, technology has allowed us to begin to bring tools like simulation to bear on our understanding of how such systems work. While previous generations of scientists and practitioners were unable to gather spatial data or to incorporate it into models at any meaningful scale, new methodologies and data sources are becoming increasingly available to researchers, developers, users, and practitioners. This flowering of different approaches is occurring simultaneously across many fields, and at every point in the research process."
Andreas Züfle,GeoAI for Public Health,2023,https://www.taylorfrancis.com/chapters/edit/10.1201/9781003308423-15/geoai-public-health-andreas-z%C3%BCfle-taylor-anderson-hamdi-kavak-dieter-pfoser-joon-seok-kim-amira-roess,"Infectious disease spread within the human population can be conceptualized as a complex system composed of individuals who interact and transmit viruses through spatio-temporal processes that manifest across and between scales. The complexity of this system ultimately means that the spread of infectious diseases is difficult to understand, predict, and respond to effectively. Research interest in GeoAI for public health has been fueled by the increased availability of rich data sources such as human mobility data, OpenStreetMap data, contact tracing data, symptomatic online surveys, retail and commerce data, genomics data, and more. This data availability has resulted in a wide variety of data-driven solutions for infectious disease spread prediction which show potential in enhancing our forecasting capabilities. This chapter (1) motivates the need for AI-based solutions in public health by showing the …"
Andreas Züfle,Investigating high-latitude permafrost carbon dynamics with artificial intelligence and Earth system data assimilation,2023,https://essopenarchive.org/doi/full/10.22541/essoar.170355053.35677457,"It is well-established that positive feedbacks between permafrost degradation and the release of soil carbon into the atmosphere impacts land-atmosphere interactions, disrupts the global carbon cycle, and accelerates climate change. The widespread distribution of thawing permafrost is causing a cascade of geophysical and biochemical disturbances with global impact. Currently, few earth system models account for permafrost carbon feedback mechanisms. This research identifies, interprets, and explains the feedback sensitivities attributed to permafrost degradation and terrestrial carbon cycling imbalance with in situ and flux tower measurements, remote sensing observations, process-based modeling simulations, and deep learning architecture. We defined and formulated high-resolution polymodal datasets with multitemporal extents and hyperspatiospectral fidelity (i.e., 12.4 million parameters with 13.1 million in situ data points, 2.84 billion ground-controlled remotely sensed data points, and 36.58 million model-based simulation outputs to computationally reflect the state space of the earth system), simulated the non-linear feedback mechanisms attributed to permafrost degradation and carbon cycle perturbation across Alaska with a process-constrained deep learning architecture composed of cascading stacks of convolutionally layered memory-encoded recurrent neural networks (i.e., GeoCryoAI), and interpreted historical and future emulations of freeze-thaw dynamics and the permafrost carbon feedback with a suite of evaluation and performance metrics (e.g., cross-entropic loss, root-mean-square deviation, accuracy). This framework …"
Andreas Züfle,Searching semantically diverse paths,2023,https://link.springer.com/article/10.1007/s10619-022-07413-x,"Location-Based Services are often used to find proximal Points of Interest (PoIs)—e.g., nearby restaurants and museums, police stations, hospitals, etc.—in a plethora of applications. An important recently addressed variant of the problem not only considers the distance/proximity aspect, but also desires semantically diverse locations in the answer-set. For instance, rather than picking several close-by attractions with similar features—e.g., restaurants with similar menus; museums with similar art exhibitions—a tourist may be more interested in a result set that could potentially provide more diverse types of experiences, for as long as they are within an acceptable distance from a given (current) location. Towards that goal, in this work we propose a novel approach to efficiently retrieve a path that will maximize the semantic diversity of the visited PoIs that are within distance limits along a given road network. Our …"
Andreas Züfle,Human mobility-based synthetic social network generation,2022,https://dl.acm.org/doi/abs/10.1145/3557921.3565540,"Location-Based Social Networks (LBSNs) combine location information with social networks and have been studied vividly in the last decade. The main research gap is the lack of available and authoritative social network datasets. Publicly available social network datasets are small and sparse, as only a small fraction of the population is captured in the dataset. For this reason, network generators are often employed to generate social networks to study LBSNs synthetically. In this work, we propose an evolving social network implemented in an agent-based simulation to generate realistic social networks. In the simulation, as agents move to different places of interest have the chance to make social connections with other agents as they visit the same place. A large-scale real-world mobility dataset informs the choice of places that agents visit in our simulation. We show qualitatively that our simulated social networks …"
Andreas Züfle,Towards Large-Scale Agent-Based Geospatial Simulation,2021,https://scholar.google.com/scholar?cluster=16099309276903693248&hl=en&oi=scholarr,
Andreas Züfle,Station-to-user transfer learning: Towards explainable user clustering through latent trip signatures using tidal-regularized non-negative matrix factorization,2020,https://dl.acm.org/doi/abs/10.1145/3397536.3422250,"Urban areas provide us with a treasure trove of available data capturing almost every aspect of a population's life. This work focuses on mobility data and how it will help improve our understanding of urban mobility patterns. Readily available and sizable farecard data captures trips in a public transportation network. However, such data typically lacks temporal signatures and as such the task of inferring trip semantics, station function, and user clustering is quite challenging. While existing approaches either focus on station-level or user-level signals only, we propose a Station-to-User (S2U) transfer learning framework, which augments user-level learning with shared temporal patterns learned from station-level signals. Our framework is based on a novel, so-called ""Tidal-Regularized Non-negative Matrix Factorization"" method, which incorporates a-priori tidal traffic patterns in generic Non-negative Matrix …"
Andreas Züfle,Expert-in-the-Loop Prescriptive Analytics using Mobility Intervention for Epidemics.(2020),2020,https://scholar.google.com/scholar?cluster=6572563999413663239&hl=en&oi=scholarr,
Andreas Züfle,Chatting with Logs: An exploratory study on Finetuning LLMs for LogQL,2024,https://arxiv.org/abs/2412.03612,"Logging is a critical function in modern distributed applications, but the lack of standardization in log query languages and formats creates significant challenges. Developers currently must write ad hoc queries in platform-specific languages, requiring expertise in both the query language and application-specific log details -- an impractical expectation given the variety of platforms and volume of logs and applications. While generating these queries with large language models (LLMs) seems intuitive, we show that current LLMs struggle with log-specific query generation due to the lack of exposure to domain-specific knowledge. We propose a novel natural language (NL) interface to address these inconsistencies and aide log query generation, enabling developers to create queries in a target log query language by providing NL inputs. We further introduce ~\textbf{NL2QL}, a manually annotated, real-world dataset of natural language questions paired with corresponding LogQL queries spread across three log formats, to promote the training and evaluation of NL-to-loq query systems. Using NL2QL, we subsequently fine-tune and evaluate several state of the art LLMs, and demonstrate their improved capability to generate accurate LogQL queries. We perform further ablation studies to demonstrate the effect of additional training data, and the transferability across different log formats. In our experiments, we find up to 75\% improvement of finetuned models to generate LogQL queries compared to non finetuned models."
Andreas Züfle,Spatial Transfer Learning for Estimating PM in Data-Poor Regions,2024,https://link.springer.com/chapter/10.1007/978-3-031-70378-2_24,"Air pollution, especially particulate matter 2.5 (PM), is a pressing concern for public health and is difficult to estimate in developing countries (data-poor regions) due to a lack of ground sensors. Transfer learning models can be leveraged to solve this problem, as they use alternate data sources to gain knowledge (i.e., data from data-rich regions). However, current transfer learning methodologies do not account for dependencies between the source and the target domains. We recognize this transfer problem as spatial transfer learning and propose a new feature named Latent Dependency Factor (LDF) that captures spatial and semantic dependencies of both domains and is subsequently added to the feature spaces of the domains. We generate LDF using a novel two-stage autoencoder model that learns from clusters of similar source and target domain data. Our experiments show that transfer learning models …"
Andreas Züfle,Leveraging Simulation Data to Understand Bias in Predictive Models of Infectious Disease Spread,2024,https://dl.acm.org/doi/abs/10.1145/3660631,"The spread of infectious diseases is a highly complex spatiotemporal process, difficult to understand, predict, and effectively respond to. Machine learning and artificial intelligence (AI) have achieved impressive results in other learning and prediction tasks; however, while many AI solutions are developed for disease prediction, only a few of them are adopted by decision-makers to support policy interventions. Among several issues preventing their uptake, AI methods are known to amplify the bias in the data they are trained on. This is especially problematic for infectious disease models that typically leverage large, open, and inherently biased spatiotemporal data. These biases may propagate through the modeling pipeline to decision-making, resulting in inequitable policy interventions. Therefore, there is a need to gain an understanding of how the AI disease modeling pipeline can mitigate biased input data, in …"
Andreas Züfle,Probabilistic counting in uncertain spatial databases using generating functions,2023,https://dl.acm.org/doi/pdf/10.1145/3617291.3617300,"8.1 Our ability to unearth valuable knowledge from large sets of spatial data is often impaired by the uncertainty of the data, which geography has named the “the Achilles heel of GIS”[Goodchild 1998]. The uncertainty is caused by several reasons:(1) imprecision caused by physical limitations of sensing devices and connection errors;(2) data records may be obsolete;(3) data can be obtained from unreliable sources, such as volunteered geographic information; and (4) data may be deliberately obfuscated to preserve the privacy of users. These issues introduce the notion of uncertainty in the context of spatiotemporal data management. Many algorithms have been proposed in the last decade to handle different spatial query predicates (such as distance range, kNN, and distance ranking) described in various tutorials [Renz et al. 2010, Cheng et al. 2014, Züfle et al. 2017, 2020] and surveys [Aggarwal and Philip 2009 …"
Andreas Züfle,Synthetic Geosocial Network Generation,2023,https://dl.acm.org/doi/abs/10.1145/3615896.3628345,"Generating synthetic social networks is an important task for many problems that study humans, their behavior, and their interactions. Geosocial networks enrich social networks with location information. Commonly used models to generate synthetic social networks include the classical Erdős-Rényi, Barabási-Albert, and Watts-Strogatz models. However, these classic social network models do not consider the location of individuals. Real-world geosocial networks do exhibit a strong spatial autocorrelation, thus having a higher likelihood of a social connection between agents that are spatially close. As such, recent variants of the three classical models have been proposed to consider location information. Yet, these existing solutions assume that individuals are located on a uniform lattice and exhibit certain limitations when applied to real-world data that exhibits clusters. In this work, we discuss these limitations and …"
Andreas Züfle,Proceedings of the 4th ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology,2023,https://dl.acm.org/doi/abs/10.1145/3615898,"The 21st century has seen major epidemics and pandemics caused by infectious diseases like coronaviruses, influenza, and most recently, monkey pox. Infectious disease spread within the human population can be conceptualized as a complex system composed of individuals that interact and transmit viruses via spatiotemporal processes that manifest across and between scales. The complexity of this system ultimately means that infectious disease spread is difficult to understand, predict, and effectively respond to. As spatial data becomes increasingly available at high spatial and temporal resolutions and computing resources can more efficiently handle such data, there have been opportunities for new data science and simulation-based solutions towards improved public health."
Andreas Züfle,"Spatial Gems, Volume 1",2022,https://dl.acm.org/doi/abs/10.1145/3548732,"This book presents fundamental new techniques for understanding and processing geospatial data. These “spatial gems” articulate and highlight insightful ideas that often remain unstated in graduate textbooks, and which are not the focus of research papers. They teach us how to do something useful with spatial data, in the form of algorithms, code, or equations. Unlike a research paper, Spatial Gems, Volume 1 does not focus on “Look what we have done!” but rather shows “Look what YOU can do!” With contributions from researchers at the forefront of the field, this volume occupies a unique position in the literature by serving graduate students, professional researchers, professors, and computer developers in the field alike."
Andreas Züfle,Proceedings of the 1st ACM SIGSPATIAL International Workshop on Searching and Mining Large Collections of Geospatial Data,2021,https://dl.acm.org/doi/abs/10.1145/3486640,"The amount of location data generated and models that are being developed is increasing quickly. Remote sensing provides exabytes of Earth observation data, sensor networks generate measurements with unprecedented velocity, social networks, autonomous cars, smart cities, and the Internet of Things (IoT) add to these collections. Traditionally, geospatial data management is based on curating datasets and catalogue services which provide the ability to filter datasets based on size, location, and thematic focus. For example, the Worldview-3 satellite observes the world at a resolution of 31cm per pixel, which translates into 10.4 million pixels per km2, and covers 680, 000km2 a day1 resulting in more than 7 trillion pixels per day. Our ability to develop models that can recognize objects on a given image has improved tremendously in the last decade, allowing us to monitor a region to detect flooding, or forest …"
Andreas Züfle,Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology,2021,https://dl.acm.org/doi/abs/10.1145/3486633,"The spatial behavior of humans, plants, and animals as well as changing geographical and ecological environments play a role in the spread of diseases. In light of the COVID-19 pandemic, recent scientific efforts focus on the development of real time monitoring and response systems, modeling and simulation to predict disease outcomes under existing or hypothetical scenarios, and the analysis of spatiotemporal data to describe or explain behaviors that affect disease trajectories. In general, these efforts seek to generate or leverage spatiotemporal data to improve our understanding, prediction, and response to infectious disease outbreaks."
Andreas Züfle,The 3rd ACM sigspatial international workshop on geospatial simulation: geosim 2020 workshop report,2021,https://dl.acm.org/doi/abs/10.1145/3447994.3448000,"Space has long been acknowledged by researchers as a fundamental constraint which shapes our world. As technological changes have transformed the very concept of distance, the relative location and connectivity of geospatial phenomena have remained stubbornly significant in how systems function. At the same time, however, technology has advanced the science of geospatial simulation to bear on our understanding of how such systems work. While previous generations of scientists and practitioners were unable to gather spatial data or to incorporate it into models at any meaningful scale, new methodologies and data sources are becoming increasingly available to researchers, developers, users, and practitioners. These developments present new research opportunities for geospatial simulation."
Andreas Züfle,Agent-based simulation of human mobility using high-resolution foot-traffic data,2021,https://journals.gmu.edu/index.php/jssr/article/view/3235,"Accurate models for human mobility are crucial in simulations of disease transmission, autonomous transportation, and urban planning. However, contemporary mobility models rely on random representations of human mobility due to insufficient data sources. We compare the accuracy of human mobility using three distinct statistical models: a probabilistic and Latent Dirichlet Allocation (LDA) model that are calibrated using foot-traffic data from SafeGraph and a random model that delineates human mobility without being data-driven. We fit the probabilistic and LDA models on a single month and evaluate their respective accuracies on empirical data from subsequent months using the Jaccard similarity coefficient. Our findings demonstrate that the probability model produces the most accurate inferences of human mobility, followed by the LDA model, with the random model yielding the lowest accuracy. Our future …"
Andreas Züfle,Proceedings of the 1st ACM SIGSPATIAL International Workshop on Modeling and Understanding the Spread of COVID-19,2020,https://dl.acm.org/doi/abs/10.1145/3423459,"The 1st ACM SIGSPATIAL International Workshop on Modeling and Understanding the Spread of COVID-19 workshop (COVID'2020) will focus on all aspects of modeling, simulating, mining, and understanding the spatial processes and patterns of the spread of COVID-19 and other infectious diseases. This cross-disciplinary workshop is a forum to bring together researchers in the SIGSPATIAL community as well as researchers in epidemiology. Also, this workshop is of interest to everyone who works with infectious disease data and models (not necessarily COVID19)."
Andreas Züfle,Deep Identification of Propagation Trees,2025,https://arxiv.org/abs/2503.00646,"Understanding propagation structures in graph diffusion processes, such as epidemic spread or misinformation diffusion, is a fundamental yet challenging problem. While existing methods primarily focus on source localization, they cannot reconstruct the underlying propagation trees i.e., ""who infected whom"", which are substantial for tracking the propagation pathways and investigate diffusion mechanisms. In this work, we propose Deep Identification of Propagation Trees (DIPT), a probabilistic framework that infers propagation trees from observed diffused states. DIPT models local influence strengths between nodes and leverages an alternating optimization strategy to jointly learn the diffusion mechanism and reconstruct the propagation structure. Extensive experiments on five real-world datasets demonstrate the effectiveness of DIPT in accurately reconstructing propagation trees."
Andreas Züfle,Commuting flow prediction using OpenStreetMap data,2025,https://link.springer.com/article/10.1007/s43762-025-00161-5,"Accurately predicting commuting flows is crucial for sustainable urban planning and preventing disease spread due to human mobility. While recent advancements have produced effective models for predicting these recurrent flows, the existing methods rely on datasets exclusive to a few study areas, limiting the transferability to other locations. This research broadens the utility of state-of-the-art commuting flow prediction models with globally available OpenStreetMap data while achieving prediction accuracy comparable to location-specific and proprietary data. We show that the types of buildings, residential and non-residential, are a strong indicator for predicting commuting flows. Consistent with theoretical and analytical models, our experiments indicate that building types, distance, and population are the determining characteristics for mobility related to commuting. Our experiments show that predicted flows …"
Andreas Züfle,Simplifying traffic simulation-from Euclidean distances to agent-based models,2024,https://link.springer.com/article/10.1007/s43762-024-00145-x,"Urban settings require a thorough understanding of traffic patterns to best manage traffic, be prepared for emergency scenarios and to guide future infrastructure investments. In addition to analyzing collected traffic data, traffic modeling is an important tool that often requires detailed simulations that can be computationally intensive and time-consuming. A well-known comprehensive simulation framework is MATSim. On the other hand, simpler shortest-path routing systems that compute trips on an individual basis promise faster computations. The primary focus of this study is to assess the viability of a fast shortest path routing system as a method of traffic simulation. This study compares the MATSim with the Graphhopper routing system. Key metrics include travel time accuracy, congestion levels, route similarity, vehicle miles traveled, and average travel time. By analyzing these metrics, this study shows that a …"
Andreas Züfle,Human Mobility Challenge: Are Transformers Effective for Human Mobility Prediction?,2024,https://dl.acm.org/doi/abs/10.1145/3681771.3700130,"Transformer-based models are popular for time series forecasting and spatiotemporal prediction due to their ability to infer semantic correlations in long sequences. However, for human mobility prediction, temporal correlations, such as location patterns at the same time on previous days or weeks, are essential. While positional encodings help retain order, the self-attention mechanism causes a loss of temporal detail. To validate this claim, we used a simple approach in the 2nd ACM SIGSPATIAL Human Mobility Prediction Challenge, predicting locations based on past patterns weighted by reliability scores for missing data. Our simple approach was among the top 10 competitors and significantly outperformed the Transformer-based model that won the 2023 challenge."
Andreas Züfle,An Infectious Disease Spread Simulation to Control Data Bias,2024,https://dl.acm.org/doi/abs/10.1145/3678717.3691293,"The increased availability of datasets during the COVID-19 pandemic enabled machine-learning approaches for modeling and forecasting infectious diseases. However, such approaches are known to amplify the bias in the data they are trained on. Bias in such input data like clinical case data for COVID-19 is difficult to measure due to disparities in testing availability, reporting standards, and healthcare access among different populations and regions. Furthermore, the way such biases may propagate through the modeling pipeline to decision-making is relatively unknown. Therefore, we present a system that leverages a highly detailed agent-based model (ABM) of infectious disease spread in a city to simulate the collection of biased clinical case data where the bias is known. Our system allows users to load either a pre-selected region or select their own (using OpenStreetMap data for the environment and …"
Andreas Züfle,"Data and Resources for Combining Point of Interest Semantics, Locations, and Road Networks",2024,https://dl.acm.org/doi/abs/10.1145/3678717.3691300,"The advancements in Location Based Services (LBS) and Location Based Social Networks (LBSN) have spurred multiple research efforts in query processing as well as recommendation systems that enable planning trips based on combining location and semantic properties of Points of Interest (POI). However, often times such trips need to involve the reality of existing road networks, for the purpose of obeying constraints such as distance or travel-time. Although there are many publicly available datasets (e.g., Gowalla) that include check-in data at POIs with location, they are often not integrated with existing roads-based data (e.g., Open Street Maps (OSM)) causing researchers to spend extra time and labour to experimentally evaluate their findings. In this paper, we present: (1) methodologies for extracting information regarding POIs from publicly available datasets based on users posting; (2) extracting concise …"
Andreas Züfle,Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Searching and Mining Large Collections of Geospatial Data,2024,https://dl.acm.org/doi/abs/10.1145/3681769,"To search and localize objects of interest among massive and multi-modality geospatial data is key in spatial computing. However, the effective and efficient searching among an extensive collection of geospatial data (e.g., global satellite imagery, building footprint) for interesting patterns can be challenging. In this context, not only does one need to know where to look to find objects of interest but also which model to use for different searching tasks. What if prior efforts had already created models on an exact or very similar task? How should users search for such models? When models are available, how should they be stored? Many applications become possible if we manage to make large data collections and models searchable by content, metadata, and analytic tasks. Application users would like to solve these challenges by knowing which model to use, which task the model is relevant for, and how to …"
Andreas Züfle,GeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Dataset,2024,https://dl.acm.org/doi/abs/10.1145/3681770.3698573,"Analyzing individual human trajectory data helps our understanding of human mobility and finds many commercial and academic applications. There are two main approaches to accessing trajectory data for research: one involves using real-world datasets like GeoLife, while the other employs simulations to synthesize data. Real-world data provides insights from real human activities, but such data is generally sparse due to voluntary participation. Conversely, simulated data can be more comprehensive but may capture unrealistic human behavior. In this Data and Resource paper, we combine the benefit of both by leveraging the statistical features of real-world data and the comprehensiveness of simulated data. Specifically, we extract features from the real-world GeoLife dataset such as the average number of individual daily trips, average radius of gyration, and maximum and minimum trip distances. We …"
Andreas Züfle,Kinematic Detection of Anomalies in Human Trajectory Data,2024,https://dl.acm.org/doi/abs/10.1145/3681765.3698464,"Historically, much of the research in understanding, modeling, and mining human trajectory data has focused on where an individual stays. Thus, the focus of existing research has been on where a user goes. On the other hand, the study of how a user moves between locations has great potential for new research opportunities. Kinematic features describe how an individual moves between locations and can be used for tasks such as identification of individuals or anomaly detection. Unfortunately, data availability and quality challenges make kinematic trajectory mining difficult. In this paper, we leverage the Geolife dataset of human trajectories to investigate the viability of using kinematic features to identify individuals and detect anomalies. We show that humans have an individual ""kinematic profile"" which can used as a strong signal to identify individual humans. We experimentally show that, for the two use-cases …"
Andreas Züfle,Urban Anomalies: A Simulated Human Mobility Dataset with Injected Anomalies,2024,https://dl.acm.org/doi/abs/10.1145/3681765.3698459,"Human mobility anomaly detection based on location is essential in areas such as public health, safety, welfare, and urban planning. Developing models and approaches for location-based anomaly detection requires a comprehensive dataset. However, privacy concerns and the absence of ground truth hinder the availability of publicly available datasets. With this paper, we provide extensive simulated human mobility datasets featuring various anomaly types created using an existing Urban Patterns of Life Simulation. To create these datasets, we inject changes in the logic of individual agents to change their behavior. Specifically, we create four of anomalous agent behavior by (1) changing the agents' appetite (causing agents to have meals more frequently), (2) changing their group of interest (causing agents to interact with different agents from another group). (3) changing their social place selection (causing …"
Andreas Züfle,Transfer Learning via Latent Dependency Factor for Estimating PM 2.5,2024,https://ui.adsabs.harvard.edu/abs/2024arXiv240407308G/abstract,"Air pollution, especially particulate matter 2.5 (PM 2.5), is a pressing concern for public health and is difficult to estimate in developing countries (data-poor regions) due to a lack of ground sensors. Transfer learning models can be leveraged to solve this problem, as they use alternate data sources to gain knowledge (ie, data from data-rich regions). However, current transfer learning methodologies do not account for dependencies between the source and the target domains. We recognize this transfer problem as spatial transfer learning and propose a new feature named Latent Dependency Factor (LDF) that captures spatial and semantic dependencies of both domains and is subsequently added to the datasets. We generate LDF using a novel two-stage autoencoder model that learns from clusters of similar source and target domain data. Our experiments show that transfer models using LDF have a  …"
Andreas Züfle,Spatial Gems 2022 Workshop Report: The 4th ACM SIGSPATIAL International Workshop on Spatial Gems,2023,https://dl.acm.org/doi/abs/10.1145/3632268.3632282,"Researchers and practitioners working with spatial data often develop fundamental new techniques they would like to share with their community. These are not necessarily new research results, not yet in any textbook, but they are interesting, self-contained techniques for doing something useful in the domain of spatial data. We call these techniques ""spatial gems""."
Andreas Züfle,SpatialEpi'2022 Workshop Report: The 3rd ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology,2023,https://dl.acm.org/doi/abs/10.1145/3632268.3632277,"Since the onset of the COVID-19 pandemic, researchers in the SIGSPATIAL community have utilized computational solutions to better explain, predict, and respond to infectious disease outbreaks. Using spatial computing for pandemic preparedness has also been highlighted as a major application of mobility data science [16]. At the beginning of the COVID-19 pandemic, the SIGSPATIAL community rapidly published ideas to improve our understanding of the spread of the virus in two SIGSPATIAL Special Newsletter Issues in March and July 2020 [28, 29]. These efforts led to the 1st and 2nd ACM SIGSPATIAL International Workshop on Spatial Computing for Epidemiology [5, 4] (formerly called Workshop on Modeling and Understanding the Spread of COVID-19 in 2020) which has provided authors of these newsletter articles a forum to present and discuss their solutions. Including both work published at the …"
Andreas Züfle,Implementing Spatial Social Networks with Real World Data,2023,https://journals.gmu.edu/jssr/article/view/3836,"The three classical models for synthetically generated social networks, Erdos-Renyi, Barabasi-Albert, and Watts-Strogatz have been shown to not reflect real world social networks. Spatial versions of these networks, which take into account the distance between nodes when determining the probability that two nodes connect, have been proposed to improve their realism, but these spatial versions were not tested with real world data. We altered the code for the spatial versions of the three classical models to accommodate real world data, namely the CBG coordinates for Fairfax County. In this project, we evaluate the realism of the networks generated by this code, by collecting descriptive statistics such as the number of triangles and the average length of edges, as real world networks are likely to have high clustering and nodes are more likely to connect to nodes that are near them. Our experimental results show …"
Andreas Züfle,The Partition Bridge (PB) tree: Efficient nearest neighbor query processing on road networks,2023,https://www.sciencedirect.com/science/article/pii/S0306437923000923,"With the rapid development of location-based services, many types of applications in urban areas such as transportation planning, traffic management, and deployment of infrastructure depend on spatial objects that are distributed along the road network. As current place datasets include millions of spatial objects and human mobility datasets capture billions of locations, it is an important challenge to answer k-nearest neighbor queries efficiently. However, shortest-path distance calculations are the computational bottleneck for a k-nearest neighbor queries on road networks. Existing query algorithms partition the network to mitigate this bottleneck, but they do not take the data distribution into account, which leads to inefficiencies in dense areas and sparse areas. In this paper, an efficient and scalable indexing method called the Partition Bridge tree (PB-tree), is proposed based on hierarchical network partitions that …"
Andreas Züfle,Message from the PC and General co-Chairs SSTD 2023,2023,https://experts.umn.edu/en/publications/message-from-the-pc-and-general-co-chairs-sstd-2023,"Message from the PC and General co-Chairs SSTD 2023 - Experts@Minnesota Skip to main 
navigation Skip to search Skip to main content Experts@Minnesota Home Experts@Minnesota 
Logo Home Profiles Research units University Assets Projects and Grants Research output 
Press/Media Datasets Activities Fellowships, Honors, and Prizes Search by expertise, name or 
affiliation Message from the PC and General co-Chairs SSTD 2023 Zheng Baihua, Mohamed 
Mokbel, Mario A. Nascimento, Chiara Renso, Karine Zeitouni, Andreas Züfle Computer Science 
and Engineering Research output: Contribution to journal › Editorial › peer-review Overview 
Original language English (US) Pages (from-to) VI-VII Journal ACM International Conference 
Proceeding Series State Published - Aug 23 2023 Event 18th International Symposium 
on Spatial and Temporal Data, SSTD 2023 - Calgary, United States Duration: Aug 23 …"
Andreas Züfle,"RouteDOC: Routing with Distance, Origin and Category Constraints (Demonstration Paper)",2023,https://dl.acm.org/doi/abs/10.1145/3609956.3609977," Route planning based on user’s preferences and Points of Interests (POIs) is one of the most popular applications of Location-Based Services (LBS). Variants of route planning consider distance constraints (e.g., the maximum length of the route), origin constraints (e.g., a set of possible starting locations of the route), and category constraints (e.g., a multiset of POI categories that the route must visit). However, the problem of deciding whether a route exists that visits all required POI categories under the distance constraint is known to be NP-hard. Assuming P ≠ NP, this means that there is no efficient (polynomial time) solution to find such paths. Recently, approximate algorithms have been proposed for searching for such a path. This demonstration leverages several of these algorithms to provide a web-based system with a graphical user interface (UI) which allows the users to find a path that: (a) satisfies a distance …"
Andreas Züfle,Semi-Supervised Satellite Image Segmentation Using Spatial and Temporally Informed Poisson Learning,2023,https://ieeexplore.ieee.org/abstract/document/10282967/,"Satellite image segmentation is crucial in various fields, but acquiring a large amount of labeled data can be challenging. Often, remote sensing images are unlabeled due to the high cost of manual labeling, which hampers training effectiveness and generalization. To address this issue, we propose a spatially and temporally informed graph-based semi-supervised learning approach for satellite image segmentation based on Poisson learning. The main difference to traditional Poisson learning is that our distance function that we use to compute similarity between pixels considers spectral, spatial, and temporal information. Experimental results on the Sentinel-2 time series demonstrate that our approach outperforms other traditional approaches, achieving robust performance in remote sensing image segmentation, especially at a very low label rate."
Andreas Züfle,"Searching and Mining Large Collections of Geospatial Data (GeoSearch 2023) Nov. 13, 2023, Hamburg, Germany",2023,https://dl.acm.org/doi/pdf/10.1145/3615890,"Geographic information systems (GIS) provide users with a means to efficiently search over spatial data given certain key pieces of information, like the coordinates or exact name of a location of interest. Current GIS capabilities do not enable users to search for locations using imperfect or incomplete information easily. In these cases, GIS tools help narrow down a region of interest, but users must conduct a manual last-mile search to find the exact location of interest within that region. This typically involves the user visually inspecting many remote sensing or street-view images to identify distinct landmarks or terrain features that match the partial information provided. This step of the search process is a bottleneck. Taking inspiration from the way humans recall and search for information, we present the Geospatially Enhanced Search with Terrain Augmented Location Targeting (GESTALT), an endto-end pipeline for …"
Andreas Züfle,A Framework to Explore Spatio-Temporal Surveillance of Adverse Events For Post Market Approved Drugs & Vaccines,2022,https://search.proquest.com/openview/7b65c4f0e907701a8cb5071b97785b22/1?pq-origsite=gscholar&cbl=18750&diss=y,"Discovering all drug and vaccine side effects during the development process is impossible. This dissertation aims to propose a framework in exploring spatiotemporal adverse event surveillance models by identifying adverse effects, which co-locate together and is associated with FDA approved drugs or vaccines using spatial statistics and spatial science. This study aims to find statistically significant spatio-temporal clusters among co-occurring adverse effects. We use data obtained from the FDA’s Adverse Event Reporting System (FAERS) and Vaccine Adverse Event Reporting System (VAERS) to explore the spatio-temporal distribution of combinations of adverse effects using two methods:"
Andreas Züfle,Influence of Geographic Distance on CNN Generalization for Satellite Image Classification,2021,https://ieeexplore.ieee.org/abstract/document/9553363/,"The remote sensing research community is grappling with methods to produce training data that are sufficiently representative of large areas to which they want to scale up their machine learning models for image classification. Effective generalization, will allow land cover classification models trained in data-rich regions to be applied to data-poor regions, with minimal increases in error. This study investigated cross-location generalization through model transfer of convolutional neural networks (CNN), in a series of experiments spread across eight counties within the Chesapeake Bay Catchment. The model transfer was effective (> 80% accuracy), even with as little training as 80/class, across distances up to 600 km. Classification accuracy and to a lesser extent, image similarity in CNN feature space, decreased with geographic distance, but are not the overriding factors governing model transfer."
Andreas Züfle,Introduction to this special issue: SIGSPATIAL 2020 event reports,2021,https://dl.acm.org/doi/abs/10.1145/3447994.3447995,"The 28th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2020) was originally planned to take place in Beijing, China. Due to the coronavirus outbreak, the conference was first moved to Seattle, Washington, USA and then transitioned into a fully virtual conference. This newsletter provides event and experience reports of the organizers of the main conference and the ten satellite workshops."
Andreas Züfle,The 2nd ACM SIGSPATIAL International Workshop on Spatial Gems: Spatial Gems 2020 workshop report,2021,https://dl.acm.org/doi/abs/10.1145/3447994.3448006,"Researchers and practitioners working with spatial data often develop fundamental new techniques they would like to share with their community. These are not necessarily new research results, not yet in any textbook, but they are interesting, self-contained techniques for doing something useful in the domain of spatial data. We call these techniques ""spatial gems""."
Andreas Züfle,Evaluation of Synthetic Population Data Created Using Generative Adversarial Networks,2021,https://journals.gmu.edu/index.php/jssr/article/view/3201,"The generation of realistic synthetic populations is an important function for many agent-based models to provide accurate predictions. The problem with synthetic population data lies within the high dimensional data and irregular distributions. However, deep generative models have been proposed to tackle this issue because of their ability to model arbitrary distributions with greater flexibility. This study presents a comparison and evaluation of synthetically generated populations with different generative adversarial network (GAN) models. We use the public use microdata sample (PUMS) of the population from Fairfax County, Virginia to evaluate the performance of a tabular GAN, conditional tabular GAN (CTGAN), and CopulaGAN, a variant of the CTGAN. Metrics from the TableEvaluator and SDV python libraries are used to measure correlations and probabilistic distributions of population attributes. We found that …"
Andreas Züfle,Analysis of COVID-19 Genome Data in the US,2021,https://journals.gmu.edu/jssr/article/view/3234,"Phylogenetic analysis of the COVID-19 virus is vital to identify the various strains, where and when the first case of a strain originated, and the spread dynamics of each strain. We extracted COVID-19 phylogenetic data from the GISAID website for two states in the US, Louisiana and Oregon, and parsed the data into a format that was usable. The data includes the geographic flows of many COVID-19 strains and lineages with origin and destination locations, strain names, recorded dates, and the variants from December 2019 to June 2021. Using various network analysis and visualization tools, we create spatial visualizations of the phylogenetic trees from the data. Future work will enrich these visualizations to examine the connectivity, disease, and sociodemographic characteristics of the regions where new strains emerge. By analyzing thousands of cases of various strains provided by GISAID that include the …"
Andreas Züfle,Spatial gems 2019 workshop report: The 1st ACM SIGSPATIAL International Workshop on Spatial Gems,2020,https://dl.acm.org/doi/abs/10.1145/3383653.3383659,"Researchers and practitioners working with spatial data often develop fundamental new techniques they would like to share with their community. These are not necessarily new research results, not yet in any textbook, but they are interesting, self-contained techniques for doing something useful in the domain of spatial data. We call these techniques ""spatial gems""."
Andreas Züfle,Ensemble Learning Interpretation of COVID-19 Simulation Models Through Clustering Latent Feature Representations and Aggregated Time-Series Forecasts with Deep Learning,2020,https://journals.gmu.edu/jssr/article/view/2913,"Amidst the COVID-19 pandemic, there have been significant efforts to develop simulation models to forecast trends of the virus. However, there remains a lack of analysis between such models, resulting in uncertainty among policy-makers and the general population about the virus’s future trends. This study develops two ensemble learning approaches of classification and regression to find agreement between prominent COVID-19 death forecast models for more comprehensive policy-making and judgement. To standardize uneven forecasts, we test imputation and normalization methods including, but not limited to linear interpolation, tensor factorization, and generative adversarial networks. We show that piecewise linear interpolation outperforms more complex approaches due their inability to exploit temporal autocorrelations. For classification, we apply a principal component analysis to extract latent feature …"
Andreas Züfle,Using Agent-based Simulations with Latent Dirichlet Allocation Topic Modeling on Mobile Location Data to Prescribe COVID-19 Interventions,2020,https://journals.gmu.edu/jssr/article/view/2918,"Agent-based simulations play a prominent role in guiding critical decision-making to aid in the COVID-19 pandemic. However, many fall short by treating point of interests (POIs) as identical, generic locations in which the virus may spread, relying on the assumption that all POIs receive a relatively equal number of visiting agents per day and that each agent has an equal chance of visiting any given POI. In light of this, we propose a novel COVID-19 simulation using Latent Dirichlet Allocation (LDA) to model agent visits to POIs by treating POIs as “words” and agent home census block groups (CBGs) as “documents”. LDA provides “topics” of CBGs from which a similar proportion of agents visit specific POIs. This preserves the statistical relationship between agent home CBGs and POI visits, allowing us to simulate agent visits to given POIs based on the LDA topic distribution of their home CBG. Using agent and POI …"
