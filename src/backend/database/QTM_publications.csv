Author,Title,Year,URL,Abstract
Weihua An,Causal network analysis,2022,https://www.annualreviews.org/content/journals/10.1146/annurev-soc-030320-102100,"Fueled by recent advances in statistical modeling and the rapid growth of network data, social network analysis has become increasingly popular in sociology and related disciplines. However, a significant amount of work in the field has been descriptive and correlational, which prevents the findings from being more rigorously translated into practices and policies. This article provides a review of the popular models and methods for causal network analysis, with a focus on causal inference threats (such as measurement error, missing data, network endogeneity, contextual confounding, simultaneity, and collinearity) and potential solutions (such as instrumental variables, specialized experiments, and leveraging longitudinal data). It covers major models and methods for both network formation and network effects and for both sociocentric networks and egocentric networks. Lastly, this review also discusses future …"
Weihua An,Friendship network formation in Chinese middle schools: Patterns of inequality and homophily,2022,https://www.sciencedirect.com/science/article/pii/S0378873321000599,"Previous studies on adolescent friendship network formation emphasize the roles played by individual characteristics, structural opportunities, and endogenous tie formation processes. This study extends previous studies in three major aspects: 1) developing and testing theories of status differential (i.e., friendship ties are more likely to run from low status subjects to high status subjects than vice versa) and differential homophily (i.e., homophily is stronger between high status subjects than between low status subjects) through modeling tie-mixing effects of individual characteristics, 2) including qualitative analyses to elaborate selected mechanisms, and 3) comparing selected friendship patterns between China and the U.S. The extended framework is applied to analyzing survey data obtained from 4,094 students in six middle schools in China. The results show that friendship ties are unevenly distributed by …"
Weihua An,"You said, they said: A framework on informant accuracy with application to studying self-reports and peer-reports",2022,https://www.sciencedirect.com/science/article/pii/S0378873321001155,"Informants have been used extensively to provide information on others. However, informant accuracy has rarely been systematically studied. In this paper I argue that studying informant accuracy both helps deepen our understanding about how perceptions of others are configured by personal and network factors and helps develop better methods to use informant reports to correct self-reporting bias. I propose a framework (a systematic conceptualization) that links informant accuracy to not only informant characteristics, but also alter characteristics, dyadic characteristics shared by the informant and the alter, and characteristics of the behavior being reported on. I apply the framework to analyzing self-reports and peer-reports of smoking among 4094 middle school students in China. The analyses present novel strategies to validate a behavior when the truth is unknown, confirm previous findings (e.g., central …"
Weihua An,Opening the blackbox of treatment interference: Tracing treatment diffusion through network analysis,2022,https://journals.sagepub.com/doi/abs/10.1177/0049124119852384,"Causal inference under treatment interference is a challenging but important problem. Past studies usually make strong assumptions on the structure of treatment interference in order to estimate causal treatment effects while accounting for the effect of treatment interference. In this article, we view treatment diffusion as a concrete form of treatment interference that is prevalent in social settings and also as an outcome of central interest. Specifically, we analyze data from a smoking prevention intervention conducted with 4,094 students in six middle schools in China. We measure treatment interference by tracing how the distributed intervention brochures are shared by students, which provides information to construct the so-called treatment diffusion networks. Besides providing descriptive analyses, we use exponential random graph models to model the treatment diffusion networks in order to reveal covariates and …"
Weihua An,Methodological advances in quantitative social science: In celebration of the Social Science Research 50th anniversary,2023,https://pubmed.ncbi.nlm.nih.gov/36797000/,"Methodological advances in quantitative social science: In celebration of the Social Science 
Research 50th anniversary Methodological advances in quantitative social science: In 
celebration of the Social Science Research 50th anniversary Soc Sci Res. 2023 Feb:110:102843. 
doi: 10.1016/j.ssresearch.2022.102843. Epub 2022 Dec 15. Authors Weihua An 1 , Shawn 
Bauldry 2 Affiliations 1 Department of Sociology and Department of Quantitative Theory and 
Methods, Emory University, 1555 Dickey Drive, 102 Tarbutton Hall, Atlanta, GA, 30322, 
United States. Electronic address: weihua.an@emory.edu. 2 Department of Sociology, 
Purdue University, 700 W State St, 249 Stone Hall, West Lafayette, IN, 47907, United States. 
Electronic address: sbauldry@purdue.edu. PMID: 36797000 DOI: 10.1016/j.ssresearch.2022.102843 
No abstract available Publication types Historical Article …"
Weihua An,"Fear not scarcity but inequality, not poverty but instability",2021,https://journals.sagepub.com/doi/abs/10.1177/00491241211024295,"This special issue, “New Quantitative Approaches to Studying Social Inequality”, aims to present some of the latest methodological innovations that arise from new analytical methods, innovative study designs, and novel and large-scale data that are particularly useful for studying social inequality. The articles included in the special issue not only showcase methodological innovations but also share the common theme that social inequalities are often interconnected across domains of life, time, space, or different policies."
Weihua An,A tale of twin dependence: a new multivariate regression model and an FGLS estimator for analyzing outcomes with network dependence,2023,https://journals.sagepub.com/doi/abs/10.1177/00491241211031263,"In this article, I present a new multivariate regression model for analyzing outcomes with network dependence. The model is capable to account for two types of outcome dependence including the mean dependence that allows the outcome to depend on selected features of a known dependence network and the error dependence that allows the outcome to be additionally correlated based on patterned connections in the dependence network (e.g., according to whether the ties are asymmetric, mutual, or triadic). For example, when predicting a group of students’ smoking status, the outcome can depend on the students’ positions in their friendship network and also be correlated among friends. I show that analyses ignoring the mean dependence can lead to severe bias in the estimated coefficients while analyses ignoring the error dependence can lead to inefficient inferences and failures in recognizing …"
Weihua An,Characterization of trajectories of physical activity and cigarette smoking from early adolescence to adulthood,2023,https://link.springer.com/article/10.1186/s12889-023-17365-1,"Cigarette smoking and physical inactivity are two critical risk factors for noncommunicable diseases and all-cause mortality. However, few studies have compared the long-term trajectories of both behaviors, as well as multilevel factors associated with trajectory patterns. Using the National Longitudinal Study of Adolescent to Adult Health (Add Health) Wave I through V survey data, this study characterized distinct subgroups of the population sharing similar behavioral patterns from adolescence to adulthood, as well as predictors of subgroup membership for physical activity (PA) and cigarette smoking behavior respectively.Using the Add Health Wave I through V survey data, we identified the optimal number of latent classes and class-specific trajectories of PA and cigarette smoking from early adolescence to adulthood, fitting latent growth mixture models with standardized PA score and past 30 …"
Weihua An,"Race, state surveillance, and policy spillover: Do restrictive immigration policies affect citizen earnings?",2023,https://academic.oup.com/sf/article-abstract/102/2/681/7079025,"This paper investigates whether restrictive immigration policy affects earnings among White, African-American, and Latinx US citizens. Incorporating sociological theories of race that point to state surveillance of Black and Latinx bodies as a linchpin of racial inequality, we ask: Do immigration policies that expand the reach of law enforcement spill over to lower or to raise earnings of employed US citizens? If so, are the effects of these policies greater for Latinx and African-American citizens compared to their White counterparts? Are the effects of these policies stronger among Latinx and African-American men—who are more directly targeted by surveillance policing as a function of their gender—than for co-ethnic women? To investigate these questions, we combine two nationally representative longitudinal datasets—the 1979 National Longitudinal Survey of Youth and the 1997 National Longitudinal Survey of …"
Weihua An,"The nearness between us, and the space within ourselves",2020,https://journals.sagepub.com/doi/abs/10.1177/0190272520973654,"The year 2020 has been unprecedented. As a result of the COVID-19 pandemic, many children have been out of school for more than six months, missing face-toface interaction with their friends, unable to visit with extended family, and experiencing unaccustomed isolation. With little support from kin and friends, pandemic parenting is more than a full-time job. Both challenging and exhausting, the demands of the day leave many parents eager to put their kids to bed, hoping for a reprieve from the day’s events. Amid this fragmenting of relationships, neighbors are rediscovering each other while social distancing outdoors, and others create and experience Zoom memorials for those loved ones who have been lost to COVID-19 or something else. Still others have lost their jobs or have been furloughed and are relying on friends and family for support in ways they could not have imagined before. It is a time of …"
Weihua An,Testing a Population-Based Outreach Intervention for Ovarian Cancer Survivors to Encourage their Close Relatives to Consider Genetic Counseling,2024,https://aacrjournals.org/cebp/article/33/9/1185/747328,"Most relatives of women with ovarian cancer are unaware of their increased risk for cancer and their eligibility for genetic counseling. State cancer registries offer a platform to communicate about inherited risk to this population.We conducted a two-arm randomized trial to test a theory-based communication intervention—Your Family Connects (YFC)—compared to the standard Georgia Cancer Registry (GCR) contact. A total of 1,938 eligible ovarian cancer survivors were randomly assigned to either the YFC arm (n = 969) or the Standard Care arm (n = 969). We assessed the number of ovarian cancer survivors and their close relatives who logged on to the study website by arm.Survivor reach was significantly higher in the Standard Care arm than YFC (20.8% vs. 15.2%, respectively; P < 0.001). However, reach to relatives was …"
Weihua An,Comparing Egocentric and Sociocentric Centrality Measures in Directed Networks,2024,https://journals.sagepub.com/doi/abs/10.1177/00491241221122606,"Egocentric networks represent a popular research design for network research. However, to what extent and under what conditions egocentric network centrality can serve as reasonable substitutes for their sociocentric counterparts are important questions to study. The answers to these questions are uncertain simply because of the large variety of networks. Hence, this paper aims to provide exploratory answers to these questions by analyzing both empirical and simulated data. Through analyses of various empirical networks (including some classic albeit small ones), this paper shows that egocentric betweenness approximates sociocentric betweenness quite well (the correlation is high across almost all the networks being examined) while egocentric closeness approximates sociocentric closeness only reasonably well (the correlation is a bit lower on average with a larger variance across networks). Simulations …"
Weihua An,Developing and assessing a kin keeping scale with application to identifying central influencers in African American family networks,2023,https://link.springer.com/article/10.1007/s12687-023-00665-9,"Promoting family communication about inherited disease risk is an arena in which family systems theory is highly relevant. One family systems’ construct that can support promotion of family communication regarding inherited disease risk is the notion of “kin keeping.” However, kin keeping and whether it might be capitalized on to encourage family communication about inherited risk has been understudied. The goal of this report was to propose a broadened conceptualization of kin keeping that distinguishes between a structural functional perspective (role conceptualization) and transitional behaviors (skill conceptualization), and to develop and evaluate a scale that would enable this assertion to be tested among a sample of African American community health workers. We developed a scale using four steps: item development using concept analysis and content validity, scale development among a national …"
Michal Arbilly,Gene–culture coevolution in the cognitive domain,2023,https://academic.oup.com/edited-volume/45648/chapter/396358370,"Gene–culture coevolution in the cognitive domain is expected to occur whenever cultural phenomena select for genes that affect cognition. Such cultural selection would occur, for example, if the culture of making certain tools leads to selection that favours genetic variants that somehow make one better at learning to make these tools. While these coevolutionary processes seem probable and important, they are difficult to study because the genetic underpinnings of cognitive traits are often poorly understood. Indeed, most evidence for cognitive gene–culture coevolution are circumstantial or indirect, and the role of such processes is often a topic of debate. This chapter suggests, however, that a strong case for cognitive gene–culture coevolution can be made based on theoretical considerations, which can also guide future work and put current evidence in context. Using a process-based (mechanistic) approach to …"
Michal Arbilly,The Ecological and,2024,https://books.google.com/books?hl=en&lr=&id=TT4UEQAAQBAJ&oi=fnd&pg=PA29&dq=info:XUg8dMUZYdgJ:scholar.google.com&ots=r3iXPphFbN&sig=Udpni4Uc1t2ehIkVioKBNE-mMoA,"In many situations across biology and economics, there is often one individual, or"" agent,"" that invests effort into a beneficial task and also one individual that, in contrast, foregoes the effort of investing, and instead simply exploits the efforts of another. What makes an individual choose to invest in production versus exploiting the efforts of another? If everyone invests, then exploitative strategies become very profitable; however if everyone is exploitative, there will be no investments to exploit. How does natural selection resolve this dilemma? What can economic institutions do to encourage investment? Can biologists and economists learn from the approach of each other's discipline? This chapter outlines the commonalities and differences in approach of the two disciplines to the general problem of investment versus exploitation. It develops a model to encapsulate the general features of many scenarios ("" games"") involving potential exploitation and explores the benefits of a unified approach, outlining current limitations and important areas for future investigation."
Hun Chung,A formal theory of democratic deliberation,2020,https://www.cambridge.org/core/journals/american-political-science-review/article/formal-theory-of-democratic-deliberation/78A6828E834595C799DB4103C1C7976B,"Inspired by impossibility theorems of social choice theory, many democratic theorists have argued that aggregative forms of democracy cannot lend full democratic justification for the collective decisions reached. Hence, democratic theorists have turned their attention to deliberative democracy, according to which “outcomes are democratically legitimate if and only if they could be the object of a free and reasoned agreement among equals” (Cohen 1997a, 73). However, relatively little work has been done to offer a formal theory of democratic deliberation. This article helps fill that gap by offering a formal theory of three different modes of democratic deliberation: myopic discussion, constructive discussion, and debate. We show that myopic discussion suffers from indeterminacy of long run outcomes, while constructive discussion and debate are conclusive. Finally, unlike the other two modes of deliberation, debate is …"
Hun Chung,Rawls’s self-defeat: a formal analysis,2020,https://link.springer.com/article/10.1007/s10670-018-0079-4,"One of John Rawls’s major aims, when he wrote A Theory of Justice, was to present a superior alternative to utilitarianism. Rawls’s worry was that utilitarianism may fail to protect the fundamental rights and liberties of persons in its attempt to maximize total social welfare. Rawls’s main argument against utilitarianism was that, for such reasons, the representative parties in the original position will not choose utilitarianism, but will rather choose his justice as fairness, which he believed would securely protect the worth of everybody’s basic rights and liberties. In this paper, I will argue that, under close formal examination, Rawls’s argument against utilitarianism is self-defeating. That is, I will argue that Rawls’s own reasons, assumptions, and the many theoretical devices he employs demonstrably imply that the representative parties in the original position will choose utilitarianism instead of justice as fairness."
Hun Chung,The Well‐Ordered Society under Crisis: A Formal Analysis of Public Reason vs. Convergence Discourse,2020,https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12445,"A well‐ordered society faces a crisis whenever a sufficient number of noncompliers enter into the political system. This has the potential to destabilize liberal democratic political order. This article provides a formal analysis of two competing solutions to the problem of political stability offered in the public reason liberalism literature—namely, using public reason or using convergence discourse to restore liberal democratic political order in the well‐ordered society. The formal analyses offered in this article show that using public reason fails completely, and using convergent discourse, although doing better, has its own critical limitations that have not been previously recognized properly."
Hun Chung,Diversity and rights: a social choice-theoretic analysis of the possibility of public reason,2020,https://link.springer.com/article/10.1007/s11229-018-1737-4,"Public reason liberalism takes as its starting point the deep and irreconcilable diversity we find characterizing liberal societies. This deep and irreconcilable diversity creates problems for social order. One method for adjudicating these conflicts is through the use of rights. This paper is about the ability of such rights to adjudicate disputes when perspectival disagreements—or disagreements over how to categorize objects in the world—obtain. We present both formal possibility and impossibility results for rights structures under varying degrees of perspectival diversity. We show that though perspectival diversity appears to be a troubling problem for the prospect of stable social order, if rights are defined properly then disagreements can likely be resolved in a consistent manner, achieving social cooperation rather than conflict."
Hun Chung,Prospect Utilitarianism and the Original Position,2023,https://www.cambridge.org/core/journals/journal-of-the-american-philosophical-association/article/prospect-utilitarianism-and-the-original-position/3CF6299DB07C60CCF9DF8285788658B6,"Suppose we assume that the parties in the original position took Kahneman and Tversky's prospect theory as constituting their general knowledge of human psychology that survives through the veil of ignorance. How would this change the choice situation of the original position? In this paper, I present what I call ‘prospect utilitarianism’. Prospect utilitarianism combines the utilitarian social welfare function with individual utility functions characterized by Kahneman and Tversky's prospect theory. I will argue that, once prospect utilitarianism is on the table, Rawls's original arguments in support of justice as fairness as well as his arguments against utilitarianism are, at best, inconclusive. This shows that how implausible a choice for utilitarianism in the original position is heavily depends on what one assumes to be general knowledge of human psychology that the original contracting parties know."
Hun Chung,When utilitarianism dominates justice as fairness: an economic defence of utilitarianism from the original position,2023,https://www.cambridge.org/core/journals/economics-and-philosophy/article/when-utilitarianism-dominates-justice-as-fairness-an-economic-defence-of-utilitarianism-from-the-original-position/825402952EDCB03C1FCD2148A4B2D2BC,"The original position together with the veil of ignorance have served as one of the main methodological devices to justify principles of distributive justice. Most approaches to this topic have primarily focused on the single person decision-theoretic aspect of the original position. This paper, in contrast, will directly model the basic structure and the economic agents therein to project the economic consequences and social outcomes generated either by utilitarianism or Rawls’s two principles of justice. It will be shown that when the differences in people’s productive abilities are sufficiently great, utilitarianism dominates Rawls’s two principles of justice by providing a higher level of overall well-being to every member of society. Whenever this is the case, the parties can rely on the Principle of Dominance (which is a direct implication of instrumental rationality) to choose utilitarianism over Rawls’s two principles of justice …"
Hun Chung,COMMENTS AND CRITICISM: ON CHOOSING THE DIFFERENCE PRINCIPLE BEHIND THE VEIL OF IGNORANCE: A REPLY TO GUSTAFSSON.,2021,https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=0022362X&asa=N&AN=152087167&h=M%2BUS%2BweIPjUTJYg%2FXX21a%2BqCGaaSVtksPzXQnAQvZ%2F3t8Htv2SMLr2PiXOjWP1LZaeHc1mQTlktArkPyKa3lbA%3D%3D&crl=c,"In the article, the author explains how Johan E. Gustafsson's arguments about philosopher John Rawls' theories of the Difference Principle and veil of ignorance are problematic. Also cited are the relationship between wellbeing and the ownership of people of primary goods, the theory of utilitarianism, and why Gustafsson's application of the Difference Principle to well-being is inappropriate."
Hun Chung,Locke’s state of nature and its epistemic deficit: a game-theoretic analysis,2022,https://link.springer.com/article/10.1007/s11229-022-03582-5,"Locke rejected anarchism. Locke defended the universal necessity of political governments on the grounds that the state of nature will occasionally generate the inconveniences of war. The standard interpretation of Locke identifies three main causes of war in the state of nature: the lack of a common judge, moral disagreement over the law of nature, and self-love. In this paper, I argue that the combination of these three factors does not guarantee that war will occur in every plausible scenarios of Locke’s state of nature. Instead, in order for war to occur at least sometimes in every plausible scenario of Locke’s state of nature, there has to be some sort of epistemic deficit. In this paper, I show via the tools of modern game theory, how Locke’s state of nature may occasionally generate war by two kinds of epistemic problems implied by Locke’s own epistemology: (a) disagreements in subjective probabilities, and (b …"
Hun Chung,(The Impossibility of) Deliberation‐Consistent Social Choice,2024,https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12792,"There is now a growing consensus among democratic theorists that we should incorporate both “democratic deliberation” and “aggregative voting” into our democratic processes. But how should the two democratic mechanisms of deliberation and voting interact? In this article, we introduce a new axiom, which we call “Nonnegative Response toward Successful Deliberation” (NNRD). The basic idea is that if some individuals change their preferences toward other individuals’ preferences through democratic deliberation, then the social choice rule should not make everybody who has successfully persuaded others through reasoned deliberation worse off than what they would have achieved without deliberation. We prove an impossibility theorem that shows that there exists no aggregation rule that can simultaneously satisfy NNRD along with other mild axioms that reflect deliberative democracy's core commitment …"
Hun Chung,Formal models in normative political theory,2024,https://journals.sagepub.com/doi/abs/10.1177/09516298241266267,"This article revisits the conventional distinction in political science between ‘positive’ and ‘normative’ political theory, particularly the belief that formal and mathematical methods are only pertinent to positive political theory. We argue that formal models are equally valuable in normative political theory for three reasons: they can make thought experiments more rigorous, they can demonstrate the consistency of normative principles, and they can provide insights into the practical workings of novel institutional arrangements in the absence of empirical data. The integration of formal models into normative political theory presents challenges, including the development of criteria for evaluating these models and potential shifts in research focus. Integration can also strengthen political theory’s tenuous role in the political science discipline."
Hun Chung,Stable dystopia: A critique of the circular definition of stability in Nozick’s model of utopia,2024,https://academic.oup.com/analysis/article-abstract/84/3/465/7691245,"In Part III of Anarchy, State, and Utopia (1974), Robert Nozick presents what he calls ‘the model of possible worlds’ (307) to examine the formal properties of utopia, defined as ‘the best of all possible worlds’ (298). The basic idea is that each person is given the power to create any possible world and its inhabitants by imagining them. Two definitions of stability have been proposed: (a) the non-circular definition according to which a world is stable if and only if nobody can imagine a better world and (b) the circular definition according to which a world is stable if and only if nobody can imagine a better world that is also stable. In this paper, we prove four theorems (namely, the indeterminacy theorem, the stable dystopia theorem, the nobody’s utopia theorem and the redundancy theorem) that provide us with decisive reasons to reject the circular definition and opt for the non-circular definition of stability to analyse …"
Hun Chung,"Erratum to “The Well-Ordered Society under Crisis: A Formal Analysis of Public Reason vs. Convergence Discourse”(American Journal of Political Science,(2020), 64, 1,(82–101), 10.1111/ajps. 12445)",2024,https://waseda.elsevierpure.com/ja/publications/erratum-to-the-well-ordered-society-under-crisis-a-formal-analysi,"In the article titled “The Well-Ordered Society Under Crisis: A Formal Analysis of Public Reason vs. Convergence Discourse,” which was published in January 2020 in Volume 64, Issue 1 of the American Journal of Political Science, an error has been identified in the payoffs attributed to the game tree presented in Figure 4, labeled as “The Well-Ordered Society under Crisis with Public Reason”(Chung 2020: 89). The corrected Figure 4, containing the corrected payoffs, is provided below: 4 Figure (Figure presented.) The Well-Ordered Society under Crisis with Public Reason (Corrected) The statement of Proposition 2 and Proposition 3 (Chung 2020: 90) along with their corresponding proofs (Chung 2020: 98) were all established on the basis of the correct payoffs delineated in the corrected Figure 4 provided above. Consequently, no revisions are required for the textual content or the formal analyses presented within the original paper."
Hun Chung,Why Not Prospect Utilitarianism Instead of Sufficientarianism? A Formal Comparison in Terms of Continuity and Lifeboat Cases,2023,https://web.iss.u-tokyo.ac.jp/methodology/en/dp/images/E-23-003.pdf,"In his 2017 paper,“Prospect Utilitarianism: A Better Alternative to Sufficientarianism,” Hun Chung proposed a theory of distributive justice called ‘Prospect Utilitarianism (PU).’According to Chung, PU retains all the major attractions of sufficientarianism, while avoiding two major problems. The two problems are:(a) sufficientarianism fails to prescribe the right distribution under conditions of scarcity (ie,‘lifeboat’situations), and (b) sufficientarianism fails to provide continuous ethical evaluations. Recently, Ben Davies (2022) and Lasse Nielsen (2019; 2023) have provided a defense of sufficientarianism from these two charges. This paper aims to provide a comprehensive analysis of the shortcomings in Davies’s and to a lesser degree Nielsen’s defenses of sufficientarianism. Our paper will highlight that both Davies’s and Nielsen’s defenses of sufficientarianism stem from fundamental misunderstandings related to the concepts of continuity, welfarism, value satiability, and their interconnectedness with sufficientarianism. In the end, we will argue that Prospect Utilitarianism (PU) is a superior alternative to sufficientarianism."
Hun Chung,"Chain Connection, Close-Knitness, and the Difference Principle",2022,https://www.journals.uchicago.edu/doi/abs/10.1086/716968,"When distributing the benefits produced by social cooperation, Rawls’s difference principle targets a specific group (i.e., the least advantaged group) and requires its expectations to be maximized. One natural worry is whether the practical application of the difference principle comes with a significant cost to other groups in society. Rawls was quite aware of this potential worry and gave his earnest efforts to respond to it. His solution comes from his notions of chain connection and close-knitness. Rawls’s claim was that whenever society satisfies both chain connection and close-knitness, the practical implementation of the difference principle will (a) always lead to strict Pareto improvements, and, as a result, (b) the final state will be Pareto optimal. In this article, it will be shown that under close scrutiny neither of these claims holds even when society is both chain connected and close-knit."
Jacopo Di Iorio,Functional data analysis characterizes the shapes of the first COVID-19 epidemic wave in Italy,2021,https://www.nature.com/articles/s41598-021-95866-y,"We investigate patterns of COVID-19 mortality across 20 Italian regions and their association with mobility, positivity, and socio-demographic, infrastructural and environmental covariates. Notwithstanding limitations in accuracy and resolution of the data available from public sources, we pinpoint significant trends exploiting information in curves and shapes with Functional Data Analysis techniques. These depict two starkly different epidemics; an “exponential” one unfolding in Lombardia and the worst hit areas of the north, and a milder, “flat(tened)” one in the rest of the country—including Veneto, where cases appeared concurrently with Lombardia but aggressive testing was implemented early on. We find that mobility and positivity can predict COVID-19 mortality, also when controlling for relevant covariates. Among the latter, primary care appears to mitigate mortality, and contacts in hospitals, schools and …"
Jacopo Di Iorio,How to get away with statistics: Gamification of multivariate statistics,2021,https://www.tandfonline.com/doi/abs/10.1080/26939169.2021.1997128,"In this article, we discuss our attempt to teach applied statistics techniques typically taught in advanced courses, such as clustering and principal component analysis, to a non-mathematical educated audience. Considering the negative attitude and inclination toward mathematical disciplines of our students we introduce them to our topics using four different games. The four games are all user-centric, score-based arcade experiences intended to be played under the supervision of an instructor. They are developed using the Shiny web-based application framework for R. In every activity students have to follow the instructions and to interact with plots to minimize a score with a statistical meaning. No other knowledge than elementary geometry and Euclidean distance is required to complete the tasks. Results from a student questionnaire give us some confidence that the experience has benefited students, not only in …"
Jacopo Di Iorio,"On the bias of H-scores for comparing biclusters, and how to correct it",2020,https://academic.oup.com/bioinformatics/article-abstract/36/9/2955/5716326,"The H-score (or Mean Squared Residue score) underlies Cheng and Church’s (2000) biclustering algorithm, one of the best-known and most widely employed algorithms in bioinformatics and computational biology, and many subsequent algorithms (eg FLOC, Yang et al., 2005 and CBEB, Huang et al., 2012). Cheng and Church’s algorithm has $2600 citations to date, 650 since 2015 and 230 in 2018–2019 alone. It was the first to be applied to gene microarray data, and it is one of the main tools available in biclustering packages (eg the ‘biclust’R library) and in gene expression data analysis packages (eg IRIS-EDA, Monier et al., 2019). In addition, it is widely used as a benchmark: almost all published biclustering algorithms include a comparison with it. Squared residue measures such as H-scores have a double role in biclustering methods. On the one hand, they are employed by many algorithms as merit …"
Jacopo Di Iorio,funLOCI: A Local Clustering Algorithm for Functional Data,2023,,
Jacopo Di Iorio,Contrasting pre-vaccine COVID-19 waves in Italy through Functional Data Analysis,2023,https://arxiv.org/abs/2307.09820,"We use data from 107 Italian provinces to characterize and compare mortality patterns in the first two COVID-19 epidemic waves, which occurred prior to the introduction of vaccines. We also associate these patterns with mobility, timing of government restrictions, and socio-demographic, infrastructural, and environmental covariates. Notwithstanding limitations in the accuracy and reliability of publicly available data, we are able to exploit information in curves and shapes through Functional Data Analysis techniques. Specifically, we document differences in magnitude and variability between the two waves; while both were characterized by a co-occurrence of 'exponential' and 'mild' mortality patterns, the second spread much more broadly and asynchronously through the country. Moreover, we find evidence of a significant positive association between local mobility and mortality in both epidemic waves and corroborate the effectiveness of timely restrictions in curbing mortality. The techniques we describe could capture additional signals of interest if applied, for instance, to data on cases and positivity rates. However, we show that the quality of such data, at least in the case of Italian provinces, was too poor to support meaningful analyses."
Jacopo Di Iorio,Reinterpreting Economic Complexity: A co-clustering approach,2024,https://arxiv.org/abs/2406.16199,"Economic growth results from countries' accumulation of organizational and technological capabilities. The Economic and Product Complexity Indices, introduced as an attempt to measure these capabilities from a country's basket of exported products, have become popular to study economic development, the geography of innovation, and industrial policies. Despite this reception, the interpretation of these indicators proved difficult. Although the original Method of Reflections suggested a direct interconnection between country and product metrics, it has been proved that the Economic and Product Complexity Indices result from a spectral clustering algorithm that separately groups similar countries or similar products, respectively. This recent approach to economic and product complexity conflicts with the original one and treats separately countries and products. However, building on previous interpretations of the indices and the recent evolution in spectral clustering, we show that these indices simultaneously identify two co-clusters of similar countries and products. This viewpoint reconciles the spectral clustering interpretation of the indices with the original Method of Reflections interpretation. By proving the often neglected intimate relationship between country and product complexity, this approach emphasizes the role of a selected set of products in determining economic development while extending the range of applications of these indicators in economics."
Jacopo Di Iorio,funBIalign: a hierachical algorithm for functional motif discovery based on mean squared residue scores,2025,https://link.springer.com/article/10.1007/s11222-024-10537-y,"Motif discovery is gaining increasing attention in the domain of functional data analysis. Functional motifs are typical “shapes” or “patterns” that recur multiple times in different portions of a single curve and/or in misaligned portions of multiple curves. In this paper, we define functional motifs using an additive model and we propose funBIalign for their discovery and evaluation. Inspired by clustering and biclustering techniques, funBIalign is a multi-step procedure which uses agglomerative hierarchical clustering with complete linkage and a functional distance based on mean squared residue scores to discover functional motifs, both in a single curve (eg, time series) and in a set of curves. We assess its performance and compare it to other recent methods through extensive simulations. Moreover, we use funBIalign for discovering motifs in two real-data case studies; one on food price inflation and one on temperature …"
Jacopo Di Iorio,Biclustering algorithms and interactive tools for the exploration of multivariate and functional data,2020,https://www.politesi.polimi.it/handle/10589/153060,"We are living the revolution of data. Due to their recently imposed central role in the society, it has become fundamental to summarize and visualize them using many different techniques. In addition, considering the informational wealth that well-managed data could produce in many different fields, it is important to represent and express the used methods and their results to a wide and broad audience. It is thus evident that, in the age of data, creating new algorithms and improving older ones should go hand by hand with the introduction of proper ways to divulge those methods and results. Therefore this thesis, presented as a collection of papers, is structured in two parts: the first one, Part I, deals with the introduction of a new family of biclustering algorithms for functional data, the funBI family; the second one, Part II, focuses on divulging statistical results or, more generally, statistics to a non-statistical audience."
Danilo Freire,Bottom-up accountability and public service provision: Evidence from a field experiment in Brazil,2020,https://journals.sagepub.com/doi/abs/10.1177/2053168020914444,"Does local oversight improve public service delivery? We study the effect of a mobile phone application that allows citizens to monitor school construction projects in Brazilian municipalities. The app prompts users to submit data about construction sites, sends such crowdsourced information to independent engineers, and contacts the mayors’ offices about project delays. Our results show that the app has a null impact on school construction indicators. Additionally, we find that politicians are unresponsive to individual requests. The results question the impact of bottom-up monitoring on public service performance and suggest that interventions targeted at other groups, or focused on different issues, may produce better policy outcomes."
Danilo Freire,Legislature size and welfare: Evidence from Brazil,2024,https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12843,"How does legislature size impact public service provision? Despite the importance of institutional design for democratic governance, the effect of legislative features on citizen welfare remains little understood. In this article, we use a formal model to show that increasing legislature size improves public goods delivery. We argue that changes in bargaining costs depend on whether additional legislators share the executive's party affiliation: More opposition members reduce the equilibrium public goods provision, while more government‐aligned members increase it. We test this theory by exploiting sharp discontinuities in city‐council size in Brazil. We show that an additional city councilor has a 91% chance of belonging to the mayoral coalition, and this significantly improves primary school enrollment and infant mortality rates. To explore possible mechanisms, we surveyed 174 former city councilors and analyzed …"
Danilo Freire,Vigilantism and institutions: Understanding attitudes toward lynching in Brazil,2023,https://journals.sagepub.com/doi/abs/10.1177/20531680221150389,"Why do people support extrajudicial violence? In two survey experiments with respondents in Brazil, we examine which characteristics of lynching scenarios garner greater support for lynching and whether providing different types of information about lynching reduces support for it. We find that people often do support community members to take vengeance. In particular, our analysis finds that people strongly support the use of extrajudicial violence by families of victims against men who sexually assault and murder women and children. We also find that criminal punishment and the threat of vendettas reduce support, but appeals to the human rights of victims have zero effect on support for lynchings. Unlike the U.S. experience with lynchings, race was not observed to play an important role in how respondents answered the survey."
Danilo Freire,How many replicators does it take to achieve reliability? Investigating researcher variability in a crowdsourced replication,2021,https://www.sciensano.be/sites/default/files/breznau_how_many_replicators_researcher_variability_osf_3.pdf,"The paper reports findings from a crowdsourced replication. Eighty-four replicator teams attempted to verify results reported in an original study by running the same models with the same data. The replication involved an experimental condition. A “transparent” group received the original study and code, and an “opaque” group received the same underlying study but with only a methods section and description of the regression coefficients without size or significance, and no code. The transparent group mostly verified the original study (95.5%), while the opaque group had less success (89.4%). Qualitative investigation of the replicators’ workflows reveals many causes of non-verification. Two categories of these causes are hypothesized, routine and non-routine. After correcting non-routine errors in the research process to ensure that the results reflect a level of quality that should be present in ‘real-world’research, the rate of verification was 96.1% in the transparent group and 92.4% in the opaque group. Two conclusions follow:(1) Although high, the verification rate suggests that it would take a minimum of three replicators per study to achieve replication reliability of at least 95% confidence assuming ecological validity in this controlled setting, and (2) like any type of scientific research, replication is prone to errors that derive from routine and undeliberate actions in the research process. The latter suggests that idiosyncratic researcher variability might provide a key to understanding part of the “reliability crisis” in social and behavioral science and is a reminder of the importance of transparent and well documented workflows."
Danilo Freire,The reliability of replications: A study in computational reproductions,2025,https://royalsocietypublishing.org/doi/abs/10.1098/rsos.241038,"This study investigates researcher variability in computational reproduction, an activity for which it is least expected. Eighty-five independent teams attempted numerical replication of results from an original study of policy preferences and immigration. Reproduction teams were randomly grouped into a ‘transparent group’ receiving original study and code or ‘opaque group’ receiving only a method and results description and no code. The transparent group mostly verified original results (95.7% same sign and p-value cutoff), while the opaque group had less success (89.3%). Second-decimal place exact numerical reproductions were less common (76.9 and 48.1%). Qualitative investigation of the workflows revealed many causes of error, including mistakes and procedural variations. When curating mistakes, we still find that only the transparent group was reliably successful. Our findings imply a need for …"
Danilo Freire,Natural Resources and Policy Choices in Latin America,2020,https://scholar.google.com/scholar?cluster=7507386119170103463&hl=en&oi=scholarr,
Danilo Freire,The Effect of Legislature Size on Public Spending: A Meta-Analysis,2020,https://www.academia.edu/download/82022221/5ef0453b6598280167cf0e01.pdf,"In a seminal article, Weingast et al.(1981) argue that there is a positive relationship between legislature size and inefficiency in public expenditures. Their proposition is currently known as the “law of 1/” and has been widely cited by scholars in political science and public administration. However, recent studies have questioned the validity of the theory. In this paper, we estimate the first meta-analysis of the relationship between the number of legislators and public spending. Based on a sample of 26 empirical studies, we find little effect of legislature size on government budgets. The available evidence suggests that, if such an effect exists, it is driven by an increase in the upper chamber, but there is considerable heterogeneity in the results. Our meta-regressions also indicate that study coefficients vary significantly according to modelling specifications, such as estimation method or variable selection."
Danilo Freire,How to improve data validation in five steps,2021,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3812561,"Social scientists are awash with new data sources. Though data preprocessing and storage methods have developed considerably over the past few years, there is little agreement on what constitutes the best set of data validation practices in the social sciences. In this paper I provide five simple steps that can help students and practitioners improve their data validation processes. I discuss how to create testable validation functions, how to increase construct validity, and how to incorporate qualitative knowledge in statistical measurements. I present the concepts according to their level of abstraction, and I provide practical examples on how scholars can add my suggestions to their work."
Danilo Freire,Democratizing Policy Analytics with AutoML,2021,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3812593,"Machine learning methods have made significant inroads in the social sciences. Computer algorithms now help scholars design cost-effective public policies, predict rare social events, and improve the allocation of funds. However, building and evaluating machine learning algorithms remain labor-intensive, error-prone tasks. Thus, areas that could benefit from modern computer algorithms are often held back owing to implementation challenges or lack of technical expertise. In this paper, I show how scholars can use automated machine learning (AutoML) tools to preprocess their data and create powerful estimation methods with minimal human input. I demonstrate the functionalities of three open-source, easy-to-use AutoML algorithms, and I replicate a well-designed forecasting model to highlight how researchers can achieve similar results with only a few lines of code."
Danilo Freire,Financial Incentives and Healthcare Provision: Evidence from an Experimental Aedes aegypti Control Programme in Brazil,2021,https://www.medrxiv.org/content/10.1101/2021.03.10.21252321.abstract,"Mosquito control is the most effective means of reducing Aedes aegypti infections worldwide. In many developing countries, however, vector management programmes fail to reach their goals due to low worker productivity. Research suggests that financial incentives may increase the productivity of health personnel, yet there is little evidence about the impact of monetary rewards on A. aegypti-reduction strategies. We evaluated whether individual and collective financial incentives improve the performance of healthcare workers fighting A. aegypti, as well as their effect on city-level numbers of dengue hospitalisations.We hired and trained subjects to visit households, find A. aegypti breeding sites, and eliminate mosquito larvae in the city of Rio Verde, Brazil. We randomly assigned workers into three groups. The control group received a flat compensation for their tasks, while workers in the two treatment groups received individual and collective monetary bonuses, respectively. Financial rewards increased the number of cleaned breeding sites in both treatment groups (individual and team bonuses), and the collective treatment also improved larvae extermination. The intervention lowered dengue hospitalisations in 10.3%, but the result was not consistent across all model specifications.A. aegypti control programmes may benefit from alternative compensation schemes, especially when provided to teams. For this strategy to succeed, financial incentives have to be distributed widely as their aggregate effect is limited. More research is needed to assess whether higher worker …"
Adam N. Glynn,V-dem codebook v10,2020,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3557877,∗ Existence of universities (v2cauni)∗ Total number of universities (v2canuni)∗ Constitutional protection for academic freedom (v2caprotac)∗ Freedom to research and teach (v2cafres)∗ Freedom of academic exchange and dissemination (v2cafexch)∗ Institutional autonomy (v2cainsaut)∗ Campus integrity (v2casurv)∗ Academics as critics (v2cacritic)∗ International legal commitment to academic freedom under ICESCR (v2caacadfree)
Adam N. Glynn,V-Dem [Country–year/country–date]: Dataset V11. 1,2020,https://ueaeprints.uea.ac.uk/id/eprint/92180/,"V-Dem [Country–year/country–date]:Dataset V11. 1 - UEA Digital Repository University of East 
Anglia logo Search Login Repository Statistics V-Dem [Country–year/country–date]:Dataset 
V11. 1 Tools + Tools Coppedge, Michael, Gerring,, John, Knutsen, Carl Henrik, Lindberg, 
Staffan and Tzelgov, Eitan (2020) V-Dem [Country–year/country–date]:Dataset V11. 1. In: 
Varieties of Democracy. Cambridge University Press. ISBN 9781108347860 Full text not 
available from this repository. (Request a copy) Item Type: Book Section Faculty \ School: 
Faculty of Arts and Humanities > School of Politics, Philosophy, Language and Communication 
Studies UEA Research Groups: Faculty of Arts and Humanities > Research Groups > Political, 
Social and International Studies Depositing User: LivePure Connector Date Deposited: 25 May 
2023 09:34 Last Modified: 21 Jul 2023 10:47 URI: https://ueaeprints.uea.ac.uk/id/eprint/92180 …"
Adam N. Glynn,V-dem [country–year/country–date] dataset v10. varieties of democracy (v-dem) project,2020,https://scholar.google.com/scholar?cluster=5569840696612043320&hl=en&oi=scholarr,
Adam N. Glynn,V-dem country-year dataset v10,2020,https://scholar.google.com/scholar?cluster=5642110547920826153&hl=en&oi=scholarr,
Adam N. Glynn,Varieties of democracy: Measuring two centuries of political change,2020,https://www.academia.edu/download/109287666/13510347.2020.172974620231220-1-dw6muc.pdf,"Many years have passed between the release of the Varieties of Democracy (V-Dem) dataset (version 5) in January 2016 and the publication of this timely book. In these years, the use of democracy indices has changed fundamentally. For a long time, Polity IV and Freedom House had dominated the political science literature when measuring democracy; since 2016, however, V-Dem has reshuffled the cards. In the field of conceptualizing and measuring democracy, it is a challenge to write a book with up-to-date methods and discussions on conceptualization, measurement, and aggregation strategies due to the voluminous literature and debates on democracy conceptualization and aggregation rules. Overall, the Varieties of Democracy volume has more than stood up to this challenge.In the first part of the book, which comprises 7 chapters, the team of 23 authors introduces the conceptual rationale and methodological foundations of the V-Dem project. In the first chapter, the authors introduce the origin, historical development and infrastructure of the V-Dem project, noting that it is the largest democracy dataset, and probably the largest collaborative data-collection effort in political science, with a cumulative budget of more than 26 million USD. The V-Dem project includes 7 principal investigators, 17 project managers, more than 30 regional managers who manage more than 3000 country experts, on whose codings the V-Dem data rest. Including leading scholars on democracy and social science research methods is definitely a key success factor of the project. The second chapter outlines the conceptual foundations of democracy, mainly …"
Adam N. Glynn,VDem [country–year/country–date] dataset v12,2022,https://scholar.google.com/scholar?cluster=16766030903212589335&hl=en&oi=scholarr,
Adam N. Glynn,V-Dem Codebook v11. 1. Varieties of Democracy (V-Dem) Project,2021,https://scholar.google.com/scholar?cluster=13804712173638528416&hl=en&oi=scholarr,
Adam N. Glynn,Varieties of democracy (V-Dem) project,2020,https://scholar.google.com/scholar?cluster=2730270759330750468&hl=en&oi=scholarr,
Adam N. Glynn,Constitutional reform and the gender diversification of peak courts,2021,https://www.cambridge.org/core/journals/american-political-science-review/article/constitutional-reform-and-the-gender-diversification-of-peak-courts/D9B56B946416D4582B34D769B3F937F5,"Do the processes states use to select judges for peak courts influence gender diversity? Scholars have debated whether concentrating appointment power in a single individual or diffusing appointment power across many individuals best promotes gender diversification. Others have claimed that the precise structure of the process matters less than fundamental changes in the process. We clarify these theoretical mechanisms, derive testable implications concerning the appointment of the first woman to a state’s highest court, and then develop a matched-pair research design within a Rosenbaum permutation approach to observational studies. Using a global sample beginning in 1970, we find that constitutional change to the judicial selection process decreases the time until the appointment of the first woman justice. These results reflect claims that point to institutional disruptions as critical drivers of gender …"
Adam N. Glynn,Counterevidence of crime-reduction effects from federal grants of military equipment to local police,2021,https://www.nature.com/articles/s41562-020-00995-5,"In 2017, the Trump Administration restored local law enforcement agencies’ access to military weapons and some other types of surplus military equipment (SME) that had been prohibited by the Obama Administration. The Justice Department background paper used to justify this decision cited two papers published by the American Economic Association. These papers used SME data collected with a 2014 Freedom of Information Act request and concluded that SME, supplied to local law enforcement by the federal government via the 1033 Program, reduces crime. Here we show that the findings of these studies are not credible due to problems with the data. Using more detailed audit data on 1033 SME, we show that the 2014 data are flawed and that the more recent data provide no evidence that 1033 SME reduces crime."
Adam N. Glynn,Partisan schadenfreude and candidate cruelty,2024,https://onlinelibrary.wiley.com/doi/abs/10.1111/pops.12922,"We establish the prevalence of partisan schadenfreude—that is, taking “joy in the suffering” of partisan others. Analyzing attitudes on health care, taxation, climate change, and the coronavirus pandemic, we find that a sizable portion of the American mass public engages in partisan schadenfreude and that these attitudes are most expressed by those who are ideologically extreme. Additionally, we find that a sizable portion of the American public is more likely than not to vote for candidates who promise to pass policies that “disproportionately harm” supporters of the opposing political party, and we demonstrate experimental evidence of demand/preference for candidates who promise cruelty among those who exhibit high amounts of schadenfreude. In sum, our results suggest that partisan schadenfreude is widespread and has disturbing implications for American political behavior."
Adam N. Glynn,Are police racially biased in the decision to shoot?,2023,https://www.journals.uchicago.edu/doi/abs/10.1086/723973,"We present a theoretical model predicting that racially biased policing produces (1) more use of potentially lethal force by firearms against Black civilians than against White civilians and (2) lower fatality rates for Black civilians than White civilians. We empirically evaluate this second prediction with original officer-involved shooting data from 2010 to 2017 for eight local police jurisdictions, finding that Black fatality rates are significantly lower than White fatality rates and that this significance would survive an omitted covariate three times as strong as any of our observed covariates. Furthermore, using outcome test methodology and a comparability assumption, we estimate that at least 30% of Black civilians shot by the police would not have been shot had they been White. An omitted covariate would need to be at least three times as strong as any of our observed covariates to eliminate this finding. Finally, any omitted …"
Adam N. Glynn,Advances in experimental mediation analysis,2021,https://books.google.com/books?hl=en&lr=&id=WJgjEAAAQBAJ&oi=fnd&pg=PA257&dq=info:kSdK2QfRnYUJ:scholar.google.com&ots=v_yam21i5F&sig=NL7vwhZQNJca_uXwLbMOdb23Ay8,"Mediation analysis has been called “harder than it looks”(Bullock and Ha 2011) due to difficulties of experimental identification. However, recent work has clarified that, while hard, some experimental designs for mediation can be informative. Other recent work has provided “easier” substitutes for mediation analysis. This chapter has two goals. First, to summarize some of the findings published since Bullock and Ha (2011) and to consider the implications these findings have for mediation analysis. Second, to consider the situations in which a close alternative to mediation analysis would be useful (either as a supplement or a substitute). Such situations often depend on the motivation for the analysis."
Adam N. Glynn,Treatment effect deviation as an alternative to Blinder–Oaxaca decomposition for studying social inequality,2021,https://journals.sagepub.com/doi/abs/10.1177/0049124119852387,"The Blinder–Oaxaca decomposition (BOD) is a popular method for studying the contributions of explanatory factors to social inequality. The results have often been given causal interpretations. While recent work and this article both show that some types of BOD are equivalent to a counterfactual-based treatment effect/selection bias decomposition, this equivalence does not hold in general. Given this lack of general equivalence, in this article based on the counterfactual framework, we propose a method of treatment effect deviation (TED) to study social inequality. Essentially, the TED assesses to what extent the omission of particular covariates (i.e., selection bias in the omitted variables) can alter the estimated treatment effect. The TED has a better causal interpretation and can be estimated nonparametrically (and hence is more robust to model misspecification errors). Therefore, the TED may serve as an …"
Adam N. Glynn,Police shooting statistics and public support for police reforms,2024,https://www.cambridge.org/core/journals/journal-of-experimental-political-science/article/police-shooting-statistics-and-public-support-for-police-reforms/FC2F0F209FAC53F19B0A284C00FCEEDE,"Does providing information about police shootings influence policing reform preferences? We conducted an online survey experiment in 2021 among approximately 2,600 residents of 10 large US cities. It incorporated original data we collected on police shootings of civilians. After respondents estimated the number of police shootings in their cities in 2020, we randomized subjects into three treatment groups and a control group. Treatments included some form of factual information about the police shootings in respondents’ cities (e.g., the actual total number). Afterward, respondents were asked their opinions about five policing reform proposals. Police shooting statistics did not move policing reform preferences. Support for policing reforms is primarily associated with partisanship and ideology, coupled with race. Our findings illuminate key sources of policing reform preferences among the public and reveal …"
Adam N. Glynn,Methodology V10,2020,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3557904,Part I sets forth the V-Dem conceptual scheme. Part II discusses the process of data collection. Part III describes the measurement model along with efforts to identify and correct errors.
Adam N. Glynn,Post-instrument bias in linear models,2024,https://journals.sagepub.com/doi/abs/10.1177/00491241231156965,"Post-instrument covariates are often included as controls in instrumental variable (IV) analyses to address a violation of the exclusion restriction. However, we show that such analyses are subject to biases unless strong assumptions hold. Using linear constant-effects models, we present asymptotic bias formulas for three estimators (with and without measurement error): IV with post-instrument covariates, IV without post-instrument covariates, and ordinary least squares. In large samples and when the model provides a reasonable approximation, these formulas sometimes allow the analyst to bracket the parameter of interest with two estimators and allow the analyst to choose the estimator with the least asymptotic bias. We illustrate these points with a discussion of the settler mortality IV used by Acemoglu, Johnson, and Robinson."
Adam N. Glynn,Post-Instrument Bias,2021,https://files.de-1.osf.io/v1/resources/bfh95/providers/osfstorage/65a0151a1c92110713abe3de?format=pdf&action=download&direct&version=2,"When using instrumental variables, researchers often assume that causal effects are only identified conditional on covariates. We show that the role of these covariates in applied research is often unclear and that there exists confusion regarding their ability to mitigate violations of the exclusion restriction. We explain when and how existing adjustment strategies may lead to “post-instrument” bias. We then discuss assumptions that are sufficient to identify various treatment effects when adjustment for post-instrument variables is required. In general, these assumptions are highly restrictive, albeit they sometimes are testable. We also show that other existing tests are generally misleading. Then, we introduce a sensitivity analysis that uses information on variables influenced by the instrument to gauge the effect of potential violations of the exclusion restriction. We illustrate it in two replications of existing analyses and summarize our results in easy-to-understand guidelines."
Adam N. Glynn,V-Dem: Varieties of Democracy (V-Dem Dataset—Version 10)[Data set]. V-Dem Institute,2020,https://scholar.google.com/scholar?cluster=14741183074731669852&hl=en&oi=scholarr,
Adam N. Glynn,Deadly force: Police shootings in urban America,2025,https://books.google.com/books?hl=en&lr=&id=TC82EQAAQBAJ&oi=fnd&pg=PR9&dq=info:krb4D0JslOUJ:scholar.google.com&ots=F2yeqhWcSt&sig=P3Q9XFNIGpNPdG6Ioh7GpJUfVa4,"A groundbreaking study of when, where, and whom police shoot in America’s largest cities Police shootings in America spark outrage and protest and raise questions about police use of lethal force. Yet despite the attention given to high-profile shootings, it is extremely difficult to draw wider conclusions about the frequency and outcomes of police gunfire because there is no systematic and centralized source of information on these incidents. This pioneering book draws on original data, compiled by the authors, to examine police shootings, both fatal and non-fatal, in hundreds of American cities. It documents racial disparities in shooting incidents and shows that the media spotlight on the most shocking fatal shootings tell only part of the story of police gunfire in our cities. The authors find that there are patterns in when, where, and whom the police shoot, and they present strong evidence of unjustifiable disparities. It’s not just that young, unarmed Black men are disproportionately subjected to gunfire during encounters with police officers; there is also a disproportionate concentration of shootings in the places where most Black and Hispanic urbanites live, even accounting for violent crime rates and other factors. As a consequence, Black and Hispanic residents of large cities are disproportionately exposed to police gunfire, even when they are not themselves the targets of it. The authors offer other insights as well, exploring the connection between police department funding and rates of shootings, and considering the influence of a city’s political leadership on police use of gunfire. It is only through a deeper understanding of police shootings, the …"
Adam N. Glynn,"Five Years of Peace Agreement Implementation in Colombia: Achievements, Challenges and Opportunities to Increase Implementation Levels, December 2016-October 2021",2021,https://curate.nd.edu/articles/report/Five_Years_of_Peace_Agreement_Implementation_in_Colombia_Achievements_Challenges_and_Opportunities_to_Increase_Implementation_Levels_December_2016_-_October_2021/24723264,"This report presents the status of implementation of the Final Agreement after five years through three sections of analysis. First, it presents overall implementation status as of October 2021, in accordance with results stemming from the Kroc Institute’s methodology for monitoring the 578 stipulations contained in the Final Agreement.1 Second, it lays out the main implementation milestones during these five years for each of the agreement’s six points and the cross-cutting ethnic and gender approaches. Finally, the Kroc Institute identifies strategic accord commitments that can create positive cascades and have the capacity to increase implementation levels for each point of the Agreement.  Evaluating implementation of the Colombian Final Agreement five years after its signing is a significant task. As stipulated in section 6.3.2 of the Final Agreement, the Kroc Institute has the mandate to provide technical assistance to the International Verification Component (CIV) and the Commission for Monitoring, Promoting, and Verifying the Implementation of the Final Agreement (CSIVI). The Kroc Institute aims to provide the public and the academic community with the results of its monitoring and analysis to contribute to public dialogue about the current state of implementation of the Final Agreement."
Adam N. Glynn,Estimating Controlled Direct Effects with Panel Data: An Application to Reducing Support for Discriminatory Policies,2024,https://mattblackwell.org/files/papers/did_cde.pdf,"Recent experimental studies in the social sciences have demonstrated that short, perspectivetaking conversations are effective at reducing prejudicial attitudes and support for discriminatory public policies, but it is unclear if such interventions can directly affect policy views without changing prejudice. Unfortunately, the identification and estimation of the controlled direct effect—the natural causal quantity of interest for this question—has required strong selectionon-observables assumptions for any mediator. We leverage a recent experimental study with multiple survey waves of follow-up to identify and estimate the controlled direct effect using the changes in the outcome and mediator over time. This design allows us to weaken the identification assumptions to allow for linear and time-constant unmeasured confounding between the mediator and the outcome. Furthermore, we develop a semiparametrically efficient and doubly robust estimator for these quantities. We find that there is a robust controlled direct effect of perspective-taking conversations when subjective feelings are neutral but not positive or negative."
Adam N. Glynn,"Bimonthly Report: Implementation Status of the Colombian Final Peace Accord, September–October 2020",2022,https://curate.nd.edu/articles/report/Bimonthly_Report_Implementation_Status_of_the_Colombian_Final_Peace_Accord_September_October_2020/24723267/1/files/43539072.pdf,"On a bimonthly basis, the Kroc Institute produces independent, impartial, and academically rigorous information on the status of the implementation of the Final Accord. The bimonthly reports aim to promote implementation processes and public dialogue and are presented to the government and non-government entities in charge of implementation, civil society organizations, the international community, and all other parties committed or interested in this process."
Adam N. Glynn,The Effect of Public Information about Police Shootings of Civilians on Public Support for Police Reforms,2021,https://osf.io/h32e5/resources,"Does exposure to accurate information about local police shootings of civilians affect public support for proposed police reforms? Prior studies examine whether narrative and visual information about police behavior affects individuals' perceptions of the police and policing. Our study uses municipal data on police shootings of civilians to investigate whether, if at all, receiving accurate information about police shooting in their city influences public support for police reform. Through YouGov, we conduct a survey experiment in 2021 in ten large US cities. We randomly assign respondents to treatments of descriptive statistics on police shootings in their cities:(a) total number of civilians police shot in 2020,(b) total number of shootings with a disaggregation by armed and unarmed civilians shot, or (c) total number of shootings with a breakdown of fatal and non-fatal shootings. A control group receives no information about police shootings for their cities. All respondents' make guesses about the number of police shootings in their cities before random assignment. We identify treatment effects on support for five proposed policing reforms:(1) limiting armed police officer involvement in low-level traffic stops,(2) using unarmed “first responders” instead of police to address mental health emergencies,(3) reducing the use of no-knock warrants,(4) reducing qualified immunity protections, and (5) empowering civilian oversight boards to review police misconduct. The findings may inform policymakers about how public knowledge of police shootings may influence public support for police reforms."
Jo Guldi,The dangerous art of text mining: A methodology for digital history,2023,https://books.google.com/books?hl=en&lr=&id=2PHSEAAAQBAJ&oi=fnd&pg=PR9&dq=info:oZ--FV1I0RcJ:scholar.google.com&ots=F7zwnZPelE&sig=dJpnx9NzEZawXiVBJ8CNwE7u5h0,"The Dangerous Art of Text Mining celebrates the bold new research now possible because of text mining: the art of counting words over time. However, this book also presents a warning: without help from the humanities, data science can distort the past and lead to perilous errors. The book opens with a rogue's gallery of errors, then tours the ground-breaking analyses that have resulted from collaborations between humanists and data scientists. Jo Guldi explores how text mining can give a glimpse of the changing history of the past-for example, how quickly Americans forgot the history of slavery. Textual data can even prove who was responsible in Congress for silencing environmentalism over recent decades. The book ends with an impassioned vision of what text mining in defence of democracy would look like, and why humanists need to be involved."
Jo Guldi,The long land war: The global struggle for occupancy rights,2022,https://books.google.com/books?hl=en&lr=&id=d4xhEAAAQBAJ&oi=fnd&pg=PP1&dq=info:EL-iCoQzviMJ:scholar.google.com&ots=1NXvAY8Sol&sig=QmJpOavlciUQ_1b-699m0t1n9IM,"A definitive history of ideas about land redistribution, allied political movements, and their varied consequences around the world"" An epic work of breathtaking scope and moral power, The Long Land War offers the definitive account of the rise and fall of land rights around the world over the last 150 years.""--Matthew Desmond, Pulitzer Prize-winning author of Evicted: Poverty and Profit in the American City Jo Guldi tells the story of a global struggle to bring food, water, and shelter to all. Land is shown to be a central motor of politics in the twentieth century: the basis of movements for giving reparations to formerly colonized people, protests to limit the rent paid by urban tenants, intellectual battles among development analysts, and the capture of land by squatters taking matters into their own hands. The book describes the results of state-engineered"" land reform"" policies beginning in Ireland in 1881 until US-led interests and the World Bank effectively killed them off in 1974. The Long Land War provides a definitive narrative of land redistribution alongside an unflinching critique of its failures, set against the background of the rise and fall of nationalism, communism, internationalism, information technology, and free-market economics. In considering how we could make the earth livable for all, she works out the important relationship between property ownership and justice on a changing planet."
Jo Guldi,What kind of information does the era of climate change require?,2021,https://link.springer.com/article/10.1007/s10584-021-03243-5,"This article explores the promise of institutions and infrastructures associated with democracy to limit the worst consequences of climate change. The article highlights the apparent conflict between expert governance on the one hand, and, on the other hand, calls for democratization that reflect the diverse perspectives of groups whose rights and labor have been exploited over historical timescales. Drawing on the history of bureaucracy and governance, this article argues that the apparent contradiction between the two poles of discourse can be reconciled by a system of information infrastructure designed to create a robust, accountable system of environmental data monitoring that also accounts for the work of inclusive community groups as stewards of landscapes. The article concludes by recommending a 6-point “Outline of an Information Infrastructure for Responsive, Accountable Governance of the …"
Jo Guldi,History’s Future in the Age of the Internet,2020,https://academic.oup.com/ahr/article-abstract/125/4/1337/5933592,"Ian Milligan’s History in the Age of Abundance? How the Web Is Transforming Historical Research (2019) presents and interrogates the challenges and opportunities that born-digital materials have for historians. Milligan argues that historians who wish to grapple with the archived internet need to think much more aggressively about engaging with digital methods and tools that can complement and extend the well-honed practices of close reading with approaches that can help analyze the vast and often unstructured archives of internet data. In this AHR Review Roundtable, three historians—Jo Guldi, Tim Hitchcock, and Michelle Moravec, all of whom incorporate digital approaches and concerns into their work—engage with a set of questions developed by Digital Scholarship Librarian Daniel J. Story, to discuss Milligan’s treatment of the digital archive of the web and its implications for historians’ work …"
Jo Guldi,Scholarly Infrastructure as Critical Argument: Nine principles in a preliminary survey of the bibliographic and critical values expressed by scholarly web-portals for visualizing data.,2020,https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=19384122&AN=148402380&h=r5nHzwnP%2FPlGZelLwESWeJUonRyt2GhVBZGZB5mHIIG7jOxwcHyJqr1dSYAMNSh60TK20r%2Fr5TiVsJl7WYFgyA%3D%3D&crl=c,"What values does infrastructure-building represent? This article begins by situating scholarly practices around infrastructure within a broader transformation of twenty-first century life and indeed scholarship and learning by infrastructures, and distinguishing scholarly infrastructure from other kinds of infrastructure designed to share information that nevertheless lack scholarly engagement with analysis. This article compares the role of scholar-builders in crystallizing a set of theoretical concerns, data, and analyses to that of the architects of opera houses during the golden age of European opera, who structured, illuminated, and constrained possible future creations of art. The article next attempts to excavate a set of implicit values, while making room for the possibility that the list of values put forward here is only incomplete, and that the list of values itself is the subject of potential debate, critique, or dissent, some of …"
Jo Guldi,The Algorithm: Mapping Long-Term Trends and Short-Term Change at Multiple Scales of Time,2022,https://academic.oup.com/ahr/article-abstract/127/2/895/6705108,"Can statistics help historians to identify the events that are most distinctive of a particular era of time? This essay explores the use of a distinctiveness algorithm from library science for measuring the distinctiveness of manuscripts, tf-idf, recast as ""tf-ipf"" for the study of the terms most distinctive of historical periods. In a case study, tf-ipf is applied to the text of Hansard's Parliamentary Debates, varying the ""period"" from a 20-year horizon to a 6-month or one-day horizon. It is shown that the algorithm's assessments of what is most distinctive of 20-year and 10-year periods largely matches the consensus of British historians, while debates that held parliament's attention for six months or fewer have largely fallen beneath the threshold of scholarly attention. Attending to concerns that took up parliamentary debate for six months or fewer, the essay argues that tf-ipf thus presents a metric of parliamentary attention that …"
Jo Guldi,Connected ogres: Global sources in the digital era,2022,https://shs.cairn.info/article/MOND1_221_0073?tab=texte-integral,The Trans-Atlantic and Intra-American slave trade databases are the culmination of decades of independent and collaborative research by scholars using library and archival data from the Atlantic world.[https://www. slavevoyages. org/](accessed in January 2022).
Jo Guldi,"The climate emergency demands a new kind of history: Pragmatic approaches from science and technology studies, text mining, and affiliated disciplines",2022,https://www.journals.uchicago.edu/doi/abs/10.1086/719704,"How shall we judge the element of practicality or urgency for scholars working in the era of the 2030 deadline for action on climate change? This essay surveys the reaction to climate change by scholars who work with data, using the philosopher Stephen Gardiner’s conceit of “corrupt institutions” to organize the approaches according to an index of pragmatic orientation. This survey will lead to the identification of some challenges for those seeking to engage the climate deadline with data, especially work making climate data more transparent, text mining to identify aspects of corruption and reform within contemporary institutions, and building infrastructure for citizen participation."
Jo Guldi,"The Official Mind’s View of Empire, in Miniature",2021,https://www.jstor.org/stable/27106237,"For many scholars who are not themselves historians of political thought, the major use of official records is as a benchmark for studying other kinds of development. Official records of modern political bodies are widely available in digitized form and provide one of the primary sources with which digital historians have trained their methods. This article applies the process of “reducing” textual expressions to regular form to investigate how British members of Parliament talked about empire in extremely general terms: which places did they mention, how much, and in what context. Reducing parliamentary speech to regular occurrences makes it possible to quantitatively generalize about regular and predictable structures—for example, the Eurocentric bias of Parliament and Parliament’s bias toward portion of the empire under long command, with certain notable exceptions. The technique lends itself to a wide variety …"
Jo Guldi,"From critique to audit: A pragmatic response to the climate emergency from the humanities and social sciences, and a call to action",2021,https://www.journals.uchicago.edu/doi/full/10.1086/716854,This short piece reviews the causes of delays to action on climate change and suggests that academics can play a greater role in hastening global policy changes.
Jo Guldi,The Role of Critical Thinking in Humanities Infrastructure: The Pipeline Concept with a Study of HaToRI (Hansard Topic Relevance Identifier).,2020,https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=19384122&AN=148402395&h=a3L7%2F4%2FEBG0pyQtMJiepL%2BlVOnu0bibA7A61NPIJhD%2B33teCvEbWo9z1DSsJfP6gdNpzcnvI6ibgDuvaZy7Yow%3D%3D&crl=c,"This article proposes the concept of the pipeline as a category of tool that organizes a series of algorithms for users. The pipeline concept, adopted with limitations by the humanities, documents how a suite of algorithms produces a particular research result, with the goal of enabling interoperability, transparency, and iteration by future scholars who may switch out particular algorithms within the pipeline with different results. A pipeline-based application amplifies the concepts of interoperability and transparency for users by allowing the researcher to toggle on and off particular options, for example selecting and deselecting particular topics of interest from a program of visualizations based on a topic model of a large body of text. Pipelines support modular, interoperable, transparent, and documented processes of research that lend themselves to Prof. Guldi's Theory of Critical Search—the argument that critical …"
Jo Guldi,"Another Take on Quantitative Methods: Claire Lemercier and Claire Zalc, Quantitative Methods in the Humanities",2020,https://muse.jhu.edu/pub/1/article/752936/summary,"342 their limits, and examining the limits of interpretation of any analysis. They offer a basic introduction to tests of statistical significance, and a cogent introduction to network analysis. Carefully described case studies review recent landmarks of quantitative social history, including Mariot and Zalc’s study of the fate of Jews in the French village of Lens 1940–44 (pp. 47–49), and the use of social network analysis to develop insight into the success of the Medici political alliances and other historical relationships of class, social embeddedness, authors in journals, and world systems (p. 106). Throughout these case studies, discussions of statistical principles are rendered in clear language with easy examples from published historical scholarship. For the new graduate student in the archives, overviews of this kind and the accompanying advice have much to recommend them. One strain of advice stresses the …"
Jo Guldi,The Revolution in Text Mining for Historical Analysis is Here,2024,https://academic.oup.com/ahr/article-abstract/129/2/519/7690490,"We have known since Vico to think of written text and oral traditions as two systems of culture. Social historians have long treated the rise of literacy itself as an important index of modernity, although collectors of oral traditions have typically transcribed folk songs and oral stories into text. Modern historians track the appearance of different genres of writing, from parliamentary blue books to the newspaper to the novel to published transcripts of court cases, as an index of evolving institutions and markets. And knowledge of the way that these texts circulated—whether read aloud in the post office or debated on bulletin board systems on the early internet—is often a clue to important social structures. The knowledge accessible through text does not exhaust in any way the full repository of artifacts that historians use—which of course extends to the formats of texts; to visual and audio media, which may or may not …"
Jo Guldi,Infrastructure: A Useful Anachronism?,2024,https://muse.jhu.edu/pub/1/article/944055/summary,This essay introduces our special issue by arguing that the concept of infrastructure can help us better understand eighteenth-century culture and history even if the word did not exist in that period. It shows moreover how scholars of the eighteenth-century world can contribute to the burgeoning field of infrastructure studies.
Jo Guldi,A Critique of Local History: The Return of the Longue Durée from an Anglo-American Perspective,2024,https://ostour.dohainstitute.org/en/issue21/pages/art08.aspx,"This study discusses the recent return of the longue durée in historical research, as a major type of historical analysis that prioritizes major issues and global history. In the many years of its absence, microhistory steeped in details and based on a short-term vision prevailed, with fragmented studies limited to a narrow circle of readers, hindering coherent synthetic works. But this return, aided by the abundance of digital tools and data, is framed by new ambitions represented in the desire to contribute to the interpretation of events and phenomena from a global perspective, to provide synthetic research that can be read by specialists and laypersons alike, and to enrich the debate related to public policies alongside other actors in the neighbouring humanities and social sciences."
Jo Guldi,"Changing Land: Diaspora Activism and the Irish Land War, by Niall Whelehan",2023,https://academic.oup.com/ehr/article-abstract/138/594-595/1455/7465031,"A borderless history of Ireland makes sense for a modern Ireland, now one of the tech capitals of the European Union, and in that sense the orientation is presentist. But presentism of this kind also can illuminate neglected truths. In Whelehan’s case, a global understanding of Ireland in the world leads him to capture truths about earlier episodes of global Ireland that were less visible when all histories tended towards the Easter Rebellion. The new Irish studies of diaspora—of which Whelehan’s is part—reveal how the framework of nationalism and the shape of the national archive has limited our sight. Whelehan’s inclusive, international portrait of Irish land politics demonstrates the variety of political radicalisms brought together in England and Ireland around 1879–81, when the Irish Land League and Ladies’ Land League began to organise programmes to resist eviction. As Whelehan demonstrates, a radical wing …"
Jo Guldi,"Addressing an Emergency: The “Pragmatic Tilt” Required of Scholarship, Data, and Design by the Climate Crisis",2023,https://books.google.com/books?hl=en&lr=&id=UKyTEAAAQBAJ&oi=fnd&pg=RA1-PT157&dq=info:TeyAEcuj4cYJ:scholar.google.com&ots=XCEr8HGrmh&sig=BXf36Jr1xk8CCSkfhjskfrvpqak,"The sense in which our contemporary moment is unprecedented has a great deal to do with data delivered in real time. As a result of the# BlackLivesMatter movement, any citizens previously ignorant of the acts of violence perpetrated by the police against people of color became familiar with those facts, which were circulated almost instantly by citizen observers armed with phones. Calls for action were amplified in real time by social media, leading to some of the largest protests in the history of the United States. During the first phase of the coronavirus pandemic, newspaper readers around the world became accustomed to reading daily updates on the disease’s spread, packaged as bar charts and data-driven maps, with individuals, families, schools, and corporations adjusting their plans on a weekly or even daily basis to respond to the latest information about the disease’s vectors. At the same time, scientists and UN advisory bodies have identified the present decade as a moment of unprecedented crisis, writ in terms of a limited opportunity for the planet’s inhabitants to decide to keep carbon in the ground (Asayama et al.). Through this series of emergencies, experts have mobilized data—in the form of stories, numbers, and figures—to help the public make sense of their experience. Emergencies beg for a response, and often the timeliness of the response is critical in its appropriateness to the problem in question. In the case of climate change, President Joseph Biden has set a deadline of 2030 for limiting carbon emissions, based on the recommendations of scientists, who in turn based their consensus on data collected and analyzed over …"
Jo Guldi,Can historians be replaced by algorithms?,2022,https://www.torrossa.com/gs/resourceProxy?an=5204399&publisher=FZ0661#page=120,"HISTORICAL UNDERSTANDING 104 the scholars motivated by these questions work in disciplines outside of history, although sometimes they have collaborated with renowned historians to produce their work (Klingenstein, Hitchcock, and DeDeo 2014; Barron et al. 2018). In certain recent studies of this kind, it has become commonplace to measure history through an imaginary that we might call the “historian cyborg,” an assortment of algorithms described as automatically detecting change over time. Actualized as a black-box algorithm contrived of a multiplicity of different measures of lexicon, grammar, and topic distribution, the cyborg is designed to “stand in” for an absent historian and measure how much the digitized documents in a particular database changed from one epoch to the next."
Jo Guldi,The Climate Emergency Demands a New Kind of History,2022,https://scholar.smu.edu/hum_sci_history_research/19/,"How shall we judge the element of practicality or urgency for scholars working in the era of the 2030 deadline for action on climate change? This essay surveys the reaction to climate change by scholars who work with data, using the philosopher Stephen Gardiner’s conceit of “corrupt institutions” to organize the approaches according to an index of pragmatic orientation. This survey will lead to the identification of some challenges for those seeking to engage the climate deadline with data, especially work making climate data more transparent, text mining to identify aspects of corruption and reform within contemporary institutions, and building infrastructure for citizen participation."
Jo Guldi,Big data,2021,https://www.taylorfrancis.com/chapters/edit/10.4324/9780367821814-27/big-data-jo-guldi,"What is “big” about big data, and how new are the modes of thinking necessary to analyze it? This chapter profiles three dimensions of data that are changing the contemporary study of our collective past: data about labour and demographics; data about climate; and textual data. The chapter argues that encounters with “big data”, therefore, have required scholars to raise new questions about how we know what we know about the past and frequently to participate in new kinds of scholarly cooperations and institutional alignments. These developments foreground the necessity for special kinds of critical thinking, especially those that combine humanistic and scientific, quantitative, and narrative thought and those that reflect on the life of data and where it comes from."
Jo Guldi,From Critique to Audit: A Pragmatic Approach to the Climate Emergency,2021,https://scholar.smu.edu/hum_sci_history_research/17/,"Rethinking the work of academics in a time of pressing deadlines for climate action, this paper offers a series of new pragmatic strategies that academics can take up. It suggests a"" climate pledge"" where university teachers promise 5% or more of their teaching time to link the field of their traditional research to climate issues. It suggests that humanists, social scientists and data scientists need not only to"" critique"" the logic of extraction that propels our climate catastrophe, but also to"" audit"" individual institutions, writers, and politicians for their continuing engagement with climate or lack thereof."
Jo Guldi,The Common Landscape of Digital History,2020,https://library.oapen.org/bitstream/handle/20.500.12657/45703/1/digital-histories.pdf#page=348,"In old-fashioned social history, the study of the ‘common landscape’used to serve an index of social and cultural difference. 1 Take two regions, two neighbourhoods or two houses, side by side: their differences illuminate cultural ideas about hierarchy, the reality of divergent incomes, and separate relationships with the material world. Just so, the current volume invites us to conduct a survey of the ‘common landscape’of digital history in all its variation.‘Field’though it might be in name, the domain of history as practised by scholars of different methodological and political orientations, geographical and temporal subjects of study, and institutions around the globe is really more of a patchwork of different fields and sub-fields, connected by an infrastructure of main-travelled roads and divergent footpaths that only precariously serve the whole. Some of these fields are closely guarded by an embattled elite, others plowed by an army of workers, still others remote provinces known only to a handful of toilers. Here and there, social historians and"
Craig Hadley,Unpacking the “black box” of global food insecurity and mental health,2021,https://www.sciencedirect.com/science/article/pii/S0277953621003749,"Food insecurity is a global concern. While it was once characterized mainly as a problem of undernutrition, it is now recognized that a person may be food insecure without experiencing hunger. Numerous studies have demonstrated that food insecurity is strongly related to poor mental health around the world, but the mechanisms that underpin that relationship remain poorly understood. One body of research from nutritional sciences posits that nutrient deficiency impacts brain function, producing symptoms of depression and anxiety. Another body of research from the social sciences posits that the social consequences of having to eat non-preferred foods or obtain food in socially unacceptable ways may compromise mental health through stress. This study was designed to clarify the mechanisms linking food insecurity and mental health using case studies in rural Brazil and urban Ethiopia. Working with samples …"
Craig Hadley,Food insecurity and mental health: a meta-analysis,2020,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3520061,"Background: A growing body of literature investigates whether food insecurity is related to common mental disorders (CMD). This paper aims to characterize the association between food insecurity and CMD across studies.Methods: We performed a PubMed search for relevant articles published between January 2000 and December 2018. Only studies of adult participants (>= 18 years) were eligible. Data extracted from each published study included the food insecurity and mental health variables, the relevant point estimates, confidence intervals, and standard errors. We completed five random-effects meta-analyses to quantify the associations between food insecurity and various CMD-related outcomes. The results of each meta-analysis were expressed as meta-odds ratios (meta-ORs) and corresponding 95% confidence intervals (CIs). Inter-study heterogeneity was assessed by calculating an I 2 statistic.Findings: Of 2,014 candidate records, 110 were suitable for inclusion in a meta-analysis. Food insecurity was associated with greater odds of depressive symptoms (81 studies, 304,405 participants; meta-OR 2· 35, 95% CI 2· 14–2· 59, I 2= 95%), anxiety symptoms (16 studies, 93,997 participants; meta-OR 1· 78, 95% CI 1· 49–2· 13, I 2= 71· 80%), post-traumatic stress (5 studies, 5,838 participants; meta-OR 1· 81, 95% CI 1· 54–2· 13, I 2= 0%), psychosocial stress (9 studies, 17,110 participants; meta-OR 2· 39, 95% CI 1· 90–3· 00, I 2= 45%), and self-reported poor mental health or unspecified CMD (36 studies, 396,848 participants; meta-OR 2· 40 95% CI 2· 02–2· 86, I 2= 98%).Interpretation: Food insecurity is related to CMD. Future research …"
Craig Hadley,Subjective social status and mental health among adolescents in Ethiopia: Evidence from a panel study,2023,https://www.sciencedirect.com/science/article/pii/S2352827323000472,"Numerous studies have found that a relationship between subjective status and measures of human health persists even after controlling for objective measures, including income, education, and assets. However, few studies have probed how status shapes health among adolescents, particularly those in low-and-middle-income settings. This study examines the relative effects of subjective and objective status on mental health among Ethiopian adolescents. Using data from two waves of the Jimma Longitudinal Family Survey of Youth (N = 1,045), this study uses a combination of linear regression and linear mixed-effects models to examine the relationships between objective social status, subjective social status, and mental well-being among adolescents in Ethiopia. Three measures of objective status, including household income, adolescent education, and a multidimensional measure of material wealth, were …"
Craig Hadley,Context matters for food security: multi-sited evidence of shared cultural models of food consumption,2022,https://www.tandfonline.com/doi/abs/10.1080/03670244.2021.1969927,"Anthropologists have long emphasized the social significance of foods and the contexts in which they are consumed. Expanding on this idea, we define the context of consumption as the non-eating behaviors that surround eating, such as the manner of food preparation, food sharing, and dietary patterns. In this study, we used cultural consensus analysis to assess whether there exist consistently shared, normative ideas about preferable context of food consumption in three diverse research sites: urban Ethiopia, rural Brazil, and rural Haiti. Our analysis demonstrates that in all three communities, there are distinct sets of behaviors that people identified as non-preferable because they reliably associate them with poverty and food insecurity, and behaviors that people identify as preferable because they reliably associate them with wealth and food security. Across the settings, there was little variation in agreement …"
Craig Hadley,A mixed methods study of the challenges and rewards of fatherhood in a diverse sample of US Fathers,2023,https://journals.sagepub.com/doi/abs/10.1177/21582440231193939,"Fathers contribute to healthy child development, but there are limited data that provide an in-depth understanding of fathers’ perceptions of the challenges and rewards of fatherhood. We recruited 122 fathers from three different ethnic groups living in Atlanta, Georgia to conduct a mixed-methods research study on fathers’ perceptions of the challenges and rewards of fatherhood. Challenges included financial responsibilities (56%), sleep-deprivation (47%), work-family conflict (44%), negative changes in their relationship with their partner (43%), and children crying and whining (23%). Ninety seven percent of fathers agreed that having children added meaning to their life when asked. Many indicated that having children infused their life with an invaluable sense of meaning and purpose, and inspired them to become better people. The most common spontaneously mentioned rewards included witnessing …"
Craig Hadley,The social meaning of food consumption behaviors in rural Brazil: Agreement and intracultural variation,2021,https://journals.sagepub.com/doi/abs/10.1177/1525822X21992162,"Food insecurity (FI) is often assessed through experienced-based measures, which address the number and extent of coping strategies people employ. Coping indices are limited because, methodologically, they presuppose that people engage coping strategies uniformly. Ethnographic work suggests that subgroups experience FI quite differently, meaning that coping strategies might also vary within a population. Thus, whether people actually agree on FI coping behaviors is an open question. This article describes methods used to test whether there was a culturally agreed on set of coping behaviors around FI in rural Brazilian majority-female heads of household, and to detect patterned subgroup variation in that agreement. We used cultural consensus and residual agreement analyses on freelist and rating exercise data. This process could be applied as a first step in developing experience-based measures of …"
Craig Hadley,The relationship between altitude and BMI varies across low‐and middle‐income countries,2024,https://onlinelibrary.wiley.com/doi/abs/10.1002/ajhb.24036,"Studies suggest that living at high altitude decreases obesity risk, but this research is limited to single‐country analyses. We examine the relationship between altitude and body mass index (BMI) among women living in a diverse sample of low‐ and middle‐income countries.Using Demographic and Health Survey data from 1 583 456 reproductive age women (20–49 years) in 54 countries, we fit regression models predicting BMI and obesity by altitude controlling for a range of demographic factors—age, parity, breastfeeding status, wealth, and education.A mixed‐effects model with country‐level random intercepts and slopes predicts an overall −0.162 kg/m2 (95% CI −0.220, −0.104) reduction in BMI and lower odds of obesity (OR 0.90, 95% CI 0.87, 0.95) for every 200 m increase in altitude. However, countries vary dramatically in whether they exhibit a negative …"
Craig Hadley,Sorting it out: perceptions of foods among newly arrived adolescent refugees in the Southeastern USA,2025,https://www.cambridge.org/core/journals/public-health-nutrition/article/sorting-it-out-adolescent-refugees-perceptions-of-food-upon-arrival-to-the-us/9F8C741040AD290FD90986F4EC57CFE6,
Craig Hadley,"The relationship between mental well‐being and wealth varies by wealth type, place and sex/gender: Evidence from Namibia",2024,https://onlinelibrary.wiley.com/doi/abs/10.1002/ajhb.24064,"This paper explores the impact of livelihood strategies and place on mental well‐being. Identifying different socioeconomic factors that impact mental well‐being across contexts is pressing given the global rise in mental health disorders. Numerous studies in the population and social sciences have emphasized the protective role of material wealth on human health and well‐being; however, scholars frequently assess wealth as a one‐dimensional variable, which may fail to capture diverse forms of wealth. Acknowledging different forms of wealth may be particularly important in settings where agricultural economies coexist with cash economies. Using data from the 2013 Namibia Demographic Health Survey (n = 13 377), we use a newly developed measure of success in agricultural activities, an agricultural wealth index, or AWI, generated by Hackman et al., (2021). To examine the role of different forms of …"
Craig Hadley,Close quarters: An investigation of neighborhood effects and SARS-CoV-2 in Chicago,2022,https://etd.library.emory.edu/concern/etds/0k225c322,"The unequal impact of SARS-CoV-2 on minority communities across the United States is undeniable, with different disciplines proposing theories to understand the origins of these inequalities. Here I investigate individual behavioral predictors of SARS-CoV-2 exposure and zip code-level predictors of infection in a large COVID-19 seroprevalence study in Chicago, IL (N= 7,058), conducted June-November 2020. Participants provided self-collected finger stick dried blood samples which were analyzed for the presence of antibodies against the receptor binding domain of SARS-CoV-2. Seropositivity was modeled as a function of individual variables with multilevel logistic regressions. Results show that age and household density were individual-level variables significantly associated with the odds of seropositivity. Individuals who were over 60 (OR: 0.62, 95% CI: 0.43, 0.90) had lower odds of seropositivity. Those …"
David A. Hirshberg,Synthetic difference-in-differences,2021,https://www.aeaweb.org/articles?id=10.1257/aer.20190159,"We present a new estimator for causal effects with panel data that builds on insights behind the widely used difference-in-differences and synthetic control methods. Relative to these methods we find, both theoretically and empirically, that this “synthetic difference-in-differences” estimator has desirable robustness properties, and that it performs well in settings where the conventional estimators are commonly used in practice. We study the asymptotic behavior of the estimator when the systematic part of the outcome model includes latent unit factors interacted with latent time factors, and we present conditions for consistency and asymptotic normality. (JEL C23, H25, H71, I18, L66)"
David A. Hirshberg,Confidence intervals for policy evaluation in adaptive experiments,2021,https://www.pnas.org/doi/abs/10.1073/pnas.2014602118,"Adaptive experimental designs can dramatically improve efficiency in randomized trials. But with adaptively collected data, common estimators based on sample means and inverse propensity-weighted means can be biased or heavy-tailed. This poses statistical challenges, in particular when the experimenter would like to test hypotheses about parameters that were not targeted by the data-collection mechanism. In this paper, we present a class of test statistics that can handle these challenges. Our approach is to adaptively reweight the terms of an augmented inverse propensity-weighting estimator to control the contribution of each term to the estimator’s variance. This scheme reduces overall variance and yields an asymptotically normal test statistic. We validate the accuracy of the resulting estimates and their CIs in numerical experiments and show that our methods compare favorably to existing alternatives in …"
David A. Hirshberg,Augmented minimax linear estimation,2021,https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-6/Augmented-minimax-linear-estimation/10.1214/21-AOS2080.short,"We provide complete proofs for the results in the main text, details about our simulation study, and a discussion of computational issues."
David A. Hirshberg,Off-policy evaluation via adaptive weighting with data from contextual bandits,2021,https://dl.acm.org/doi/abs/10.1145/3447548.3467456,"It has become increasingly common for data to be collected adaptively, for example using contextual bandits. Historical data of this type can be used to evaluate other treatment assignment policies to guide future innovation or experiments. However, policy evaluation is challenging if the target policy differs from the one used to collect data, and popular estimators, including doubly robust (DR) estimators, can be plagued by bias, excessive variance, or both. In particular, when the pattern of treatment assignment in the collected data looks little like the pattern generated by the policy to be evaluated, the importance weights used in DR estimators explode, leading to excessive variance.In this paper, we improve the DR estimator by adaptively weighting observations to control its variance. We show that a t-statistic based on our improved estimator is asymptotically normal under certain conditions, allowing us to form …"
David A. Hirshberg,The balancing act in causal inference,2021,https://arxiv.org/abs/2110.14831,"The idea of covariate balance is at the core of causal inference. Inverse propensity weights play a central role because they are the unique set of weights that balance the covariate distributions of different treatment groups. We discuss two broad approaches to estimating these weights: the more traditional one, which fits a propensity score model and then uses the reciprocal of the estimated propensity score to construct weights, and the balancing approach, which estimates the inverse propensity weights essentially by the method of moments, finding weights that achieve balance in the sample. We review ideas from the causal inference, sample surveys, and semiparametric estimation literatures, with particular attention to the role of balance as a sufficient condition for robust inference. We focus on the inverse propensity weighting and augmented inverse propensity weighting estimators for the average treatment effect given strong ignorability and consider generalizations for a broader class of problems including policy evaluation and the estimation of individualized treatment effects."
David A. Hirshberg,Debiased inference of average partial effects in single-index models: Comment on wooldridge and zhu,2020,https://www.tandfonline.com/doi/full/10.1080/07350015.2019.1681277,"There has recently been a considerable amount of interest in developing methods for statistical inference in highdimensional regimes with more covariates than data points (Javanmard and Montanari 2014; van de Geer et al. 2014; Zhang and Zhang 2014; Belloni et al. 2017; Athey, Imbens, and Wager 2018). Wooldridge and Zhu build on this literature, and propose a new method for inference about average partial effects (APEs) in high-dimensional probit models; they then extend their approach to nonlinear panels with correlated random effects (Wooldridge 2010). This is a valuable result, with many potential application areas. In order to achieve"
David A. Hirshberg,Large-sample properties of the synthetic control method under selection on unobservables,2023,https://www.aeaweb.org/conference/2024/program/paper/rN25s72F,"We analyze the synthetic control (SC) method in panel data settings with many units. We assume the treatment assignment is based on unobserved heterogeneity and pretreatment information, allowing for both strictly and sequentially exogenous assignment processes. We show that the critical property that determines the behavior of the SC method is the ability of input features to approximate the unobserved heterogeneity. Our results imply that the SC method delivers asymptotically normal estimators for a large class of linear panel data models as long as the number of pre-treatment periods is sufficiently large, making it a natural alternative to the Difference-in-Differences."
David A. Hirshberg,Least squares with error in variables,2021,https://arxiv.org/abs/2104.08931,"Error-in-variables regression is a common ingredient in treatment effect estimators using panel data. This includes synthetic control estimators, counterfactual time series forecasting estimators, and combinations. We study high-dimensional least squares with correlated error-in-variables with a focus on these uses. We use our results to derive conditions under which the synthetic control estimator is asymptotically unbiased and normal with estimable variance, permitting inference without assuming time-stationarity, unit-exchangeability, or the absence of weak factors. These results hold in an asymptotic regime in which the number of pre-treatment periods goes to infinity and the number of control units can be much larger ."
David A. Hirshberg,A Stable and Efficient Covariate-Balancing Estimator for Causal Survival Effects,2023,https://arxiv.org/abs/2310.02278,We propose an empirically stable and asymptotically efficient covariate-balancing approach to the problem of estimating survival causal effects in data with conditionally-independent censoring. This addresses a challenge often encountered in state-of-the-art nonparametric methods: the use of inverses of small estimated probabilities and the resulting amplification of estimation error. We validate our theoretical results in experiments on synthetic and semi-synthetic data.
David A. Hirshberg,Synthetic Differences-in-Differences with Covariates,2024,https://klosins.github.io/Hirshberg_Klosin_SDIDC.pdf,We propose a synthetic difference-in-difference estimator that incorporates time-varying covariates. We incorporate covariates into a high-dimensional least squares with correlated error-in-variables setting. We use results from this setting to derive conditions under which our synthetic differences-in-differences estimator is asymptotically normal with estimable variance. Monte Carlo simulations demonstrate that our estimator outperforms classic synthetic difference-in-differences in settings where covariates contain information about the outcome. We illustrate the practical performance of our estimator by studying the impact of subsidy increases on crop insurance choices within the United States Federal Crop Insurance Program (FCIP).
David A. Hirshberg,Perception of Increasing Wildfire Risk Lowers Appreciation of Residential Real Estate in California,2023,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4540783,"Wildfires exacerbated by climate change are a growing issue in the US. However, the full economic implications of wildfires for the housing market are largely unknown. As a case study, we estimate the effect of changing wildfire risk perceptions on residential home sale prices in California. We employ cutting edge tools from causal inference to understand an often hard to estimate channel for the economic effects of natural disasters exacerbated by climate change: the cascading impact of changing risk perception on housing markets. Because of heightened risk perceptions of wildfires relative to pre-2015 levels, since 2015, homes in census tracts with high wildfire risk in California sell for 7.5% less than they otherwise would have. For an average California homeowner in a high wildfire risk census tract, this is a $37,715 loss due to lower home value appreciation, in part due to increased insurance costs. The impacts of this reduced appreciation are expected to extend beyond homeowners and have adverse effects on statewide revenues due to lower property taxes. We discuss how policy solutions that ignore these considerations may be inadequate in responding to the challenge of increasing climate risk and risk salience in the context of California wildfires."
Lauren Frederica Klein,Data feminism,2023,https://books.google.com/books?hl=en&lr=&id=rHOdEAAAQBAJ&oi=fnd&pg=PR9&dq=info:C8IdLVl20XwJ:scholar.google.com&ots=mXvstadleq&sig=Uknz3cjnqJb93IVNnLiFYwjkq4A,"Cutting edge strategies for thinking about data science and data ethics through an intersectional feminist lens.“Without ever finger-wagging, Data Feminism reveals inequities and offers a way out of a broken system in which the numbers are allowed to lie.”—WIRED Today, data science is a form of power. It has been used to expose injustice, improve health outcomes, and topple governments. But it has also been used to discriminate, police, and surveil. This potential for good, on the one hand, and harm, on the other, makes it essential to ask: Data science by whom? Data science for whom? Data science with whose interests in mind? The narratives around big data and data science are overwhelmingly white, male, and techno-heroic. In Data Feminism, Catherine D'Ignazio and Lauren Klein present a new way of thinking about data science and data ethics—one that is informed by intersectional feminist thought. Illustrating data feminism in action, D'Ignazio and Klein show how challenges to the male/female binary can help challenge other hierarchical (and empirically wrong) classification systems. They explain how, for example, an understanding of emotion can expand our ideas about effective data visualization, and how the concept of invisible labor can expose the significant human efforts required by our automated systems. And they show why the data never, ever “speak for themselves.” Data Feminism offers strategies for data scientists seeking to learn how feminism can help them work toward justice, and for feminists who want to focus their efforts on the growing field of data science. But Data Feminism is about much more than gender. It is …"
Lauren Frederica Klein,Seven intersectional feminist principles for equitable and actionable COVID-19 data,2020,https://journals.sagepub.com/doi/abs/10.1177/2053951720942544,"This essay offers seven intersectional feminist principles for equitable and actionable COVID-19 data, drawing from the authors' prior work on data feminism. Our book, Data Feminism (D'Ignazio and Klein, 2020), offers seven principles which suggest possible points of entry for challenging and changing power imbalances in data science. In this essay, we offer seven sets of examples, one inspired by each of our principles, for both identifying existing power imbalances with respect to the impact of the novel coronavirus and its response, and for beginning the work of change."
Lauren Frederica Klein,No: Critical refusal as feminist data practice,2020,https://dl.acm.org/doi/abs/10.1145/3406865.3419014,"Harmful data practices produce and perpetuate structural inequities that are compounded by the intersections of one's gender, race, ethnicity, class, sexuality, ability, and citizenship. This panel mobilizes 'critical refusal' as an organizing principle and lens for examining interlocking struggles across data domains, contexts, practices and cultures within CSCW and social computing research."
Lauren Frederica Klein,Abolitionist networks: Modeling language change in nineteenth-century activist newspapers,2021,https://arxiv.org/abs/2103.07538,"The abolitionist movement of the nineteenth-century United States remains among the most significant social and political movements in US history. Abolitionist newspapers played a crucial role in spreading information and shaping public opinion around a range of issues relating to the abolition of slavery. These newspapers also serve as a primary source of information about the movement for scholars today, resulting in powerful new accounts of the movement and its leaders. This paper supplements recent qualitative work on the role of women in abolition's vanguard, as well as the role of the Black press, with a quantitative text modeling approach. Using diachronic word embeddings, we identify which newspapers tended to lead lexical semantic innovations -- the introduction of new usages of specific words -- and which newspapers tended to follow. We then aggregate the evidence across hundreds of changes into a weighted network with the newspapers as nodes; directed edge weights represent the frequency with which each newspaper led the other in the adoption of a lexical semantic change. Analysis of this network reveals pathways of lexical semantic influence, distinguishing leaders from followers, as well as others who stood apart from the semantic changes that swept through this period. More specifically, we find that two newspapers edited by women -- THE PROVINCIAL FREEMAN and THE LILY -- led a large number of semantic changes in our corpus, lending additional credence to the argument that a multiracial coalition of women led the abolitionist movement in terms of both thought and action. It also contributes additional …"
Lauren Frederica Klein,"Dimensions of scale: Invisible labor, editorial work, and the future of quantitative literary studies",2020,https://www.cambridge.org/core/journals/pmla/article/dimensions-of-scale-invisible-labor-editorial-work-and-the-future-of-quantitative-literary-studies/9BB30779EA9C9CF7AF176E7FEF12F484,"This essay calls for a conceptual reorientation of how quantitative methods in literary studies are currently framed, arguing for an expansion from a linear model bounded by the endpoints of distant and close to a space defined by multiple dimensions of scale. I explore the axis bounded by visible and invisible as an example of one of the additional dimensions that might constitute this expanded conceptual frame. In demonstrating its potential for producing new knowledge, I examine the editorial work of two women abolitionists, Mary Ann Shadd (1823–93) and Lydia Maria Child (1802–80). I show how topic modeling and statistical analysis can help identify and describe their invisible editorial labor. I thus provide an additional layer of evidence in support of the argument that positions women, and black women in particular, at abolition's vanguard. I also show how both women employed editing as a method of …"
Lauren Frederica Klein,An archive of taste: race and eating in the early United States,2020,https://books.google.com/books?hl=en&lr=&id=lpDgDwAAQBAJ&oi=fnd&pg=PT6&dq=info:o-p_XfoHMfQJ:scholar.google.com&ots=CN_95vUvU_&sig=X1ESvqj2cnWyxEyJC2MKaXrEY_c,"A groundbreaking synthesis of food studies, archival theory, and early American literature There is no eating in the archive. This is not only a practical admonition to any would-be researcher but also a methodological challenge, in that there is no eating—or, at least, no food—preserved among the printed records of the early United States. Synthesizing a range of textual artifacts with accounts (both real and imagined) of foods harvested, dishes prepared, and meals consumed, An Archive of Taste reveals how a focus on eating allows us to rethink the nature and significance of aesthetics in early America, as well as of its archive. Lauren F. Klein considers eating and early American aesthetics together, reframing the philosophical work of food and its meaning for the people who prepare, serve, and consume it. She tells the story of how eating emerged as an aesthetic activity over the course of the eighteenth century and how it subsequently transformed into a means of expressing both allegiance and resistance to the dominant Enlightenment worldview. Klein offers richly layered accounts of the enslaved men and women who cooked the meals of the nation’s founders and, in doing so, directly affected the development of our national culture—from Thomas Jefferson’s emancipation agreement with his enslaved chef to Malinda Russell’s Domestic Cookbook, the first African American–authored culinary text. The first book to examine the gustatory origins of aesthetic taste in early American literature, An Archive of Taste shows how thinking about eating can help to tell new stories about the range of people who worked to establish a cultural foundation …"
Lauren Frederica Klein,Data feminism for AI,2024,https://dl.acm.org/doi/abs/10.1145/3630106.3658543," This paper presents a set of intersectional feminist principles for conducting equitable, ethical, and sustainable AI research. In Data Feminism (2020), we offered seven principles for examining and challenging unequal power in data science. Here, we present a rationale for why feminism remains deeply relevant for AI research, rearticulate the original principles of data feminism with respect to AI, and introduce two potential new principles related to environmental impact and consent. Together, these principles help to 1) account for the unequal, undemocratic, extractive, and exclusionary forces at work in AI research, development, and deployment; 2) identify and mitigate predictable harms in advance of unsafe, discriminatory, or otherwise oppressive systems being released into the world; and 3) inspire creative, joyful, and collective ways to work towards a more equitable, sustainable world in which all of us can thrive."
Lauren Frederica Klein,AboutMe: Using self-descriptions in webpages to document the effects of english pretraining data filters,2024,https://arxiv.org/abs/2401.06408,"Large language models' (LLMs) abilities are drawn from their pretraining data, and model development begins with data curation. However, decisions around what data is retained or removed during this initial stage are under-scrutinized. In our work, we ground web text, which is a popular pretraining data source, to its social and geographic contexts. We create a new dataset of 10.3 million self-descriptions of website creators, and extract information about who they are and where they are from: their topical interests, social roles, and geographic affiliations. Then, we conduct the first study investigating how ten ""quality"" and English language identification (langID) filters affect webpages that vary along these social dimensions. Our experiments illuminate a range of implicit preferences in data curation: we show that some quality classifiers act like topical domain filters, and langID can overlook English content from some regions of the world. Overall, we hope that our work will encourage a new line of research on pretraining data curation practices and its social implications."
Lauren Frederica Klein,Riveter: Measuring Power and Social Dynamics Between Entities,2023,https://arxiv.org/abs/2312.09536,"Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research."
Lauren Frederica Klein,What Data Visualization Reveals: Elizabeth Palmer Peabody and the Work of Knowledge Production,2022,https://hdsr.mitpress.mit.edu/pub/oraonikr,"This essay offers the chronological charts of Elizabeth Palmer Peabody (1804–1894), the 19th-century educator and intellectual, as early examples of how data visualization can reveal a range of forms of knowledge. It challenges the universality of the goals of clarity and efficiency when designing data visualizations, and argues for the value of visualizations that encourage sustained reflection and imaginative response. Drawing from feminist and Black studies scholarship, it confirms how visual knowledge is informed by the social, cultural, and political contexts that surround it, and how an awareness of those contexts can lead to more intentional and more effective visualization design. It concludes with a call to expand the archive of data visualization so that visualization designers, in the present, might be prompted to imagine a wider and more capacious array of visual and interactive forms."
Lauren Frederica Klein,Entanglements for visualization: Changing research outcomes through feminist theory,2024,https://ieeexplore.ieee.org/abstract/document/10670254/,"A growing body of work draws on feminist thinking to challenge assumptions about how people engage with and use visualizations. This work draws on feminist values, driving design and research guidelines that account for the influences of power and neglect. This prior work is largely prescriptive, however, forgoing articulation of how feminist theories of knowledge — or feminist epistemology — can alter research design and outcomes. At the core of our work is an engagement with feminist epistemology, drawing attention to how a new framework for how we know what we know enabled us to overcome intellectual tensions in our research. Specifically, we focus on the theoretical concept of entanglement, central to recent feminist scholarship, and contribute: a history of entanglement in the broader scope of feminist theory; an articulation of the main points of entanglement theory for a visualization context; and a …"
Lauren Frederica Klein,Who Collects the Data? A Tale of Three Maps,2021,https://mit-serc.pubpub.org/pub/tale-of-three-maps,"Who makes maps and who gets mapped? Using a comparative reading of three maps, this case study introduces the idea that data may be useful, but they are not neutral. Rather, they represent the interests and goals of the groups and institutions that are doing the data collection. These interests and goals may be liberatory, discriminatory, or something in between. In all cases, we argue that an analysis of social inequality is essential to understanding the ethical impacts of data collection and use. To aid such analysis, we introduce a model of power out of sociology called the matrix of domination. This model helps us understand why collecting data is political, why not collecting data is also political, and what actions we can take to address unequal social relations using data science."
Lauren Frederica Klein,Debates in the digital humanities 2023,2023,https://books.google.com/books?hl=en&lr=&id=UKyTEAAAQBAJ&oi=fnd&pg=PA1985&dq=info:o-C90s9DaWkJ:scholar.google.com&ots=XCEr8HInsf&sig=ggnsZ-axFMYLZRxV69VWJ8qFsKA,"A cutting-edge view of the digital humanities at a time of global pandemic, catastrophe, and uncertainty Where do the digital humanities stand in 2023? Debates in the Digital Humanities 2023 presents a state-of-the-field vision of digital humanities amid rising social, political, economic, and environmental crises; a global pandemic; and the deepening of austerity regimes in US higher education. Providing a look not just at where DH stands but also where it is going, this fourth volume in the Debates in the Digital Humanities series features both established scholars and emerging voices pushing the field’s boundaries, asking thorny questions, and providing space for practitioners to bring to the fore their research and their hopes for future directions in the field. Carrying forward the themes of political and social engagement present in the series throughout, it includes crucial contributions to the field—from a vital forum centered on the voices of Black women scholars, manifestos from feminist and Latinx perspectives on data and DH, and a consideration of Indigenous data and artificial intelligence, to essays that range across topics such as the relation of DH to critical race theory, capital, and accessibility. Contributors: Harmony Bench, Ohio State U; Christina Boyles, Michigan State U; Megan R. Brett, George Mason U; Michelle Lee Brown, Washington State U; Patrick J. Burns, New York U; Kent K. Chang, U of California, Berkeley; Rico Devara Chapman, Clark Atlanta U; Marika Cifor, U of Washington; María Eugenia Cotera, U of Texas; TL Cowan, U of Toronto; Marlene L. Daut, U of Virginia; Quinn Dombrowski, Stanford U; Kate Elswit, U of London …"
Lauren Frederica Klein,The power of absence: Thinking with archival theory in algorithmic design,2024,https://dl.acm.org/doi/abs/10.1145/3643834.3660690," This paper explores the value of archival theory as a means of grappling with bias in algorithmic design. Rather than seek to mitigate biases perpetuated by datasets and algorithmic systems, archival theory offers a reframing of bias itself. Drawing on a range of archival theory from the fields of history, literary and cultural studies, Black studies, and feminist STS, we propose absence—as power, presence, and productive—as a concept that might more securely anchor investigations into the causes of algorithmic bias, and that can prompt more capacious, creative, and joyful future work. This essay, in turn, can intervene into the technical as well as the social, historical, and political structures that serve as sources of bias."
Lauren Frederica Klein,Gender and Power in Japanese Light Novels.,2022,https://ceur-ws.org/Vol-3290/short_paper1101.pdf,"In Japanese culture, the light novel–a combination of text and anime-style illustrations–is a relatively new literary form. It derives from the broader otaku culture, which is also associated with video games, manga, cosplay, anime, and other forms of Japanese popular culture. Though the light novel lacks the global reach of some of these other genres, such as manga and anime, it nonetheless attracts millions of readers across a range of gender and age groups. While distinct subgenres of the light novel have emerged, such as romance, adventure, horror, and harem, issues of gender stereotyping, power imbalances and other forms of inequality remain strongly entrenched. These issues can be attributed to how otaku culture is rooted in heterosexual male desire. This paper o 昀昀 ers a quantitative assessment of these issues of gender inequality. We analyze 290 light novels, scraped from the Baka-Tsuki Translation Community Wiki, in terms of the power relationships between female and male characters as they evolve over the course of each novel. We 昀椀 nd patterns consistent with issues of gender stereotyping and power di 昀昀 erentials. More speci 昀椀 cally, we 昀椀 nd that female characters consistently wield less power than male characters, especially toward the end of each novel. We 昀椀 nd some variation in speci 昀椀 c subgenres. We conclude with close readings of two light novels, demonstrating how a power frames approach to analyzing gender stereotypes in otaku culture augments existing work on the subject."
Lauren Frederica Klein,Introducing Data Feminism,2023,https://link.springer.com/chapter/10.1007/978-3-031-29332-0_8,"As data are increasingly mobilized in the service of governments and corporations, their unequal conditions of production, their asymmetrical methods of application, and their unequal effects on both individuals and groups have become increasingly difficult for data scientists—and others who rely on data in their work—to ignore. But it is precisely this power that makes it worth asking: Data science by whom? Data science for whom? Data science with whose interests in mind? These are some of the questions that emerge from a larger project we call data feminism, a way of thinking about data science and its uses that is informed by the past several decades of intersectional feminist activism and critical thought. In this essay, we introduce data feminism and outline its seven principles."
Lauren Frederica Klein,Introducción: por qué la ciencia de datos necesita feminismo,2023,https://data-feminism.mitpress.mit.edu/pub/v874jd7x/release/1?readingCollection=b371d820,"Christine Mann Darden cruzó por primera vez las puertas del Centro de Investigación Langley de la NASA en Hampton, Virginia, en el verano de 1967. Su maestría recién obtenida en matemáticas aplicadas le había valido un puesto como analista de datos allí. En la ciudad de Hampton y en todo Estados Unidos, las tensiones estaban a flor de piel. En Los Ángeles, una protesta masiva contra la guerra de Vietnam solo terminó cuando más de mil policías armados atacaron a las personas que se manifestaban pacíficamente. Un mes después, la ciudad de Detroit se vio envuelta en más violencia, después de que una redada policial se saliera de control. El disturbio de Detroit de 1967 o la rebelión de Detroit de 1967, como popularmente se la conoce, terminó con más de cuarenta muertos y mil heridos.Puede que las puertas de Langley protegieran a Darden de esas confrontaciones físicas, pero su trabajo allí no estaba alejado del escenario nacional. En 1967, la carrera espacial estaba muy avanzada y Estados Unidos estaba perdiendo. La Unión Soviética ya había enviado un hombre al espacio y un cohete a la luna. Lo único que se interponía en el camino de una victoria soviética era juntar esas dos piezas. Mientras tanto, Estados Unidos había sufrido una serie de derrotas y, en enero de ese año, un completo desastre, cuando un incendio repentino durante una prueba de lanzamiento de la nave espacial Apolo 1 mató a los tres astronautas a bordo."
Lauren Frederica Klein,Social Justice Frameworks for Leveraging Data Science to Advance Gender Equity,2022,https://www.unwomen.org/sites/default/files/2022-12/EP.8_Lauren%20Klein%20and%20Brandeis%20Marshall.pdf,"In the world today, data is a form of power. Data has been used in scientific research to advance medical discovery, in crisis response to direct resources to communities in need, and in analysis and evaluation settings to provide evidence of programmatic success (or failure). But far more often, data has been used to discriminate, police, and surveil. Perhaps most famously, Amazon was required to scrap its automated first-round resume-screening system when it was discovered to have down-graded the resumes of women applicants (Goodman 2018). In the United States, fears about the restrictions recently placed on abortion access–the result of the rollback of Roe v. Wade–have led to widespread calls for women and girls to delete all menstruation data from their health-tracking apps (Garamvolgyi 2022). And advocacy by the Algorithmic Justice League has called attention to the global risks of facial recognition software when employed by both corporate and state actors, particularly risks to Black and brown women and to nonbinary people, for whom the software performs particularly poorly while simultaneously being subject to disproportionate monitoring and surveillance (2022). The interrelated and intersectional harms brought about by these data-driven systems can be traced to the fact that the power of data is currently wielded unequally. More specifically, it is corporations, governments, and other well-resourced institutions–institutions that represent the values and views of those in positions of power–who have the ability to design and deploy these data systems, while those whose lives and livelihoods are most dependent on the output of …"
Lauren Frederica Klein,"Feminist Data Practices: Conversations with Catherine D’Ignazio, Lauren Klein, and Maya Livio",2021,https://horizonteenfermeria.uc.cl/index.php/Disena/article/view/41545,"Many of the papers and more-than-textual proposals submitted for this special issue included machine vision technologies and other data-and AI-mediated practices. To provide a critical perspective on data-driven (design) research, we decided to explore the emerging field of data feminism through online interviews with three scholars and practitioners who apply intersectional feminist theory and practice to the realm of data-driven work: Catherine D’Ignazio, Lauren Klein, and Maya Livio."
Lauren Frederica Klein,What Data Does and Does Not Represent: Visualizing the Archive of Slavery,2025,https://ieeexplore.ieee.org/abstract/document/10935303/,"This paper presents a design report on a humanistically-informed data visualization of a dataset related to the trans-Atlantic slave trade. The visualization employs a quantitative dataset of slaving voyages that took place between 1565 and 1858 and uses historical scholarship and humanistic theory in order to call attention to the people behind the data, as well as to what the data does not or cannot represent. In the paper, we summarize the intersecting histories of slavery and data and then outline the theories that inform our design: of the archive of slavery, of the dangers of restaging historical violence, and of visibility, opacity, representation, and resistance. We then describe our design approach and discuss the visualization's ability to honor the lives of the enslaved by calling attention to their acts of resistance, both recorded and unrecorded."
Lauren Frederica Klein,Provocations from the Humanities for Generative AI Research,2025,https://arxiv.org/abs/2502.19190,"This paper presents a set of provocations for considering the uses, impact, and harms of generative AI from the perspective of humanities researchers. We provide a working definition of humanities research, summarize some of its most salient theories and methods, and apply these theories and methods to the current landscape of AI. Drawing from foundational work in critical data studies, along with relevant humanities scholarship, we elaborate eight claims with broad applicability to current conversations about generative AI: 1) Models make words, but people make meaning; 2) Generative AI requires an expanded definition of culture; 3) Generative AI can never be representative; 4) Bigger models are not always better models; 5) Not all training data is equivalent; 6) Openness is not an easy fix; 7) Limited access to compute enables corporate capture; and 8) AI universalism creates narrow human subjects. We conclude with a discussion of the importance of resisting the extraction of humanities research by computer science and related fields."
Lauren Frederica Klein,Clinician as editor: notes in the era of AI scribes,2024,https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(24)02568-6/abstract,"Every clinician has a strategy. Between patients, before going home, late at night—clinical notes must be written. They are essential for recording patient visits, ensuring continuity of care, arriving at accurate diagnoses, and facilitating communication between doctors, as well as providing medico-legal protection and enabling reimbursement. But these notes are increasingly burdensome to write, thanks in part to the electronic health record (EHR). Artificial intelligence (AI) scribes—computational systems that record clinical encounters and produce narrative summaries—promise much-needed help. Indeed, in many settings, health-care organisations are already adopting this technology. Nevertheless, AI scribes arrive at a moment when the note has already been changing, with legislation increasingly granting patients access to their medical records. Given AI scribes’ promised disruption, it is crucial to consider what …"
Lauren Frederica Klein,۳. در مورد نگرش‌های عقلانی، علمی، و عینی در مقابل دیدگاه‌های اسطوره‌ای، خیالی، و غیرممکن,2024,https://data-feminism.mitpress.mit.edu/pub/gvk9lcpn/release/2,"Principle# 3 of Data Feminism is to Elevate Emotion and Embodiment. Data feminism teaches us to value multiple forms of knowledge, including the knowledge that comes from people as living, feeling bodies in the world."
Lauren Frederica Klein,۴. آن چیزی که شمارش می‌شود، اهمیت پیدا دارد,2024,https://data-feminism.mitpress.mit.edu/pub/vereskzd/release/3?readingCollection=445ed6b5,"Principle# 4 of Data Feminism is to Rethink Binaries and Hierarchies. Data feminism requires us to challenge the gender binary, along with other systems of counting and classification that perpetuate oppression."
Lauren Frederica Klein,مقدمه: چرا علم داده به فمینیسم احتیاج دارد,2024,https://data-feminism.mitpress.mit.edu/pub/nusp4u9f?readingCollection=445ed6b5,در تابستان ۱۹۶۷، کریستین مان داردن 1 از دروازه‌های مرکز تحقیقات لانگلیِ ناسا 2 در همپتون ویرجینیا گذشت و با مدرک کارشناسی ارشدی که به تازگی در رشته ریاضیات کاربردی گرفته بود، به‌عنوان تحلیلگر داده شروع به کار کرد. در آن زمان، تنش‌ در شهر همپتون و در سراسر ایالات‌متحده رو به افزایش بود و اعتراضات گسترده‌ در لس‌آنجلس علیه جنگ ویتنام تنها زمانی به پایان رسید که بیش از ۱۰۰۰ پلیس مسلح به معترضان در تظاهرات مسالمت‌آمیز حمله کردند. حدود یک ماه بعد، پس از آن‌که یورش پلیس در دیترویت از کنترل خارج شد، خشونت شهر را فرا گرفت. شورش‌های ۱۹۶۷ دیترویت، یا قیام ۱۹۶۷ دیترویت، که بیشتر با این عنوان شناخته می‌شود، بیش از ۴۰ کشته و ۱۰۰۰ زخمی بر جای گذاشت.با اینکه دروازه‌های لانگلی، حائلی فیزیکی بین داردن و آن درگیری‌ها بودند، اما کار او در آنجا به‌هیچ‌وجه از صحنه ملی دور نبود. در سال ۱۹۶۷، رقابت فضایی (بین ایالات‌متحده و شوروی) در جریان بود و ایالات‌متحده در این رقابت عقب مانده بود. شوروی پیش‌تر یک انسان را به فضا و یک موشک را به ماه فرستاده بود و تنها انجام آن دو کار در کنار هم بود که مانع پیروزی نهایی شوروی شده بود. در همان زمان، ایالات‌متحده متحمل یک سری شکست نیز شده بود-در ژانویه همان سال، فاجعه‌ای رخ داد و در یک آتش‌سوزی ناگهانی در حین آزمایش پرتاب فضاپیمای «آپولو۱»، سه فضانورد کشته شدند.
Lauren Frederica Klein,Keynote: Lauren Klein “Data Feminism and Digital Scholarship “,2022,https://digitalcommons.bucknell.edu/digital-scholarship-conference/budsc22/Keynote/1/,"Bucknell Digital Commons - Bucknell University Digital Scholarship Conference: Keynote: 
Lauren Klein “Data Feminism and Digital Scholarship“ Home Search Browse Collections My 
Account About DC Network Digital Commons Network™ Skip to main content Bucknell University 
logo Home About FAQ My Account Bucknell University Digital Scholarship Conference Next 
Event > Home colloquium conferences Digital Scholarship Conference BUDSC22 keynote 1 
#BUDSC22 Keynotes Keynote: Lauren Klein “Data Feminism and Digital Scholarship“ Authors 
Lauren Klein, Emory University Start Date 18-10-2022 11:00 AM End Date 18-10-2022 12:30 
PM Related Description An opening Keynote presentation by Lauren Klein introduced by Evan 
Peck. Lauren Klein is Winship Distinguished Research Professor and Associate Professor 
in the departments of English and Quantitative Theory & Methods at Emory University…"
Lauren Frederica Klein,Denmark's' techplomacy'efforts should confront inequalities,2021,https://policycommons.net/artifacts/1850299/denmarks-techplomacy-efforts-should-confront-inequalities/2597117/,"Denmark’s efforts of technological diplomacy must move past priorities that are beyond its sphere of influence. Instead, a single priority should flow through its work over the coming years: addressing inequalities exacerbated by emerging tech and Silicon Valley giants."
Lauren Frederica Klein,"Whitney Battle-Baptiste and Britt Rusert, eds. WEB Du Bois's Data Portraits: Visualizing Black America.",2020,https://scholar.google.com/scholar?cluster=8772249990790309967&hl=en&oi=scholarr,"On October 4, 1899, lawyer and educator Thomas J. Calloway penned a letter to over one hundred prominent black citizens across the United States, enlisting their support in advocating for a"" well selected and prepared exhibit"" to be shown at the 1900 Exposition Universelle, which was scheduled to open in Paris in several months' time. It would take several weeks for the letters of support to arrive, and several more weeks to obtain a funding commitment from President William McKinley. But time was already running short, so Calloway turned to WEB Du Bois, a Fisk University classmate, for help in assembling the books, photographs, charts, and other artifacts that would come to constitute the American Negro Exhibit. The exhibit opened on April 14, 1900 and ran for six months. It was seen by many of the more than fifty million people who attended the Paris Exposition, as the event is more commonly known today …"
Kevin McAlister,Measuring election frauds,2022,http://websites.umich.edu/~wmebane/measfrauds.pdf,"A measurement model called eforensics produces valid estimates of the incidence and magnitude of election frauds, using as input aggregation unit counts of eligible voters and of votes for the ballot alternatives. While valid, the estimates are imperfect: eforensics cannot detect procedural defects, measures only frauds that benefit one alternative and is sensitive to things—particularly elector strategic behavior and election administration weaknesses—not produced by the kinds of malevolent distortions of elector intentions that constitute genuine frauds. eforensics parameters support distinguishing results of malevolent distortions from results of strategic behavior. We use 32 real elections to demonstrate that eforensics measures the magnitude of election frauds at aggregation units such as polling stations, precincts or ballot boxes."
Kevin McAlister,Disagreement and Dimensionality: A Varying Dimensions Approach to Roll Call Scaling in the US Congress,2021,http://www.kevinmcalister.org/uploads/1/2/0/2/120250241/bpirt_draft_version.pdf,"Studies of legislative behavior focus upon the relationship between legislative preferences, institutional structure, and legislative outcomes. A common method used to better understand these relationships utilizes scaling models that uncover the ideal points of legislators. While there are many approaches to uncovering the ideal points of legislators, by far the most common approach uses the outcomes from the various roll call votes that are cast by members of Congress. Roll call scaling techniques such as NOMINATE (Poole and Rosenthal 1997) and its Bayesian analogue (Clinton et al. 2004) seek to project roll call data into a low-dimensional policy space that captures the complexities of how members of Congress make vote decisions. The ideal points can then be used to make comparisons of various behaviors between different members of the legislatures, such as the role of parties (Aldrich and Rohde 2000; Cox and Poole 2002; Cox and McCubbins 2005), influences within and between branches of the US government (Binder 1999; Krehbiel 1998), and other features of the legislative institution. 1Ideal point models require assumptions that have implications for the interpretation of the estimated quantities. One such assumption is the dimensionality of the latent space. Assuming a unidimensional ideal point, legislators behave predictably and rational choice models can provide simple explanations of how legislators make policy proposals and vote choices under the rules of the institution (Krehbiel 1998; Cox and McCubbins 2005). On the other hand, multidimensional ideal points create an environment where legislators behave in a more …"
Kevin McAlister,Essays on Latent Variable Models and Roll Call Scaling,2020,https://deepblue.lib.umich.edu/handle/2027.42/163023,"This dissertation comprises three essays on latent variable models and Bayesian statistical methods for the study of American legislative institutions and the more general problems of measurement and model comparison.  In the first paper, I explore the dimensionality of latent variables in the context of roll call scaling.  The dimensionality of ideal points is an aspect of roll call scaling which has received significant attention due to its impact on both substantive and spatial interpretations of estimates.  I find that previous evidence for unidimensional ideal points is a product of the Scree procedure.  I propose a new varying dimensions model of legislative voting and a corresponding Bayesian nonparametric estimation procedure (BPIRT) that allows for probabilistic inference on the number of dimensions.  Using this approach, I show that there is strong evidence for multidimensional ideal points in the U.S. Congress and that using only a single dimension misses much of the disagreement that occurs within parties.  I reexamine theories of U.S. legislative voting and find that empirical evidence for these models is conditional on unidimensionality.  In the second paper, I expand on the varying dimensions model of legislative voting and explore the role of group dependencies in legislative voting.  Assumptions about independence of observations in the scaling model ignore the possibility that members of the voting body have shared incentives to vote as a group and lead to problems in estimating ideal points and corresponding latent dimensions.  I propose a new ideal point model, clustered beta process IRT (C-BPIRT), that explicitly allows for group …"
Kevin McAlister,The Multiplicity of Factions: Multi-Dimensional Ideal Points for Interest Groups & Members of Congress,2023,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4388918,"America’s two-party system and related political institutions generally collapse conflict toward a single left-right dimension. While previous work underscored how such forces belie actual latent disagreement across multiple preference dimensions, more recent methodological improvements and new data allow for greater analysis of both the optimal number of dimensions as well as the ideal points of individual actors on each dimension. We apply these methods to a dataset of legislators’ roll-call votes and interest groups’ publicly-observable positions on bills. Doing so demonstrates that in addition to the classic left vs. right dimension, American national political conflict is optimally-characterized by dimensions concerning agriculture, conservation and development, and industry versus privacy. Characterizing these dimensions and the actors that exemplify them informs speculation about potential latent factions in American politics that might be “released” if American political institutions were reformed to better encourage multiparty-ism"
Kevin McAlister,Ordered Bayesian Aldrich-McKelvey Scaling: Improving Bias Correction on the Liberal-Conservative Scale,2022,http://www.kevinmcalister.org/uploads/1/2/0/2/120250241/ordered_bayesian_aldrich_mckelvey_scaling__improving_bias_correction_on_the_liberal_conservative_scale______ecikanek_umich_edu__2018_12_03t19_24_17_80__2_.pdf,"AIMWhile a majority of the mass public is found to have an inconsistent understanding of ideology (Converse 1964; Kinder and Kalmoe 2017), ideology is still a prominent variable in political science research. Ideology has been linked to elite polarization, which some"
B Pablo Montagnes,Lobbyists as gatekeepers: Theory and evidence,2023,https://www.journals.uchicago.edu/doi/abs/10.1086/723026,"Lobbyists are omnipresent in the policy-making process, but the value that they bring to both clients and politicians remains poorly understood. We develop a model in which a lobbyist’s value derives from his ability to selectively screen which clients he brings to a politician, thereby earning the politician’s trust and preferential treatment for his clients. Lobbyists face a dilemma, as their ability to screen also increases their value to special interests and the prices they can charge. A lobbyist’s profit motive undermines his ability to solve this dilemma, but an interest in policy outcomes—due to either a political ideology or a personal connection—enhances it, which paradoxically increases his profits. Using a unique data set from reports mandated by the Foreign Agents Registration Act, we find that lobbyists become more selective when they are more ideologically aligned with politicians, consistent with our prediction."
B Pablo Montagnes,Critical success factors for routine immunization performance: A case study of Zambia 2000 to 2018,2022,https://www.sciencedirect.com/science/article/pii/S2590136222000262,"The essential components of a vaccine delivery system are well-documented, but robust evidence on how and why the related processes and implementation strategies prove effective at driving coverage is not well-established. To address this gap, we identified critical success factors associated with advancing key policies and programs that may have led to the substantial changes in routine childhood immunization coverage in Zambia between 2000 and 2018.We identified Zambia as an exemplar in the delivery of childhood vaccines through analysis of DTP1 and DTP3 coverage data. Through interviews and focus group discussions at the national and subnational levels, we investigated factors that contributed to high and sustained vaccination coverage. We conducted a thematic analysis through application of implementation science frameworks to determine critical success factors. We …"
B Pablo Montagnes,Critical success factors for high routine immunization performance: A case study of Senegal,2023,https://www.sciencedirect.com/science/article/pii/S2590136223000372,"The essential components of a vaccine delivery system are well-documented, but robust evidence is lacking on how policies and implementation strategies are operationalized to drive catalytic improvements in coverage. To address this gap, we identified success factors that supported improvements in routine immunization coverage in Senegal, especially from 2000 to 2019.We identified Senegal as an exemplar in the delivery of childhood vaccines through analysis of DTP1 and DTP3 coverage data. Through interviews and focus group discussions at the national, regional, district, health facility, and community-level, we investigated factors that contributed to high and sustained vaccination coverage. We conducted a thematic analysis through application of implementation science frameworks to determine critical success factors. We triangulated these findings with quantitative analyses using …"
B Pablo Montagnes,Critical success factors for high routine immunization performance: A case study of Nepal,2022,https://www.sciencedirect.com/science/article/pii/S2590136222000742,"IntroductionThe essential components of a vaccine delivery system are well-documented, but robust evidence on how and why the related processes and implementation strategies drive catalytic improvements in vaccination coverage are not well established. To address this gap, we identified critical success factors that may have led to substantial improvements in routine childhood immunization coverage in Nepal from 2000 through 2019.MethodsWe identified Nepal as an exemplar in the delivery of early childhood immunization through analysis of DTP1 and DTP3 coverage data. Through interviews and focus group discussions at the national, regional, district, health post, and community level, we investigated factors that contributed to high and sustained vaccine coverage. We conducted a thematic analysis through application of implementation science frameworks to determine critical success factors. We …"
B Pablo Montagnes,Politics from the bench? Ideology and strategic voting in the US Supreme Court,2022,https://www.sciencedirect.com/science/article/pii/S0047272722001281,"In the United States, Supreme Court justices often vote along ideological lines. Why this is the case remains incompletely understood. To learn more about justices’ preferences and the nature of decision-making in the Court, we differentiate between votes that were pivotal and those that were not. We find that in situations in which a justice is pivotal, her ideology is even more predictive of her vote than usual, especially when her choice matters for unambiguously establishing legal precedent. To interpret this previously unknown pattern in the data, we develop a model of voting in which justices have both expressive and instrumental preferences. That is, the justices strategically trade off which litigant should prevail based on the merits of a case with their desire to shape precedent."
B Pablo Montagnes,Stable Matching on the Job? Theory and Evidence on Internal Talent Markets,2024,,
B Pablo Montagnes,Distinguishing between false positives and genuine results: the case of irrelevant events and elections,2023,https://www.journals.uchicago.edu/doi/abs/10.1086/719636,"Graham et al.  attempt to reassess previous findings on the electoral effects of droughts, floods, tornadoes, and college football games. Reassessing previous findings by collecting new data, implementing new specifications, and preregistering these efforts is a valuable exercise, and we hope future researchers build on this model. This practice could be even more productive if researchers present independent evidence and think about how their various tests distinguish between different possibilities. We focus our discussion on the purported effect of college football games on elections in the United States. Although Graham et al. state that their results support the conclusion that college football games affect elections, we show why the new evidence they offer should decrease our beliefs that there is a genuine, substantively meaningful effect."
B Pablo Montagnes,Priming self-reported partisanship: implications for survey design and analysis,2022,https://academic.oup.com/poq/article-abstract/86/3/643/6706811,"Can features of surveys, such as question ordering and informational stimuli, affect respondent self-reported partisanship? We report the results of two studies to examine how the survey environment affects the probability that a respondent identifies with a particular party and presidential approval conditional on self-reported partisanship. In an original experiment, we find that, under some circumstances, a question-ordering treatment increases Republican partisanship. The estimated effects are statistically different from zero in unweighted specifications where leaners are excluded from the definition of Republicans and also among respondents who identified as Republicans in previous survey waves. In our second study, we show that an informational intervention reduces the probability that a respondent identifies as an Independent and that including post-treatment partisanship in a regression changes the …"
B Pablo Montagnes,How Well Do Voting Choice Policies Represent Public and Investor Preferences?,2024,https://www.wallis.rochester.edu/assets/pdf/conference31/mps_body.pdf,"“Voting choice policies” allow investors in mutual funds and ETFs to express their preferences on how shares are voted in corporate proxy contests. We conduct an original survey to estimate the public’s preferences on management and shareholder proposals. The survey allows us to measure how well the voting choice policies offered by asset managers agree with the preferences of survey respondents. Among the voting choice policies that are currently offered, the average US adult can only achieve a maximum agreement score of 76.7 percent and the average stock owner is only slightly better at 77 percent. We then structurally estimate the ideological locations of the survey respondents and the voting choice policies. We find that in each of the dimensions a large share of respondents are poorly represented and that there are important differences across subgroups in the quality of representation."
B Pablo Montagnes,How to Design an Internal Talent Marketplace Align company needs and employee preferences,2023,https://scholar.google.com/scholar?cluster=460937046637057096&hl=en&oi=scholarr,
B Pablo Montagnes,On the Importance of Independent Evidence: A Reply to Graham et al.,2022,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4204045,"Do college football games influence US elections? Healy, Malhotra, and Mo (2010) found that college football outcomes are correlated with election results. Fowler and Montagnes (2015) found that the estimated effects of college football games do not vary in the ways we would theoretically expect if the effect were genuine and that NFL games have no effect, suggesting that the original result was likely a chance false positive. Graham et al.(2022a) reevaluated the effect of college football games on elections by adding new data. Although the estimates weakened when a small amount of new data was added, they concluded that the evidence mostly supports the original finding. Fowler and Montagnes (2022) responded with simulations showing that the evidence in Graham et al.(2022a) is statistically consistent with the possibility that the original result was a chance false positive and statistically inconsistent with the possibility of a genuine result of the magnitude reported in the original paper. Graham et al.(2022b) have written a reply to Fowler Montagnes (2022), and as ridiculous as this all sounds, this is our reply to that reply."
B Pablo Montagnes,On the incentives to exacerbate polarization,2024,https://academic.oup.com/jleo/article-abstract/40/3/854/7227932,"An organizer seeks to extract rents from competing interests in a polarized environment. We model these interests as three potential bidders, a neutral bidder, and two bidders who are “polarized” in that they prefer the neutral bidder to win rather than the other polarized bidder. The organizer cannot commit to an optimal mechanism, but can decide which bidders to allow to participate. While greater competition is generally thought to benefit the organizer, we identify conditions under which she increases expected revenue by preventing the neutral bidder from participating, thereby increasing the willingness to pay for polarized bidders. Thus, rather than seeking to bring about compromise, organizers have an incentive to exacerbate conflict. Excluding the neutral bidder always makes the auction less efficient, but the incentive to exclude her is greatest precisely when it lowers efficiency the most. We discuss …"
B Pablo Montagnes,The Public Meeting Paradox: How NIMBY-Dominated Public Meetings Can Enable New Housing,2024,https://files.osf.io/v1/resources/gfbva/providers/osfstorage/6643d047e8eec566246beb6b?action=download&direct&version=1,"Public meetings to consider new housing proposals often feature visible and vocal opposition from neighboring residents, creating a perception that these meetings impede the growth of the housing supply contributing to inequality. We analyze a model where residents can legally challenge a developer’s housing proposal. A public meeting serves as a critical tool for developers to identify potential litigants, enabling them to adjust proposals and avoid legal action. Interestingly, developers prefer meetings dominated by opponents since it is easier to identify potentially litigious neighbors. Contrary to common belief, our findings suggest that public meetings dominated by NIMBY opponents can increase housing supply by fostering compromise projects. This challenges the prevailing conventional wisdom that unrepresentative meetings significantly restrict housing development. Our analysis instead focuses attention on the threat of litigation as the key driver of the undersupply of housing."
B Pablo Montagnes,Firm Strategy and Internal Talent Markets,2023,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4399389,"How should executives strategically allocate talent? Organizations have recently adopted talent marketplaces to address job assignment and internal mobility. We formalize the worker-to-division matching problem, in which executives match workers and divisions, and face agents' preferences as the primary constraint. Our main result is market-based assignments can benefit organizations, but only in particular settings. Internal markets fail to deliver a classic benefit of strategic management: coordination across business units. Nonetheless, markets do perform well on another managerial dimension: creating incentives for employee engagement and truthful reporting. The performance of internal talent markets thus depends on which factor is more important for the firm's strategic position. We show that this can depend on each firm’s production technology, workplace incentives, workforce preferences, turnover costs, and other business parameters."
B Pablo Montagnes,Principals Matching Agents: Applications to Organizations and Auctions,2023,https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=4398819,"We develop a principal/agent model for matching agents in two-sided assignments. A principal has preferences over all agents' assignments, and agents have privately-known preferences about their own match (but are indifferent about others'). Unhappy agents can quit, but the principal can stop agents from trading assignments and can pay targeted transfers to agents to induce retention. We show that the principal values flexibility from agents to accommodate other players' interests. The principal therefore pays each side information rent over all their productive match partners (including for pairs that are ultimately not chosen). This induces truthful revelation on all productive dimensions (on both sides), and the principal can choose her preferred allocation (given constraints). The mechanism can be interpreted as a scoring auction. We conclude by discussing applications to job assignments within organizations, and extensions to other multi-sided mechanism design problems."
Gregory Palermo,Re-Landscaping Digital Scholarship: A Computational Analysis of Digital Humanities and Writing Studies,2022,https://search.proquest.com/openview/91b7499598c9df1e7b20dfe234a85eba/1?pq-origsite=gscholar&cbl=18750&diss=y,"This dissertation theorizes and demonstrates an approach to co-citation analysis for tactically linking distinct research areas with shared values and practices, as well as for supporting citational justice. Citation metrics and their analytics can reproduce inequity in scholarly advancement and the academic publishing record by way of information retrieval. Using these same bibliometric methods like co-citation analysis, which counts and visualizes clustered networks of sources often cited together, scholars can support an ongoing project of citing interventionally to build bridges and shift the academic landscape. My project critiques the conceptual metaphors for academic fields, as well as the spatial vantage from which practitioners navigate these computational methods. I do so by recuperating the methodological literature that first introduced co-citation analysis, in which bibliometricians plot maps of co-citation …"
Gregory Palermo,An Inexhaustible (Digital) Landscape,2020,https://www.jstor.org/stable/48616949,"Those new to the Digital Humanities often find themselves keen to offer a conversion narrative, and what follows is Kelly’s:"
John Patty,Ex post review and expert policy making: When does oversight reduce accountability?,2021,https://www.journals.uchicago.edu/doi/abs/10.1086/708913,"Ex post review is a common feature of policy-making institutions. We consider an environment in which an expert agent makes a policy recommendation, which can then be accepted or rejected by an overseer whose policy goals differ from those of the agent. The theory suggests that both behavior and optimal institutional design are sensitive to several factors, including actors’ preference alignment, the importance of the policy decision, and the uncertainty about the correct policy choice. We characterize the types of situations in which ex post review creates incentives for the agent to make pathological policy choices. In these situations, ex post review can reduce accountability of the agent to overseer wishes and ultimately provide incentives to set aside review entirely. The theory also offers testable predictions about policy recommendations and the overseer’s acceptance or rejection of these recommendations."
John Patty,Designing deliberation for decentralized decisions,2024,https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12756,"I describe and analyze a model of strategic communication and deliberation in decentralized decision‐making settings. I show that, in a cheap‐talk environment, inclusion and exclusion of agents can affect the credibility of messaging between agents and, accordingly, the quality of policy decisions and overall social welfare. Somewhat surprisingly, the inclusion of agents can aid information aggregation and social welfare even when the added agents do not themselves communicate truthfully. Analogously, the results suggest an informational, social welfare–based rationale for excluding agents not only from observing policy‐relevant deliberation but also from observing the product of the communication precisely because the excluded agents possess decision‐making authority."
John Patty,Algorithmic fairness and statistical discrimination,2023,https://compass.onlinelibrary.wiley.com/doi/abs/10.1111/phc3.12891,"Algorithmic fairness is a new interdisciplinary field of study focused on how to measure whether a process, or algorithm, may unintentionally produce unfair outcomes, as well as whether or how the potential unfairness of such processes can be mitigated. Statistical discrimination describes a set of informational issues that can induce rational (i.e., Bayesian) decision‐making to lead to unfair outcomes even in the absence of discriminatory intent. In this article, we provide overviews of these two related literatures and draw connections between them. The comparison illustrates both the conflict between rationality and fairness and the importance of endogeneity (e.g., “rational expectations” and “self‐fulfilling prophecies”) in defining and pursuing fairness. Taken in concert, we argue that the two traditions suggest a value for considering new fairness notions that explicitly account for how the individual characteristics an …"
John Patty,Identity and information in organizations,2020,https://columbiapeseminar.wordpress.com/wp-content/uploads/2019/04/pattypenn.pdf,"Identity, reputation, and culture represent ways to understand why organizations with similar structures and memberships nevertheless behave differently. While a large body of work has advanced our understanding of the effects of formal institutional details such as delegation, hierarchy, transparency, and oversight on organizational behavior, less attention has been paid to informal institutional details such as shared mission, professionalism, and other bases of organizational identity. We present a theory of organizational decision-making that incorporates organizational identity in the form of “mission.” The degree to which individuals will be motivated to adopt their organization’s mission will be influenced by both the preferences of others within, and the structure of, the organization. Thus, we provide a theory of endogenous preferences within organizations that incorporates features of both formal and informal institutions."
John Patty,Working Towards Policy: A Theory of Organizational Implementation and Management,2024,https://academic.oup.com/jpart/article-abstract/34/1/53/7224952,"Much of policy-making involves prioritization—deciding not only what to do but also when—and uncertainty—not knowing exactly how the choices made will affect actual policy outcomes. I present a theory of dynamic prioritization within a hierarchical organization. The model illustrates how notions such as an agency’s performance, mission, and critical tasks are linked with details such as institutional structure and the preferences of both front-line bureaucrats and their overseers. The theory highlights some reasons why even sincere, representative policy-making decisions might appear irrational, inconsistent, or “captured” to outside observers. This is in contrast to classical “spatial models” of policy that abstract from the more quotidian details of how policy is actually made as opposed to simply being “chosen.” The theory also generates traditional comparative static-style predictions about the features of the …"
John Patty,"Ban The Box? Information, Incentives, and Statistical Discrimination",2022,https://arxiv.org/abs/2208.08348,"""Banning the Box"" refers to a policy campaign aimed at prohibiting employers from soliciting applicant information that could be used to statistically discriminate against categories of applicants (in particular, those with criminal records). In this article, we examine how the concealing or revealing of informative features about an applicant's identity affects hiring both directly and, in equilibrium, by possibly changing applicants' incentives to invest in human capital. We show that there exist situations in which an employer and an applicant are in agreement about whether to ban the box. Specifically, depending on the structure of the labor market, banning the box can be (1) Pareto dominant, (2) Pareto dominated, (3) benefit the applicant while harming the employer, or (4) benefit the employer while harming the applicant. Our results have policy implications spanning beyond employment decisions, including the use of credit checks by landlords and standardized tests in college admissions."
John Patty,Why Are Pandemics Ideological?,2021,https://www.tomclarkphd.com/s/Why_Are_Pandemics_Ideological_.pdf,"Effective governmental responses to disasters rely in part on the expertise and skills of government workers. Building and retaining expertise within the government often requires granting unelected civil servants discretion over policy-relevant decisions. We present a simple model of policy-making that captures the trade-offs faced by a policymaker when considering implementing a policy that may reduce the level of expertise within the government in the shadow of a potential disaster in the future. The model illustrates how policy motivations of an elected government might lead to governmental failure in a response to a future disaster. The model predicts that governmental failures will be more likely when the policy-maker has relatively extreme preferences, and that the failures will tend to occur in agencies where the experts’ policy preferences are opposed to those of the policy-maker."
John Patty,Strange Bedfellows: How the Need for Good Governance Shapes Budgetary Control of Bureaucracy,2023,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4676395,"Legislators can benefit from delegation to executive agencies, but they have limited tools to hold these agencies accountable. One key tool is power of the purse: control of the agency's appropriations. We present a theory that incorporates heterogeneous legislator preferences over bureaucratic activity, legislative budgetary control, and endogenous bureaucratic policy discretion to understand legislative incentives when appropriating funds to bureaucratic agencies. Our theory provides several insights: first, legislators' induced preferences over budgets are only partially determined by their policy preferences. Second, in some cases legislators who are opposed to the direction that the agency will take policy nevertheless support increased funding for that agency. Finally,"" strange bedfellows"" coalitions emerge in which legislators with competing policy preferences may nonetheless agree on their most-desired budget level for the agency."
John Patty,"Algorithms, Incentives, and Democracy",2023,https://arxiv.org/abs/2307.02319,"Classification algorithms are increasingly used in areas such as housing, credit, and law enforcement in order to make decisions affecting peoples' lives. These algorithms can change individual behavior deliberately (a fraud prediction algorithm deterring fraud) or inadvertently (content sorting algorithms spreading misinformation), and they are increasingly facing public scrutiny and regulation. Some of these regulations, like the elimination of cash bail in some states, have focused on \textit{lowering the stakes of certain classifications}. In this paper we characterize how optimal classification by an algorithm designer can affect the distribution of behavior in a population -- sometimes in surprising ways. We then look at the effect of democratizing the rewards and punishments, or stakes, to algorithmic classification to consider how a society can potentially stem (or facilitate!) predatory classification. Our results speak to questions of algorithmic fairness in settings where behavior and algorithms are interdependent, and where typical measures of fairness focusing on statistical accuracy across groups may not be appropriate."
John Patty,Algorithmic Fairness with Feedback,2023,https://arxiv.org/abs/2312.03155,"The field of algorithmic fairness has rapidly emerged over the past 15 years as algorithms have become ubiquitous in everyday lives. Algorithmic fairness traditionally considers statistical notions of fairness algorithms might satisfy in decisions based on noisy data. We first show that these are theoretically disconnected from welfare-based notions of fairness. We then discuss two individual welfare-based notions of fairness, envy freeness and prejudice freeness, and establish conditions under which they are equivalent to error rate balance and predictive parity, respectively. We discuss the implications of these findings in light of the recently discovered impossibility theorem in algorithmic fairness (Kleinberg, Mullainathan, & Raghavan (2016), Chouldechova (2017))."
John Patty,Achieving Accountability: Aligning Institutions and Behavior,2023,https://www.cambridge.org/core/services/aop-cambridge-core/content/view/37D7A66544098460F08B1AC71D6177D7/stamped-9781009168328c11_242-262.pdf/achieving_accountability_aligning_institutions_and_behavior.pdf,"Decades of scholarship have noted and explored the challenges of designing efficient institutions for democratic policy choice and implementation. My immediate goal in this chapter is to consider how some empirical features of how people evaluate alternatives and make choices interact with institutional details in organizational decision-making settings. The more general goal is to expand our positive understanding of how to structure the relationships between–and responsibilities of–elected and unelected officials in order to promote policies that serve the public interest. A simpler way to describe this is that I hope the chapter provides some new insights into how to achieve political accountability.While the theoretical literature on institutional design and the empirical literatures on individual choice and belief formation are each well-developed and active, there has been much less study to date of their intersection …"
John Patty,The Art of Modeling,2025,https://www.johnwpatty.net/wp-content/uploads/2025/01/EITM_Edited_Volume_Chapter.pdf,"In this chapter, I provide some practical advice for how to build a model. The overall message is “keep it as simple as possible.”"
John Patty,Coordination in Bureaucratic Policy-Making,2024,https://www.jennyseoyeonkim.com/uploads/1/3/8/2/138265852/kimpatty_coordinationseptember2024.pdf,"Many public policies rely on multiple agencies, raising the question of how agencies with overlapping policy responsibilities coordinate their decisions. We consider a model of coordination in which a political executive can provide subsidized coordination between two agencies and consider how this possibility affects both the agencies’ incentives and, ultimately, social welfare. Our model of subsidizing coordination is very simple: an executive can invest her own resources in a coordination protocol that the agencies can (but need not) use to align their decisions. We consider the impact of scarce attention at the agency level and demonstrate that, while coordination between the agencies is maximized by the agencies having aligned policy preferences, the fact that the executive can invest in the coordination protocol undermines these incentives."
John Patty,Paved with Partisan Intentions: The Impressive and Disheartening Validity of Cox and McCubbins’s Legislative Leviathan,2023,https://www.johnwpatty.net/wp-content/uploads/2023/11/Paved_with_Partisan_Intentions.pdf,"We expand the party cartel model (Cox and McCubbins (1993, 2005)) to incorporate the electoral environment. Our theory demonstrates how external electoral forces can affect the credibility of the majority party leadership’s use of appointments within the legislative process to maintain party loyalty. We then discuss these findings with a particular focus on the House GOP Conference since 2011, including the recent successful motion to vacate against then-Speaker Kevin McCarthy and the subsequent process ultimately electing Mike Johnson as Speaker of the 118th Congress in October, 2023."
John Patty,"Personnel, Politics, and Policy-Making",2023,https://www.nowpublishers.com/article/Details/PIP-0074,"We present a theory of bureaucratic staffing in which staffers affect bureaucratic policy-making by influencing their agency’s policy priorities. The theory offers several predictions. First, presidents should appoint higher-quality staffers to agencies with policy goals that are more distant from the president. Second, presidents should be concerned with a staffer’s ideological bias only when the staffer is either sufficiently effective or when the staffer’s bias is sufficiently similar to the agency’s. Third, presidents should appoint a staffer to an agency with policy goals that are opposed to the staffer’s own, relative to the president’s goals. Fourth, less active agencies and agencies with narrow policy missions should be less likely to receive scarce staffing resources. To our knowledge, this is the first theory of political appointments to demonstrate how agencies’ structural and process-based characteristics affect the president’s incentives when making appointments."
John Patty,Editors’ introduction to JTP issue 32(3),2020,https://journals.sagepub.com/doi/abs/10.1177/0951629820934967,"This issue contains five articles. Each of the articles deals in some way with political accountability (a theme common to much of the work we publish in the JTP these days) and, accordingly, is relevant to the current waves of political upheaval and populism around the world.In ‘When strategic uninformed abstention improves democratic accountability,’Gento Kato confronts the thorny question of when mass political participation might hinder accountability. Kato’s theory is relevant to a very active area of both empirical and theoretical research into whether, when, and how voters can protect their interests through the electoral process. A central point of Kato’s analysis is that abstention by less informed voters can improve their own (and, indeed, social) welfare, but that this possibility is conditional on the proportion of ‘purely ideological’voters for whom the quality of a given public policy is insufficient to sway their …"
Kevin Quinn,Correcting measurement error bias in conjoint survey experiments,2023,https://gking.harvard.edu/files/gking/files/conerr.pdf,"Conjoint survey designs are spreading across the social sciences due to their unusual capacity to estimate many causal effects from a single randomized experiment. Unfortunately, by their ability to mirror complicated real-world choices, these designs often generate substantial measurement error and thus bias. We replicate both the data collection and analysis from eight prominent conjoint studies, all of which closely reproduce published results, and show that a large proportion of observed variation in answers to conjoint questions is effectively random noise. We then discover a common empirical pattern in how measurement error appears in conjoint studies and, with it, introduce an easy-to-use statistical method to correct the bias."
Kevin Quinn,Measuring perceived skin color: Spillover effects and likert-type scales,2023,https://www.journals.uchicago.edu/doi/abs/10.1086/720941,"Discrimination based on skin color has been documented as a considerable problem in social science research. Most of this research relies on Likert-type ratings of skin color such as the Massey-Martin Scale (MMS). Scholars have raised questions about measurement error in such scales. We hypothesize that the coding of a person’s skin color will vary depending on the race of persons previously coded. We find that the MMS is vulnerable to spillover effects: a person’s skin is coded as darker, on average, if he is observed following a sequence of White persons than if he is observed following a sequence of Black persons. We also replicate previous work showing that Black and White coders use the scale differently. Finally, having coders cross-reference the palette at the time of coding, rather than recalling the palette from memory, fails to mitigate either race-of-coder or spillover effects."
Kevin Quinn,Partisan Panel Composition and Reliance on Earlier Opinions in the Circuit Courts,2024,https://journals.sagepub.com/doi/abs/10.1177/2755323X241240384,"Does the partisan composition of three-judge panels affect how earlier opinions are treated and thus how the law develops? Using a novel data set of Shepard's treatments for all cases decided in the U.S. courts of appeals from 1974 to 2017, we investigate three different versions of this question. First, are panels composed of three Democratic (Republican) appointees more likely to follow opinions decided by panels of three Democratic (Republican) appointees than are panels composed of three Republican (Democratic) appointees? Second, does the presence of a single out-party judge change how a panel relies on earlier decisions compared to what one would expect from a panel with homogeneous partisanship? Finally, does the size of these potential partisan effects change over time in a way that would be consistent with partisan polarization on the courts? We find that partisanship does, in fact, structure …"
Kevin Quinn,"The Revival of US Hospital Care, 2004–2019",2024,"https://journals.lww.com/lww-medicalcare/fulltext/2024/03000/the_revival_of_us_hospital_care,_2004_2019.3.aspx?context=latestarticles","Background:Between 2004 and 2019, the US hospital industry reversed the 21-year decline in its share of national health spending.Objective:To measure and explain changes in hospital utilization, cost, charges, and inpatient case mix.Data Sources:Principal sources were the American Hospital Association annual survey, the National Inpatient Sample, and the Healthcare Cost Reporting Information System. The study included all US community hospitals (n= 5141 in 2019)."
Kevin Quinn,"Twenty-first century split: Partisan, racial, and gender differences in circuit judges following earlier opinions",2023,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/byulr49&section=13,"Many researchers have studied the relationship between judges' behavior and their political party, race, or gender. Most of these studies focus on whether judges' votes in a particular set of cases are associated with the judges' party, race, or gender. 1 As we discuss in more detail in Part II, these studies have generally found1. Throughout this Article, we generally use the term"" race"" to refer to both race and ethnicity. And, as we discuss below, in determining party we look to the political party of the President who most recently appointed the judge. See infra note 42 and accompanying text. To avoid wordiness, we sometimes refer to Democratic and Republican appointees by the shorthand"" Democrats"" and"" Republicans."""
Kevin Quinn,Introduction to the Symposium: Comments on Scholarship Measuring Judicial Personality,2021,https://www.cambridge.org/core/journals/journal-of-law-and-courts/article/introduction-to-the-symposium/DC54303FEBC8EDD355020CBE4B7622C2,"This issue of the Journal of Law and Courts features articles devoted to measuring the personality traits of US Supreme Court justices. In this brief comment, I attempt to do the following. First, I briefly summarize Hall et al. (2021) and Black et al. (2021). Here I pay special attention to some of the methodological issues that give rise to the disagreement between these authors. Second, I provide some general thoughts on the enterprise of attempting to measure personality traits of US Supreme Court justices. While I am generally skeptical of the utility of such an enterprise, I could be convinced of its value. Accordingly, I attempt to lay out what a skeptic like myself would like to see in order to be convinced of the intellectual value added of work in this area."
Kevin Quinn,Online Appendix What to Observe When Assuming Selection on Observables,2024,https://epstein.wustl.edu/s/WATEAppendix.pdf,"(Yi− ˆm0 (xi))(B. 2) where ˆm1 (x) is the ordinary least squares (OLS) regression estimator of E [Y| X= x, Z= 1] constructed by subsetting the data to the Z= 1 units and fitting an OLS regression to those data and ˆm0 (x) is the OLS regression estimator of E [Y| X= x, Z= 0] constructed by subsetting the data to the Z= 0 units and fitting an OLS regression to those data. We will also consider the OLS estimator of τ in the regression y= Xβ+ zτ+ ϵ.(B. 3)"
Kevin Quinn,NOTES & COMMENTS,2023,https://digitalcommons.law.byu.edu/cgi/viewcontent.cgi?article=3473&context=lawreview,"Table of Contents Page 1 BYU Law Review Volume 49 Issue 2 Article 5 Winter 12-27-2023 
Table of Contents Follow this and additional works at: https://digitalcommons.law.byu.edu/lawreview 
Recommended Citation Table of Contents, 49 BYU L. Rev. (2023). Available at: https://digitalcommons.law.byu.edu/lawreview/vol49/iss2/5 
This Frontmatter is brought to you for free and open access by the Brigham Young 
University Law Review at BYU Law Digital Commons. It has been accepted for inclusion in 
BYU Law Review by an authorized editor of BYU Law Digital Commons. For more 
information, please contact hunterlawlibrary@byu.edu. Page 2 ETofc.49.2.FIN.docx 12/26/2023 
9:18 PM Brigham Young University Law Review VOLUME 49 NUMBER 2 ARTICLES 
Hidden Contracts Shmuel I. Becher & Uri Benoliel ........................................... 307 Twenty-First 
Century Split: Partisan, Racial, and Gender Differences in Circuit …"
Kevin Quinn,325 Measuring Political Preferences,2023,https://scholar.google.com/scholar?cluster=8039291763628559952&hl=en&oi=scholarr,"Almost all theories of judicial behaviour ascribe a key role to political preferences. The idea is that the judges want to align the law with their political commitments—whether ideological or partisan. This chapter explores strategies for measuring and estimating the judges’ political preferences. It consists of two major parts: exogenous measures of political preferences (those that are based on information causally prior to any votes cast or other choices the judges make) and endogenous measures (those that depend on revealed behaviour). The authors detail the strengths and weaknesses of the various measures, and offer suggestions for forward movement. Mostly, though, they encourage readers to keep an open mind as to the best ways to measure political preferences in their own applications."
Kevin Quinn,NOTES & COMMENTS,2023,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/byulr49&section=10,"Consumer standard form contracts-the most pervasive type of contracts-govern much of our everyday lives. 1 One enters into a standard form contract when using social media, signing up for an"
Kevin Quinn,Correcting measurement error bias in conjoint survey experiments,2023,https://gking.harvard.edu/files/gking/files/conerr.pdf,"Conjoint survey designs are spreading across the social sciences due to their unusual capacity to estimate many causal effects from a single randomized experiment. Unfortunately, by their ability to mirror complicated real-world choices, these designs often generate substantial measurement error and thus bias. We replicate both the data collection and analysis from eight prominent conjoint studies, all of which closely reproduce published results, and show that a large proportion of observed variation in answers to conjoint questions is effectively random noise. We then discover a common empirical pattern in how measurement error appears in conjoint studies and, with it, introduce an easy-to-use statistical method to correct the bias."
Kevin Quinn,Measuring perceived skin color: Spillover effects and likert-type scales,2023,https://www.journals.uchicago.edu/doi/abs/10.1086/720941,"Discrimination based on skin color has been documented as a considerable problem in social science research. Most of this research relies on Likert-type ratings of skin color such as the Massey-Martin Scale (MMS). Scholars have raised questions about measurement error in such scales. We hypothesize that the coding of a person’s skin color will vary depending on the race of persons previously coded. We find that the MMS is vulnerable to spillover effects: a person’s skin is coded as darker, on average, if he is observed following a sequence of White persons than if he is observed following a sequence of Black persons. We also replicate previous work showing that Black and White coders use the scale differently. Finally, having coders cross-reference the palette at the time of coding, rather than recalling the palette from memory, fails to mitigate either race-of-coder or spillover effects."
Kevin Quinn,Partisan Panel Composition and Reliance on Earlier Opinions in the Circuit Courts,2024,https://journals.sagepub.com/doi/abs/10.1177/2755323X241240384,"Does the partisan composition of three-judge panels affect how earlier opinions are treated and thus how the law develops? Using a novel data set of Shepard's treatments for all cases decided in the U.S. courts of appeals from 1974 to 2017, we investigate three different versions of this question. First, are panels composed of three Democratic (Republican) appointees more likely to follow opinions decided by panels of three Democratic (Republican) appointees than are panels composed of three Republican (Democratic) appointees? Second, does the presence of a single out-party judge change how a panel relies on earlier decisions compared to what one would expect from a panel with homogeneous partisanship? Finally, does the size of these potential partisan effects change over time in a way that would be consistent with partisan polarization on the courts? We find that partisanship does, in fact, structure …"
Kevin Quinn,"The Revival of US Hospital Care, 2004–2019",2024,"https://journals.lww.com/lww-medicalcare/fulltext/2024/03000/the_revival_of_us_hospital_care,_2004_2019.3.aspx?context=latestarticles","Background:Between 2004 and 2019, the US hospital industry reversed the 21-year decline in its share of national health spending.Objective:To measure and explain changes in hospital utilization, cost, charges, and inpatient case mix.Data Sources:Principal sources were the American Hospital Association annual survey, the National Inpatient Sample, and the Healthcare Cost Reporting Information System. The study included all US community hospitals (n= 5141 in 2019)."
Kevin Quinn,"Twenty-first century split: Partisan, racial, and gender differences in circuit judges following earlier opinions",2023,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/byulr49&section=13,"Many researchers have studied the relationship between judges' behavior and their political party, race, or gender. Most of these studies focus on whether judges' votes in a particular set of cases are associated with the judges' party, race, or gender. 1 As we discuss in more detail in Part II, these studies have generally found1. Throughout this Article, we generally use the term"" race"" to refer to both race and ethnicity. And, as we discuss below, in determining party we look to the political party of the President who most recently appointed the judge. See infra note 42 and accompanying text. To avoid wordiness, we sometimes refer to Democratic and Republican appointees by the shorthand"" Democrats"" and"" Republicans."""
Kevin Quinn,Introduction to the Symposium: Comments on Scholarship Measuring Judicial Personality,2021,https://www.cambridge.org/core/journals/journal-of-law-and-courts/article/introduction-to-the-symposium/DC54303FEBC8EDD355020CBE4B7622C2,"This issue of the Journal of Law and Courts features articles devoted to measuring the personality traits of US Supreme Court justices. In this brief comment, I attempt to do the following. First, I briefly summarize Hall et al. (2021) and Black et al. (2021). Here I pay special attention to some of the methodological issues that give rise to the disagreement between these authors. Second, I provide some general thoughts on the enterprise of attempting to measure personality traits of US Supreme Court justices. While I am generally skeptical of the utility of such an enterprise, I could be convinced of its value. Accordingly, I attempt to lay out what a skeptic like myself would like to see in order to be convinced of the intellectual value added of work in this area."
Kevin Quinn,Online Appendix What to Observe When Assuming Selection on Observables,2024,https://epstein.wustl.edu/s/WATEAppendix.pdf,"(Yi− ˆm0 (xi))(B. 2) where ˆm1 (x) is the ordinary least squares (OLS) regression estimator of E [Y| X= x, Z= 1] constructed by subsetting the data to the Z= 1 units and fitting an OLS regression to those data and ˆm0 (x) is the OLS regression estimator of E [Y| X= x, Z= 0] constructed by subsetting the data to the Z= 0 units and fitting an OLS regression to those data. We will also consider the OLS estimator of τ in the regression y= Xβ+ zτ+ ϵ.(B. 3)"
Kevin Quinn,NOTES & COMMENTS,2023,https://digitalcommons.law.byu.edu/cgi/viewcontent.cgi?article=3473&context=lawreview,"Table of Contents Page 1 BYU Law Review Volume 49 Issue 2 Article 5 Winter 12-27-2023 
Table of Contents Follow this and additional works at: https://digitalcommons.law.byu.edu/lawreview 
Recommended Citation Table of Contents, 49 BYU L. Rev. (2023). Available at: https://digitalcommons.law.byu.edu/lawreview/vol49/iss2/5 
This Frontmatter is brought to you for free and open access by the Brigham Young 
University Law Review at BYU Law Digital Commons. It has been accepted for inclusion in 
BYU Law Review by an authorized editor of BYU Law Digital Commons. For more 
information, please contact hunterlawlibrary@byu.edu. Page 2 ETofc.49.2.FIN.docx 12/26/2023 
9:18 PM Brigham Young University Law Review VOLUME 49 NUMBER 2 ARTICLES 
Hidden Contracts Shmuel I. Becher & Uri Benoliel ........................................... 307 Twenty-First 
Century Split: Partisan, Racial, and Gender Differences in Circuit …"
Kevin Quinn,325 Measuring Political Preferences,2023,https://scholar.google.com/scholar?cluster=8039291763628559952&hl=en&oi=scholarr,"Almost all theories of judicial behaviour ascribe a key role to political preferences. The idea is that the judges want to align the law with their political commitments—whether ideological or partisan. This chapter explores strategies for measuring and estimating the judges’ political preferences. It consists of two major parts: exogenous measures of political preferences (those that are based on information causally prior to any votes cast or other choices the judges make) and endogenous measures (those that depend on revealed behaviour). The authors detail the strengths and weaknesses of the various measures, and offer suggestions for forward movement. Mostly, though, they encourage readers to keep an open mind as to the best ways to measure political preferences in their own applications."
Kevin Quinn,NOTES & COMMENTS,2023,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/byulr49&section=10,"Consumer standard form contracts-the most pervasive type of contracts-govern much of our everyday lives. 1 One enters into a standard form contract when using social media, signing up for an"
Kevin Quinn,A multidimensional pairwise comparison model for heterogeneous perceptions with an application to modelling the perceived truthfulness of public statements on COVID‐19,2022,https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssa.12810,"Pairwise comparison models are an important type of latent attribute measurement model with broad applications in the social and behavioural sciences. Current pairwise comparison models are typically unidimensional. The existing multidimensional pairwise comparison models tend to be difficult to interpret and they are unable to identify groups of raters that share the same rater‐specific parameters. To fill this gap, we propose a new multidimensional pairwise comparison model with enhanced interpretability which explicitly models how object attributes on different dimensions are differentially perceived by raters. Moreover, we add a Dirichlet process prior on rater‐specific parameters which allows us to flexibly cluster raters into groups with similar perceptual orientations. We conduct simulation studies to show that the new model is able to recover the true latent variable values from the observed binary choice …"
Kevin Quinn,Brief of Empirical Scholars as Amici Curiae in Support of Respondents,2022,https://gking.harvard.edu/node/692515,Amici curiae are leaders in the field of quantitative social science and statistical methodology. Amici submit this brief to point out the substantial methodological flaws in the “mismatch” research discussed in the Brief for Richard Sander as Amicus Curiae in Support of Petitioner. Professor Sander’s mismatch hypothesis is unsupported and based on work that fails to adhere to basic tenets of research design.
Kevin Quinn,COMMENTS ON SCHOLARSHIP MEASURING JUDICIAL PERSONALITY,2021,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/jlawct9&section=20,"This issue of the Journal ofLaw and Courts features articles devoted to measuring the personality traits of US Supreme Court justices. In this brief comment, I attempt to do the following. First, I briefly summarize Hall et al.(2021) and Black et al.(2021). Here I pay special attention to some of the methodological issues that give rise to the disagreement between these authors. Second, I provide some general thoughts on the enterprise of attempting to measure personality traits of US Supreme Court justices. While I am generally skeptical of the utility of such an enterprise, I could be convinced of its value. Accordingly, I attempt to lay out what a skeptic like myself would like to see in order to be convinced of the intellectual value added of work in this area.This issue of the Journal of Law and Courts features two articles devoted to measuring the personality traits of US Supreme Court justices, as well as a response from the …"
Kevin Quinn,SOUTHERN CALIFORNIA LAW REVIEW,2020,https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/scal93&section=22,"Popular media coverage about artificial intelligence("" Al"")'often makes it sound as though the technology itself is an autonomous actor. It's easy to understand the urge to anthropomorphize Al: sometimes, the results of algorithmic research are altogether different from what the data scientists who created the algorithm expected in ways that suggest algorithmic autonomy. 2 Consider, for instance, an algorithm that was told to sort data. Like Amelia Bedelia, the software took this directive a bit too literally and deleted all the data fed to it, apparently on the theory that data that did not exist could not be considered unsorted."
Alejandro Sanchez Becerra,Identifying causal effects in experiments with social interactions and non-compliance,2021,https://ora.ox.ac.uk/objects/uuid:a9556699-546c-4df2-ae47-cbde6388e370,"This paper shows how to use a randomized saturation experimental design to identify and estimate causal effects in the presence of social interactions—one person’s treatment may affect another’s outcome–and one-sided non-compliance–subjects can only be offered treatment, not compelled to take it up. Two distinct causal effects are of interest in this setting: direct effects quantify how a person’s own treatment changes her outcome, while indirect effects quantify how her peers’ treatments change her outcome. We consider the case in which social interactions occur only within known groups, and take-up decisions do not depend on peers’ offers. In this setting we point identify local average treatment effects, both direct and indirect, in a flexible random coefficients model that allows for both heterogenous treatment effects and endogeneous selection into treatment. We go on to propose a feasible, kernel-based estimator."
Alejandro Sanchez Becerra,"The Network Propensity Score: Spillovers, Homophily, and Selection into Treatment",2022,https://arxiv.org/abs/2209.14391,"I establish primitive conditions for unconfoundedness in a coherent model that features heterogeneous treatment effects, spillovers, selection-on-observables, and network formation. I identify average partial effects under minimal exchangeability conditions. If social interactions are also anonymous, I derive a three-dimensional network propensity score, characterize its support conditions, relate it to recent work on network pseudo-metrics, and study extensions. I propose a two-step semiparametric estimator for a random coefficients model which is consistent and asymptotically normal as the number and size of the networks grows. I apply my estimator to a political participation intervention Uganda and a microfinance application in India."
Alejandro Sanchez Becerra,Robust inference for the treatment effect variance in experiments using machine learning,2023,https://arxiv.org/abs/2306.03363,"Experimenters often collect baseline data to study heterogeneity. I propose the first valid confidence intervals for the VCATE, the treatment effect variance explained by observables. Conventional approaches yield incorrect coverage when the VCATE is zero. As a result, practitioners could be prone to detect heterogeneity even when none exists. The reason why coverage worsens at the boundary is that all efficient estimators have a locally-degenerate influence function and may not be asymptotically normal. I solve the problem for a broad class of multistep estimators with a predictive first stage. My confidence intervals account for higher-order terms in the limiting distribution and are fast to compute. I also find new connections between the VCATE and the problem of deciding whom to treat. The gains of targeting treatment are (sharply) bounded by half the square root of the VCATE. Finally, I document excellent performance in simulation and reanalyze an experiment from Malawi."
Alejandro Sanchez Becerra,How to Weight in Moments Matching: A New Approach and Applications to Earnings Dynamics,2023,https://www.sas.upenn.edu/~asheph/files/papers/Cheng-Sanchez-Shephard_Weighting.pdf,"Following the seminal paper by Altonji and Segal (1996), empirical studies have widely embraced equal or diagonal weighting in minimum distance estimation to mitigate the finite-sample bias caused by sampling errors in the weighting matrix. This paper introduces a new weighting scheme that combines cross-fitting and regularized weighting matrix estimation. We also provide a new cross-fitting standard error, applying cross-fitting to estimate the asymptotic variance. In a many-moment asymptotic framework, we demonstrate the effectiveness of cross-fitting in eliminating a first-order asymptotic bias due to weighting matrix sampling errors. Additionally, we demonstrate that some economic models in the earnings dynamics literature meet certain sparsity conditions, ensuring that the proposed regularized weighting matrix behaves similarly to the oracle weighting matrix for these applications. Extensive simulation studies based on the earnings dynamics literature validate the superiority of our approach over commonly employed alternative weighting schemes."
Alejandro Sanchez Becerra,How to weight in moments matchings: A new approach and applications to earnings dynamics,2023,https://www.econstor.eu/handle/10419/284137,"Following the seminal paper by Altonji and Segal (1996), empirical studies have widely embraced equal or diagonal weighting in minimum distance estimation to mitigate the finite-sample bias caused by sampling errors in the weighting matrix. This paper introduces a new weighting scheme that combines cross-fitting and regularized weighting matrix estimation. We also provide a new cross-fitting standard error, applying cross-fitting to estimate the asymptotic variance. In a many-moment asymptotic framework, we demonstrate the effectiveness of cross-fitting in eliminating a first-order asymptotic bias due to weighting matrix sampling errors. Additionally, we demonstrate that some economic models in the earnings dynamics literature meet certain sparsity conditions, ensuring that the proposed regularized weighting matrix behaves similarly to the oracle weighting matrix for these applications. Extensive simulation studies based on the earnings dynamics literature validate the superiority of our approach over commonly employed alternative weighting schemes."
Alejandro Sanchez Becerra,Bounds for within-household encouragement designs with interference,2025,https://arxiv.org/abs/2503.14314,"We obtain partial identification of direct and spillover effects in settings with strategic interaction and discrete treatments, outcome and independent instruments. We consider a framework with two decision-makers who play pure-strategy Nash equilibria in treatment take-up, whose outcomes are determined by their joint take-up decisions. We obtain a latent-type representation at the pair level. We enumerate all types that are consistent with pure-strategy Nash equilibria and exclusion restrictions, and then impose conditions such as symmetry, strategic complementarity/substitution, several notions of monotonicity, and homogeneity. Under any combination of the above restrictions, we provide sharp bounds for our parameters of interest via a simple Python optimization routine. Our framework allows the empirical researcher to tailor the above menu of assumptions to their empirical application and to assess their individual and joint identifying power."
Sandeep Soni,Racism is a virus: Anti-Asian hate and counterspeech in social media during the COVID-19 crisis,2021,https://dl.acm.org/doi/abs/10.1145/3487351.3488324,"The spread of COVID-19 has sparked racism and hate on social media targeted towards Asian communities. However, little is known about how racial hate spreads during a pandemic and the role of counterspeech in mitigating this spread. In this work, we study the evolution and spread of anti-Asian hate speech through the lens of Twitter. We create COVID-HATE, the largest dataset of anti-Asian hate and counterspeech spanning 14 months, containing over 206 million tweets, and a social network with over 127 million nodes. By creating a novel hand-labeled dataset of 3,355 tweets, we train a text classifier to identify hateful and counterspeech tweets that achieves an average macro-F1 score of 0.832. Using this dataset, we conduct longitudinal analysis of tweets and users. Analysis of the social network reveals that hateful and counterspeech users interact and engage extensively with one another, instead of living …"
Sandeep Soni,"Speak, memory: An archaeology of books known to chatgpt/gpt-4",2023,https://arxiv.org/abs/2305.00118,"In this work, we carry out a data archaeology to infer books that are known to ChatGPT and GPT-4 using a name cloze membership inference query. We find that OpenAI models have memorized a wide collection of copyrighted materials, and that the degree of memorization is tied to the frequency with which passages of those books appear on the web. The ability of these models to memorize an unknown set of books complicates assessments of measurement validity for cultural analytics by contaminating test data; we show that models perform much better on memorized books than on non-memorized books for downstream tasks. We argue that this supports a case for open models whose training data is known."
Sandeep Soni,Abolitionist networks: Modeling language change in nineteenth-century activist newspapers,2021,https://arxiv.org/abs/2103.07538,"The abolitionist movement of the nineteenth-century United States remains among the most significant social and political movements in US history. Abolitionist newspapers played a crucial role in spreading information and shaping public opinion around a range of issues relating to the abolition of slavery. These newspapers also serve as a primary source of information about the movement for scholars today, resulting in powerful new accounts of the movement and its leaders. This paper supplements recent qualitative work on the role of women in abolition's vanguard, as well as the role of the Black press, with a quantitative text modeling approach. Using diachronic word embeddings, we identify which newspapers tended to lead lexical semantic innovations -- the introduction of new usages of specific words -- and which newspapers tended to follow. We then aggregate the evidence across hundreds of changes into a weighted network with the newspapers as nodes; directed edge weights represent the frequency with which each newspaper led the other in the adoption of a lexical semantic change. Analysis of this network reveals pathways of lexical semantic influence, distinguishing leaders from followers, as well as others who stood apart from the semantic changes that swept through this period. More specifically, we find that two newspapers edited by women -- THE PROVINCIAL FREEMAN and THE LILY -- led a large number of semantic changes in our corpus, lending additional credence to the argument that a multiracial coalition of women led the abolitionist movement in terms of both thought and action. It also contributes additional …"
Sandeep Soni,Follow the leader: Documents on the leading edge of semantic change get more citations,2021,https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.24421,"Diachronic word embeddings—vector representations of words over time—offer remarkable insights into the evolution of language and provide a tool for quantifying sociocultural change from text documents. Prior work has used such embeddings to identify shifts in the meaning of individual words. However, simply knowing that a word has changed in meaning is insufficient to identify the instances of word usage that convey the historical meaning or the newer meaning. In this study, we link diachronic word embeddings to documents, by situating those documents as leaders or laggards with respect to ongoing semantic changes. Specifically, we propose a novel method to quantify the degree of semantic progressiveness in each word usage, and then show how these usages can be aggregated to obtain scores for each document. We analyze two large collections of documents, representing legal opinions and …"
Sandeep Soni,"Linguistic characterization of divisive topics online: case studies on contentiousness in abortion, climate change, and gun control",2022,https://ojs.aaai.org/index.php/ICWSM/article/view/19270,"As public discourse continues to move and grow online, conversations about divisive topics on social media plat-forms have also increased. These divisive topics prompt both contentious and non-contentious conversations. Although what distinguishes these conversations, often framed as what makes these conversations contentious, is known in broad strokes, much less is known about the linguistic signature of these conversations. Prior work has shown that contentious content and structure can be a predictor for this task, however, most of them have been focused on conversation in general, very specific events, or complex structural analysis. Additionally, many models used in prior work have lacked interpretability, a key factor in online moderation. Our work fills these gaps by focusing on conversations from highly divisive topics (abortion, climate change, and gun control), operationalizing a set of novel linguistic and conversational characteristics and user factors, and incorporating them to build interpretable models. We demonstrate that such characteristics can largely improve the performance of prediction on this task, and also enable nuanced interpretability. Our case studies on these three contentious topics suggest that certain generic linguistic characteristics are highly correlated with contentiousness in conversations while others demonstrate significant contextual influences on specific divisive topics."
Sandeep Soni,Grounding characters and places in narrative texts,2023,https://arxiv.org/abs/2305.17561,"Tracking characters and locations throughout a story can help improve the understanding of its plot structure. Prior research has analyzed characters and locations from text independently without grounding characters to their locations in narrative time. Here, we address this gap by proposing a new spatial relationship categorization task. The objective of the task is to assign a spatial relationship category for every character and location co-mention within a window of text, taking into consideration linguistic context, narrative tense, and temporal scope. To this end, we annotate spatial relationships in approximately 2500 book excerpts and train a model using contextual embeddings as features to predict these relationships. When applied to a set of books, this model allows us to test several hypotheses on mobility and domestic space, revealing that protagonists are more mobile than non-central characters and that women as characters tend to occupy more interior space than men. Overall, our work is the first step towards joint modeling and analysis of characters and places in narrative text."
Sandeep Soni,Small Worlds: Measuring the Mobility of Characters in English-Language Fiction,2024,https://jcls.io/article/id/3917/,"The representation of mobility in literary narratives has important implications for the cultural understanding of human movement and migration. In this paper, we introduce novel methods for measuring the physical mobility of literary characters through narrative space and time. We capture mobility through geographically defined space, as well as through generic locations such as homes, driveways, and forests. Using a dataset of over 13,000 books published in English since 1789, we observe significantsmall world'effects in fictional narratives. Specifically, we find that fictional characters cover far less distance than their nonfictional counterparts; the pathways covered by fictional characters are highly formulaic and limited from a global perspective; and fiction exhibits a distinctive semantic investment in domestic and private places. Surprisingly, we do not find that characters' ascribed gender has a statistically significant effect on distance traveled, but it does influence the semantics of domesticity."
Sandeep Soni,Predicting long-term citations from short-term linguistic influence,2022,https://arxiv.org/abs/2210.13628,"A standard measure of the influence of a research paper is the number of times it is cited. However, papers may be cited for many reasons, and citation count offers limited information about the extent to which a paper affected the content of subsequent publications. We therefore propose a novel method to quantify linguistic influence in timestamped document collections. There are two main steps: first, identify lexical and semantic changes using contextual embeddings and word frequencies; second, aggregate information about these changes into per-document influence scores by estimating a high-dimensional Hawkes process with a low-rank parameter matrix. We show that this measure of linguistic influence is predictive of  citations: the estimate of linguistic influence from the two years after a paper's publication is correlated with and predictive of its citation count in the following three years. This is demonstrated using an online evaluation with incremental temporal training/test splits, in comparison with a strong baseline that includes predictors for initial citation counts, topics, and lexical features."
Sandeep Soni,Words and Action: Modeling Linguistic Leadership in# BlackLivesMatter Communities,2024,https://arxiv.org/abs/2412.02637,"In this project, we describe a method of modeling semantic leadership across a set of communities associated with the #BlackLivesMatter movement, which has been informed by qualitative research on the structure of social media and Black Twitter in particular. We describe our bespoke approaches to time-binning, community clustering, and connecting communities over time, as well as our adaptation of state-of-the-art approaches to semantic change detection and semantic leadership induction. We find substantial evidence of the leadership role of BLM activists and progressives, as well as Black celebrities. We also find evidence of the sustained engagement of the conservative community with this discourse, suggesting an alternative explanation for how we arrived at the present moment, in which ""anti-woke"" and ""anti-CRT"" bills are being enacted nationwide."
Sandeep Soni,MODELING THE LEADERSHIP OF LANGUAGE CHANGE FROM DIACHRONIC TEXT,2021,https://core.ac.uk/download/pdf/541055622.pdf,"When I started working towards this thesis, I could not believe my luck of being in a fully funded PhD program at a premier US university with the opportunity to do interdisciplinary research. There are so many to thank for making this thesis possible in the first place and then helping it take shape.A huge behind-the-scenes effort is required to help any student focus on research—my case is no different. I want to start by acknowledging the work of Jessica Celestine, Renee Jamieson, Tina Charest, Danielle Shenise, and Becky Wilson. They were responsible for handling several queries ranging from admissions to visa approvals, from travel reimbursements to getting teaching assistantships, and many others that I don’t remember now. The school of interactive computing has been a smooth working machine because of the labor of these women which should not go unnoticed. A special thanks also to Gregory Abowd who was the PhD coordinator when I started in the program. Gregory conducted a series of seminars that were highly informative and reassuring as I took baby steps in PhD research. I’m also very grateful to Rosa Arriaga, who later became the PhD coordinator, for her earnest efforts to check my progress without putting too much pressure; the fact that she did this for all the students in the chaos caused due to the pandemic is really remarkable."
Allison Stashko,Do Police Maximize Arrests or Minimize Crime? Evidence from Racial Profiling in U.S. Cities,2022,https://academic.oup.com/jeea/article-abstract/21/1/167/6632967,"It is difficult to identify sources of discrimination in police stop and search data. In part, this is due to uncertainty over the objective of discretionary police stops: Do officers aim to maximize arrests or to minimize crime? In this paper, I compare theoretical predictions implied by these two objectives to data from U.S. cities. Empirical evidence is consistent with a model of arrest maximization and inconsistent with a model of crime minimization. The findings support the validity of existing tests for discrimination that rely on the assumption that police officers maximize arrests."
Allison Stashko,Crossing the district line: Border mismatch and targeted redistribution,2020,https://extranet.sioe.org/uploads/sioe2020/stashko.pdf,"Electoral district borders regularly cross the borders of local governments. At the same time, legislatures allocate resources using transfers to local governments. Political parties may try to target these transfers in order to win elections, but can only do so imperfectly because of border mismatch. This border mismatch creates inequality: otherwise similar local governments receive different transfers depending on the district map. To show this, I incorporate border mismatch into a model of political competition and test the predictions using data on transfers from US states to counties. The results demonstrate a novel link between redistricting and voter welfare."
Allison Stashko,Polling Place Location and the Costs of Voting,2022,https://jmargitic.github.io/JM/Margitic_JMP.pdf,"Surprisingly little is known about the location of polling places across the United States and their effect on turnout. To fill this gap, we acquire voter registration data, voting history data, and polling locations for over 15 million voters from Pennsylvania and Georgia. Using a precinct border discontinuity design, we find small average effects of a voter’s distance to the polling place on turnout, but considerable heterogeneity. A one mile increase in distance to polling place decreases the likelihood of voting by up to 1.2 pp, but by up to 27.6 pp in areas where eligible voters rely on public transportation to go to work. The availability of no excuse vote by mail may help to substantially attenuate the reduction in turnout caused by distance to the polling place."
Allison Stashko,Pack-Crack-Pack: Gerrymandering with Differential Turnout,2023,https://www.nber.org/papers/w31442,"This paper studies the manipulation of electoral maps by political parties, known as gerrymandering. At the core of our analysis is the recognition that districts must have the same population size but only voters matter for electoral outcomes. We propose a model of gerrymandering that allows for heterogeneity in turnout rates across individuals. We show how this modifies the gerrymandering strategies: the novel pattern is to pack-crack-pack along the turnout dimension. That is, parties benefit from packing their supporters when they have too low turnout rate as well as their opponents when they have too high turnout rate. In between, they create cracked districts that mix moderate-to-high-turnout supporters with lower-turnout opponents. This produces testable empirical implications about the link between partisan support, turnout rates, and electoral maps. Using a novel empirical strategy that relies on the comparison of maps proposed by Democrats and Republicans during the 2020 redistricting cycle in the US, we bring such empirical implications to the data and find support for them."
Allison Stashko,Prosecutor Elections and Police Accountability,2021,https://marriner-wpmedia.s3.us-west-2.amazonaws.com/wp-content/uploads/2021/05/district_attorney_paper.pdf,"Prosecutors play an important role in holding police accountable by determining whether or not an officer has broken the law. At the same time, prosecutors and police officers work together closely, raising concern over conflicts of interest. We study the effect of prosecutor turnover on the number of deaths caused by police officers. Using data from 2,315 district attorney elections in the United States, we find that the election of a new district attorney leads to a 17% reduction in the number of deaths caused by police officers. For close elections, deaths decrease by 40%(0.3 fewer deaths per year) after a new district attorney ousts an incumbent. We observe no corresponding changes in crime, arrests, assaults on police officers, or deaths of police officers. The effects are significant regardless of the political party of the newly elected district attorney. We find suggestive evidence in favor of increased police accountability and uncertainty about the district attorney’s type as mechanisms.* Email: allison. stashko@ eccles. utah. edu (Corresponding author); haritz. garro@ gmail. com. Stashko is an assistant professor at the David Eccles School of Business, University of Utah. Garro was a postdoctoral fellow in the Democracy and Polarization lab at Stanford University while working on this project. The authors thank Aurelie Ouss and seminar participants at the University of Utah, Berkeley Haas, and the Economics of Crime seminar for useful comments and suggestions."
Joseph L. Sutherland,Keeping your mouth shut: Spiraling self-censorship in the United States,2023,https://academic.oup.com/psq/article-abstract/138/3/361/7192889,"Over the period from the heyday of McCarthyism to the present, the percentage of the American people not feeling free to express their views has tripled. In 2020, more than four in ten people engaged in self-censorship. Our analyses of over-time and cross-sectional variability suggest that, first, self-censorship is connected to affective polarization among the mass public, with greater polarization associated with more self-censorship. Second, levels of mass opposition to full civil liberties bear no relationship to self-censorship. Third, those who perceive a more repressive government are slightly more likely to self-censor. Fourth, conservatives report engaging in more self-censorship than liberals (but this is not true when comparing Republicans with Democrats). Together, these findings suggest that one's larger macro-environment may have little to do with self-censorship. Instead, micro-environment sentiments …"
Joseph L. Sutherland,The effect of gender on interruptions at congressional hearings,2023,https://www.cambridge.org/core/journals/american-political-science-review/article/effect-of-gender-on-interruptions-at-congressional-hearings/DDD33F28A1C8ED9C162E1793D8126243,"Women in Congress are highly effective legislators. Yet, if women are more likely than men to be interrupted during committee work, they may face a gender-related impediment. We examine speech patterns during more than 24,000 congressional committee hearings from 1994 to 2018 to determine whether women Members are more likely to be interrupted than men. We find that they are. This is especially true in Senate committees—where women are about 10% more likely to be interrupted. Furthermore, in hearings that discuss women’s issues, women are more than twice as likely to be interrupted than while discussing other issues. We see a similar pattern for rapid-fire “interruption clusters,” an aggressive form of interruption. We further consider a range of moderating factors, which yields little evidence that women change their communication strategy as they gain experience in Congress. We also find …"
Joseph L. Sutherland,Have state policy agendas become more nationalized?,2023,https://www.journals.uchicago.edu/doi/abs/10.1086/720792,Previous work has shown that US voters are focused on national news and national issues and that US elections have become more nationalized. We explore whether state policy agendas have become more nationalized over time. We measure the state agenda by analyzing governors’ State of the State addresses from 1960 to 2016. Our analysis shows that state agendas have become more similar to each other over time and that state agendas are more similar to the national agenda (as laid out in the State of the Union address). The nationalization of US politics is not only affecting voters and elections; it is also seen in the nationalization of the policy agenda.
Joseph L. Sutherland,The Rise of Self-Censorship in America,2024,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4671208,"This paper provides new data and analysis of the increasing trend of self-censorship among Americans from 1954 to 2023. Drawing upon a nationally representative survey, it reveals that 48% of Americans in 2023 feel less free to express their opinions, a slight increase from 46% in 2020. This trend is placed in historical context, showing a stark contrast with the 1950s, where only 13.4% felt a restriction in expressing their views despite the Red Scare's potential repercussions. The paper explores various hypotheses for this rise in self-censorship, including affective polarization and support for civil liberties. Self-censorship is connected to affective polarization among the mass public, with greater polarization associated with more self-censorship. Levels of mass opposition to full civil liberties bear no relationship to self-censorship. This study highlights the significant implications of widespread self-censorship for the health of democracy in the United States, emphasizing the need to reduce the costs of expressing dissenting views to foster a more vibrant democracy."
Joseph L. Sutherland,Encouraging Black and Latinx Radio Audiences to Register to Vote: A Field Experiment,2023,https://journals.sagepub.com/doi/abs/10.1177/1532673X231184437,"Traditional in-person voter registration drives increase voter registration rates in minority communities but became infeasible during the 2020 COVID-19 epidemic. An alternative approach is to promote registration through mass media, such as local radio. We present results from a large-scale experiment testing the effects of radio ads on voter registration. During the run up to the November 2020 election, we identified 186 radio stations with predominantly Latinx or African American audiences; 50 randomly selected stations were assigned to a week-long advertising campaign each week for 3 weeks. Nonpartisan messages encouraged voter registration by stressing the importance of the election and featured celebrity voices. The number of new registrants rose slightly in treated areas during the week when the ads aired. No further gains were apparent one or 2 weeks later."
Joseph L. Sutherland,Three Essays on the Study of Nationalization with Automated Content Analysis,2020,https://search.proquest.com/openview/d944f549836a18ae60805249542b7ba8/1?pq-origsite=gscholar&cbl=18750&diss=y,"In three papers, I consider two questions of nationalization in American politics, and one question of the methodology necessary to study them."
Alexander Williams Tolbert,Reconciling Individual Probability Forecasts✱,2023,https://dl.acm.org/doi/abs/10.1145/3593013.3593980," Individual probabilities refer to the probabilities of outcomes that are realized only once: the probability that it will rain tomorrow, the probability that Alice will die within the next 12 months, the probability that Bob will be arrested for a violent crime in the next 18 months, etc. Individual probabilities are fundamentally unknowable. Nevertheless, we show that two parties who agree on the data—or on how to sample from a data distribution—cannot agree to disagree on how to model individual probabilities. This is because any two models of individual probabilities that substantially disagree can together be used to empirically falsify and improve at least one of the two models. This can be efficiently iterated in a process of “reconciliation” that results in models that both parties agree are superior to the models they started with, and which themselves (almost) agree on the forecasts of individual probabilities (almost …"
Alexander Williams Tolbert,Correcting underrepresentation and intersectional bias for fair classification,2023,https://openreview.net/forum?id=A9nAzFjNBF,"We consider the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered from the data at different, unknown rates for a fixed number of sensitive groups. We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out rates, even in settings where intersectional group membership makes learning each intersectional rate computationally infeasible. Using these estimates, we construct a reweighting scheme that allows us to approximate the loss of any hypothesis on the true distribution, even if we only observe the empirical error on a biased sample. From this, we present an algorithm encapsulating this learning and reweighting process along with a thorough empirical investigation. Finally, we define a bespoke notion of PAC learnability for the underrepresentation and intersectional bias setting and show that our algorithm …"
Alexander Williams Tolbert,Causal agnosticism about race: Variable selection problems in causal inference,2024,https://www.cambridge.org/core/journals/philosophy-of-science/article/causal-agnosticism-about-race-variable-selection-problems-in-causal-inference/EFF78D42C71F15B11C17EE043208A851,"This paper proposes a novel view in the the philosophy of race & causation literature known as “causal agnosticism” about race. Causal agnosticism about race implies that it is reasonable to refrain from making judgments about whether race is a cause. The paper’s thesis asserts that certain conditions must be met to infer that something is a cause, according to the fundamental assumptions of causal inference. However, in the case of race, these conditions are often violated. By advocating for causal agnosticism, the paper suggests a more modest approach to understanding the role of race in causal relationships."
Alexander Williams Tolbert,Restricted racial realism: Heterogeneous effects and the instability of race,2025,https://journals.sagepub.com/doi/abs/10.1177/00483931241299884,"This paper challenges the view that race is a reliable scientific variable or kind for the purpose of inductive inference within the social sciences. I characterize stability in terms of Extended Conditional Independence (ECI) and show that the heterogeneity and instability of racial categories across different background circumstances undermines their ability to support robust inductive inference and explanatory power. I claim this, in turn, undermines racial categories' status as real scientific variables or kinds. Race, has local stability within restricted sets of target systems and thus, its reality is limited to those domains. I argue for a restricted form of racial realism, a view I call Restricted Racial Realism (RRR)."
Alexander Williams Tolbert,Adaptive Algorithmic Interventions for Escaping Pessimism Traps in Dynamic Sequential Decisions,2024,https://arxiv.org/abs/2406.04462,"In this paper, we relate the philosophical literature on pessimism traps to information cascades, a formal model derived from the economics and mathematics literature. A pessimism trap is a social pattern in which individuals in a community, in situations of uncertainty, begin to copy the sub-optimal actions of others, despite their individual beliefs. This maps nicely onto the concept of an information cascade, which involves a sequence of agents making a decision between two alternatives, with a private signal of the superior alternative and a public history of others' actions. Key results from the economics literature show that information cascades occur with probability one in many contexts, and depending on the strength of the signal, populations can fall into the incorrect cascade very easily and quickly. Once formed, in the absence of external perturbation, a cascade cannot be broken -- therefore, we derive an intervention that can be used to nudge a population from an incorrect to a correct cascade and, importantly, maintain the cascade once the subsidy is discontinued. We study this both theoretically and empirically."
Alexander Williams Tolbert,Correcting Underrepresentation and Intersectional Bias for Classification,2023,https://arxiv.org/abs/2306.11112,"We consider the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered from the data at different, unknown rates for a fixed number of sensitive groups. We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out rates, even in settings where intersectional group membership makes learning each intersectional rate computationally infeasible. Using these estimates, we construct a reweighting scheme that allows us to approximate the loss of any hypothesis on the true distribution, even if we only observe the empirical error on a biased sample. From this, we present an algorithm encapsulating this learning and reweighting process along with a thorough empirical investigation. Finally, we define a bespoke notion of PAC learnability for the underrepresentation and intersectional bias setting and show that our algorithm permits efficient learning for model classes of finite VC dimension."
Alexander Williams Tolbert,Resolving the Reference Class Problem At Scale,2025,https://philsci-archive.pitt.edu/23589/,"We draw a distinction between the traditional reference class problem which describes an obstruction to estimating a single individual probability---which we re-term the individual reference class problem---and what we call the reference class problem at scale, which can result when using tools from statistics and machine learning to systematically make predictions about many individual probabilities simultaneously. We argue that scale actually helps to mitigate the reference class problem, and purely statistical tools can be used to efficiently minimize the reference class problem at scale, even though they cannot be used to solve the individual reference class problem."
Alexander Williams Tolbert,Causal Feature Learning in the Social Sciences,2025,https://arxiv.org/abs/2503.12784,"Variable selection poses a significant challenge in causal modeling, particularly within the social sciences, where constructs often rely on inter-related factors such as age, socioeconomic status, gender, and race. Indeed, it has been argued that such attributes must be modeled as macro-level abstractions of lower-level manipulable features, in order to preserve the modularity assumption essential to causal inference. This paper accordingly extends the theoretical framework of Causal Feature Learning (CFL). Empirically, we apply the CFL algorithm to diverse social science datasets, evaluating how CFL-derived macrostates compare with traditional microstates in downstream modeling tasks."
Alexander Williams Tolbert,BiasConnect: Investigating Bias Interactions in Text-to-Image Models,2025,https://arxiv.org/abs/2503.09763,"The biases exhibited by Text-to-Image (TTI) models are often treated as if they are independent, but in reality, they may be deeply interrelated. Addressing bias along one dimension, such as ethnicity or age, can inadvertently influence another dimension, like gender, either mitigating or exacerbating existing disparities. Understanding these interdependencies is crucial for designing fairer generative models, yet measuring such effects quantitatively remains a challenge. In this paper, we aim to address these questions by introducing BiasConnect, a novel tool designed to analyze and quantify bias interactions in TTI models. Our approach leverages a counterfactual-based framework to generate pairwise causal graphs that reveals the underlying structure of bias interactions for the given text prompt. Additionally, our method provides empirical estimates that indicate how other bias dimensions shift toward or away from an ideal distribution when a given bias is modified. Our estimates have a strong correlation (+0.69) with the interdependency observations post bias mitigation. We demonstrate the utility of BiasConnect for selecting optimal bias mitigation axes, comparing different TTI models on the dependencies they learn, and understanding the amplification of intersectional societal biases in TTI models."
Alexander Williams Tolbert,A Theoretical Model for Grit in Pursuing Ambitious Ends,2025,,
Alexander Williams Tolbert,Escaping the Subprime Trap in Algorithmic Lending,2025,https://arxiv.org/abs/2502.17816,"Disparities in lending to minority applicants persist even as algorithmic lending practices proliferate. Further, disparities in interest rates charged can remain large even when loan applicants from different groups are equally creditworthy. We study the role of risk-management constraints, specifically Value-at-Risk (VaR) constraints, in the persistence of segregation in loan approval decisions. We develop a formal model in which a mainstream (low-interest) bank is more sensitive to variance risk than a subprime (high-interest) bank. If the mainstream bank has an inflated prior belief about the variance of the minority group, it may deny that group credit indefinitely, thus never learning the true risk of lending to that group, while the subprime lender serves this population at higher rates. We formalize this as a ""subprime trap"" equilibrium. Finally, we show that a small, finite subsidy (or partial guarantee) can help minority groups escape the trap by covering enough of the mainstream bank's downside so that it can afford to lend and learn the minority group's true risk. Once it has sufficiently many data points, it meets its VaR requirement with no further assistance, minority groups are approved for loans by the mainstream bank, and competition drives down the interest rates of subprime lenders."
Alexander Williams Tolbert,Reconciling Predictive Multiplicity in Practice,2025,https://arxiv.org/abs/2501.16549,"Many machine learning applications predict individual probabilities, such as the likelihood that a person develops a particular illness. Since these probabilities are unknown, a key question is how to address situations in which different models trained on the same dataset produce varying predictions for certain individuals. This issue is exemplified by the model multiplicity (MM) phenomenon, where a set of comparable models yield inconsistent predictions. Roth, Tolbert, and Weinstein recently introduced a reconciliation procedure, the Reconcile algorithm, to address this problem. Given two disagreeing models, the algorithm leverages their disagreement to falsify and improve at least one of the models. In this paper, we empirically analyze the Reconcile algorithm using five widely-used fairness datasets: COMPAS, Communities and Crime, Adult, Statlog (German Credit Data), and the ACS Dataset. We examine how Reconcile fits within the model multiplicity literature and compare it to existing MM solutions, demonstrating its effectiveness. We also discuss potential improvements to the Reconcile algorithm theoretically and practically. Finally, we extend the Reconcile algorithm to the setting of causal inference, given that different competing estimators can again disagree on specific causal average treatment effect (CATE) values. We present the first extension of the Reconcile algorithm in causal inference, analyze its theoretical properties, and conduct empirical tests. Our results confirm the practical effectiveness of Reconcile and its applicability across various domains."
Ruoxuan Xiong,Preventing cytokine storm syndrome in COVID-19 using α-1 adrenergic receptor antagonists,2020,https://www.jci.org/articles/view/139642?ref=steve-kirsch-home-page,"Dysregulated host immune responses drive mortality in pneumonia and acute respiratory distress syndrome (ARDS) caused by a wide range of infections. In coronavirus disease 2019 (COVID-19), severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) elicits an exuberant local or systemic immune response (hyperinflammation) in the lung and other sites of viral replication, compromising organ function and leading to high morbidity and mortality (1–4)."
Ruoxuan Xiong,Stable prediction with model misspecification and agnostic distribution shift,2020,https://aaai.org/ojs/index.php/AAAI/article/view/5876,"For many machine learning algorithms, two main assumptions are required to guarantee performance. One is that the test data are drawn from the same distribution as the training data, and the other is that the model is correctly specified. In real applications, however, we often have little prior knowledge on the test data and on the underlying true model. Under model misspecification, agnostic distribution shift between training and test data leads to inaccuracy of parameter estimation and instability of prediction across unknown test data. To address these problems, we propose a novel Decorrelated Weighting Regression (DWR) algorithm which jointly optimizes a variable decorrelation regularizer and a weighted regression model. The variable decorrelation regularizer estimates a weight for each sample such that variables are decorrelated on the weighted training data. Then, these weights are used in the weighted regression to improve the accuracy of estimation on the effect of each variable, thus help to improve the stability of prediction across unknown test data. Extensive experiments clearly demonstrate that our DWR algorithm can significantly improve the accuracy of parameter estimation and stability of prediction with model misspecification and agnostic distribution shift."
Ruoxuan Xiong,Large dimensional latent factor modeling with missing observations and applications to causal inference,2022,https://www.sciencedirect.com/science/article/pii/S0304407622000914,"This paper develops the inferential theory for latent factor models estimated from large dimensional panel data with missing observations. We propose an easy-to-use all-purpose estimator for a latent factor model by applying principal component analysis to an adjusted covariance matrix estimated from partially observed panel data. We derive the asymptotic distribution for the estimated factors, loadings and the imputed values under an approximate factor model and general missing patterns. The key application is to estimate counterfactual outcomes in causal inference from panel data. The unobserved control group is modeled as missing values, which are inferred from the latent factor model. The inferential theory for the imputed values allows us to test for individual treatment effects at any time under general adoption patterns where the units can be affected by unobserved factors."
Ruoxuan Xiong,State-varying factor models of large dimensions,2022,https://www.tandfonline.com/doi/abs/10.1080/07350015.2021.1927744,"This article develops an inferential theory for state-varying factor models of large dimensions. Unlike constant factor models, loadings are general functions of some recurrent state process. We develop an estimator for the latent factors and state-varying loadings under a large cross-section and time dimension. Our estimator combines nonparametric methods with principal component analysis. We derive the rate of convergence and limiting normal distribution for the factors, loadings, and common components. In addition, we develop a statistical test for a change in the factor structure in different states. We apply the estimator to the U.S. Treasury yields and S&P500 stock returns. The systematic factor structure in treasury yields differs in times of booms and recessions as well as in periods of high market volatility. State-varying factors based on the VIX capture significantly more variation and pricing information in …"
Ruoxuan Xiong,Optimal experimental design for staggered rollouts,2024,https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2023.4928,"In this paper, we study the design and analysis of experiments conducted on a set of units over multiple time periods in which the starting time of the treatment may vary by unit. The design problem involves selecting an initial treatment time for each unit in order to most precisely estimate both the instantaneous and cumulative effects of the treatment. We first consider nonadaptive experiments, in which all treatment assignment decisions are made prior to the start of the experiment. For this case, we show that the optimization problem is generally NP-hard, and we propose a near-optimal solution. Under this solution, the fraction entering treatment each period is initially low, then high, and finally low again. Next, we study an adaptive experimental design problem, in which both the decision to continue the experiment and treatment assignment decisions are updated after each period’s data are collected. For the …"
Ruoxuan Xiong,Alpha-1 adrenergic receptor antagonists to prevent hyperinflammation and death from lower respiratory tract infection,2021,https://elifesciences.org/articles/61700,"In severe viral pneumonia, including Coronavirus disease 2019 (COVID-19), the viral replication phase is often followed by hyperinflammation, which can lead to acute respiratory distress syndrome, multi-organ failure, and death. We previously demonstrated that alpha-1 adrenergic receptor (⍺1-AR) antagonists can prevent hyperinflammation and death in mice. Here, we conducted retrospective analyses in two cohorts of patients with acute respiratory distress (ARD, n = 18,547) and three cohorts with pneumonia (n = 400,907). Federated across two ARD cohorts, we find that patients exposed to ⍺1-AR antagonists, as compared to unexposed patients, had a 34% relative risk reduction for mechanical ventilation and death (OR = 0.70, p = 0.021). We replicated these methods on three pneumonia cohorts, all with similar effects on both outcomes. All results were robust to sensitivity analyses. These results highlight the urgent need for prospective trials testing whether prophylactic use of ⍺1-AR antagonists ameliorates lower respiratory tract infection-associated hyperinflammation and death, as observed in COVID-19."
Ruoxuan Xiong,Federated causal inference in heterogeneous observational data,2023,https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9868,"We are interested in estimating the effect of a treatment applied to individuals at multiple sites, where data is stored locally for each site. Due to privacy constraints, individual‐level data cannot be shared across sites; the sites may also have heterogeneous populations and treatment assignment mechanisms. Motivated by these considerations, we develop federated methods to draw inferences on the average treatment effects of combined data across sites. Our methods first compute summary statistics locally using propensity scores and then aggregate these statistics across sites to obtain point and variance estimators of average treatment effects. We show that these estimators are consistent and asymptotically normal. To achieve these asymptotic properties, we find that the aggregation schemes need to account for the heterogeneity in treatment assignments and in outcomes across sites. We demonstrate the …"
Ruoxuan Xiong,The association between alpha-1 adrenergic receptor antagonists and in-hospital mortality from COVID-19,2021,https://www.frontiersin.org/articles/10.3389/fmed.2021.637647/full,"Effective therapies for coronavirus disease 2019 (COVID-19) are urgently needed, and pre-clinical data suggest alpha-1 adrenergic receptor antagonists (α1-AR antagonists) may be effective in reducing mortality related to hyperinflammation independent of etiology. Using a retrospective cohort design with patients in the Department of Veterans Affairs healthcare system, we use doubly robust regression and matching to estimate the association between baseline use of α1-AR antagonists and likelihood of death due to COVID-19 during hospitalization. Having an active prescription for any α1-AR antagonist (tamsulosin, silodosin, prazosin, terazosin, doxazosin, or alfuzosin) at the time of admission had a significant negative association with in-hospital mortality (relative risk reduction 18%; odds ratio 0.73; 95% CI 0.63–0.85; p ≤ 0.001) and death within 28 days of admission (relative risk reduction 17%; odds ratio 0.74; 95% CI 0.65–0.84; p ≤ 0.001). In a subset of patients on doxazosin specifically, an inhibitor of all three alpha-1 adrenergic receptors, we observed a relative risk reduction for death of 74% (odds ratio 0.23; 95% CI 0.03–0.94; p = 0.028) compared to matched controls not on any α1-AR antagonist at the time of admission. These findings suggest that use of α1-AR antagonists may reduce mortality in COVID-19, supporting the need for randomized, placebo-controlled clinical trials in patients with early symptomatic infection."
Ruoxuan Xiong,Interpretable sparse proximate factors for large dimensions,2022,https://www.tandfonline.com/doi/abs/10.1080/07350015.2021.1961786,"This article proposes sparse and easy-to-interpret proximate factors to approximate statistical latent factors. Latent factors in a large-dimensional factor model can be estimated by principal component analysis (PCA), but are usually hard to interpret. We obtain proximate factors that are easier to interpret by shrinking the PCA factor weights and setting them to zero except for the largest absolute ones. We show that proximate factors constructed with only 5%–10% of the data are usually sufficient to almost perfectly replicate the population and PCA factors without actually assuming a sparse structure in the weights or loadings. Using extreme value theory we explain why sparse proximate factors can be substitutes for non-sparse PCA factors. We derive analytical asymptotic bounds for the correlation of appropriately rotated proximate factors with the population factors. These bounds provide guidance on how to …"
Ruoxuan Xiong,Semiparametric Estimation of Treatment Effects in Observational Studies with Heterogeneous Partial Interference,2021,https://arxiv.org/abs/2107.12420,"In many observational studies in social science and medicine, subjects or units are connected, and one unit's treatment and attributes may affect another's treatment and outcome, violating the stable unit treatment value assumption (SUTVA) and resulting in interference. To enable feasible estimation and inference, many previous works assume exchangeability of interfering units (neighbors). However, in many applications with distinctive units, interference is heterogeneous and needs to be modeled explicitly. In this paper, we focus on the partial interference setting, and only restrict units to be exchangeable conditional on observable characteristics. Under this framework, we propose generalized augmented inverse propensity weighted (AIPW) estimators for general causal estimands that include heterogeneous direct and spillover effects. We show that they are semiparametric efficient and robust to heterogeneous interference as well as model misspecifications. We apply our methods to the Add Health dataset to study the direct effects of alcohol consumption on academic performance and the spillover effects of parental incarceration on adolescent well-being."
Ruoxuan Xiong,Data-Driven Switchback Experiments: Theoretical Tradeoffs and Empirical Bayes Designs,2024,https://arxiv.org/abs/2406.06768,"We study the design and analysis of switchback experiments conducted on a single aggregate unit. The design problem is to partition the continuous time space into intervals and switch treatments between intervals, in order to minimize the estimation error of the treatment effect. We show that the estimation error depends on four factors: carryover effects, periodicity, serially correlated outcomes, and impacts from simultaneous experiments. We derive a rigorous bias-variance decomposition and show the tradeoffs of the estimation error from these factors. The decomposition provides three new insights in choosing a design: First, balancing the periodicity between treated and control intervals reduces the variance; second, switching less frequently reduces the bias from carryover effects while increasing the variance from correlated outcomes, and vice versa; third, randomizing interval start and end points reduces both bias and variance from simultaneous experiments. Combining these insights, we propose a new empirical Bayes design approach. This approach uses prior data and experiments for designing future experiments. We illustrate this approach using real data from a ride-sharing platform, yielding a design that reduces MSE by 33% compared to the status quo design used on the platform."
Ruoxuan Xiong,Stable estimation of heterogeneous treatment effects,2023,https://proceedings.mlr.press/v202/wu23i.html,"Estimating heterogeneous treatment effects (HTE) is crucial for identifying the variation of treatment effects across individuals or subgroups. Most existing methods estimate HTE by removing the confounding bias from imbalanced treatment assignments. However, these methods may produce unreliable estimates of treatment effects and potentially allocate suboptimal treatment arms for underrepresented populations. To improve the estimation accuracy of HTE for underrepresented populations, we propose a novel Stable CounterFactual Regression (StableCFR) to smooth the population distribution and upsample the underrepresented subpopulations, while balancing confounders between treatment and control groups. Specifically, StableCFR upsamples the underrepresented data using uniform sampling, where each disjoint subpopulation is weighted proportional to the Lebesgue measure of its support. Moreover, StableCFR balances covariates by using an epsilon-greedy matching approach. Empirical results on both synthetic and real-world datasets demonstrate the superior performance of our StableCFR on estimating HTE for underrepresented populations."
Ruoxuan Xiong,Target PCA: Transfer learning large dimensional panel data,2024,https://www.sciencedirect.com/science/article/pii/S0304407623002373,"This paper develops a novel method to estimate a latent factor model for a large target panel with missing observations by optimally using the information from auxiliary panel data sets. We refer to our estimator as target-PCA. Transfer learning from auxiliary panel data allows us to deal with a large fraction of missing observations and weak signals in the target panel. We show that our estimator is more efficient and can consistently estimate weak factors, which are not identifiable with conventional methods. We provide the asymptotic inferential theory for target-PCA under very general assumptions on the approximate factor model and missing patterns. In an empirical study of imputing data in a mixed-frequency macroeconomic panel, we demonstrate that target-PCA significantly outperforms all benchmark methods."
Ruoxuan Xiong,Learning instrumental variable from data fusion for treatment effect estimation,2023,https://ojs.aaai.org/index.php/AAAI/article/view/26229,"The advent of the big data era brought new opportunities and challenges to draw treatment effect in data fusion, that is, a mixed dataset collected from multiple sources (each source with an independent treatment assignment mechanism). Due to possibly omitted source labels and unmeasured confounders, traditional methods cannot estimate individual treatment assignment probability and infer treatment effect effectively. Therefore, we propose to reconstruct the source label and model it as a Group Instrumental Variable (GIV) to implement IV-based Regression for treatment effect estimation. In this paper, we conceptualize this line of thought and develop a unified framework (Meta-EM) to (1) map the raw data into a representation space to construct Linear Mixed Models for the assigned treatment variable;(2) estimate the distribution differences and model the GIV for the different treatment assignment mechanisms; and (3) adopt an alternating training strategy to iteratively optimize the representations and the joint distribution to model GIV for IV regression. Empirical results demonstrate the advantages of our Meta-EM compared with state-of-the-art methods. The project page with the code and the Supplementary materials is available at https://github. com/causal-machine-learning-lab/meta-em."
Ruoxuan Xiong,Instrumental variables in causal inference and machine learning: A survey,2022,https://arxiv.org/abs/2212.05778,"Causal inference is the process of using assumptions, study designs, and estimation strategies to draw conclusions about the causal relationships between variables based on data. This allows researchers to better understand the underlying mechanisms at work in complex systems and make more informed decisions. In many settings, we may not fully observe all the confounders that affect both the treatment and outcome variables, complicating the estimation of causal effects. To address this problem, a growing literature in both causal inference and machine learning proposes to use Instrumental Variables (IV). This paper serves as the first effort to systematically and comprehensively introduce and discuss the IV methods and their applications in both causal inference and machine learning. First, we provide the formal definition of IVs and discuss the identification problem of IV regression methods under different assumptions. Second, we categorize the existing work on IV methods into three streams according to the focus on the proposed methods, including two-stage least squares with IVs, control function with IVs, and evaluation of IVs. For each stream, we present both the classical causal inference methods, and recent developments in the machine learning literature. Then, we introduce a variety of applications of IV methods in real-world scenarios and provide a summary of the available datasets and algorithms. Finally, we summarize the literature, discuss the open problems and suggest promising future research directions for IV methods and their applications. We also develop a toolkit of IVs methods reviewed in this survey at https://github …"
Ruoxuan Xiong,Learning individual treatment effects under heterogeneous interference in networks,2024,https://dl.acm.org/doi/abs/10.1145/3673761,"Estimating individual treatment effects in networked observational data is a crucial and increasingly recognized problem. One major challenge of this problem is violating the stable unit treatment value assumption (SUTVA), which posits that a unit’s outcome is independent of others’ treatment assignments. However, in network data, a unit’s outcome is influenced not only by its treatment (i.e., direct effect) but also by the treatments of others (i.e., spillover effect) since the presence of interference. Moreover, the interference from other units is always heterogeneous (e.g., friends with similar interests have a different influence than those with different interests). In this article, we focus on the problem of estimating individual treatment effects (including direct effect and spillover effect) under heterogeneous interference in networks. To address this problem, we propose a novel dual weighting regression (DWR) algorithm by …"
Ruoxuan Xiong,Instrumental variable-driven domain generalization with unobserved confounders,2023,https://dl.acm.org/doi/abs/10.1145/3595380,"Domain generalization (DG) aims to learn from multiple source domains a model that can generalize well on unseen target domains. Existing DG methods mainly learn the representations with invariant marginal distribution of the input features, however, the invariance of the conditional distribution of the labels given the input features is more essential for unknown domain prediction. Meanwhile, the existing of unobserved confounders which affect the input features and labels simultaneously cause spurious correlation and hinder the learning of the invariant relationship contained in the conditional distribution. Interestingly, with a causal view on the data generating process, we find that the input features of one domain are valid instrumental variables for other domains. Inspired by this finding, we propose an instrumental variable-driven DG method (IV-DG) by removing the bias of the unobserved confounders with …"
Ruoxuan Xiong,Ten rules for conducting retrospective pharmacoepidemiological analyses: Example COVID-19 study,2021,https://www.frontiersin.org/articles/10.3389/fphar.2021.700776/full,"Since the beginning of the COVID-19 pandemic, pharmaceutical treatment hypotheses have abounded, each requiring careful evaluation. A randomized controlled trial generally provides the most credible evaluation of a treatment, but the efficiency and effectiveness of the trial depend on the existing evidence supporting the treatment. The researcher must therefore compile a body of evidence justifying the use of time and resources to further investigate a treatment hypothesis in a trial. An observational study can provide this evidence, but the lack of randomized exposure and the researcher’s inability to control treatment administration and data collection introduce significant challenges. A proper analysis of observational health care data thus requires contributions from experts in a diverse set of topics ranging from epidemiology and causal analysis to relevant medical specialties and data sources. Here we summarize these contributions as 10 rules that serve as an end-to-end introduction to retrospective pharmacoepidemiological analyses of observational health care data using a running example of a hypothetical COVID-19 study. A detailed supplement presents a practical how-to guide for following each rule. When carefully designed and properly executed, a retrospective pharmacoepidemiological analysis framed around these rules will inform the decisions of whether and how to investigate a treatment hypothesis in a randomized controlled trial. This work has important implications for any future pandemic by prescribing what we can and should do while the world waits for global vaccine distribution."
Ruoxuan Xiong,Contrastive balancing representation learning for heterogeneous dose-response curves estimation,2024,https://ojs.aaai.org/index.php/AAAI/article/view/29663,"Estimating the individuals' potential response to varying treatment doses is crucial for decision-making in areas such as precision medicine and management science. Most recent studies predict counterfactual outcomes by learning a covariate representation that is independent of the treatment variable. However, such independence constraints neglect much of the covariate information that is useful for counterfactual prediction, especially when the treatment variables are continuous. To tackle the above issue, in this paper, we first theoretically demonstrate the importance of the balancing and prognostic representations for unbiased estimation of the heterogeneous dose-response curves, that is, the learned representations are constrained to satisfy the conditional independence between the covariates and both of the treatment variables and the potential responses. Based on this, we propose a novel Contrastive balancing Representation learning Network using a partial distance measure, called CRNet, for estimating the heterogeneous dose-response curves without losing the continuity of treatments. Extensive experiments are conducted on synthetic and real-world datasets demonstrating that our proposal significantly outperforms previous methods."
Ruoxuan Xiong,Learning shadow variable representation for treatment effect estimation under collider bias,2024,https://openreview.net/forum?id=ycXo4tQIpN,"One of the significant challenges in treatment effect estimation is collider bias, a specific form of sample selection bias induced by the common causes of both the treatment and outcome. Identifying treatment effects under collider bias requires well-defined shadow variables in observational data, which are assumed to be related to the outcome and independent of the sample selection mechanism, conditional on the other observed variables. However, finding a valid shadow variable is not an easy task in real-world scenarios and requires domain-specific knowledge from experts. Therefore, in this paper, we propose a novel method that can automatically learn shadow-variable representations from observational data without prior knowledge. To ensure the learned representations satisfy the assumptions of the shadow variable, we introduce a tester to perform hypothesis testing in the representation learning process. We iteratively generate representations and test whether they satisfy the shadow-variable assumptions until they pass the test. With the help of the learned shadow-variable representations, we propose a novel treatment effect estimator to address collider bias. Experiments show that the proposed methods outperform existing treatment effect estimation methods under collider bias and prove their potential application value."
Ruoxuan Xiong,Two-stage shadow inclusion estimation: an IV approach for causal inference under latent confounding and collider bias,2024,https://openreview.net/forum?id=YRWdiaupCr,"Latent confounding bias and collider bias are two key challenges of causal inference in observational studies. Latent confounding bias occurs when failing to control the unmeasured covariates that are common causes of treatments and outcomes, which can be addressed by using the Instrumental Variable (IV) approach. Collider bias comes from non-random sample selection caused by both treatments and outcomes, which can be addressed by using a different type of instruments, i.e., shadow variables. However, in most scenarios, these two biases simultaneously exist in observational data, and the previous methods focusing on either one are inadequate. To the best of our knowledge, no approach has been developed for causal inference when both biases exist. In this paper, we propose a novel IV approach, Two-Stage Shadow Inclusion (2SSI), which can simultaneously address latent confounding bias and collider bias by utilizing the residual of the treatment as a shadow variable. Extensive experimental results on benchmark synthetic datasets and a real-world dataset show that 2SSI achieves noticeable performance improvement when both biases exist compared to existing methods."
Ruoxuan Xiong,Higher-order causal message passing for experimentation with complex interference,2024,https://proceedings.neurips.cc/paper_files/paper/2024/hash/94f008bcc2a5eb785fb8e0ad7aedd4fc-Abstract-Conference.html,"Accurate estimation of treatment effects is essential for decision-making across various scientific fields. This task, however, becomes challenging in areas like social sciences and online marketplaces, where treating one experimental unit can influence outcomes for others through direct or indirect interactions. Such interference can lead to biased treatment effect estimates, particularly when the structure of these interactions is unknown. We address this challenge by introducing a new class of estimators based on causal message-passing, specifically designed for settings with pervasive, unknown interference. Our estimator draws on information from the sample mean and variance of unit outcomes and treatments over time, enabling efficient use of observed data to estimate the evolution of the system state. Concretely, we construct non-linear features from the moments of unit outcomes and treatments and then learn a function that maps these features to future mean and variance of unit outcomes. This allows for the estimation of the treatment effect over time. Extensive simulations across multiple domains, using synthetic and real network data, demonstrate the efficacy of our approach in estimating total treatment effect dynamics, even in cases where interference exhibits non-monotonic behavior in the probability of treatment."
Ruoxuan Xiong,Causal Inference with Complex Treatments: A Survey,2024,https://arxiv.org/abs/2407.14022,"Causal inference plays an important role in explanatory analysis and decision making across various fields like statistics, marketing, health care, and education. Its main task is to estimate treatment effects and make intervention policies. Traditionally, most of the previous works typically focus on the binary treatment setting that there is only one treatment for a unit to adopt or not. However, in practice, the treatment can be much more complex, encompassing multi-valued, continuous, or bundle options. In this paper, we refer to these as complex treatments and systematically and comprehensively review the causal inference methods for addressing them. First, we formally revisit the problem definition, the basic assumptions, and their possible variations under specific conditions. Second, we sequentially review the related methods for multi-valued, continuous, and bundled treatment settings. In each situation, we tentatively divide the methods into two categories: those conforming to the unconfoundedness assumption and those violating it. Subsequently, we discuss the available datasets and open-source codes. Finally, we provide a brief summary of these works and suggest potential directions for future research."
Ruoxuan Xiong,Factor Analysis for Causal Inference on Large Non-Stationary Panels with Endogenous Treatment,2024,https://www.researchgate.net/profile/Markus-Pelger/publication/381331075_Factor_Analysis_for_Causal_Inference_on_Large_Non-Stationary_Panels_with_Endogenous_Treatment/links/66dddf32b1606e24c216dc87/Factor-Analysis-for-Causal-Inference-on-Large-Non-Stationary-Panels-with-Endogenous-Treatment.pdf,"This paper studies the imputation and inference for large-dimensional non-stationary panel data with general missing observations. Our novel method, Within-Transform-PCA (wi-PCA), transforms the data under endogenous missingness to remove non-stationarities and heterogeneous mean effects before estimating an approximate latent factor structure with PCA. This within-transformation is equivalent to estimating two-way non-stationary fixed effects separately from the latent factor structure. Our approach allows for one of the most general and broadly applicable models for data generation and missing patterns in the factor modeling literature. We provide entry-wise inferential theory for the values imputed with wi-PCA. The key application of wi-PCA is the estimation of counterfactuals on causal panels, where we allow for two-way endogenous treatment effects, time trends and general latent confounders. In an empirical study of the liberalization of marijuana, we show that wi-PCA yields more accurate estimates of treatment effects and more credible economic conclusions compared to its two special cases of conventional difference-in-differences and PCA."
Ruoxuan Xiong,Automated Experimental Design with Optimization from Historical Data Simulations,2025,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5126080,"We study the problem of designing randomized experiments to estimate the causal effects of new interventions. The design problem involves selecting a treatment assignment mechanism, including assignment probabilities, in order to optimize a user-defined objective (eg, maximizing the precision of a causal-effect estimator). A key challenge is that the objective is typically a black-box function of the design, depending on unknown outcome-generating processes and causal effects. To tackle this challenge, we propose a novel automated experimental design (Auto-EXD) approach. Auto-EXD evaluates the objective value of a candidate design by simulating experiments based on stationary historical control data and prior distributions of causal effects. Then a gradient-free method is used to iteratively optimize the design. We rigorously analyze the convergence behavior of Auto-EXD and show how it depends on temporal and cross-unit correlations in historical data as well as on implementation specifics. In synthetic experiments on three application domains-digital platforms, health, and energy-Auto-EXD can reduce the estimation error of treatment effects by up to 25% compared to the state-of-the-art benchmark designs. Our results reveal new insights into improving design efficiency. In particular, for multi-unit crossover experiments with multiple interventions, we find that efficiency is improved by sequentially rolling out (a) the same intervention across units and (b) different interventions on the same unit."
Ruoxuan Xiong,Can We Validate Counterfactual Estimations in the Presence of General Network Interference?,2025,https://arxiv.org/abs/2502.01106,"In experimental settings with network interference, a unit's treatment can influence outcomes of other units, challenging both causal effect estimation and its validation. Classic validation approaches fail as outcomes are only observable under one treatment scenario and exhibit complex correlation patterns due to interference. To address these challenges, we introduce a new framework enabling cross-validation for counterfactual estimation. At its core is our distribution-preserving network bootstrap method -- a theoretically-grounded approach inspired by approximate message passing. This method creates multiple subpopulations while preserving the underlying distribution of network effects. We extend recent causal message-passing developments by incorporating heterogeneous unit-level characteristics and varying local interactions, ensuring reliable finite-sample performance through non-asymptotic analysis. We also develop and publicly release a comprehensive benchmark toolbox with diverse experimental environments, from networks of interacting AI agents to opinion formation in real-world communities and ride-sharing applications. These environments provide known ground truth values while maintaining realistic complexities, enabling systematic examination of causal inference methods. Extensive evaluation across these environments demonstrates our method's robustness to diverse forms of network interference. Our work provides researchers with both a practical estimation framework and a standardized platform for testing future methodological developments."
Ruoxuan Xiong,Essays on Statistical Learning and Causal Inference on Panel Data,2020,https://search.proquest.com/openview/e91842e452e4600f4ce97bebe8996d68/1?pq-origsite=gscholar&cbl=44156,"Panel data that provides multiple observations on each individual over time has become widely available and received growing interests in many domains. For example, in asset pricing, panel data on asset returns over time is central in the study of how financial assets, such as stocks, bonds, and futures, are priced. In public policy, panel data is valuable in estimating and analyzing economic and social policies' effects. Panel data can improve the power of analyses, uncover dynamic relationships of variables, and generate more accurate predictions for individual outcomes."
